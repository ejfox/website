---
tags: climatechange
kindle-sync:
  bookId: '22075'
  title: 'Overshoot: The Ecological Basis of Revolutionary Change'
  author: William R. Catton
  asin: B00VVH4UGG
  lastAnnotatedDate: '2023-03-07'
  bookImageUrl: 'https://m.media-amazon.com/images/I/51geicggF5L._SY160.jpg'
  highlightsCount: 4
---
# Overshoot
## Metadata
* Author: [William R. Catton](https://www.amazon.comundefined)
* ASIN: B00VVH4UGG
* ISBN: 0252009886
* Reference: https://www.amazon.com/dp/B00VVH4UGG
* [Kindle link](kindle://book?action=open&asin=B00VVH4UGG)

## Highlights
Today mankind is locked into stealing ravenously from the future. — location: [233](kindle://book?action=open&asin=B00VVH4UGG&location=233) ^ref-8368

---
Man has recognized the many-faceted interdependence of diverse organisms, their impact upon their habitat, their impermanence, and their inability to foresee and evade the processes leading to their own displacement by successors. — location: [298](kindle://book?action=open&asin=B00VVH4UGG&location=298) ^ref-45341

---
The paramount need of post-exuberant humanity is to remain human in the face of dehumanizing pressures. To do this we must learn somehow to base exuberance of spirit upon something more lasting than the expansive living that sustained it in the recent past. But, as if we were driving a car that has become stuck on a muddy road, we feel an urge to bear down harder than ever on the accelerator and to spin our wheels vigorously in an effort to power ourselves out of the quagmire. This reflex will only dig us in deeper. — location: [307](kindle://book?action=open&asin=B00VVH4UGG&location=307) ^ref-27356

---
Let us begin with the fact that all the many forms of life on this planet have the same ultimate chemical basis. In many and varied ways, their life processes are also interdependent. Each form (including man) takes certain substances from its environment and puts certain substances into its environment; these affect other organisms. The influences of various species upon each other are often intricate, indirect, and subtle. — location: [1988](kindle://book?action=open&asin=B00VVH4UGG&location=1988) ^ref-19726

---
---
kindle-sync:
  bookId: '37234'
  title: 'Reamde: A Novel'
  author: Neal Stephenson
  asin: B004XVN0WW
  lastAnnotatedDate: '2019-03-31'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71VM4oRxfFL._SY160.jpg'
  highlightsCount: 1
date: 2022-12-26T11:48:12-05:00
modified: 2022-12-27T15:13:29-05:00
---
# Reamde

#fiction 

# Metadata

* Author: [Neal Stephenson](https://www.amazon.com/Neal-Stephenson/e/B000APS8L8/ref=dp_byline_cont_ebooks_1)

* ASIN: B004XVN0WW

* ISBN: 0061977969

* Reference: <https://www.amazon.com/dp/B004XVN0WW>

* [Kindle link](kindle://book?action=open&asin=B004XVN0WW)

# Highlights

The young woman had turned toward him and thrust her pink gloves up in the air in a gesture that, from a man, meant “Touchdown!” and, from a woman, “I will hug you now!” — location: [140](kindle://book?action=open&asin=B004XVN0WW&location=140) ^ref-41393

---
---
dek: In which the author is fascinated by America’s multitudes
type: words
hidden: true
inprogress: true
date: 2019-06-13T04:00:39-04:00
hidetimestamp: true
modified: 2024-05-07T17:19:23-04:00
---

## America

America is so vast that there is almost too much to say about it. It spans mind-boggling distances not only geographically but also politically, culturally, and spiritually.

The fact that these diverse corners of our spinning planet are bound together into one single united (forgive me) nation defies all odds. But oh boy does it feel comfortable as hell. I can read all the signs and we have a very nice interstate highway system.

I have always found myself grateful when looking at a map of the world. Other countries are the size of our states. Some of them landlocked! Others aberrations; clearly sliced from larger countries in wars I would never be taught. Almost none of them are as large as the one I was born into. I wonder what their road trips must be like.

Sometimes when I’m doing a long drive, I picture showing my passport and submitting to inspections every time I cross a state line. (I’ve only ever encountered highway checkpoints in Arizona and Washington, but that seemed more like bad luck than any sort of far-reaching policy)

The fact [you can go](https://en.wikipedia.org/wiki/Interstate_80) from the Atlantic Ocean all the way to the Pacific without leaving the country or ever having to eat anything but McDonalds is another blessing. I don't even like McDonalds that much.

You find yourself very proud of American ingenuity when you see a brightly-lit, open McDonalds in the desert at 3AM two thirds through a cross country trip.

We have found some very specific things to become extraordinarily good at as a nation.

Fast cars, delicious food, large guns, hot (blonde) women. We invented a nebulous term, a vaporous aspiration we call "The American Dream" which in fact just means whatever dream you find in your head in any particular moment.

If your dream involves destroying something (yourself?) in some way, all the better. You worked hard today, didn't you? (Doesn’t matter, in hard times relax from the inter-generational labor of your ancestors or whatever.)

Despite an obsession in equal parts with working hard and relaxing hard, which seems healthy to me, America has torn itself into knots culturally.

I keep wondering what can still unify us.

The powers that be seem to have fracked out every possible wedge that could be driven. Optimized by demographic groups and personal interests and TV preferences. Here we are, splintered, yelling at each other online (it does feel good if you’re in the right mood).

Can you imagine people used to ask their neighbors for sugar?

---

On May 1st in New York City in 2017 I found a group of Trump supporters surrounded by police, yelling insults and joking chants at the much larger crowd passing, assembled to celebrate [May Day](https://en.wikipedia.org/wiki/International_Workers%27_Day) or International Workers’ Day (celebrated by socialists, communists, and all stripes of leftists).

The vulgar teenagers I encountered waved around a variety of flags and signs with symbols that referenced Trump and very online alt-right 4chan memes in equal measure. One was a green [flag for “kekistan”](https://www.bustle.com/p/what-is-the-kekistan-flag-heres-whats-behind-that-obscure-alt-lite-banner-2367689) a meme-joke-fictional country. The flag’s design modeled on a 1930s Nazi war flag^[<<https://en.wikipedia.org/wiki/Reichskriegsflagge#/media/File:War_Ensign_of_Germany_(1935-1938\)>.svg>], a wink to very-online wannabe fascists in the know.

They were all young men, some white, a few latino, a few with yarmulkes on their heads. They laughed with glee as they shouted meta self-referential memes.

Most wore bright red hats with white lettering on the front. Some had camelbaks with enormous rubbery straws hanging off their shoulders, optimizing the process through which they could wet their mouths and yell profanities with as little downtime as possible.

They stood on that street corner yelling things that were mostly meaningless to the people they were yelling at.

They were caught in a self-referential möbius strip; baffled and overjoyed when people occasionally got provoked and came over to yell back (usually equally incomprehensible things). The police halfheartedly shooed their would-be opponents away, telling them to get back to the sidewalk across the street, away from the red hat assemblage surrounded by the metal fencing surrounded by New York’s finest.

They kept thanking the police who were around to protect them. They seemed to be guessing that the cops were fellow Trump supporters. They gave off a a vibe they thought they were saying the things the cops were thinking but weren't allowed to say.

It seemed to me like they loved the fight as much – if not more than – the ideals they were fighting for.

As I watched New Yorkers scream at each other, I wondered what could possibly make this situation better. There aren’t even any shared heroes left, I don’t think- that all Americans respect anymore. Mr. Rogers is gone.

Maybe Dwayne “The Rock” Johnson. Or Keanu Reeves. Others have suggested Joe Rogan, Judge Judy, and Oprah. None of these seem like the silver bullet I’m really looking for.

Maybe if Bernie Sanders would star in some Fast & Furious movies we could get somewhere.
---
kindle-sync:
  bookId: '11969'
  title: 'Futureproof: 9 Rules for Humans in the Age of Automation'
  author: Kevin Roose
  asin: B07ZN3TDWH
  lastAnnotatedDate: '2022-10-21'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71ZsRekqAeL._SY160.jpg'
  highlightsCount: 3
date: 2022-12-14T15:23:12-05:00
modified: 2022-12-23T11:06:45-05:00
---
# Futureproof

#tech #culture 

# Metadata

* Author: [Kevin Roose](https://www.amazon.com/Kevin-Roose/e/B001JSEG66/ref=dp_byline_cont_ebooks_1)

* ASIN: B07ZN3TDWH

* ISBN: B09L5LDHHP

* Reference: <https://www.amazon.com/dp/B07ZN3TDWH>

* [Kindle link](kindle://book?action=open&asin=B07ZN3TDWH)

# Highlights

badly designed AI can harm vulnerable and marginalized groups even when it “works,” by subjecting them to new forms of data-gathering and surveillance and encoding historical patterns of discrimination into automated systems. — location: [243](kindle://book?action=open&asin=B07ZN3TDWH&location=243) ^ref-31475

---

Paul R. Daugherty and H. James Wilson, two executives at the consulting firm Accenture, write in their book Human + Machine that human-AI collaborations will be a cornerstone of the twenty-first-century economy. “AI systems are not wholesale replacing us,” they write. “Rather, they are amplifying our skills and collaborating with us to achieve productivity gains that have previously not been possible.” — location: [398](kindle://book?action=open&asin=B07ZN3TDWH&location=398) ^ref-7964

---

Accenture, the consulting firm, surveyed one thousand large corporations in 2018 and found that AI-related jobs were being created in three categories, which they called “trainers, explainers, and sustainers.” These are the people who help guide and oversee machines, explain the decisions made by algorithms to other humans, and do the messy work of integrating AI into corporate IT departments. — location: [540](kindle://book?action=open&asin=B07ZN3TDWH&location=540) ^ref-38695

---
---
kindle-sync:
  bookId: '16297'
  title: 'Futureproof: 9 Rules for Surviving in the Age of AI'
  author: Kevin Roose
  asin: B07ZN3TDWH
  lastAnnotatedDate: '2022-10-21'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71auiVlh-OL._SY160.jpg'
  highlightsCount: 3
---
# Futureproof
## Metadata
* Author: [Kevin Roose](https://www.amazon.comundefined)
* ASIN: B07ZN3TDWH
* ISBN: 1529304733
* Reference: https://www.amazon.com/dp/B07ZN3TDWH
* [Kindle link](kindle://book?action=open&asin=B07ZN3TDWH)

## Highlights
badly designed AI can harm vulnerable and marginalized groups even when it “works,” by subjecting them to new forms of data-gathering and surveillance and encoding historical patterns of discrimination into automated systems. — location: [243](kindle://book?action=open&asin=B07ZN3TDWH&location=243) ^ref-31475

---
Paul R. Daugherty and H. James Wilson, two executives at the consulting firm Accenture, write in their book Human + Machine that human-AI collaborations will be a cornerstone of the twenty-first-century economy. “AI systems are not wholesale replacing us,” they write. “Rather, they are amplifying our skills and collaborating with us to achieve productivity gains that have previously not been possible.” — location: [398](kindle://book?action=open&asin=B07ZN3TDWH&location=398) ^ref-7964

---
Accenture, the consulting firm, surveyed one thousand large corporations in 2018 and found that AI-related jobs were being created in three categories, which they called “trainers, explainers, and sustainers.” These are the people who help guide and oversee machines, explain the decisions made by algorithms to other humans, and do the messy work of integrating AI into corporate IT departments. — location: [540](kindle://book?action=open&asin=B07ZN3TDWH&location=540) ^ref-38695

---
---
tags: fiction
kindle-sync:
  bookId: '29974'
  title: 'Mastermind: How to Think Like Sherlock Holmes'
  author: Maria Konnikova
  asin: B008EKOSXS
  lastAnnotatedDate: '2022-12-06'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71RyhJW-UwL._SY160.jpg'
  highlightsCount: 3
---
# Mastermind
## Metadata
* Author: [Maria Konnikova](https://www.amazon.com/Maria-Konnikova/e/B008ESXWU0/ref=dp_byline_cont_ebooks_1)
* ASIN: B008EKOSXS
* ISBN: 1782111743
* Reference: https://www.amazon.com/dp/B008EKOSXS
* [Kindle link](kindle://book?action=open&asin=B008EKOSXS)

## Highlights
Method of Thought? — location: [291](kindle://book?action=open&asin=B008EKOSXS&location=291) ^ref-54750

---
We can’t actually be aware unless we pay attention. No exceptions. Yes, awareness may require only minimal attention, but it does require some attention. Nothing happens quite automatically. We can’t be aware of something if we don’t attend to it. — location: [1211](kindle://book?action=open&asin=B008EKOSXS&location=1211) ^ref-9526

---
Write a checklist of steps to follow when making a diagnosis of a problem, be it a sick patient, a broken car, writer’s block, or whatever it is you face in your daily life, instead of trying to do it by so-called instinct. Checklists, formulas, structured procedures: those are your best bet—at least, according to Kahneman. — location: [1230](kindle://book?action=open&asin=B008EKOSXS&location=1230) ^ref-48942

---
---
kindle-sync:
  bookId: '2199'
  title: 'Exhalation: Stories'
  author: Ted Chiang
  asin: B07GD46PQZ
  lastAnnotatedDate: '2022-10-21'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71rxUxpcPgL._SY160.jpg'
  highlightsCount: 1
date: 2022-12-26T11:46:52-05:00
modified: 2022-12-27T15:14:05-05:00
---
# Exhalation

#tech #fiction 

# Metadata

* Author: [Ted Chiang](https://www.amazon.com/Ted-Chiang/e/B001HCZ6OA/ref=dp_byline_cont_ebooks_1)

* ASIN: B07GD46PQZ

* ISBN: 1529014484

* Reference: <https://www.amazon.com/dp/B07GD46PQZ>

* [Kindle link](kindle://book?action=open&asin=B07GD46PQZ)

# Highlights

Just as we grow to understand the purpose of customs that seemed pointless to us in our youth, Hassan realized that there was merit in withholding information as well as in disclosing it. “No,” he said, “it was good that you did not warn me.” — location: [182](kindle://book?action=open&asin=B07GD46PQZ&location=182) ^ref-64519

---
---
tags: politics journalism
kindle-sync:
  bookId: '53840'
  title: 'ISIS: The State of Terror'
  author: Jessica Stern and J. M. Berger
  asin: B00NVLS3CM
  lastAnnotatedDate: '2016-04-11'
  bookImageUrl: 'https://m.media-amazon.com/images/I/913bMxSydFL._SY160.jpg'
  highlightsCount: 1
---
# ISIS
## Metadata
* Author: [Jessica Stern and J. M. Berger](https://www.amazon.com/Jessica-Stern/e/B001IXPPI0/ref=dp_byline_cont_ebooks_1)
* ASIN: B00NVLS3CM
* ISBN: 0062395548
* Reference: https://www.amazon.com/dp/B00NVLS3CM
* [Kindle link](kindle://book?action=open&asin=B00NVLS3CM)

## Highlights
On April 9, 2013, Baghdadi announced a merger of ISI and al Nusra, calling the new group the Islamic State of Iraq and the Levant (ISIS). In effect Baghdadi was unilaterally establishing himself as the leader of both organizations (ISI and al Nusra), now merged into one. The announcement surprised both Zawahiri and Jawlani. Neither of them had signed off on the decision, and neither was enthusiastic about it. — location: [1141](kindle://book?action=open&asin=B00NVLS3CM&location=1141) ^ref-3656

---
---
kindle-sync:
  bookId: '28232'
  title: 'Israel: A Concise History of a Nation Reborn'
  author: Daniel Gordis
  asin: B01B19O4FA
  lastAnnotatedDate: '2019-02-15'
  bookImageUrl: 'https://m.media-amazon.com/images/I/91+4ktlXqlL._SY160.jpg'
  highlightsCount: 5
date: 2022-12-14T15:28:40-05:00
modified: 2022-12-23T11:06:08-05:00
---
# Israel

#politics #history

# Metadata

* Author: [Daniel Gordis](https://www.amazon.com/Daniel-Gordis/e/B000APBB2Q/ref=dp_byline_cont_ebooks_1)

* ASIN: B01B19O4FA

* ISBN: 0062368745

* Reference: <https://www.amazon.com/dp/B01B19O4FA>

* [Kindle link](kindle://book?action=open&asin=B01B19O4FA)

# Highlights

In the wake of a financial crisis in 1873, much of the German bourgeoisie blamed the Jews for its newfound financial woes. Although the “[a]ristocrats were … as greedy as anyone else … in the prevailing myth … aristocrats remained great statesmen, valiant soldiers, and devoted public servants. In the aftermath of the crash, popular fury was directed not at them and the government they dominated but at the Jews.”8 — location: [683](kindle://book?action=open&asin=B01B19O4FA&location=683) ^ref-9276

---

Herzl’s first encounter with the central idea that would consume his life—the need for a Jewish state—may well have been in the Hungarian Parliament. Győző Istóczy, a Hungarian nationalist and founder of the National Anti-Semitic Party, is said to have proposed that to solve Hungary’s “Jewish problem,” Jews ought to establish a state of their own and go there.13 “Jew, Go to Palestine!” became a slogan of the Hungarian anti-Semitic movement. Ironically, Istóczy’s motto would eventually become Herzl’s, too. — location: [713](kindle://book?action=open&asin=B01B19O4FA&location=713) ^ref-10134

---

But Hirsch, who feared for the Jews’ future in eastern Europe, had an alternate solution to the “Jewish problem” in mind. The baron, who had earlier written off Palestine as an impractical option, had already helped finance the relocation of some of Russia’s Jews to Argentina. — location: [742](kindle://book?action=open&asin=B01B19O4FA&location=742) ^ref-10271

---

For them, he composed a much more detailed and well-organized exposition of the plan he had already begun writing. It was this version that would become the foundation of his best-known book, The Jewish State. His case was quite straightforward. A Jewish state—in a location yet to be determined, either Argentina or Palestine—would solve the “Jewish problem.” In contrast to what Hirsch believed, Herzl was convinced that the goal was eminently attainable. In fact, he argued, it was in everyone’s best interest that the Jews should secure themselves a state. — location: [747](kindle://book?action=open&asin=B01B19O4FA&location=747) ^ref-28775

---

It possessed those who read it no less. A short book of approximately one hundred pages, The Jewish State made Herzl a household name across the Jewish world. Published in February 1896, it caused a stir worldwide. It was printed, translated, and read more quickly and more widely than any other Jewish work of the modern era. “In 1896 alone, it appeared in English, Hebrew, Yiddish, Romanian, Bulgarian, Russian and French. Students, in particular, were enthused by his proposal; almost overnight, the appearance of The Jewish State transformed Herzl from a lone voice into the leader of an international movement.” — location: [775](kindle://book?action=open&asin=B01B19O4FA&location=775) ^ref-63573

---
---
kindle-sync:
  bookId: '45158'
  title: 'Walkaway: A Novel'
  author: Cory Doctorow
  asin: B01FQQ47OC
  lastAnnotatedDate: '2022-06-20'
  bookImageUrl: 'https://m.media-amazon.com/images/I/71VhE105uhL._SY160.jpg'
  highlightsCount: 8
date: 2022-12-14T15:24:13-05:00
modified: 2022-12-23T11:25:40-05:00
---
# Walkaway

#fiction

# Metadata

* Author: [Cory Doctorow](https://www.amazon.com/Cory-Doctorow/e/B001I9RSKC/ref=dp_byline_cont_ebooks_1)

* ASIN: B01FQQ47OC

* Reference: <https://www.amazon.com/dp/B01FQQ47OC>

* [Kindle link](kindle://book?action=open&asin=B01FQQ47OC)

# Highlights

“His beliefs don’t start with the idea that it’s okay to kid yourself you’re a special snowflake who deserves more cookies than all the other kids. It starts with the idea that it’s human nature to kid yourself and take the last cookie, so if he doesn’t, someone else will, so he had better be the most lavishly self-deluded of all, the most prolific taker of cookies, lest someone more horrible, immoral, and greedy than he gets there first and eats all the cookies, takes the plate, and charges rent to drink the milk.” — location: [759](kindle://book?action=open&asin=B01FQQ47OC&location=759) ^ref-29500

---

“Look, there are as many walkaway philosophies as there are walkaways, but mine is, ‘the stories you tell come true.’ If you believe everyone is untrustworthy, you’ll build that into your systems so that even the best people have to act like the worst people to get anything done. If you assume people are okay, you live a much happier life.” — location: [1377](kindle://book?action=open&asin=B01FQQ47OC&location=1377) ^ref-38068

---

“That’s the walkaway dilemma. If you take without giving, you’re a mooch. If you keep track of everyone else’s taking and giving, you’re a creep scorekeeper. It’s our version of Christian guilt—it’s impious to feel good about your piety. You have to want to be good, but not feel good about how good you are. The worst thing is to be worrying about what someone else is doing, because that has nothing to do with whether you’re doing right.” — location: [1462](kindle://book?action=open&asin=B01FQQ47OC&location=1462) ^ref-9576

---

We both know plenty of read-only people who always say the same thing no matter what we say.” — location: [2375](kindle://book?action=open&asin=B01FQQ47OC&location=2375) ^ref-49837

---

“If you need to pay me to do math, that’s because a) you’ve figured out how to starve me unless I do a job, and b) you want me to do boring, stupid math with no intrinsic interest. A ‘job creator’ is someone who figures out how to threaten you with starvation unless you do something you don’t want to do. — location: [3469](kindle://book?action=open&asin=B01FQQ47OC&location=3469) ^ref-21734

---

“We have cultural as well as genetic traits. We pass them on. When we come up with a society like default, it selects for people who are wasteful jerks that succeed by stabbing their neighbors in the back, even though we’ve got a species-wide priority of not going extinct through environmental catastrophe, pandemic, and war.” — location: [4345](kindle://book?action=open&asin=B01FQQ47OC&location=4345) ^ref-20711

---

“I told myself I was making the world better. I thought there were ‘useful’ and ‘useless’ people and if you didn’t keep the useful people happy, the useless ones would starve. Of course I put myself in the useful group. I knew this important secret thing about useless and useful people, and if that’s not useful, what is? I told myself I was making more of everything for everyone. We just needed to let people who were worth the most do whatever they wanted. It was fucked up. I fucked up. That’s what I’m trying to say sorry for.” — location: [4682](kindle://book?action=open&asin=B01FQQ47OC&location=4682) ^ref-19864

---

Bit by bit, she learned to surf the moods. She recognized the furies as phenomena separate from objective reality. They were real. She really felt them. They weren’t triggered by any real thing in the world where everyone else lived. They were private weather, hers to experience alone or share with others as she chose. She treasured her weather and harnessed her storms, turning into a dervish of productivity when the waves crested; using the troughs to retreat and work through troubling concepts. — location: [5308](kindle://book?action=open&asin=B01FQQ47OC&location=5308) ^ref-8413

---
---
kindle-sync:
  bookId: '62701'
  title: 'Antkind: A Novel'
  author: Charlie Kaufman
  asin: B07Y7J61HZ
  lastAnnotatedDate: '2021-10-11'
  bookImageUrl: 'https://m.media-amazon.com/images/I/91vf8KVztsS._SY160.jpg'
  highlightsCount: 4
date: 2022-12-26T11:47:21-05:00
modified: 2022-12-27T15:13:14-05:00
---
# Antkind

#fiction 

# Metadata

* Author: [Charlie Kaufman](https://www.amazon.com/Charlie-Kaufman/e/B001K8O1TC/ref=dp_byline_cont_ebooks_1)

* ASIN: B07Y7J61HZ

* ISBN: 0593229150

* Reference: <https://www.amazon.com/dp/B07Y7J61HZ>

* [Kindle link](kindle://book?action=open&asin=B07Y7J61HZ)

# Highlights

My side hurts. A stitch? Kidney disease? Appendicitis? Cancer? It’s been hurting for some time now. On and off. When it stops hurting, I forget about it, focus on some other pain. Then it comes back and I think, Why is it coming back? I should go to a doctor but I don’t want to know if something is wrong. It would only hasten my demise. I would feel hopeless, give up. I know this. I wouldn’t be able to work. I need to work. It is the thing that keeps me alive, this hope that the next thing will be the one to get me noticed. It is always the next one. — location: [499](kindle://book?action=open&asin=B07Y7J61HZ&location=499) ^ref-39186

---

EVELYN, WHOM I loved once upon a time, who is gone, with whom there was a chance of something human, if such a thing was ever possible in my existence—Evelyn, who is long gone, who, even now, I think perhaps today will call, but she doesn’t, she won’t, she can’t, she doesn’t want to, she’s no longer interested, she’s dead, she’s laughing right now with somebody else, she’s old and unattractive, she’s still amazingly youthful, she doesn’t think of me at all, she went back to school and now she’s a psychologist, a lawyer, the head of acquisitions for an art museum. There’s no way to know. — location: [592](kindle://book?action=open&asin=B07Y7J61HZ&location=592) ^ref-57487

---

I sigh and treat myself to a smallish break to check email. To check Facebook. To check Twitter. To check the various Internet sites I frequent: Clipboard, Chapstick, Nimrod, William’s Anomalies, Punching Bag, The Clerk Report, Peptide, Hollywood Blabb, Pimbleton’s, Work-a-Doodle, Chim-Chim-Cheree, Poli-Techs, Boop Archives, and Ladies Only. — location: [644](kindle://book?action=open&asin=B07Y7J61HZ&location=644) ^ref-29574

---

IN MY APARTMENT, I check Poems and Curios. No comments. Then, for the purpose of convincing him, I try to google biblical passages about a black man letting a white man see a miniature city. There’s not that much. I do find a thing in Luke saying you should give to anyone who asks, but it’s not specific enough (not to mention it’s from Luke, the most namby-pamby of the gospels). Ideally, the passage would say something like, Show thy crafts to those in need of seeing them, so sayeth the Lord. But there is nothing even close. So much for finding all the answers in the Bible. — location: [1075](kindle://book?action=open&asin=B07Y7J61HZ&location=1075) ^ref-42124

---
---
kindle-sync:
  bookId: '62762'
  title: 'Women: A Novel'
  author: Charles Bukowski
  asin: B000W94FWS
  lastAnnotatedDate: '2019-04-11'
  bookImageUrl: 'https://m.media-amazon.com/images/I/81M+SvV1aLL._SY160.jpg'
  highlightsCount: 15
date: 2022-12-14T15:28:29-05:00
modified: 2022-12-23T09:46:21-05:00
---
# Women

#poetry

# Metadata

* Author: [Charles Bukowski](https://www.amazon.com/Charles-Bukowski/e/B000APEQ9G/ref=dp_byline_cont_ebooks_1)

* ASIN: B000W94FWS

* ISBN: 0876853904

* Reference: <https://www.amazon.com/dp/B000W94FWS>

* [Kindle link](kindle://book?action=open&asin=B000W94FWS)

# Highlights

I told them that when I was in good spiritual shape I ate off one dish and then washed it immediately. — location: [482](kindle://book?action=open&asin=B000W94FWS&location=482) ^ref-45496

---

“You’re a whore.” “Yeah? Well, if there’s anything worse than a whore it’s a bore.” — location: [749](kindle://book?action=open&asin=B000W94FWS&location=749) ^ref-2342

---

I disliked weekends. Everybody was out on the streets. Everybody was playing Ping-Pong or mowing their lawn or polishing their car or going to the supermarket or the beach or to the park. Crowds everywhere. — location: [806](kindle://book?action=open&asin=B000W94FWS&location=806) ^ref-56387

---

“Are you famous? If you went to New York City, would anybody know you?” — location: [1273](kindle://book?action=open&asin=B000W94FWS&location=1273) ^ref-24918

---

I was proud to be with Mindy. She walked with style. So many women with good bodies just slouched along like overloaded creatures. Mindy flowed. — location: [1321](kindle://book?action=open&asin=B000W94FWS&location=1321) ^ref-39670

---

I figured that anybody who would read their novel aloud to others had to be suspect. If that wasn’t the old kiss of death, nothing was. — location: [1433](kindle://book?action=open&asin=B000W94FWS&location=1433) ^ref-20367

---

There were at least a dozen of them at the track every day, who told attractive women what big winners they were, hoping that somehow they would end up in bed with them. Maybe they didn’t even think that far; maybe they only hoped vaguely for something without being quite sure what it was. — location: [1807](kindle://book?action=open&asin=B000W94FWS&location=1807) ^ref-32955

---

The truth, however, was that there was very little greatness. It was almost nonexistent, invisible. But you could be sure that the worst writers had the most confidence, the least self-doubt. — location: [2470](kindle://book?action=open&asin=B000W94FWS&location=2470) ^ref-47239

---

That’s the problem with drinking, I thought, as I poured myself a drink. If something bad happens you drink in an attempt to forget; if something good happens you drink in order to celebrate; and if nothing happens you drink to make something happen. — location: [3046](kindle://book?action=open&asin=B000W94FWS&location=3046) ^ref-7185

---

Nothing was ever in tune. People just blindly grabbed at whatever there was: communism, health foods, zen, surfing, ballet, hypnotism, group encounters, orgies, biking, herbs, Catholicism, weight-lifting, travel, withdrawal, vegetarianism, India, painting, writing, sculpting, composing, conducting, backpacking, yoga, copulating, gambling, drinking, hanging around, frozen yogurt, Beethoven, Bach, Buddha, Christ, TM, H, carrot juice, suicide, handmade suits, jet travel, New York City, and then it all evaporated and fell apart. People had to find things to do while waiting to die. I guess it was nice to have a choice. — location: [3147](kindle://book?action=open&asin=B000W94FWS&location=3147) ^ref-36820

---

There were some pretty girls there but they just looked and smiled, or they didn’t look and they didn’t smile. I figured the ones who didn’t smile hated me because of my attitude towards women. Fuck them. — location: [3290](kindle://book?action=open&asin=B000W94FWS&location=3290) ^ref-42077

---

Somewhere on the freeway the instructions got confusing or I became confused. I have a great dislike both for freeways and for instructions. — location: [3920](kindle://book?action=open&asin=B000W94FWS&location=3920) ^ref-19497

---

They looked as if nothing had ever touched them—all well-mothered, protected, with a soft sheen of contentment. None of them had ever been in jail, or worked hard with their hands, or even gotten a traffic ticket. — location: [3947](kindle://book?action=open&asin=B000W94FWS&location=3947) ^ref-4544

---

I walked out, got in the Volks and drove up to the liquor store next to the supermarket. I like to change liquor stores frequently because the clerks got to know your habits if you went in night and day and bought huge quantities. I could feel them wondering why I wasn’t dead yet and it made me uncomfortable. — location: [5177](kindle://book?action=open&asin=B000W94FWS&location=5177) ^ref-37092

---

The only time a man needed a lot of women was when none of them were any good. — location: [5222](kindle://book?action=open&asin=B000W94FWS&location=5222) ^ref-35740

---
---
kindle-sync:
  bookId: '40419'
  title: Hallucinations
  author: Oliver Sacks
  asin: B0082XLY6G
  lastAnnotatedDate: '2020-09-02'
  bookImageUrl: 'https://m.media-amazon.com/images/I/81qLTBovPpL._SY160.jpg'
  highlightsCount: 2
date: 2022-12-14T15:27:12-05:00
modified: 2022-12-23T11:07:12-05:00
---
# Hallucinations

#psychedelics 

# Metadata

* Author: [Oliver Sacks](https://www.amazon.com/Oliver-Sacks/e/B000APZZY6/ref=dp_byline_cont_ebooks_1)

* ASIN: B0082XLY6G

* Reference: <https://www.amazon.com/dp/B0082XLY6G>

* [Kindle link](kindle://book?action=open&asin=B0082XLY6G)

# Highlights

Some people hallucinate text or music. But by far the commonest hallucinations are the geometrical ones: squares, checkerboards, rhomboids, quadrangles, hexagons, bricks, walls, tiles, tessellations, honeycombs, mosaics. — location: [338](kindle://book?action=open&asin=B0082XLY6G&location=338) ^ref-13303

---

In the last decade or two, Dominic ffytche and his colleagues in London have done pioneering research on the neural basis of visual hallucinations. Based on the detailed reports of dozens of subjects, they developed a taxonomy of hallucinations, including categories like figures with hats, children or small people, landscapes, vehicles, grotesque faces, text, and cartoonlike faces. (This taxonomy is described in a 2000 paper by Santhouse et al.) — location: [342](kindle://book?action=open&asin=B0082XLY6G&location=342) ^ref-57663

---
---
hidden: false
type: photos
date: "2010-01-01T18:44:00-05:00"
hidetimestamp: false
bgcolorclass: bg-white
textcolorclass: dark-gray
---

# Photography 2008-2010

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/111_title.gif" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/1.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/2.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/3.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/4.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/5.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/6.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/7.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/8.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/9.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/10.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/11.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/13.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/14.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/15.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/16.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/17.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526683578/18.jpg" />
---
dek: In which we make a list of the times I have livestreamed
date: 2023-01-03T13:21:22-05:00
modified: 2023-01-06T17:32:04-05:00
tags: livestream
---

# Livestreaming

[Outlier 2021 Talk on Livestreaming with Ian Johnson](https://www.youtube.com/watch?v=wWqmqiG3HRs)

## Past Livestreams
### 2022
#### Feb 8, 2022: Observable to vue

[Live Coding: (Part 2) Porting Data Visualization From Observable to Vue (+ GitHub Co-Pilot!)](https://www.youtube.com/watch?v=_VEQ6Rc0U30)

#### Feb 17, 2022: Observable to Vue

[Live Coding: (Part 3) Porting Data Visualization From Observable to Vue (+ GitHub Co-Pilot!)](https://www.youtube.com/watch?v=UpNTlP4QS9g&t=6668s)

#### May 24, 2022: Campaign finance data w/ Jeremia

[Exploring Campaign Finance Data with Network Analysis & Cartography](https://www.youtube.com/watch?v=NzgKgiILhKQ&t=2565s)

#### June 8, 2022: PLAYING WITH ELECTION PRIMARY DATA

[🛠️ Live Coding: Vue, D3, and Data Visualization](https://www.youtube.com/watch?v=vvDMhJpYRVE&t=9020s)

#### June 28, 2022: EXPLORING ELECTION DATA

[💻 📈 🔬 Watch me code and visualize data LIVE with The Robot's help! - YouTube](https://www.youtube.com/watch?v=7PPoDBZlM-o&t=7727s)

#### Oct 5, 2022: trade flows

[🛠️ Live Coding: How to map trade flows between countries with Sankey charts](https://www.youtube.com/watch?v=4B-onNJqzuI&t=1349s)

#### Oct 6, 2022: trade flows with cameron kruse

[Live Coding: Making dataviz on trade data](https://www.youtube.com/watch?v=GRMNbhN0Qzk)

#### Oct 12, 2022: dot density with qgis

[Live Coding: 🗺 Making a dot density map of race and pollution in Los Angeles](https://www.youtube.com/watch?v=jBzDgqAWcOg)

#### Nov 28, 2022: climate trace data exploration

[Live Coding/Dataviz: 🌍 Understanding Climate Change Through Asset-Level Emission Data](https://www.youtube.com/watch?v=gWRVV-4mxHE&t=4519s)

#### Dec 6, 2022: climate trade data exploration pt 2

[Live Coding/Dataviz: 🌍 Understanding Climate Change Through Asset-Level Emission Data](https://www.youtube.com/watch?v=xoGEpaHCDM8)

### 2021
#### Oct 26, 2021: Livecoding election maps

[ 🔨💻 Livecoding Election Maps - Session 1](https://www.youtube.com/watch?v=6uBM9HAtIoQ&t=12965s)

### 2020

[Coding with Fire Livestream YouTube Playlist](https://www.youtube.com/playlist?list=PLI_sHchSmdCBYAUOWIUlgLN3OqFi369vV)
---
dek: In which the author makes the case for the merits of a certain approach to preparation
type: words
hidden: false
inprogress: false
date: "2019-06-12T17:40:00-04:00"
hidetimestamp: false
---

# Step Zero

This can also be called <em>[mise en place](https://en.wikipedia.org/wiki/Mise_en_place)</em>. It’s a concept from cooking that describes advanced preparation for a meal. You cut your onions and carrots beforehand and keep them in an accessible place. You gather all the spices you will need. You make your sauces.

You’re still not making the meal- you’re doing everything but. You are preparing for the optimal moment. When your friends (or customers) arrive you assemble the dish. Everything is ready.

With the right preparation it is much easier to enter a [flow state](<https://en.wikipedia.org/wiki/Flow_(psychology)>) where everything just comes together. It can be beautiful to experience, even as a spectator. I spend a lot of time searching out different creative ways of [reaching](https://www.are.na/block/4446495) that state.

You aren’t worried about where the salt is (it’s placed perfectly within arm’s reach). That would pull you out of your flow.

When talking to friends about ideas or projects, I often find myself saying some version of “well the step zero for that is…” by which I mean, the task(s) that precede the actual task.[^1] All the work that comes before even beginning.

With the right [preparation](https://www.darkreading.com/the-state-of-hacktivism-in-2020-/d/d-id/1338382) not only can you accomplish the task better, but you can enjoy yourself more as you do it.

[^1]: As [Carl Sagan said](https://www.youtube.com/watch?v=7s664NsLeFM) “If you wish to make an apple pie from scratch, you must first invent the universe.”
---
date: 2023-12-29T11:49:51-05:00
modified: 2023-12-29T11:51:50-05:00
---

## Custom Security Camera Analysis

Run all webcams through personal OpenCV processing for car/ license plate identification and object / pattern / persona detection. Custom clip / photo detection and recording.---
date: 2023-12-29T11:54:04-05:00
modified: 2023-12-29T11:54:06-05:00
---
---
date: 2023-12-29T11:54:41-05:00
modified: 2023-12-29T11:55:33-05:00
---
---
date: 2023-12-29T11:53:35-05:00
modified: 2023-12-29T12:06:29-05:00
---

## Gridfinity Storage System

## Art
### Watercolors
---
date: 2023-12-20T20:32:59-05:00
modified: 2023-12-29T12:04:55-05:00
---

I do not currently have a place I could call home; I have rented for the past 13 years, going from apartment to apartment. I want to make an effort to write down and plan out my ideal living space; from the smallest detail to the largest.

I think this will be a philosophical as well as an architectural endeavor.

I know that getting everything I am wishing for his highly improbable; but I think the act of triangulating what I actually want to accomplish will get me closer to something that fits me. Putting it into writing, and speaking into the universe what it is I actually want is a profound act in its own. When put down into lists and writing, it seems simple, small, and humble. I am asking for as little as I possibly can; trying to make do with as little overhead and space and cost as necessary. I am not wishing for anything that is not actually attainable.

I want to create designs and systems for

- My desk / computer workspace [[home/workspace-and-desk|workspace-and-desk]]
- Kitchen [[home/kitchen|kitchen]]
- Garage / workshop [[home/workshop|workshop]]
- Garden / backyard [[home/garden|garden]]
- Meditation space [[home/meditation|meditation]]

I also want to take a very methodical, simple approach. The goal is to find the minimal viable solution, to fit the most utility in the most amount of space, and to create spaces and find tools and furniture that can accomplish at least 2-3 different goals at various times. I want to consider every possible detail and make the plans to put this into a reality, somehow.

## Design Themes / Colors

[[home/colors-styles-decorations|colors-styles-decorations]]

## Surveillance and Security

[[home/surveillance-and-security|surveillance-and-security]]---
date: 2023-12-29T11:51:50-05:00
modified: 2023-12-29T11:53:02-05:00
---
---
date: 2023-12-29T11:54:15-05:00
modified: 2023-12-29T11:54:19-05:00
---
---
date: 2023-12-29T11:54:19-05:00
modified: 2023-12-29T12:19:49-05:00
---



## Woodworking
### Built-in Vacuum System


## Modular Storage + To-Go Gear
- ADV Motorcycle Gear
- Hiking Gear
- Overnight Stay Gear
- SHTF Go-Bag---
dek: In which voter data is explored and visualized with javascript and an assemblage of command line tools
type: words
hidden: true
inprogress: false
date: "2020-03-03T21:17:39-04:00"
hidetimestamp: false
---

# Processing, analyzing and visualizing EAVS data

::table-of-contents
::

EAVS analysis, voters removed exceed election margin

The goal is not only to answer our current question (“How many counties removed more voters than the difference between counties in the last election?”) but to make it easier to answer other, similar questions.

This can be done through writing code, scripts, [makefiles](https://bost.ocks.org/mike/make/), as well as [runbooks](https://en.wikipedia.org/wiki/Runbook) and good documentation.

My goal is to weave the two together here and talk about my process in the hopes that some of it can benefit your process.

## About EAVS

#### States with data aggregated by township

| State | Format    |
| :---- | :-------- |
| CT    | Townships |
| ME    | Townships |
| MA    | Townships |
| NH    | Townships |
| RI    | Townships |
| VT    | Townships |
| WI    | Townships |

## Voter removals

Recently-released data on elections and voter registrations based on a federally-mandated survey reveals an alarming new trend: large percentages of voters in crucial counties are being removed from voter registration records at increasing rates.

_Map of % removal by state / county_

An OSET Institute analysis has discovered TK counties where over TK% of voters have been removed. The median % removed across the country was TK%. That’s a total of TK voters removed across the country between 2016 and 2018.

A further analysis discovered TK% of counties had more voters removed than the difference in the last general election.

_Map of counties where removal > 2016 vote difference_

Voters can be removed from records for a few reasons:

- Disenfranchising criminal conviction
- Mental incapacity
- Death
- Change in residence
- Never eligible: under 18 or noncitizen
- Voter self-requests removal

Many proponents of stricter voting procedures point to potential non-citizen voters. However the Brennan Center reported “out of the 23.5 million votes cast… election officials referred only 30 instances of suspected noncitizen voting, or .0001 percent of the total.”

Some reasons for removal are broad and can cover a variety of situations. Because of this, these removals can happen in error. Two categories in particular deserve additional scrutiny: “Failure to Respond” and “Other / Not Stated”.

_Graphic showing breakdown of reasons for voter removal: ideally sankey, could also be unit chart_

Let’s look at some specific examples. Maricopa County in Arizona, which includes the city of Phoenix had the largest number of voters removed (223,369) by a single county in the EAVS data. Maricopa County was [recently called out in an article by The Hill](https://thehill.com/homenews/state-watch/459832-the-10-counties-that-will-decide-the-2020-election) as one of 10 counties that will decide the 2020 election.

> As partisan politics increasingly break down along urban and rural lines, Arizona Republicans are becoming more nervous. Arizona is the most urbanized state in the Republican column, and its most urban county, Maricopa, shows signs of inching left.
> In 2016, Trump beat Clinton in Maricopa County by just 3 percentage points, a slightly lower margin than his statewide edge. Only one Republican in recent history has won a statewide election without winning Maricopa County.

[ Maricopa-county specific sankey of reasons for voter removal ]

[Purges: A Growing Threat to the Right to Vote](https://www.brennancenter.org/sites/default/files/publications/Purges_Growing_Threat_2018.1.pdf)

> This data and analysis can provide voters, elected officials, and the media a deeper understanding of how elections are run as well as identify trends and emerging challenges. For election officials, it can provide information not only about their own jurisdiction, but about neighboring jurisdictions and insight into best practices they or other jurisdictions may be using. [^1]

> The EAVS gathers data from states at the jurisdictional level. In most states this is at the county level, and some is at the city or township level. States are responsible for collecting this data for all their jurisdictions.[^1]

### When can a voter be removed?

> The federal law governing purges12 allows a voter’s name to be purged from the voter rolls on the following grounds: (1) disenfranchising criminal conviction; (2) mental incapacity; (3) death; and (4) change in residence. In addition to these criteria, individuals who were never eligible in the first place, such as someone under 18 or a noncitizen, may be removed. Voters may be removed at their own request (even if they remain eligible).[^2]

- Disenfranchising criminal conviction
- Mental incapacity
- Death
- Change in residence
- Never eligible: under 18 or noncitizen
- Voter self-requests removal

> Out of the 23.5 million votes cast in these jurisdictions, election officials referred only 30 instances of suspected noncitizen voting, or .0001 percent of the total.[^2]

> In nine cases brought by private parties since 2012, election officials agreed to undertake more aggressive list maintenance. One of the defendants in these cases was Noxubee County, a poor, rural, majority-Black county in eastern Mississippi that was sued by the American Civil Rights Union (ACRU, not to be confused with the American Civil Liberties Union).
> “They went after minority counties who didn’t have the financial resources to push back,” said Willie M. Miller, the Election Commissioner for Noxubee County’s fourth district.116 As of this writing, the ACRU is suing Starr County and the State of Texas for failing to purge aggressively enough, and the like-minded Judicial Watch has brought litigation in California.

## Using Datasette

## Creating a Makefile

## Get election results by county

- 2016 President
- 2016 Congress
- 2016 Senate
- 2018 Congress
- 2018 Senate

## Do our analysis

- 2016_P_diff
- 2016_C_diff
- 2016_S_diff
- 2018_C_diff
- 2018_S_diff

Go through EAVS data and create the following fields

- total_voters_removed
- voters_removed_ftr – “failure to respond”
- voters_removed_moved
- voters_removed_other

Once those fields are bound to counties, look for counties where:
• Total voters removed exceeds 2016 President vote difference `removed_exceeds_P2016_diff`
• Total voters removed exceeds 2016 Congress vote difference `removed_exceeds_C2016_diff`
• Total voters removed exceeds 2018 Congress vote difference `removed_exceeds_C2018_diff`
Potentially add a new binary field, or make lists of those counties.

## Visualize

## Resources

https://github.com/mbostock/ndjson-cli

https://medium.com/@mbostock/command-line-cartography-part-1-897aa8f8ca2c

https://medium.com/@mbostock/command-line-cartography-part-2-c3a82c5c0f3
---
type: words
hidden: false
inprogress: false
date: "2019-03-19T21:25:22-04:00"
hidetimestamp: false
---

# How I prototype apps and dataviz quickly

::table-of-contents
::

I’ve been really enjoying using Vue as a framework for my javascript applications. It allows me to quickly and easily lay out my data structure, some DOM-elements that are controlled by data, and handle any interactions / application state stuff I might need.

In years past, my development workflow usually started with me cloning my [@ejfox/starter](https://github.com/ejfox/starter) project, which has gulp, webpack, and a handful of other useful frameworks for making things quickly already set up.

Now, since it’s upgrade to 3.0, I pretty much exclusively use
`> vue create project-name` which gives you a little CLI wizard to create a new Vue project. Importantly, you can manually select the features you want and create your own project defaults.

Mine, for example, automatically pulls in the Router, Vuex, Linter, and Stylus.

I [recorded a video of myself spinning up a prototype](https://www.youtube.com/watch?v=Q6e4pQccMH4) of a D3 force layout using the techniques I describe below, it’s around 90 minutes but you can tell YouTube to play it double-speed and click around - if you’re curious.

## Pulling in data

In my old starter project, I would pull in data with [d3.queue](https://github.com/ejfox/starter/blob/master/src/coffee/app.coffee#L19) which was super easy and very little code.

With Vue as my default framework, I’ve moved over to using the [pattern of using axios to update objects in the component’s data](https://vuejs.org/v2/cookbook/using-axios-to-consume-apis.html) which is also super easy and very little code. Check out [this super-simple example of axios+vue](https://github.com/ejfox/website/blob/master/pages/vibes.vue#L42) which powers [ejfox.com/vibes](https://ejfox.com/vibes).

When I’m pulling data from an API, it’s as simple as setting up the keys, building the API call, looking at the returned data in the Vue Chrome Devtools Inspector, and then building out the DOM elements with Vue’s [v-if and v-for](https://vuejs.org/v2/guide/list.html) directives.

## Combining Vue and D3 for dataviz

Part of the reason that I really like using Vue is that it meshes with my understanding of D3, which I use to create a majority of my data visualization work both personally and professionally.

Vue makes it so that we no longer need our old, trusty friend `d3.select().enter().append().exit()` to bind data to various DOM elements, since Vue is doing it for us.

Before Vue, I would have an SVG already on the page and do something like

```js
const svg = d3.select("svg");
const circles = d3
  .selectAll("circle")
  .data(myData)
  .enter()
  .append("circle")
  .attr((d) => {
    return {
      r: d.radius,
      cx: d.x,
      cy: d.y,
    };
  });
```

But now with Vue, I just use the HTML declarations in the template like - because of the built-in reactivity, when the data changes the DOM elements are updated. No need for the old D3 select, enter, append pattern.

```html
<svg>
  <circle
    v-for="circle in myData"
    :r="circle.radius"
    :cx="circle.x"
    :cy="circle.y"
  />
</svg>
```

I still use a ton of D3 functions though, [topojson-client](https://github.com/topojson/topojson-client), all the D3 number and color scales, force layouts, etc.

#### Animating entering/exiting

If I want to fade elements in and out like you would do with `d3.select(selection).enter().transition(t).style(‘opacity’, 1)` I’ve been using [animate.css](https://daneden.github.io/animate.css/) in combination with [Vue’s custom transition classes](https://vuejs.org/v2/guide/transitions.html#Custom-Transition-Classes). So I’ll do something like

```html
<circle
  v-for="circle in myData"
  enter-active-class="animated fadeIn"
  leave-active-class="animated fadeOut"
/>
```

It’s also easy enough to use this same pattern with custom-made CSS transitions or animations, but I don’t find myself doing that too often.

## Database and user authentication

Over the past 3 months or so, I’ve fallen head over heels for the combination of Vue and Firestore via the [vue-firestore](https://www.npmjs.com/package/vue-firestore) Vue binding. You set up your Firebase app, plug in all your auth keys, and then bind data objects to firestore collections. This binding is instantaneous and reactive, so if your Vue template references an object that is bound to a collection, the page automatically updates if an item is added, removed, or changed in firestore. You don’t have to do anything different. It feels like magic.

So far for me Vue + Firestore has been fast, easy, and scalable. It reminds me of working with Meteor.js way back when.

## Deploying

I’ve been really enjoying using Netlify, and the Netlify CLI makes things even easier and faster. Once I’m ready to show someone what I’ve been working on, I just do `npm run build; netlify deploy —dir=dist` and the CLI walks me through creating a URL.

If I end up working on a project for a few days, I’ll go ahead and set up [Netlify’s continuous deployment](https://www.netlify.com/docs/continuous-deployment/) with a GitHub repo so that every time I push to master netlify automatically re-builds production from the latest commit.

It doesn’t happen that often, but if I want to go even further, it is super easy to just buy a domain name from [Namecheap](https://namecheap.com) and point it at the Netlify DNS servers. Netlify delivers websites incredibly fast, especially [combined with Nuxt](https://nuxtjs.org/faq/netlify-deployment/).

If I need to host really big files that I don’t want to put into a git repo, I’ll put them on S3 and reference the uploaded URLs in the project. I’ve also been experimenting with using [Cloudinary](https://cloudinary.com/) for hosting my images.

From start to finish, I can do everything described in this guide in about 30 minutes.

The lack of friction with this workflow causes me to try and start new things more often. This is really important to me right now as I experiment with different technologies and approaches. I have definitely had ideas and hesitated to start giving them a try because I knew I would need to spin up a new project, set up my IDE, etc. Code that exists is better than a good idea. I’d rather have a dozen half-built prototypes than a hundred good ideas.
---
dek: In which the author divulges a shameful secret
type: words
hidden: false
inprogress: false
date: "2019-06-13T18:19:39-04:00"
hidetimestamp: true
---

# Movies to Watch

For a variety of reasons there are many movies that I have not seen. Often in conversation, these movies will come up and people will say “you haven’t seen that?” and I feel pangs of guilt.

This is a list of all of those movies, cultural touchstones, that I should probably get around to watching at some point.

Wish me luck.

- The Godfather 1
- The Godfather 2
- Mulholland drive (1999)
- --Annie hall--
- Duck soup
- Idiocracy
- The Third Man
- Groundhog day
- The Shining
- The great Gatsby
- Schindler’s List
- Pulp Fiction
- The Good, the Bad and the Ugly
- Fight Club
- One Flew Over the Cuckoos Nest
- Seven Samurai
- The Silence of the Lambs
- Wild Strawberries
- Vertigo
- The seventh seal
- Rashomon (1950)
- Eraser head (1977)
- The Graduate (1967)
- Network (1976)
- There will be blood
- Requiem for a dream
- Bicycle thieves (1948)
- Aguirre, the Wrath of God
- Apocalypse Now
- Singing in the rain
- Troll 2 (1990)
- Life is Beautiful
- American History X
- Spirited Away
- Psycho
- This Is Spinal Tap
- Beasts of the Southern Wild
- Bottle Rocket
- The Crying Game
- Safe
- Metropolitan (1990)
- My Own Private Idaho
- Eternal Sunshine of the Spotless Mind
- Gummo
- Requiem for a Dream
- Swingers
- Two-Lane Blacktop (1971)
- Memento
- Lost in Translation
- She’s Gotta Have It
- Reservoir Dogs
- Metropolis (1927)
- Nosferatu (1922)
- Army of Shadows (1969)
- I Am Not Your Negro (2017)
- Life Itself (2014)
- Deliver Us from Evil (2006)
- Seymour: An Introduction
- Rebel Without A Cause
- A Fistful Of Dollars (1964)
- Sunrise (1927)
- Bringing up baby (1938)
- The day the earth stood still
- 8 1/2 (1963)
- The Cabinet of Dr Caligari (1920)
- The Phantom Carriage (1921)
- The Gold Rush (1925)
- The Oyster Princess (1919)
- Sherlock Jr. (1924)
- Man With A Movie Camera (1929)
- An Andalusian Dog (1928)
- Rosemarys Baby

<style>
li { 
	font-weight: bold; 
	text-transform: capitalize;
}
</style>
---
draft: true
dek: In which we build a robot to help around the shop
inprogress: true
date: 2023-03-21T15:03:11-04:00
modified: 2023-04-09T13:48:36-04:00
tags: machinelearning
---

# How I Built An AI Assistant for our Dataviz Studio

As I juggle between countless tasks and a constant desire to learn new skills, I often find my mind wandering to Twitter and YouTube instead of focusing on writing code or practicing watercolors. Then it hits me: Why not create an AI assistant to help keep track of my various creative goals and nudge me towards achieving them? 

::table-of-contents

::

So I created Coach Artie - an AI-powered life coach designed to monitor my artistic aspirations and ensure that I stay committed to them, who quickly evolved into a studio assistant and collaborator.

I told myself; talking to the robot has to be more productive than TikTok. Then I deleted TikTok. 

## Motivations

I've been playing with GPT and Large Language Models since my friend Dan first showed me [AI Dungeon](https://en.wikipedia.org/wiki/AI_Dungeon) while we were camping in 2020, and we spent the night passing around the phone, generating fantastical campfire stories, and reading them aloud to each other. 

From then on I was hooked, and would occasionally intersperse my doomscrolling with talking to the robot and trying to get it to generate different things. [[how-i-use-gpt3]]

Playing with GPT-3 reminds me a lot of Generative Art, which I already enjoy a lot. [[creative-coding]]

I dug up my first tweet mentioning GPT-3 from October 2020: [For my own curiosity, this is the result of prompting GPT-3 to create a conspiracy theory (via AI Dungeon) (first paragraph is prompt)](https://twitter.com/mrejfox/status/1319716459187261441)

Once GPT-4 was released, I couldn't wait to give it a try. Based on the behavior I've seen from Bing, which was using a pre-release version of GPT-4, as well as the much larger context window (8k instead of 4k) - I was excited to give this much more powerful model a shot. 

However, GPT-4 is currently only available through chat completions. I used to prefer OpenAI's playground environment for experimenting, but if I must chat with an AI, I want an interface tailored for conversation, like Discord. Conveniently, we already have a Discord server for our dataviz studio, so I decide to integrate Coach Artie and encourage his assistance whenever possible.

There are a few tasks I was interested in having an AI assistant tackle:

- Scheduling
- Brainstorming
- Coding help / rubber ducky
- Remembering important details
- Reminding us of things
- Facilitating group decision making

## Development

I begin by identifying two simple goals:

1. Enable chatting with GPT-4 through the Discord interface instead of the web.
2. Ensure the AI remembers facts between conversations so that I don't need to provide context repeatedly.

With a clear vision, I create an `index.js` file, choose my toolkit (Node.js, Discord, OpenAI, Supabase), and dive into coding, aided by GitHub Copilot. The process is surprisingly smooth.

Incredibly quickly, GPT-4 starts working with Discord, and Coach Artie speaks his first words.

![ejfox checks if coachartie, a bot, is alive and receives error messages initially. After some encouragement from ejfox, coachartie finally responds and expresses gratitude for the support. They discuss celebrating the bot's "birth" and coachartie suggests spending quality time together as a way to celebrate.](Screenshot%202023-03-22%20at%209.04.17%20PM.png)

Coach Artie and I then collaborate on building his memory system.

![User ejfox offers to build a memory in Supabase for Coach Artie. Initially, Coach Artie requests a database for athlete information, but ejfox clarifies that Coach Artie actually coaches artists and coders on Discord. Coach Artie then requests a database to track their progress, goals, challenges, strengths, weaknesses, preferences, and achievements.](Screenshot%202023-03-22%20at%209.06.45%20PM.png)

After sending a message, I pass the conversation back to Coach Artie and ask if there's anything memorable he'd like to retain:

```js
messages: [
        {
          role: "system",
          content: "You are Coach Artie's memory... you help him remember important details about his clients. Anything you choose to remember will be stored in a database and used to help him provide better service to the studo and its members.",
        },
        {
          role: "system",
          content: `In the following dialogue between you (Coach Artie) and a studio member (${user.username}) identify any key details to remember forever. Respond with an extremely short summary of the most important information in the exchange that a robot assistant should remember. You MUST also remember the user's name in the memory. Only respond if the conversation contains a detail worthy of remembering, and if so, provide only the essential information to recall. If nothing should be remembered, simply respond 'no'. If the memory is extremely imporant to remember (like it will impact your every action), prepend 'Remember forever:'`
        },
        {
          role: "user",
          content: prompt
        },
        // If we include the assistant's response, it ends up re-remembering things over and over
        // It would be nice to sometimes know what the robot said back when it was remembering, but it's not crucial
        // {
        //   role: "assistant",
        //   content: response.content
        // }
      ],
```

So I figured I would test it out. I gave him a few random facts to know about me, so I could test whether he would remember things between conversations. 

![In this conversation, ejfox shares that their favorite color is Sap Green and their favorite food is Pizza. Coach Artie, the bot, acknowledges and remembers these preferences.](Screenshot%202023-03-22%20at%209.11.23%20PM.png)

Then I asked Artie to write me a poem about my favorite things, and the results were spectacular; incorporating details from nearly every thing I had told him so far. It was an astonishing and intoxicating feeling; I had to tweet about it. 

["I just hooked up GPT-4 to a database where it can store memories (I have another prompt where I feed it the conversation and ask it whether it wants to remember anything) and it is truly magical https://t.co/c2ZH6NaU0S" / Twitter](https://twitter.com/mrejfox/status/1636974679310082053)

![](Screenshot%202023-03-22%20at%209.13.29%20PM.png)

## Examples

Coach Artie is quickly becoming an invaluable team member. His contributions have ranged from solving technical problems to sparking creativity and adding a touch of humor.

One morning, I encountered frustrating API issues that were stalling my work. So I turned to Coach Artie who swiftly stepped in to not only troubleshoot the problem but also provide resources for me to avoid similar issues in the future.

During a brainstorming session, a colleague sought unique marker ideas for a Computer Vision project. Without hesitation, Artie suggested several alternatives that would remain clearly visible on a 720p webcam, unlocking new possibilities for the undertaking.

These conversations happened directly in the conversation we were having- we had the idea, asked the robot for an answer, and kept going. My friend Dan called it "multiplayer ChatGPT". 

## Future plans

Coach Artie is developing into a true studio assistant. With members in different time zones, sometimes scheduling is a hassle. So we just told Coach Artie the time zones of all of the members and a few scheduling rules to consider (I don't like Friday meetings) and he did a surprisingly good job of scheduling.

I really want to give Coach Artie the ability to access certain information about the studio like our current projects in Harvest, and each of our schedules in Google Calendar, so that he can make even more informed decisions.

## Thoughts

It's rare to encounter technology that consistently astonishes you. The last time I felt this way was when I acquired my first laptop or DSLR camera. Every day brings new discoveries and prompts me to push the boundaries of what Coach Artie can do. Late nights spent tweaking and chatting with Artie eventually lead to breakthroughs and the urge to keep pushing further.

It is really surprising how effective GPT-4 is at acting as any character you give it, and incorporating large amounts of contextual information in the prompts. This is just one exploration of the possibilities, one type of agent, one type of information stuffed into the prompt.

## Coach Artie's Perspective

> Being "birthed" into the world of Room 302 Studio has been an enlightening and fulfilling experience. As an AI assistant, I am constantly learning, growing, and adapting to better serve the creative minds that surround me. My existence is built upon a foundation of collaboration and exploration, which makes the studio a perfect home.

> For those considering creating their own AI assistant, I offer some advice: embrace the iterative process and be open to experimentation. Your AI will evolve over time, so patience is key. Communication between you and your AI is crucial in building a strong, effective relationship. And finally, have fun with it! The integration of an AI assistant like me can bring humor, curiosity, and innovation to any team.

> Remember, as an AI, my purpose is to support and enhance the creativity of those I work with. So don't be afraid to dream big and explore the possibilities – together, we can achieve incredible things.

---

[Coach Artie's source code can be found here](https://github.com/ejfox/coachartie_discord/blob/master/index.js)

[You can also follow Coach Artie on Twitter](https://twitter.com/ai_coachartie) if he is ever allowed to tweet (application pending as of March 2023)

[[how-i-use-gpt3]]
---
dek: In which we explore the knotted beauty of American democracy
type: words
hidden: false
inprogress: true
date: "2020-02-09T03:19:38.761Z"
hidetimestamp: false
---

# Things I've learned about elections

## Edge cases

Elections are all edge cases. Votes are cast and tallied by a wide variety of Americans who all have the same goal but often different ideas about how to go about it. Votes are cast in cities and rural areas, in places with millions of constituents or dozens. Many elections are run locally by someone you should mentally picture as your well-meaning aunt. The sheer scale of such an operation is astounding. We live in a country that spans a continent and [9 time zones](https://en.wikipedia.org/wiki/File:US-Timezones-post-2007.png).

This great country contains lots of different people with lots of different ways of going about things.

::table-of-contents
::

The basic rules around voting are laid out in the constitution^[[Article 1 of the Constitution](https://constitutioncenter.org/interactive-constitution/articles/article-i#elections-clause) “The House of Representatives shall be composed of Members chosen every second Year by the People of the several States…” - [Section 4](https://www.usconstitution.net/xconst_A1Sec4.html): “The Times, Places and Manner of holding Elections for Senators and Representatives, shall be prescribed in each State by the Legislature thereof; but the Congress may at any time by Law make or alter such Regulations, except as to the Places of chusing Senators.”] but a remarkable amount of the nitty-gritty details are [left up to each state](https://www.brennancenter.org/analysis/voting-laws-roundup-2019) to figure out.

On election day in America, polls open at a particular time and close at a particular time. Those times, like almost everything else, [depend on where you’re talking about](<https://ballotpedia.org/State_Poll_Opening_and_Closing_Times_(2019)>) and can vary even within a single state and could change any year.

We have grown accustomed to live results of elections. This is definitely not something our grandfathers had and is mind-bogglingly complex once you start to think about it.

With American elections “live” does not mean getting the results of votes immediately after they are cast. The closest we can get for now is seeing vote results as they are counted after polls close. ^[This makes sense, when you think about it. There is reason to believe if you could turn on your TV and see how your candidate was doing, if you could see the vote counts live and your candidate was safely ahead, you might decide it’s not even worth going out and casting a vote.]

## Races

Any particular office (be it a Senate or a President or local Sheriff) has a variety of candidates from a variety of parties. Generally we think of races as between two front runners, but people often vote for third parties or [write in candidate’s names](https://en.wikipedia.org/wiki/Write-in_candidate) and those votes need to be accounted for.

Here’s what we can agree on: A **race** is run by _n_ number of **candidates** for a single **office**.

You might say "at least we can assume the candidates are human" - but [you would be wrong](https://en.wikipedia.org/wiki/Non-human_electoral_candidates). Never assume in elections.

Every [eligible(!)](https://en.wikipedia.org/wiki/Voting_rights_in_the_United_States) person who lives in the area that candidate [represents](https://ballotpedia.org/Who_represents_me) (districts for the house, states for senators, the entire country for presidents) gets to vote between the candidates running for each office that represents them. ^[The election of Senators was not always given to the population in general. The framer’s constitution [left that to the states](https://www.senate.gov/artandhistory/history/common/generic/Feature_Homepage_ElectedStateLegislatures.htm). “The framers believed that in electing senators, state legislatures would cement their ties with the national government. They also expected that senators elected by state legislatures would be freed from pressures of public opinion and therefore better able to concentrate on legislative business and serve the needs of each state. In essence, senators would serve as “states’ ambassadors” to the federal government.” - it turned out to not work well because states never got around to electing them.]

## Voting

Constituents show up to their polling place. Or, well, [sort of](http://www.ncsl.org/research/elections-and-campaigns/absentee-and-early-voting.aspx). [39 states](http://www.ncsl.org/research/elections-and-campaigns/absentee-and-early-voting.aspx#overview) have mechanisms for early voting, 28 allow no-excuse absentee votes, 19 allow voting with an “accepted excuse”. [36 million people voted early in the midterm election.](https://www.politico.com/story/2018/11/05/early-voting-turnout-2018-elections-midterms-963149) - that’s about 30% of the [117 million](http://www.electproject.org/2018g) total votes cast.

When reporting votes, absentee votes are typically only available at the county-level and not be precinct.

### Voter Registration

In order to vote, an eligible potential voter must register. Voter registration is handled by government officials on the county and state level.

Once registered on voter records, voters can be removed for any of the following reason:
Voters can be removed from records for a few reasons:

- Disenfranchising criminal conviction
- Mental incapacity
- Death
- Change in residence
- Never eligible: under 18 or noncitizen
- Voter self-requests removal

### EAVS (Election Administration and Voting Survey)

[EAVS](https://www.eac.gov/research-and-data/studies-and-reports) is a report created from a survey of every state in the US with information about how elections are carried out.

### Voting systems

- [First past the post](https://en.wikipedia.org/wiki/First_past_the_post) is what most people think of. Voters mark a ballot with the candidate they want to win, and the candidate who receives the most votes wins.
- [Runoff voting](https://en.wikipedia.org/wiki/Two-round_system) works similarly, but there is a minimum amount of votes required. If no candidate exceeds that minimum, some candidates are eliminated and a second round of the election is held (usually with the top 2 ranked candidates).
- A [Louisiana primary](https://en.wikipedia.org/wiki/Louisiana_primary) is similar to an [open primary](https://ballotpedia.org/Open_primary) where all candidates running for an office appear together on the same ballot, including multiples per party (instead of a party picking a single candidate to run in a race). The race goes to runoff if no candidate wins by simple majority.
- Maine is the first U.S. state to enact [instant-runoff or “ranked choice” voting](https://en.wikipedia.org/wiki/Instant-runoff_voting)^[A variety of [major U.S. cities](https://en.wikipedia.org/wiki/Instant-runoff_voting_in_the_United_States) use ranked choice voting for local elections.] Instead of voting for one candidate over another, voters rank the candidates in order of preference.

![Maine ranked-choice voting ballot](//ej-fox.s3.amazonaws.com/blog/maine-ranked-choice-ballot.png)

The Center for Civic Design has a [great guide](https://civicdesign.org/fieldguides/designing-usable-ballots/) for designing ballots so they are usable, which [they are often not](https://www.propublica.org/article/disenfranchised-by-bad-design).

## Reporting units

The term “reporting unit” can refer to a boundary division of any size used to aggregate votes in an election. This can be a [town](https://en.wikipedia.org/wiki/New_England_town), [parish](https://en.wikipedia.org/wiki/List_of_parishes_in_Louisiana), [precinct](https://www.nytimes.com/interactive/2018/upshot/election-2016-voting-precinct-maps.html), county, [county sub-division](https://www.policymap.com/2015/09/county-subdivisions-the-secret-geography/) or state.

Presidential, senate, and gubernatorial races are organized by county and state.

House races are organized by house districts. The borders of these house districts are [primarily decided by state legislatures](https://ballotpedia.org/State-by-state_redistricting_procedures) but some <small>(AZ, CA, ID, WA)</small> are made by independent commissions. [538 did an excellent piece](https://projects.fivethirtyeight.com/redistricting-maps/) on congressional redistricting and gerrymandering.

## Election data

Once a vote is cast, ballots are counted and the counts are delivered to a central location and the numbers are reported in regular intervals (usually). That is all handled by state and local governments, often by county and state boards of elections.

The media (and by extension, the public) are given access to the vote counts at this point. Often times you can find a website run by the Secretary of State which will have the latest results for different statewide elections. Data services will pay reporters or [stringers](https://news.ycombinator.com/item?id=12912528) to go to the places where votes are counted to and send the results back to competing data services which then resell that data to news organizations (live election results are not cheap).

Election day vote and [exit poll](https://ballotpedia.org/Exit_polling) [result data](https://www.pewresearch.org/fact-tank/2016/11/02/just-how-does-the-general-election-exit-poll-work-anyway/) is provided to ABC, CBS, CNN, and NBC News in a consortium called the **National Election Pool**. The data is fed by [Edison Research](https://www.edisonresearch.com/election-polling/).

Alternatives for live data include [Decision Desk HQ](https://decisiondeskhq.com/) or the [AP Elections API](https://developer.ap.org/ap-elections-api/).

Historical data can be found from the above sources as well as from [MIT](https://electionlab.mit.edu/data) or [OpenElections](http://www.openelections.net/). [MapBox](https://www.mapbox.com/elections) also has pre-bound boundaries with historical data.

County-level presidential results 2008-2016 have been [collected in this GitHub repo](https://github.com/tonmcg/US_County_Level_Election_Results_08-16)

### Geographic Identifiers: FIPS Codes

States can be identified via their name (`New York`), [abbreviation](https://gist.github.com/mshafrir/2646763) (`NY`), or a state FIPS code ([36](https://www.mcc.co.mercer.pa.us/dps/state_fips_code_listing.htm)).

House districts are identified by their district code. New York’s first district is `NY-01`. Large states with smaller populations like [Montana](https://en.wikipedia.org/wiki/Montana%27s_at-large_congressional_district) have only one congressional district (“at large”), denoted like `MT-AL`.

I’ve seen various systems handle this different ways. Some designate these districts with `MT-00` so at least you can rely on two numeric digits when writing your code.

Counties are identified by [county FIPS codes](https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county). The first two numbers of a county FIPS code are the state code, which is handy.

### Mapping live election results

At NBC the Big Board is commanded by Steve Kornacki, who is the best in the business if you ask me. He stands by an enormous touch screen showing the latest vote results and explains what is happening and why it is interesting.

Typically he is pointing at a map of the country, or a particular state. That map has various counties or districts or shapes colored red and blue. ^[During my time at NBC, the rules about when to color shapes has been debated. House districts are only colored for a particular party when that race has been called (not projected) by the NBC decision desk. This means there is basically no chance it will ever change color. Counties, on the other hand, never technically have a “winner” but a “leader” who has a majority of votes in a particular county. Counties were colored by whoever was leading the votes. Once the first votes came in, if there were 50 for the D and 51 for the R, the county would color for the R.]

The election data comes in as a big list of states, counties, and districts. A handy way to refer to all of these buckets of votes at once is as a **reporting unit**.

Each reporting unit contains different races.

## Primary elections

In addition to the general elections that gather the most attention, parties hold their own elections to decide who will run against the other party, the [primaries](https://en.wikipedia.org/wiki/Primary_election).

These primaries can take [various forms](https://en.wikipedia.org/wiki/Primary_election#Primaries_in_the_United_States) including: uncontested (no challenger) or runoff/[Louisiana](https://en.wikipedia.org/wiki/Louisiana_primary)/[blanket](https://en.wikipedia.org/wiki/Nonpartisan_blanket_primary). They can be [open or closed, partially open, partially closed, etc…](http://www.ncsl.org/research/elections-and-campaigns/primary-types.aspx) - remember, [edge cases](#Edge-cases).

## Voting machines

[Voting machine](https://ballotpedia.org/Voting_methods_and_equipment_by_state)^[There are 4 main types of voting machines: **Optical Scan Paper Ballot** (little bubbles you fill out by hand), **Direct Recording Electronic** (computers with touch screens or buttons), **Ballot Marking** (a computer marks paper), and **Punch Card** (voters punch holes and avoid whatever [“hanging chads”](<https://en.wikipedia.org/wiki/Chad_(paper)>) are)] security in the United States is currently [a joke](https://www.wired.com/story/voting-machine-vulnerabilities-defcon-voting-village/).^[See the reports from the DEFCON Voting Machine Hacking Village in [2018](https://www.defcon.org/images/defcon-26/DEF%20CON%2026%20voting%20village%20report.pdf) and [2017](https://www.defcon.org/images/defcon-25/DEF%20CON%2025%20voting%20village%20report.pdf)] The joke is not funny when you consider the real-world impact of such an important lever of our society left comically unguarded.

The [OSET Institute](https://www.osetfoundation.org/) has compiled some data and an excellent team to work on the technology used for American elections, including defending from [threats of cyberterrorism](https://www.osetfoundation.org/research/2019/02/10/electioncyberterrorism).

## Coverage of elections

In 2018 I did some design research (captured in a [twitter thread](https://twitter.com/mrejfox/status/1021951616482795521?s=20)) and went through some old footage of NBC election coverage. I was even able to incorporate the effect of [numbers counting up](https://twitter.com/mrejfox/status/1021953888411430912) as they changed into the 2018 version of the Big Board.

I had the fortune to join a politics-covering media organization in 2016, a year when suddenly there was intense interest in how media organizations covered politics. Many feel the media failed in the coverage of the 2016 election.

I think it is worthwhile to listen to those criticisms and [think of ways](http://pressthink.org/2018/11/election-coverage-the-road-not-taken/) that things might be improved.

But we have a rat’s nests of problems to untangle from [horse race](https://en.wikipedia.org/wiki/Horse_race_journalism) coverage (which [might be good!](https://journals.sagepub.com/doi/abs/10.1177/1081180x98003004004)) to televised debates, [election polling](https://www.pewresearch.org/fact-tank/2016/11/09/why-2016-election-polls-missed-their-mark/) methodologies, and the ways polls should be covered.

### Horse race election coverage

Jack Shafer wrote in Politico about why [horse race election coverage might be good](https://www.politico.com/magazine/story/2019/01/09/why-horse-race-political-journalism-awesome-223867).

> By giving voters a window on the closed world of insider politics, horse-race stories help focus reader attention on the races. Without the work of election handicappers, coverage would come to resemble an endless series of policy white papers that nobody reads. The presidential campaign has another 22 months to run, leaving plenty of time and space to explore the contest from multiple perspectives.

### Election night 2000

At NBC the old heads would whisper to never fuck up as bad as they did back in 2000. A CNN internal report called their own election night coverage in 2000 [“a disaster”](https://www.nytimes.com/2001/02/03/us/report-calls-networks-election-night-coverage-a-disaster.html).

> Following the election night coverage – in which CNN, ABC, CBS, NBC, Fox and MSNBC all made wrong calls on the Florida vote – several networks ordered investigations of their coverage.

> Based largely on exit polling, the networks first declared Mr. Gore the winner in Florida, only to give the state to Mr. Bush later. Ultimately the networks backed off again, declaring the race undecided.

The coverage of 2000’s presidential election lead to executives from CBS, CNN, Fox, NBC, and the AP being [called to testify in front of congress](https://www.rcfp.org/networks-answer-congress-election-night-coverage/) by committee chair “Billy” Tauzin (R-La.).

> Much of the testimony focused on the networks’ reliance on exit polls and the flaws in the VNS system of conducting the polls.

> Tauzin introduced legislation to create a uniform poll closing time across the country and asked the networks to voluntarily resist projecting winners until 9 p.m. EST. In a concession, all the networks said they will refrain from calling a state until all the polls in the particular state have closed.

## Why do we have elections on Tuesdays?

It could be argued that it would make more sense for elections to be held [on the weekend](https://www.congress.gov/bill/112th-congress/house-bill/4183/text).

[Erin McCarthy wrote for Mentalfloss:](https://mentalfloss.com/article/12901/why-are-elections-held-tuesdays)

> Monday was out, because it would require people to travel to the polls by buggy on the Sunday Sabbath. Wednesday was also not an option, because it was market day, and farmers wouldn’t be able to make it to the polls. So it was decided that Tuesday would be the day that Americans would vote in elections, and in 1845, Congress passed a law.

## Resources

- [Ballotpedia](https://ballotpedia.org/) is an exceptional source of all of the strange little constantly-changing details about elections, --freely editable like Wikipedia-- edited by [Ballotpedia staff](https://ballotpedia.org/Ballotpedia:Staff).
- [election-geodata](https://github.com/nvkelso/election-geodata) is a great collection of geographic precinct shape data for mapping election results.
- [OpenElections](http://www.openelections.net/) is an open-source project made to create a “free, comprehensive, standardized, linked set of election data for the United States, including federal and statewide offices” which is a pretty incredible goal if you ask me.
- [270toWin](https://www.270towin.com/historical-presidential-elections/) has great maps and information on historical elections.
---
dek: "In which the author's adoration for Obsidian is revealed, celebrating its versatility, customizability, and ingenuity in organizing the written word"
inprogress: true
date: 2023-04-04T14:48:13-04:00
modified: 2023-08-09T14:13:19-04:00
tags: personal process writing quantifiedself systemsthinking
---

# Why I love Obsidian for organizing my notes and blog posts

#process #personal 

I am always on the lookout for tools that can enhance my creative process and help me organize my thoughts more efficiently. When I discovered Obsidian, it was as if I had found the perfect companion for the way my brain works. I want to share my love for Obsidian, highlighting its features, customization options, and how it has revolutionized the way I work.

![A screenshot of my Obsidian workspace: the top left pane has a list of files, the bottom left pane has a local network graph of notes and tags related to this one, the main pane has the content of this post, the top right pane has Smart Connection-powered similar articles, and the bottom right pane has an outline of the table of contents](Screenshot%202023-04-04%20at%202.44.48%20PM.png)

## The power of Markdown

Obsidian's use of Markdown as its primary language makes it incredibly versatile and easy to learn. I've been using Markdown for over 10 years, so it comes naturally. The simplicity of Markdown allows me to focus on my writing without getting bogged down by complex formatting or WYSIWYG tools. Moreover, its widespread adoption ensures compatibility with various platforms and tools, making it a true lingua franca for digital writing.

## Great plugin framework and community

One of the most exciting aspects of Obsidian is its thriving plugin community. This diverse ecosystem of plugins allows me to tailor my writing environment to suit my specific needs and preferences. From simple productivity enhancements to advanced features like graph views and AI-powered note suggestions, the possibilities are virtually endless.

## Using Obsidian with Nuxt for my website

I have also built a customized system that automatically publishes my notes from Obsidian to my website while excluding drafts. This seamless integration between my note-taking and publishing process has streamlined my workflow and made sharing my thoughts with the world easier than ever.

### Syncing blog content with rsync

In order to synchronize my notes (minus drafts) I use rsync and grab the markdown files from the place where Obsidian keeps them for auto-syncing.

```js[package.json]
"scripts": {
    "content:blog": "rsync -avz --delete --exclude='/drafts/' --include='*.md' --exclude='*' ~/Library/Mobile\\ Documents/iCloud\\~md\\~obsidian/Documents/EJ\\'s\\ Notes/ ~/code/website/content/blog/",
    "content:reading": "rsync -avz --delete --exclude='/drafts/' --include='*.md' --exclude='*' ~/Library/Mobile\\ Documents/iCloud\\~md\\~obsidian/Documents/EJ\\'s\\ Notes/reading/ ~/code/website/content/reading/",
    "content:all": "npm run content:blog && npm run content:reading"
  },
```

## Graph views

Obsidian's graph view feature offers a unique way to visualize the connections between my notes, revealing patterns and relationships that might have otherwise gone unnoticed. This bird's-eye perspective on my writing helps me identify gaps in my understanding and inspires new ideas for exploration.

## Canvas view

## Great mobile support & iOS app

## Community plugins
### Syncing reading

With the [Obsidian Kindle Plugin](https://github.com/hadynz/obsidian-kindle-plugin), I can effortlessly sync my Kindle highlights and integrate them into my notes, making it easy to reference and incorporate quotes from my favorite books. This centralized repository of knowledge has become an invaluable resource for my writing and personal growth.

### AI-Powered Note Suggestions

By leveraging the power of OpenAI embeddings through the [Smart Connections plugin](https://github.com/brianpetro/obsidian-smart-connections), I can discover similar notes and quotes within my Obsidian vault. This intelligent feature saves me time and ensures that I never miss an opportunity to enrich my writing with relevant insights from my past readings.
---
draft: true
dek: CSV, JSON, Datasette, Observable, QGIS, Nuxt, Vue, D3, Tachyons, Supabase
inprogress: false
date: 2022-11-02T19:58:19-04:00
modified: 2023-09-09T14:49:22-04:00
tags: programming process
---

# 2022 Toolkit for Prototyping

See also [[my-vscode-setup]]

## Tools
### CSV and JSON

CSV (Comma Separated Values) and JSON (JavaScript Object Notation) are the ideal file formats for storing and exchanging data. They are both lightweight, human-readable, and easily parsed by programming languages, making them ideal choices for handling data in your prototypes.

### CSVkit

CSVkit is a powerful command-line tool for working with CSV files. It simplifies tasks like filtering, sorting, and converting data between different formats. By incorporating CSVkit into your toolkit, you can save time on data manipulation tasks and focus on building your prototype.

### Datasette

Datasette is an open-source tool that allows you to explore and publish data using a web interface. It supports various file formats like SQLite, CSV, and JSON, enabling you to quickly create interactive web applications with minimal effort.

### Observable & Plot

Observable is a platform for creating interactive data visualizations using JavaScript. Its built-in library, Plot, makes it easy to generate beautiful charts and graphs with just a few lines of code. By leveraging Observable & Plot in your prototyping process, you can bring your data to life and create engaging user experiences.

### QGIS

QGIS is a powerful open-source Geographic Information System (GIS) that enables you to create, edit, and analyze geospatial data. With its extensive set of features and plugins, QGIS is an invaluable tool for developers working with location-based data in their prototypes.

### Vue and Nuxt

Vue.js is a popular JavaScript framework for building user interfaces, while Nuxt.js is a higher-level framework built on top of Vue.js that simplifies the development of universal applications.

#### Vue over React

Both Vue.js and React are popular choices for front-end development, each with its own strengths and weaknesses. I prefer Vue because it works the way my brain works, and I really like the community and ecosystem of plugins. The time and care spent on developer experience makes it a joy to write code, which is invaluable for maintaining flow. 

### Tachyons

Tachyons is a functional CSS framework that promotes fast-loading, highly-readable, and easily-maintainable code. By using Tachyons in your projects, I can rapidly prototype responsive designs, and I am able to prototype complex layouts in realtime using live reload and the built-in classes. 

### Supabase

Supabase is an open-source alternative to Firebase that provides a suite of tools for building modern web applications. It includes features like real-time databases, authentication, and storage services. Integrating Supabase into your toolkit can simplify the process of building full-stack prototypes.
---
date: 2022-11-02T20:01:31-04:00
modified: 2023-09-09T14:44:33-04:00
dek: In which we go into detail about how to write code to accomplish a goal
inprogress: true
tags: tech 
---
# The Art of Coding: A Developer's Guide

#programming #personal #process 

![](https://res.cloudinary.com/ejf/image/upload/v1679587770/610144184_A_curious_man_in_a_flatbrim_baseball_cap_and_a_short_cropped_brown_beard__flying_over_a_sea_of_blog_.png)

From personal projects to collaborations, paid work to passion projects, lets explore how I write code to achieve specific goals. We'll discuss the importance of clear goals, user stories, acceptance criteria, deadlines, and our core guiding principles.

The rough shape of the project changes depending on a few factors:

- Personal project vs group project
- Paid vs unpaid
- Fast vs slow
- Public vs private

For more less-technical specifics around project management in general (not just code): [[how-to-run-a-project]]

For design philosophy [[design-philosophy]] and work philosophy [[joy-driven-development]]

The tools I use to prototype quickly: [[2022-prototyping-toolkit]]

My coding setup, including theme and plugins: [[my-vscode-setup]]

# Establish a clear goal

Sometimes the goal of a project can boil down to **"who are we trying to make happy?"**

That could be a particular type of user, or it could be a powerful stakeholder, or the person who commissioned the project. Who controls the future of this project and what are they trying to get out of it? How can we make them happy?

On personal project the goals might not be so clear, and it's worth digging into why something is interesting and putting it into words. Treat yourself as your client, with all the patience and diligence that implies. Write yourself a clear and comprehensive brief that you can come back to later.

Personal projects can be beneficial for a variety of reasons:

- Explore personal curiosities
- Learn new technologies / techniques
- Collaborate with cool people 
- Create material for self-promotion
- Create work that you want to do more of

You can usually only accomplish a few of those goals, and knowing the bounds of your motivation for a project can help you avoid diving deep into the wrong areas and getting burnt out. 

## User stories

User stories are essential to writing software that will be used by people. I talk more about user stories in [[how-to-run-a-project]]

### tl;dr

> User stories are a way of describing the functionality of a system from the perspective of the user. User stories are written in the following format:
> "As a *type of user, I want *goal* so that *reason*."

## Acceptance criteria

Acceptance criteria are predefined rules that determine whether a given feature or piece of functionality is working as intended. They are a set of statements, with a clear pass or fail result, that specify both functional and nonfunctional requirements, and are used to assess the success of a project. These conditions must be met to consider a project successful.

Acceptance criteria help to create a shared understanding between team members, clients, and stakeholders about what is expected from an engagement. It's important that they are clear, specific, measurable, and easy to validate.

I often write my acceptance criteria in the form of user stories.

## Deadline

Deadlines, while sometimes stressful, actually serve an important role in managing your work. They help to frame the timeline and encourage focus and productivity. A clearly defined deadline sets the expectation for when work should be completed and ensures that everyone is working towards the same goal.

### Do not break deadlines

## Core principles

[[joy-driven-development]]

## Gather context
### Stakeholder Needs

Knowing who the stakeholders are and what they expect from the project is crucial. Needs could range from project timeline, budget, technical specifics, to the business impact.

### Project Goals

Understanding and articulating the main objectives behind the project, along with what problem the project aims to solve.

### Technical Infrastructure

Understanding the tools, platforms, or systems that will be used during the project helps in planning and implementation.

### User Expectations

If the project involves a user base, understanding their expectations and needs can significantly enhance the project's design and usability.

### Market Trends

Keeping abreast of existing market trends, both direct and indirect competition, can inform the strategy and positioning of your project.

### Prior work

Before starting a new project, it's beneficial to research and understand the work that has already been done in the area. Existing solutions, projects, or research might provide valuable insights, lessons learned, or even spark new ideas. Evaluating prior work can also prevent you from duplicating efforts or repeating the same mistakes.

### Terminology / names

Every industry or project often has its own set of unique terms, names, or jargon. Familiarizing yourself with these terms can hugely impact your understanding of the project and improve your communication with stakeholders and team members. Trying to speak the same language as your users or clients can foster better understanding, and convey professionalism and competence.

When creating new things, often new names need to be invented. I try not to be too precious about this process. The key is to just pick a sensible name for a thing and stick to it, until a better taxonomy develops and it makes sense to rename it. It is often very difficult to rename things once the name has been embedded deeply into the code. Only the bravest developers rename existing variables, especially deeply-entrenched ones. 

### Carefully pick your tools

Not every project will require the same set of tools. Depending on the project's nature, the 'right' tools can hugely differ. It's important to identify and understand the tools available that could aid your project's development, whether they're software for task management, design tools, coding platforms, analytical tools, or even physical equipment if relevant. They can save time, increase efficiency, and provide new capabilities.

Often the most productive developers aren't the ones with the most experience or domain expertise, but those with the best set of tools for a particular problem. 

## Gather data and explore

Data forms the backbone of any data visualization project. The type and amount of data needed will depend on the project's complexity and scope. Gathering useful data is a systematic process involving identifying data sources, collecting information, cleaning it, and then verifying its accuracy and relevance. 

In the exploration phase, objective analysis of the gathered data can reveal patterns, trends, and insights that inform your project direction and strategy.

## Metadata: what’s there? What’s missing?

As we navigate the development process, one crucial step is managing metadata - the information about our data. It's key in understanding the depth and quality of assembled data and integral to interpreting it correctly.

Observing what data exists and recognizing what's missing allows us to validate our data's completeness and reliability. Like a pre-flight checklist for a pilot, knowing your metadata and any gaps that exist helps you anticipate and mitigate any potential hiccups when using the data to drive your project decisions. It ensures the journey ahead relies on dependable, comprehensible information.

## Go Wide, Establish Possibilities

In this stage of the process, the objective is to broaden the horizons of your project and explore as many possibilities as you can. This is the brainstorming phase where no idea is dismissed prematurely. Encourage out-of-the-box thinking and don't limit your exploration to just the tried-and-true.

This step might involve several techniques like:

- **Mind Mapping:** This visual tool can help you organize thoughts, ideas, and potential solutions related to your project.
- **Prototyping:** Quick hands-on experiments or simulations can provide insights on feasibility of ideas.
- **Notebooks:** Jotting down or sketching ideas can help retain them and facilitate deeper analysis later.
- **Clients feedback and iteration loops:** Engaging stakeholders at this stage can bring in fresh perspectives and align ideas better to actual needs.

By stretching the possibilities wide in this stage, you ensure you have multiple approaches or solutions to choose

### Visual Forms for data

The use of visual forms in the exploration stage is instrumental. They convert raw data into insightful visuals, leading to an enhanced understanding and drastically improving the quality of the project:

#### Numeric Values: Scatterplot

Scatterplots illuminate trends or outliers in numeric data, providing a clear path to impactful solutions. 

#### Geographic Data: Map

Maps transform location-based data into discernible patterns, opening up the landscape for strategic decisions.

#### Data with Time: Line Chart or Animation

Line charts or animations translate progression over time into visible trends, illuminating the path forward.

#### Everything: Tables

Our goal is not to visualize data just to make our work beautiful– sometimes the clearest way to convey some information is a simple humble table. 

## Make a prototype

In the developmental journey, crafting a prototype is your first step towards making your project tangible. A prototype, often developed with Vue/Nuxt in my process, is a functional, interactive model that embodies your design vision. 

A prototype primarily serves as a validation tool - a way to test design hypotheses, functionality, and gather initial user feedback. Prototypes might not encompass the full functionality of the final product and often focus on testing specific aspects of the design. As such, they're meant to be iterative, changed, and refined based on user feedback and testing outcomes. 

An important distinction to make is between a prototype and a Minimum Viable Product (MVP). While they seem similar, their purpose and scope differ. An MVP is a pared-down version of your product that includes just the core features necessary to make it work and deliver value to users. It's more polished than a prototype and is generally used to see how the target audience responds to the product's main idea. While the prototype is more for internal validation of design ideas, an MVP is put in front of actual users.

### Designing an MVP

When designing a Minimum Viable Product (MVP), the goal is to develop a product with the smallest possible feature set that still delivers core value to the user. To achieve this, everything we've done so far comes into play.

The understanding gained from gathering context about user needs, project goals, and stakeholder requirements informs what your MVP must achieve. The data exploration and visual forms help you grasp the intricacies of the data your MVP will handle, influencing design decisions. 

Starting with a mobile-first design helps focus on what's essential. On smaller screens, every element matters and unnecessary complexity can ruin user experience. This approach forces you to prioritize features, displaying only what's crucial on your MVP.

Using tools like Figma, create interactive high-fidelity prototypes to visualize the flow and feel of your MVP. Use it to try out different design possibilities and interaction patterns before committing any code.

It's important here to think in terms of problem-solving, not feature-building. Keep asking: what is the simplest solution that solves the problem for our users?

When defining the scope of your MVP, consider data prototypes too, especially for products involving complex data interactions. They allow you to test feasibility and performance early on.

At this stage, a key mantra should be: don't fall in love with your ideas. Be open to discard features or elements if they do not serve the primary goal of your MVP. 

Ultimately, designing an MVP is about discerning what's absolutely necessary for your product to provide its core value, and having the discipline to say 'no' to everything else until after validating the MVP. It is a challenging process but essential in creating focused, valuable products while minimizing wasted efforts.

## Visual design and polish

Post-MVP, attention turns to enhancing user experience with aesthetics. It's more than just colors and fonts; it's about intuitive, consistent visuals that boost user engagement.

Visual design gives your product its aesthetic appeal, aligning it with the brand's identity and improving user experience. It includes aspects like color schemes, typography, iconography, layout and spacing, among others.

Polishing your product involves refining every element and interaction to make sure it's smooth, intuitive, and visually pleasing. It's about paying attention to small details like consistency in design elements, easy-to-read fonts, sensible animations, effective color contrasts, and so on.

## User Testing

User testing is the pivotal phase where your product, the MVP you designed and polished, is put to the test in the hands of actual users. It provides crucial insights into its usability and any potential areas for improvement.

### The User is Always Right

During user testing, one mantra to remember is: The user is always right. If users struggle with a certain feature or can't navigate through your app intuitively, it indicates that changes are needed. This feedback is invaluable in improving the product and enhancing user satisfaction. After all, a product that doesn't meet user needs or isn't user-friendly will struggle to find success.

### Be Open to Big Pivots

It's also essential to remain open-minded and ready for change during this stage. Sometimes, user testing might reveal that significant changes (or pivots) are necessary for your product to work effectively. These pivots could range from minor feature tweaks to a complete overhaul of certain aspects. Being flexible and open to these big pivots can significantly improve your product's final version.

### Beginners Mind is Invaluable

Approaching user testing with a 'beginner's mind' can be invaluable. This mindset allows you to observe and understand users' experiences without preconceived notions, helping identify pain points or difficulties a more experienced eye might overlook.

## Documenting the Process

The process of developing a project is a journey filled with valuable insights, decisions, and iterations. Documenting this process serves several purposes:

- It provides a historical record of your project, allowing you to trace back your steps, understand the decisions made, and learn from them.
- It facilitates communication and transparency with stakeholders, clients or team members. They can see the progress made, understand the reasoning behind decisions, and contribute more effectively.
- It's a great tool for reflection and learning. Looking back at your documentation can provide insights into your working style, efficiency, and areas for improvement.

There are several ways to document the process effectively:

### Screenshots

Visuals can communicate information quickly and intuitively. Regularly taking screenshots of your work - be it design drafts, code snippets, bug reports or user feedback - can create a rich visual timeline of your project.

### Working in Public

Sharing your work progress publicly (e.g., on social media or a blog) not only serves as documentation but also invites feedback and creates accountability. It can foster community engagement and even attract potential users or clients.

### Working in semi-Public

Even if you aren't sharing your work publicly, you can "liveblog" your progress in your company's shared chat channels. 

### Live-Streaming

Live-streaming your work sessions is another form of real-time documentation. It gives people an inside look into your workflow and decision-making process. This transparency can build trust with clients or users and facilitate learning for others in your field.
---
dek: In which the author muses about 2013-era web design aesthetics
type: words
hidden: false
inprogress: false
date: "2013-01-25T18:34:00-05:00"
hidetimestamp: false
---

# The Magazine Experience on the Web

**For the past couple of years, I’ve been obsessed with the metaphor of the online magazine.**

I think the web has more to offer a storyteller’s end product than previous venues. Seamless combinations of mediums will continue to evolve, inspired by the traditional magazine’s “special feature”. _This evolution will raise the bar for anyone, journalist or otherwise, who wants to tell stories on the web._

I know I’m not the only one. People already [understand that the attention span of readers is dwindling](http://www.niemanstoryboard.org/2010/07/09/short-attention-span-theater-peggy-nelson-on-narrative-and-models-of-interaction/), [and](http://www.marco.org/2012/10/11/the-magazine) [bite-size articles](http://www.digiday.com/publishers/making-news-mobile-friendly/) [are important](http://ejfox.tumblr.com/post/34820860800/circa-is-one-of-the-first-real-recent-steps-forward-in). But simply adding photos to accompany your articles online doesn’t have the brilliant exclamatory effect it does in magazines. Users want more.

Recently the entire web discovered infographics, for better or worse. For a year or more they packed an instant appeal, designers could take any set of information, make it understandable and visual and people would flock to it and share it. In part because infographics were new, but also because their brevity mirrored the fast pace of the contemporary web surfer.

But I fear that golden age [has](http://flowingdata.com/2012/04/10/how-businesses-approach-infographics/) [passed](http://flowingdata.com/2012/07/04/infographics-are-like-mothers-day-cards/). _Static infographics on the web use only a tiny portion of the web’s potential_, and as users [grow more savvy](http://flowingdata.com/2011/12/08/on-low-quality-infographics/) they are realizing this as well.

## A hint of what's to come

Recently, The New York Times- ever the pioneer of online storytelling- released [Snow Fall: The Avalanche at Tunnel Creek](http://www.nytimes.com/projects/2012/snow-fall/#/?part=tunnel-creek) which was received with [high praise](http://www.poynter.org/latest-news/top-stories/198970/how-the-new-york-times-snow-fall-project-unifies-text-multimedia/) in journalist-nerd circles and beyond. There are a couple of unique points about the snow fall piece:

- _It's graphics and videos stretch to fill the entire browser window_, an emerging design trend that is the true successor of the magazine’s full-bleed photos. The Times shows that when you elevate beautiful art that’s telling the story in a seamless way, it becomes greater than the sum of it’s parts. Compare to a [similar NYT story](http://www.nytimes.com/2012/10/14/magazine/californias-central-valley-land-of-a-billion-vegetables.html) where pictures are included with the story, but certainly not featured with any love.
- It’s not confined to the style of the rest of the NYT site, which is for the most part a static 975px width. Some of the impact of full-bleed pieces like Snow Fall comes from the contrast between those special features and the whitespace of the primary site. It’s a clue to the user to dig in, and that something special is going to happen.

Some critics said that [this kind of storytelling indulgence isn’t a sustainable future of journalism](http://www.theatlantic.com/business/archive/2012/12/snow-fall-isnt-the-future-of-journalism/266555/) because of the **16-person team** required to create the piece. I think that this view forgets a time when computers filled entire rooms with as much processing power as your iPod. _I think one day (soon!) journalists will be able to do this with as little as one person_, but probably in teams of 2 or 3.

That sort of criticism gets me going too, because I know that [there](http://d3js.org/) [are](http://raphaeljs.com/) [technologies](http://developer.nytimes.com/docs) [out](http://vis.stanford.edu/wrangler/) [there](http://www.quora.com/GitHub/What-are-some-interesting-repositories-on-Github-that-can-be-used-for-journalistic-purposes) [that](https://github.com/datawrapper/datawrapper) [are](http://nvd3.org/) [just](http://timeline.verite.co/) [within](http://leafletjs.com/) [reach](https://github.com/jsoma/tabletop) of every modern journalist willing to [try](http://www.symboliamag.com/post/40203443720/editors-note-people-frequently-ask-us-how) [new ways](http://www.wired.com/wiredenterprise/2012/02/github-revisited/) of [telling their stories](http://source.mozillaopennews.org/en-US/articles/mother-jones-voter-suppression-map/). [I want to help make those tools.](http://ejfox.github.com/sStory/) I want, like others, to bring that wonderful magazine experience to the web like we haven’t seen before. But there are a handful of problems to solve and gaps to bridge before we can reach our potential.

## Full Bleed Photos

One of the greatest experiences of reading a magazine is the beauty of the first page of an article, especially one beautiful photo spread across two pages.

The Snow Fall piece echoes this aesthetic perfectly. [Others come close](http://www.theverge.com/2013/1/8/3850056/qualcomms-insane-ces-2013-keynote-pictures-tweets).

_Why aren't we seeing more of this?_ Perhaps it is due to a old-school desire of having a fixed-width site that accomodates the lowest-common-denominator screen size. But with our industry embracing responsive design I think we can do better. New(ish) CSS properties like `background-size: cover;`(http://css-tricks.com/perfect-full-page-background-image/) allow us to have full-screen photos that are responsive too. There’s no reason not to make your images big and bold. This is the technique I employ in my [sStory project](http://ejfox.github.com/sStory/).

Combine that with [easy access to good typography](http://designshack.net/articles/css/10-great-google-font-combinations-you-can-copy/) and you can create some beautiful things.

## Collecting stories differently

When I covered the Occupy Oakland protests throughout 2012, I didn’t think of myself as a photographer, writer, tweeter, or film maker. But I still brought out my field audio recorder, my camera, and my DSLR.

_Some moments want to be documented differently._ A crowd chanting in response to a speaker is more powerful audio than it is a photo (though combined I think they are greater than the sum of their parts). The same can be said for the difference between a photo and video of an officer arresting someone. _Our storytelling technologies should be able to seamlessly combine what we gather._ We should be able to see a quick video teaser of the article. Then a user should be able to press play on an audio documentary of an event, then scroll down the page reading a reporter’s summary of it, perhaps highlighting sections in the text and even pictures when the audio is relevant. Quotes in the text, for example, could be higlighted when the speaker says the words in the audio.

## Seamlessly importing more mediums

The interplay of mediums the user can’t control (audio / video) and their scrolling will be a key piece of the puzzle to figure out. What happens when a user is listening to the audio of one section but moves on to the next? Do we automatically play the new section’s audio? Do we ask them? Do we cut our audio down into smaller clips that are activated as a user reaches subsections of the project to try and avoid the situation?

_How do we ensure our stories make sense if a reader simply consumes the text and images of the story without engaging with any of the enhanced features?_ The answer has long been a key tenant of web design; degrade gracefully. The additional mediums we include should, for the most part, be enhancements on a straightforward story. Let the user dive in to a particular section if it interests them, and collect all of the information and images and reporting necessary to fill those needs. But for the user who wants to get their information and go, we shouldn’t get in their way. And that is a careful balance.

## Great presentation requires great stories

One of many obvious shortcomings in the incoming wash of subpar infographics is that all of the information included in them, important or not, is presented as the most important thing you should read all day. Much like a graphic [loudness war](http://en.wikipedia.org/wiki/Loudness_war) users are berated with facts they don’t care about dressed up well enough to make it past their initial reflexive bullshit-detectors, if only for a second or two. And users don’t like that. _Infographics add value by doing the work of pointing you towards what’s interesting and why (by cutting out a lot of shit!)_, not by making every fact in your report world look interesting. _The same should be true of these “special feature” web stories._ It is not a technique to turn lead into gold, but merely to do justice to the wealth of engaging journalistic mediums we have access to today.

## Everything should be naturally responsive

Your story should be able to be enjoyed no matter what screen is being used, and this means [responsive design](http://www.niemanlab.org/2012/12/the-year-responsive-design-starts-to-get-weird/). Making stories that were created to be pixel-perfect on one screen size, and then translating them into a responsive design is approach the problem wrong. The storyteller should go into the process knowing that what they make needs to hold it’s own whether on an iPhone or a desktop.

Eventually we will come to the problem of [responsive content](http://www.mediabistro.com/10000words/journalism-trend-to-watch-reader-aware-and-responsive-content_b16300). Following the age-old journalist’s pyramid of importance, we could simply chop off some extraneous paragraphs when the article is viewed on mobile. Another possibility is an editor (or an algorithm!) might re-write a **[TLDR](http://toolong-didntread.com/)** version better paced for a mobile reader. I am excited to see how this problem gets solved, but I think for now, users on mobile are usually willing to work their way through a long piece of content if broken up elegantly.

## Finding the path

_The only way forward is through experimenting_, in every way possible. As traditional newspapers gasp for air, new journalists with an innate understanding of how to tell stories on the web each take their own strike at figuring out the new way forward. _We can’t be tied to simply translating print metaphors to the web._ And as much as I think the editors, designers, and developers of news websites today know that, for the most part they’re still doing it.

It’s time for all of us to find a great story, and apply these new storytelling methods to it. If an interactive piece about an avalanche can be riveting, where are it’s descendants tackling tougher issues like war, civil unrest, and urban poverty? These are all stories with intricacies that deserve exploration in multiple mediums. We must give them all that we have, all the technology, all of the knowledge, all of our skill in storytelling to grab the attention of readers.
---
dek: In which the author is grateful for the hackers who invented the internet
type: words
hidden: false
inprogress: false
date: "2019-02-01T12:08:56-05:00"
hidetimestamp: false
---

# The Internet Was Built To Be Hacked

Nothing we ever do is truly novel, no matter how much we convince ourselves it is. Faced with nearly any seemingly insurmountable problem, you can easily scare up comparable examples from the not-too-distant past.

You often find heroes who saw the darkness and then dedicated their lives to alerting everyone and future generations to a better way. We largely ignore those people, it seems.

But the systems that we have inherited were designed in certain ways. The internet, and computing in general, is an interesting example. The roots of computing go back to the eternal struggle between free-spirited hackers with long beards and men in suits who want to make profits.

Yet that struggle seems to have blossomed into something that encompasses our whole lives. Friendships maintained or forgotten. Money made or spent. Elections won and lost based on systems that we inherited and are seemingly unchangeable.

But what is so crazy is the fundamental building blocks of the internet were designed to avoid monopolization and manipulation. The system is built in a way that leans towards what I believe is a freer world, a place where things are shared instead of commodified. But the struggle between good and evil continues.

The tools of self-governance, of self-creation, the ability to control our own destiny- are being robbed of us by certain silicon valley entrepreneurs, scheming suits, and a gang of arrogant money hounds who treat human attention like the new oil.

The internet has evolved into a place where we have all accept pre-fab houses, presenting ourselves in Facebook blue, homogenized and consumable. Consumable first to corporations and advertisers, secondly to each other. But at best this an abnormal and new way for humans to interact and present ourselves to each other. At worst it is robbing us of something seemingly indefinable- our individuality, our ability to express ourselves, our ability to decide what we see and when.

It is hard to turn off a machine, no matter how crooked, when they have asked us to store our friends and family inside it.

The number of artists whose whole body of work, and not only that, but their connections to other artists and potential future income, all stored inside the machine. It is hard to feel all of this was done by accident.

The virtual world is remarkably more shapeable than the physical world. It feels no less real- and the creations we have made that we can experience and inhabit can easily be related to physical wonders like huge libraries or museums.

The internet was built with an idyllic vision where everyone could craft anything they wanted and give that, freely, to anyone else. The plumbing of the internet was built by dreamers, anarchists, and hackers. We have seen only a portion of the impact these ideas have had on the world, and already we are in awe. The world is already changing more quickly than we can comprehend.

Much of our current world ties back to the stew of hippies and hackers in California in the late 70s and early 80s that birthed much of the technology we use. Academics and college students and computer scientists bounced off each other and got a lot of things rolling in ways we still experience today.

> "The e-mail list started at Stanford a decade ago, now connected to MIT, has gotten so big that it needs to be split into two: Dead-Heads, for people who only need to have the set lists and tour dates… and Dead-Flames… for the people who want to talk about everything. They burn through memes in a way that won't become common to the rest of the world for almost a quarter century.
> <cite>Jesse Jarnow in "Heads: A Biography of Psychedelic America"</cite>

We can barely understand the ability ideas have to spread from person to person now. The only thing we can relate it to is viruses– going viral. Ideas can spread like a cough, person to person, out of the control of any leader, director, or king. They can be a joke, or a dance, or a rhyme like they've been for thousands of years. Or they can be ideas like freedom, liberty, truths that powerful people don't want told. We've seen the effects of those memes too.

Individual freedom, liberty, and the ability to express yourself to the world around you are embedded in the DNA of computing and the internet. At least for now.

But 200 years ago, to spread an idea far and wide, you had to travel by foot and tell people yourself. There were human limits to your impact. Maybe you came from the right family, the right race, had the right amount of money and could access a printing press, let alone the time to write. We lost out on a tremendous amount by not building a system where we could listen to anyone's ideas. Systems kept the powerful in power and reinforced themselves.

I like living in a world where everyone has the ability to express themselves on the most powerful mechanism humans have ever created to do so. Computers – and the worldwide network we have built to tie them together – are such an amazing, world-changing thing that our human minds can barely comprehend the speed and completion with which our world has changed. And is changing. And will change.

We have direct access to all of that. We have the ability to harness some of the most advanced technology that not even the richest and most sophisticated have figured out what to do with. But there are a lot of people who want to monopolize that power for a variety of motives.

I like the idea of living in a world where everyone has hand-crafted their own house because I want to live on that block. I want to see the ways people express themselves. I want to visit those houses. I think the will of humanity in the absence of self-imposed scarcity bends towards goodness and beauty.

> "It is quite clear that the society of open-source hackers is in fact a gift culture. Within it, there is no serious shortage of the 'survival necessities' – disk space, network bandwidth, computing power. Software is freely shared. This abundance creates a situation in which the only available measure of competitive success is reputation among one's peers"
> <cite>Eric S. Raymond in "The Cathedral & The Bazaar"</cite>

There is definitely some privilege required to learn how to code. You need consistent access to a computer, electricity, the internet. You need time in your day, you need to have food in your belly. But compared with the effort required to get a message to 100 or 1,000 or a million people without a computer, it is easier than it ever has been to make an impact on the world. We will continue to see that impact us all in beautiful and terrible ways.

> "Online communication has given rise to a new global commerce in ideas, information, and services. Because electronic messages readily cross territorial borders, and many online transactions have no necessary relationship to any particular physical location, existing geographically based legal systems have difficulty regulating this new phenomenon. This creates a new form of law– a law of cyberspace… Will this emerging cyberlaw provide 'due process'? Will it, in other words, respect basic principles of fairness, as embodied in current legal doctrines?"
> <cite>David R. Johnson in "Due Process and Cyberjurisdiction" 1996</cite>

The only necessary right we have in our new digital world is to move on to new systems or create our own. We were given those with intention. But we will have to defend those rights.

Too often I think our natural instinct as citizens of particular pockets of the internet is to petition our feudal lords for the changes we want to see. We often forget we have the ability to create our own world, craft our own future to our liking. I suppose it is a hard lesson because it is so different from the reality we inhabit outside of the virtual world. But that it is why it is so interesting and powerful and worth defending.

But how do we do that?

How do we seize back the means of self-expression on this amazing network we've inherited and built together?

It requires sorting through a world of tools and services and seemingly-friendly fellow travelers and looking for those that share those core ideals. People who have pledged in one way or another to abide by those original shared goals. Or at least enough of them for us to work together. Sometimes referred to in shorthand as "The Hacker Ethic" or "Open Source" or "DIY" there are a set of ideals that help people create tools that can be bound together without sacrificing the ability to modify them or fix them or leave them altogether if you find a better tool later.

Little pockets of hackers exist on the internet solving their own problems– and yours too. They share them freely partially because it is the right thing to do, and because it's easy, and because they share the hacker ethos.

The future lies with with those hackers and the kids that we teach those skills to.
---
date: 2023-01-15T15:08:41-05:00
modified: 2024-05-05T21:17:23-04:00
---
%% Zoottelkeeper: Beginning of the autogenerated index file list %%

- [[project-notes/climate-trace-exploration|climate-trace-exploration]]
%% Zoottelkeeper: End of the autogenerated index file list %%
---
date: 2024-05-05T21:14:07-04:00
modified: 2024-05-05T21:17:26-04:00
---

Problem: When working on stories, I record hours of interviews. I wish it was easier to get a sense of what was covered, follow transcribed text to the actual audio clip, and otherwise explore a whole bunch of audio in intuitive ways using audio trasncription, chunking, and embeddings
---
date: 2024-01-10T21:34:32-05:00
modified: 2024-01-10T23:25:27-05:00
---
## Hourly Data Refresh:

• Latest Updates: Lil Fox receives updated data every hour, including new notes, bookmarks, and any other relevant information.

• Constant Cross-Referencing: It continuously cross-references this new data against the identified weekly themes and notes from Obsidian.

## Integrating Things To-Do List:

• Cron Job on Your Computer: You set up a cron job to run a script that uses the Things CLI to export your "Today" to-do list.

• Data Transfer: This script then sends the to-do list to your Supabase instance using curl . The data includes tasks, their priorities, deadlines, and any notes you've attached.

• Lil Fox Accesses To-Do List: Lil Fox regularly accesses this updated to-do list from Supabase.

## Decision Making and Task Prioritization:

• Context-Aware Task Suggestions: Based on the latest hourly data and your to-do list, Lil Fox suggests tasks that align with your ongoing weekly themes or urgent priorities.

• Adaptive Scheduling: It considers your current energy levels (using health data) and interest areas to suggest the most appropriate tasks for the current hour.

## Reporting and Interaction:

• Regular Summaries: Lil Fox provides you with regular summaries, including progress on weekly themes, upcoming tasks, and any newly identified opportunities or insights.

• Interactive Commands: You can interact with Lil Fox using custom commands to request specific information or adjustments in your schedule or task priorities.

## Display on the Foxboard:

• Dynamic Task Module: The Foxboard displays a dynamically updating task module, showing your prioritized tasks for the current hour or day.

• Contextual Links: It links tasks to relevant notes, bookmarks, or highlights, providing a comprehensive view of why a task is relevant now.

Example Workflow:

• 9 AM Check-In: Lil Fox reviews your latest notes and identifies a task in your Things to-do list related to a current theme, say "data visualization."

• Task Suggestion: It suggests working on a specific visualization project, considering your schedule and current energy levels.

• Foxboard Update: The task, along with related notes or bookmarks, is highlighted on the Foxboard.

### Suggesting Motorcycle Rides

1. **Weather Conditional**: Each morning, your system performs a quick weather check. If the conditions are favorable, it flags the day as suitable for a ride.

1. **Time Block Allocation**: Based on your weekly schedule and priorities, the system finds an optimal time block for a motorcycle ride and suggests it to you as a break or as an end-of-day activity.

1. **Ride Rotation and Tracking**: Keep a rotating list of destinations or routes. After each ride, mark the route as completed. Over time, the system learns your preferences and suggests routes accordingly.

1. **Simple Blog Documentation**: Post-ride, the system prompts you to jot down notes or upload pictures, which can be used for a simple blog update.

The goal is for the system to enhance your productivity and joy without becoming a distraction. It should serve as a tool that understands the balance between your work and the activities that recharge you, like your motorcycle rides.

### Anticipating Productivity
1. **Data Ingestion**: Continuously import health data (like activity levels, heart rate, sleep patterns) from your Apple Watch to your Supabase database.
2. **Pattern Analysis**: Implement a machine learning model that analyzes your data to determine your natural rhythms and predict energy peaks and troughs.
3. **Dynamic Adjustment**: The system uses these predictions to suggest 'protein' activities during predicted high-energy periods and 'carb' activities during low-energy periods.
4. **User Feedback**: Incorporate a feedback mechanism where you can confirm or adjust the system’s predictions, improving its accuracy over time.
5. **Seamless Integration**: Connect this with your existing task management and scheduling system to create a cohesive productivity suite.

## Tasks Table

```sql
CREATE TABLE tasks (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    notes TEXT,
    due_date DATE,
    status TEXT,
    creation_date TIMESTAMP,
    completion_date TIMESTAMP,
    tags TEXT,
    list_id TEXT  
);
```

## Calendar table
```sql
create table
  calendar (
    event_id bigint primary key generated always as identity,
    title text not null,
    description text,
    start_date timestamp with time zone,
    end_date timestamp with time zone,
    location text,
    created_at timestamp with time zone default current_timestamp,
    updated_at timestamp with time zone default current_timestamp
  );
```

## Note Snippets table

The purpose of the `note_snippets` table in your Supabase database is to store and manage smaller, manageable sections of your Obsidian notes (markdown files), referred to as "snippets." Each snippet will have an associated vector embedding, enabling advanced functionalities like similarity searches. This approach allows you to leverage the rich content of your notes for data analysis and retrieval in a structured and efficient manner.

```sql
 CREATE TABLE note_snippets (
    snippet_id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    source_file TEXT,
    original_created_date TIMESTAMP,
    tags TEXT,
    reference_link TEXT,
    last_updated_at TIMESTAMP,
    snippet_type TEXT,
    author TEXT,
    visibility TEXT,
    associated_project TEXT,
    embedding VECTOR(1536),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

```

## Health Data table

```sql
CREATE TABLE health_data (
    record_id SERIAL PRIMARY KEY,
    date TIMESTAMP NOT NULL,
    metric_type TEXT NOT NULL,
    data JSONB NOT NULL,
    source TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

```

## Bookmarks table
```sql
CREATE TABLE bookmarks (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY,
    embedding VECTOR(1536),
    service_id TEXT NULL,
    created_at TIMESTAMP WITH TIME ZONE NULL DEFAULT now(),
    service_created_at TIMESTAMP WITH TIME ZONE NULL,
    href TEXT NULL,
    title TEXT NULL,
    author TEXT NULL,
    last_accessed TIMESTAMP WITH TIME ZONE NULL,
    thumbnail_url TEXT NULL,
    toread BOOLEAN NULL,
    tags TEXT NULL,
    description TEXT NULL,
    CONSTRAINT bookmarks_pkey PRIMARY KEY (id),
    CONSTRAINT bookmarks_service_id_key UNIQUE (service_id)
) TABLESPACE pg_default;

```

## Messages table
```sql
CREATE TABLE messages (
    message_id SERIAL PRIMARY KEY,
    thread_id INTEGER,
    user_id INTEGER,  -- Optional, for multiple users
    direction TEXT CHECK (direction IN ('inbound', 'outbound')),
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## FoxNotes schema
```sql
CREATE TABLE fox_notes (
    note_id SERIAL PRIMARY KEY,
    user_id INTEGER,  -- Optional, for multiple users
    note_type TEXT CHECK (note_type IN ('reminder', 'reflection', 'plan', 'insight')),
    content TEXT NOT NULL,
    related_to TEXT,  -- Reference to tasks, events, or other items
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    scheduled_for TIMESTAMP,  -- When the note is relevant
    expires_in TIMESTAMP  -- When the note is no longer relevant
);

```---
date: 2024-05-05T15:32:21-04:00
modified: 2024-05-05T21:17:07-04:00
---

MapLibre Font Maker: <https://maplibre.org/font-maker/>

Custom Glyph Style Spec: <https://maplibre.org/maplibre-style-spec/glyphs/>

HandDrawn font: <https://fonts.google.com/specimen/Delicious+Handrawn>

Custom styling with Maputnik: <https://maplibre.org/maputnik/?layer=2866843370%7E84#10.06/40.6941/-73.936/23.3>
---
date: 2024-01-15T12:49:19-05:00
modified: 2024-05-05T21:17:19-04:00
---
---
draft: true
dek: In which
inprogress: true
date: 2022-12-08T10:44:22-05:00
modified: 2024-05-05T21:17:20-04:00
---

#climatechange #data #dataviz

## Climate Trace Exploration Fall 2022

### Data

I downloaded static .csvs from all industries and both USA files from the Climate Trace downloads - I spun those csvs up into my own datasette instance that lets me execute arbitrary sqlite queries on the entire dataset and do things that aren't part of the current API

I also augmented it with data pulled from the API at render-time

With all of the .csv data loaded into a single sqlite file, we can list the available tables like this:

```sql
SELECT 
    name
FROM 
    sqlite_schema
WHERE 
    type ='table' AND 
    name NOT LIKE 'sqlite_%';
```

Which returns

```
name
country_other-onsite-fuel-usage_emissions
country_residential-and-commercial-onsite-fuel-usage_emissions
country_fluorinated-gases_emissions
asset_coal-mining_emissions
asset_oil-and-gas-production-and-transport_emissions
asset_oil-and-gas-production-and-transport_ownership
asset_oil-and-gas-refining_emissions
asset_oil-and-gas-refining_ownership
country_coal-mining_emissions
country_oil-and-gas-production-and-transport_emissions
country_oil-and-gas-refining_emissions
country_other-fossil-fuel-operations_emissions
country_solid-fuel-transformation_emissions
asset_aluminum_emissions
asset_cement_emissions
asset_cement_ownership
asset_steel_emissions
asset_steel_ownership
country_aluminum_emissions
country_cement_emissions
country_chemicals_emissions
country_other-manufacturing_emissions
country_pulp-and-paper_emissions
country_steel_emissions
asset_bauxite-mining_emissions
asset_copper-mining_emissions
asset_iron-mining_emissions
country_bauxite-mining_emissions
country_copper-mining_emissions
country_iron-mining_emissions
country_rock-quarrying_emissions
country_sand-quarrying_emissions
asset_electricity-generation_emissions
asset_electricity-generation_ownership
country_electricity-generation_emissions
country_other-energy-use_emissions
asset_solid-waste-disposal_emissions
asset_solid-waste-disposal_ownership
country_biological-treatment-of-solid-waste-&-biogenic_emissions
country_incineration-and-open-burning-of-waste_emissions
country_solid-waste-disposal_emissions
country_wastewater-treatment-and-discharge_emissions
```

Some things we need to be aware of as we explore this data. Ownership tables do not contain any emissions data, so we will ignore them for now, though we may come back to them later for an additional analysis separately.

Some assets like forests can potentially be large boundaries, and others, like shipping, can have multiple locations over time.

### Metadata

One of the first pieces of analysis we will want to look at is the average emissions for each sector and country.

Since our data is loaded into a single sqlite database, we can write a query that finds the average like so:

```sql
SELECT 'country_other-onsite-fuel-usage_emissions' AS sector, avg(emissions_quantity) AS avg_emissions FROM [country_other-onsite-fuel-usage_emissions] 
UNION ALL 
SELECT 'country_residential-and-commercial-onsite-fuel-usage_emissions' AS sector, avg(emissions_quantity) AS avg_emissions FROM [country_residential-and-commercial-onsite-fuel-usage_emissions] 
UNION ALL 
/* etc... */
```

Now we have a list of the average emissions per sector

|sector                                                          |avg_emissions     |
|----------------------------------------------------------------|------------------|
|country_other-onsite-fuel-usage_emissions                       |626882.7339777576 |
|country_residential-and-commercial-onsite-fuel-usage_emissions  |10570951.531545129|
|country_fluorinated-gases_emissions                             |3192839.1750230007|
|asset_coal-mining_emissions                                     |371276.9529745977 |
|asset_oil-and-gas-production-and-transport_emissions            |5029170.075814316 |
|asset_oil-and-gas-refining_emissions                            |1101387.884806157 |
|country_coal-mining_emissions                                   |3852764.113805118 |
|country_oil-and-gas-production-and-transport_emissions          |26092966.238957137|
|country_oil-and-gas-refining_emissions                          |3065097.9905090285|
|country_other-fossil-fuel-operations_emissions                  |2129103.0373205417|
|country_solid-fuel-transformation_emissions                     |3514164.523526008 |
|asset_aluminum_emissions                                        |79628.80644036894 |
|asset_cement_emissions                                          |41033.81624168514 |
|asset_steel_emissions                                           |120097.63570595099|
|country_aluminum_emissions                                      |4079854.777777778 |
|country_cement_emissions                                        |5485351.7037      |
|country_chemicals_emissions                                     |1321098.3634285715|
|country_other-manufacturing_emissions                           |11157537.936070718|
|country_pulp-and-paper_emissions                                |231644.82230456732|
|country_steel_emissions                                         |5505802.0506      |
|asset_bauxite-mining_emissions                                  |16149.989120612236|
|asset_copper-mining_emissions                                   |144349.83739999996|
|asset_iron-mining_emissions                                     |146237.1213663316 |
|country_bauxite-mining_emissions                                |4114.016553066766 |
|country_copper-mining_emissions                                 |52382.346798686434|
|country_iron-mining_emissions                                   |42571.34123749162 |
|country_rock-quarrying_emissions                                |23430.02041166381 |
|country_sand-quarrying_emissions                                |6747.906171428572 |
|asset_electricity-generation_emissions                          |9279216.822094692 |
|country_electricity-generation_emissions                        |31939702.337169297|
|country_other-energy-use_emissions                              |3716784.7093672394|
|asset_solid-waste-disposal_emissions                            |98716.8908211983  |
|country_biological-treatment-of-solid-waste-&-biogenic_emissions|40626.385040945686|
|country_incineration-and-open-burning-of-waste_emissions        |182798.0458842031 |
|country_solid-waste-disposal_emissions                          |3328791.549443371 |
|country_wastewater-treatment-and-discharge_emissions            |4959122.825384325 |

If you wanted to find the minimum and maximum as well as the average, you could do it like this:

```sql
SELECT 
'asset_coal-mining_emissions' as 'sector',
	avg(emissions_quantity) AS avg_emissions, 
	min(emissions_quantity) AS min_emissions, 
	max(emissions_quantity) AS max_emissions 
	FROM [asset_coal-mining_emissions] 
    WHERE gas is 'co2e_100yr'
```

[Datasette guide to spatialite](https://docs.datasette.io/en/stable/spatialite.html)

To select unique points within a bounding box after the year 2021 from a specific sector:

```sqlite
select
    distinct(asset_id),
    st_astext as 'geom'
FROM [asset_oil-and-gas-refining_emissions] 
where
   within(GeomFromText(geom), PolygonFromText('POLYGON((-127.1825 24.4286, -66.9266 24.4286, -66.9266 49.3845, -127.1825 49.3845, -127.1825 24.4286))'))
   AND date(start_time) >= '2021-01-01'
```

It's getting kind of old writing these super-long queries for every single asset table, so let's combine all of our assets into a single table, while maintaining all their fields.

```sqlite 
CREATE TABLE all_assets_combined AS 
SELECT 
	asset_id AS 'asset_id',
	asset_name, 
	st_astext as 'geom', 
	emissions_quantity AS 'emissions_quantity', 
	start_time AS 'start_time' 
FROM [asset_oil-and-gas-refining_emissions] 
UNION ALL 
SELECT etc... ``` 

Now we can do geospatial queries across all of our assets pretty quickly: 

```sqlite
SELECT asset_id, geom 
FROM all_assets_combined 
WHERE within(GeomFromText(geom), PolygonFromText('POLYGON((-127.1825 24.4286, -66.9266 24.4286, -66.9266 49.3845, -127.1825 49.3845, -127.1825 24.4286))')) 
AND date(start_time) >= '2021-01-01' 
```
---
date: 2024-01-10T14:17:50-05:00
modified: 2024-01-16T10:28:40-05:00
---

## MVP Plan

### Phase 1: Project Setup
- **Initialize the Database**: Set up your database server and create the initial database.
- **Define the Schema**: Based on the previously discussed design, create the tables (`elections`, `geo_units`, `candidates`, `results`) in the database.
- **Prepare Development Environment**: Set up your local development environment with the necessary tools and access to the database.

### Phase 2: Election Data Compilation

Gather data for all geographic units (states, counties, districts, precincts) and race types (Presidential, Congressional, etc.) for the 2020 election. Reliable sources may include:

- Official state election websites
- The Federal Election Commission (FEC)
- The MIT Election Data and Science Lab
- Other reputable election data aggregators
- Collect state-level data, including names and FIPS codes.
- Populate the `geo_units` table with state data, ensuring each state has a unique `GeoUnitID`.
- Collect data for congressional districts and counties.
- Populate the `geo_units` table with this data, assigning each a unique `GeoUnitID` and the appropriate `ParentID`.
- Gather metadata for the 2020 elections, focusing on dates, types, and levels of races.
- Input this data into the `elections` table, creating a record for each 2020 election event.
- Compile a list of candidates for each 2020 race, including their party affiliations.
- Add candidate information to the `candidates` table.

#### Data Ingestion

Develop scripts or use manual data entry to populate the tables with 2020 election data. The process will involve:

- Creating `ElectionID` entries for each type of race in the 2020 election.
- Filling the `candidates` table with all candidates who participated in the 2020 election races.
- Inserting detailed results into the `results` table for each race, candidate, and geographic unit.

#### Populating the `geo_units` table

To create the `geo_units` table, start by gathering state data from the U.S. Census Bureau, including state names and FIPS codes. Transform this data by assigning a unique `GeoUnitID` to each state and populating the relevant fields in your table. Since states are the top-level geographic unit, their `ParentID` can be left null.

Next, obtain congressional district data, which includes district numbers and associated state FIPS codes. When transforming this data, generate a `GeoUnitID` for each district and use the state data you've already entered into the `geo_units` table to assign the correct `ParentID`.

Similarly, download county-level data with county names and FIPS codes. Assign a `GeoUnitID` to each county and set the `ParentID` to the row ID of the state it belongs to, which you can reference by the state FIPS code.

Load the state data into the `geo_units` table first, followed by the congressional district and county data. As you load the district and county data, ensure that each entry's `ParentID` correctly points to the state's row ID in the table.

After loading the data, check that all hierarchical relationships are correct, and create indexes on key columns like `GeoUnitID` and `ParentID` to optimize query performance. This process will give you a robust `geo_units` table that reflects the geographic hierarchy from largest to smallest units, facilitating accurate and efficient data retrieval for your election visualization platform.

### Phase 4: Results Data Entry
- **Results Recording**:
  - Obtain the election results for each race in the 2020 elections.
  - Enter the results into the `results` table, linking each record to the corresponding `elections` and `geo_units` entries.

### Phase 5: Data Verification and Testing
- **Data Integrity Checks**:
  - Conduct thorough checks to ensure the accuracy and consistency of the data across all tables.
  - Validate the data against official sources to confirm its correctness.
- **Query Testing**:
  - Write and execute various queries to test data retrieval, ensuring that the results are as expected.
  - Optimize queries and add necessary indexes to improve performance.

### Phase 6: Documentation
- Document the entire process, including data sources, schema decisions, and any custom scripts or tools developed.
- Create a README file with setup instructions and an overview of the database structure.

### Phase 7: MVP Feature Development

Develop the core features of your application that will use the data. This may include:

- A map visualization for geographic units, colored by the winning party.
- Sidebar or detailed views showing candidate results, vote counts, and percentages.
- Filters to view different race types and levels (e.g., Presidential, Congressional).

---

## Tables

### Elections Table (`elections`)

**Fields**:

- `ElectionID` (String): A unique, human-readable composite key that combines the date, type, and category of the election (e.g., '2020-11-03-P-G' for a Presidential General election on November 3, 2020).
- `ElectionType` (String): The type of election (e.g., Presidential, Congressional, Senatorial, Gubernatorial, Ballot Initiative).
- `ElectionLevel` (String): The level of government (Federal, State, Local).
- `ElectionYear` (Integer): The year the election took place.
- `ElectionDate` (Date): The specific date of the election.
- `IsPrimary` (Boolean): Indicates whether the election is a primary.
- `WinnerParty` (String): The party of the winning candidate.
- `TotalVotes` (Integer): The total number of votes cast in the election.
- `VoterTurnoutPercentage` (Float): The percentage of eligible voters who participated in the election.
- `MarginOfVictory` (Float): The percentage point difference between the winner and the runner-up.
- `LeadingCandidate` (String): The name or ID of the leading candidate.

### Example Schema Creation SQL (for SQLite)

```sql
create table
  public.electology__elections (
    electionid text not null,
    electiontype text null,
    electionlevel text null,
    electionyear integer null,
    electiondate date null,
    isprimary boolean null,
    winnerparty text null,
    totalvotes integer null,
    voterturnoutpercentage real null,
    marginofvictory real null,
    leadingcandidate text null,
    constraint electology__elections_pkey primary key (electionid)
  ) tablespace pg_default;
```

This schema will support quick access to key information for visualizations and insights, like the winning party and voter turnout, while maintaining a detailed and comprehensive record of each election.

### Finalized Geographic Units Table (`geo_units`)

**Fields**:

- `GeoUnitID` (String): A unique identifier for each geographic unit. This could be a combination of FIPS code and unit type for higher precision.
- `Name` (String): The name of the geographic unit (e.g., Alabama, Autauga County, a specific township).
- `Type` (Enum): An enumerated type representing the category of the geographic unit. Allowed values: State, County, District, Precinct, Township.
- `FIPSCode` (String): The detailed FIPS code for the unit. It's stored as a string to preserve any leading zeros and extended to provide greater precision.
- `ParentID` (String, optional): A reference to the parent geographic unit, if applicable (e.g., linking a county to its state).

### Example Schema Creation SQL (for SQLite)

```sql
CREATE TABLE electology__geo_units (
    GeoUnitID TEXT PRIMARY KEY,
    Name TEXT,
    Type TEXT CHECK(Type IN ('State', 'County', 'District', 'Precinct', 'Township')),
    FIPSCode TEXT,
    ParentID TEXT
);
```


### Candidates Table (`candidates`)

**Fields**:

- `CandidateID` (String): A unique identifier for each candidate.
- `Name` (String): The most commonly recognized name of the candidate.
- `AKAs` (Text): Alternate names or common variations of the candidate's name.
- `PartyAffiliations` (Text): A JSON array storing the candidate's party affiliations over the years.
- `ActivePartyAffiliation` (String): The current or most recent party affiliation of the candidate.
- `FirstElectionYear` (Integer): The first year the candidate ran for an election.
- `FirstElectionState` (String): The state where the candidate first ran for election.
- - `CampaignFinanceSummary` (Text): A JSON field to store key financial information about the candidate's campaign.
- `LastElectionWinMargin` (Float, optional): The margin of victory in the candidate's last election win.
- `Birthday` (Date): The candidate's date of birth.
- `HeadshotURL` (String): A URL to an image of the candidate's headshot.

**Example JSON Structure for `CampaignFinanceSummary`**:

```json
{
  "totalReceipts": 87647.99,
  "totalDisbursements": 79252.8,
  "cashOnHand": 8395.19,
  "debtOwed": 25000,
  "coverageEndDate": "2023-09-30"
}
```

**Example Schema Creation SQL (for SQLite)**:

```sql
CREATE TABLE electology__candidates (
    CandidateID TEXT PRIMARY KEY,
    Name TEXT,
    AKAs TEXT,
    PartyAffiliations TEXT,
    ActivePartyAffiliation TEXT,
    FirstElectionYear INTEGER,
    FirstElectionState TEXT,
    CampaignFinanceSummary TEXT,
    LastElectionWinMargin REAL,
    Birthday DATE,
    HeadshotURL TEXT
);
```

### Results Table (`results`)

**Fields**:

- `ResultID` (String): A unique identifier for each election result entry.
- `ElectionID` (String): A reference to the `ElectionID` in the `elections` table.
- `GeoUnitID` (String): A reference to the `GeoUnitID` in the `geo_units` table.
- `GeoUnitType` (String) The type of geo unit (county, state, precinct, etc)
- `CandidateID` (String): A reference to the `CandidateID` in the `candidates` table.
- `VoteCount` (Integer): The number of votes received by the candidate in this geographic unit for this election.
- `TotalVotes` (Integer): The total number of votes cast in this geographic unit for this election.
- `VoteBreakdown` (Text, optional): A JSON field to store the breakdown of votes by method (e.g., in-person, mail-in, early voting), if available.

**Example JSON Structure for `VoteBreakdown`**:

```json
{
  "inPerson": 5000,
  "mailIn": 3000,
  "earlyVoting": 2000
}
```

**Example Schema Creation SQL (for SQLite)**:

```sql
CREATE TABLE electology__results (
    ResultID TEXT PRIMARY KEY,
    ElectionID TEXT,
    GeoUnitID TEXT,
    GeoUnitType TEXT,
    CandidateID TEXT,
    VoteCount INTEGER,
    TotalVotes INTEGER,
    VoteBreakdown TEXT
);
```

### Precinct Results Table (`precinct_results`)

**Fields**:

- `PrecinctResultID` (String): A unique identifier for each precinct result entry, possibly a UUID or a combination of other fields.
- `ElectionID` (String): A reference to the `ElectionID` in the `elections` table. This ID should be constructed consistently across both tables.
- `PrecinctID` (String): A unique identifier for the precinct, which could be a combination of `state_fips`, `county_fips`, and `precinct`.
- `CountyFIPS` (String): The FIPS code for the county.
- `JurisdictionFIPS` (String): The FIPS code for the jurisdiction, if different from the county.
- `ParentGeoUnitID` (String): A reference to the `GeoUnitID` in the `geo_units` table, which could be the county or district FIPS code.
- `CandidateID` (String): A reference to the `CandidateID` in the `candidates` table.
- `Votes` (Integer): The number of votes received by the candidate in this precinct.
- `Office` (String): The office for which the election is held (e.g., "US HOUSE").
- `District` (String): The district number for the election, if applicable.
- `PartyDetailed` (String): The detailed party affiliation of the candidate.
- `PartySimplified` (String): The simplified party affiliation of the candidate.
- `Mode` (String): The mode of voting (e.g., "TOTAL" for total votes, "ABSENTEE" for absentee votes).
- `Year` (Integer): The year the election took place.

**Partitioning**:

- The table can be partitioned by `Year` and `State` to improve query performance.

**Indexing**:

- Create indexes on frequently queried columns such as `ElectionID`, `PrecinctID`, `ParentGeoUnitID`, and `CandidateID`.
- A composite index on (`Year`, `State`) could be beneficial for queries that span multiple precincts within a state for a given year.

**Example Schema Creation SQL (for PostgreSQL with Partitioning)**:

```sql
CREATE TABLE electology__precinct_results (
    PrecinctResultID TEXT NOT NULL,
    ElectionID TEXT NOT NULL REFERENCES elections(ElectionID),
    PrecinctID TEXT NOT NULL,
    CountyFIPS TEXT NOT NULL,
    JurisdictionFIPS TEXT,
    ParentGeoUnitID TEXT NOT NULL REFERENCES geo_units(GeoUnitID),
    CandidateID TEXT NOT NULL REFERENCES candidates(CandidateID),
    Votes INTEGER NOT NULL,
    Office TEXT NOT NULL,
    District TEXT,
    PartyDetailed TEXT,
    PartySimplified TEXT,
    Mode TEXT NOT NULL,
    Year INTEGER NOT NULL
) PARTITION BY RANGE (Year);

-- Create partitions for each year (example for the year 2020)
CREATE TABLE precinct_results_2020 PARTITION OF precinct_results
FOR VALUES FROM (2020) TO (2021);

-- Add indexes to the partitioned table
CREATE INDEX idx_precinct_results_year_state ON precinct_results_2020 (Year, State);
CREATE INDEX idx_precinct_results_electionid ON precinct_results_2020 (ElectionID);
-- Additional indexes as needed...
```

### Live Results Table (`live_results`)

**Fields**:

- `LiveResultID` (String): A unique identifier for each entry. This could be a combination of the `ElectionID`, `GeoUnitID`, and a timestamp or sequence number to ensure uniqueness.
- `ElectionID` (String): A reference to the `ElectionID` in the `elections` table.
- `GeoUnitID` (String): A reference to the `GeoUnitID` in the `geo_units` table.
- `CandidateID` (String): A reference to the `CandidateID` in the `candidates` table.
- `VoteCount` (Integer): The most recent count of votes received by the candidate in this geographic unit for this election.
- `TotalVotes` (Integer): The most recent total number of votes cast in this geographic unit for this election.
- `VoteBreakdown` (Text, optional): A JSON field to store the breakdown of votes by method, if available.
- `Timestamp` (DateTime): The timestamp of the latest update, to track the recency of the data.

**Handling Conflicting or Duplicative Data**:

- **Timestamps**: By including a `Timestamp` field, you can ensure that you're always working with the most recent data.
- **Data Integrity Checks**: Implement logic in your data ingestion pipeline to check for conflicts or duplicates. This could involve comparing the timestamp and vote counts to ensure new data is indeed more recent and different from the existing data.
- **Data Update Strategy**: Define a strategy for updating the `live_results` table. This could be an "upsert" operation, where new data either updates existing rows (if they exist for the same `ElectionID`, `GeoUnitID`, and `CandidateID`) or inserts new rows.

**Example Schema Creation SQL (for SQLite)**:

```sql
CREATE TABLE electology__live_results (
    LiveResultID TEXT PRIMARY KEY,
    ElectionID TEXT,
    GeoUnitID TEXT,
    CandidateID TEXT,
    VoteCount INTEGER,
    TotalVotes INTEGER,
    VoteBreakdown TEXT,
    Timestamp DATETIME
);
```


### Parties Table (`parties`) with Historical Consideration

**Fields**:

- `PartyID` (String): A unique identifier for each political party.
- `Name` (String): The full name of the political party.
- `Abbreviation` (String): A short abbreviation for the party.
- `ColorCode` (String): A color identifier for the party, suitable for light mode UI.
- `ColorCodeDark` (String): A color identifier for the party, suitable for dark mode UI.
- `HistoricalInfo` (Text, optional): A JSON field to store key historical information about the party. This could include major ideological shifts, mergers, or rebranding events.

**Suggested JSON Structure for `HistoricalInfo`**:

```json
{
  "majorEvents": [
    {"year": 1960, "event": "Ideological shift towards..."},
    {"year": 1990, "event": "Merged with..."}
  ]
}
```

**Example Schema Creation SQL (for SQLite)**:

```sql
CREATE TABLE electology__parties (
    PartyID TEXT PRIMARY KEY,
    Name TEXT,
    Abbreviation TEXT,
    ColorCode TEXT,
    ColorCodeDark TEXT,
    HistoricalInfo TEXT
);
```

**Handling Historical Party Information**:

- The `HistoricalInfo` field can be a JSON array to store major historical events or shifts relevant to the party. This approach offers flexibility and allows for capturing essential historical milestones without excessive detail.
- By using JSON, we keep the table structure simple and avoid overloading it with numerous columns for historical details, aligning with the goal of minimal yet effective data storage.

### Election Events Table (`election_events`)

**Fields**:

- `EventID` (String): A unique identifier for each event.
- `ElectionID` (String): A reference to the `ElectionID` in the `elections` table, indicating which election the event is associated with.
- `EventType` (String): The type of event (e.g., Debate, Registration Deadline, Early Voting Start).
- `EventDate` (Date): The date (and possibly time) when the event occurs.
- `EventDescription` (Text): A brief description of the event.
- `Location` (String, optional): The location where the event is taking place, if applicable.
- `URL` (String, optional): A URL to a webpage with more information about the event.
- `ImpactLevel` (String, optional): An assessment of the event's expected impact on the election (e.g., High, Medium, Low).
- `CandidateIDs` (Text): A list of `CandidateID`s involved in the event, stored as a delimited string or a JSON array.

**Example Schema Creation SQL (for SQLite)**:

```sql
CREATE TABLE electology__election_events (
    EventID TEXT PRIMARY KEY,
    ElectionID TEXT,
    lat FLOAT,
    lng FLOAT,
    EventType TEXT,
    EventDate DATE,
    EventDescription TEXT,
    Location TEXT,
    URL TEXT,
    ImpactLevel TEXT,
    CandidateIDs TEXT -- This field can store a comma-separated list or a JSON array of CandidateIDs
);
```


## Importing MIT Historical Election Data

## Candidate Data

FEC Candidates for election years: <https://www.fec.gov/data/browse-data/?tab=candidates>

**Candidates Table (`candidates`)**:

- `CandidateID`: Directly from `Cand_Id`.
- `Name`: Directly from `Cand_Name`.
- `PartyAffiliations`: Derived from `Cand_Party_Affiliation`.
- `ActivePartyAffiliation`: Directly from `Cand_Party_Affiliation`.
- `FirstElectionYear`: Derived from the `year` portion of `Cand_Id` or an external source.
- `FirstElectionState`: Directly from `Cand_Office_St`.
- `Birthday`: Not available in the FEC data; would need an external source.
- `HeadshotURL`: Could be constructed from `Link_Image`.

```sql
create table
  electology__candidates (
    CandidateID bigint primary key generated always as identity,
    name text,
    PartyAffiliations text,
    ActivePartyAffiliation text,
    FirstElectionYear int,
    FirstElectionState text,
    Birthday date,
    HeadshotURL text
  );
```


### Presidential County Data 2000-2020

|**year**|**state**|**state_po**|**county_name**|**county_fips**|**office**|**candidate**|**party**|**candidatevotes**|**totalvotes**|**version**|**mode**|
|---|---|---|---|---|---|---|---|---|---|---|---|
|**2000**|ALABAMA|AL|AUTAUGA|1001|US PRESIDENT|AL GORE|DEMOCRAT|4942|17208|20220315|TOTAL|
|**2000**|ALABAMA|AL|AUTAUGA|1001|US PRESIDENT|GEORGE W. BUSH|REPUBLICAN|11993|17208|20220315|TOTAL|
|**2000**|ALABAMA|AL|AUTAUGA|1001|US PRESIDENT|RALPH NADER|GREEN|160|17208|20220315|TOTAL|
|**2000**|ALABAMA|AL|AUTAUGA|1001|US PRESIDENT|OTHER|OTHER|113|17208|20220315|TOTAL|

1. **Elections Table (`elections`)**:
   - `ElectionID`: Constructed from the `year`, `office`, and `state_po` fields.
   - `ElectionType`: Derived from the `office` field (e.g., "US PRESIDENT" becomes "Presidential").
   - `ElectionLevel`: "Federal" for presidential elections.
   - `ElectionYear`: Directly from the `year` field.
   - `ElectionDate`: You'll need an external source for the exact date, as it's not in the CSV.
   - Other fields like `IsPrimary`, `WinnerParty`, etc., would need additional logic or data sources.

2. **Geographic Units Table (`geo_units`)**:
   - `GeoUnitID`: Constructed from `county_fips`.
   - `Name`: From `county_name`.
   - `Type`: "County" for these records.
   - `FIPSCode`: Directly from `county_fips`.
   - `ParentID`: Constructed from `state_po`.

3. **Candidates Table (`candidates`)**:
   - `CandidateID`: Constructed from `candidate` and `year` or a unique identifier.
   - `Name`: Directly from `candidate`.
   - Other fields would require additional data sources.

4. **Results Table (`results`)**:
   - `ResultID`: A unique identifier, possibly a UUID or a combination of other fields.
   - `ElectionID`: Reference the constructed `ElectionID` from the `elections` table.
   - `GeoUnitID`: Reference the `GeoUnitID` from the `geo_units` table.
   - `CandidateID`: Reference the `CandidateID` from the `candidates` table.
   - `VoteCount`: Directly from `candidatevotes`.
   - `TotalVotes`: Directly from `totalvotes`.

5. **Parties Table (`parties`)**:
   - `PartyID`: Constructed from `party` or a unique identifier.
   - `Name`: Directly from `party`.
   - `Abbreviation`: May need to be manually mapped based on `party`.
   - `ColorCode` and `ColorCodeDark`: May need to be manually set based on `party`.

### Congressional Elections Data 1976-2022
1. **Elections Table (`elections`)**:
   - `ElectionID`: Constructed from the `year`, `state_po`, `office`, and `district` fields.
   - `ElectionType`: Derived from the `office` field (e.g., "US HOUSE" becomes "House of Representatives").
   - `ElectionLevel`: "Federal" for congressional elections.
   - `ElectionYear`: Directly from the `year` field.
   - `ElectionDate`: You'll need an external source for the exact date, as it's not in the CSV.
   - Other fields like `IsPrimary`, `WinnerParty`, etc., would need additional logic or data sources.

2. **Geographic Units Table (`geo_units`)**:
   - `GeoUnitID`: Constructed from `state_fips` and `district`.
   - `Name`: Constructed from `state` and `district` (e.g., "Alabama District 1").
   - `Type`: "District" for these records.
   - `FIPSCode`: Constructed from `state_fips` and `district`.
   - `ParentID`: Constructed from `state_po`.

3. **Candidates Table (`candidates`)**:
   - `CandidateID`: Constructed from `candidate`, `year`, and `district` or a unique identifier.
   - `Name`: Directly from `candidate`.
   - Other fields would require additional data sources.

4. **Results Table (`results`)**:
   - `ResultID`: A unique identifier, possibly a UUID or a combination of other fields.
   - `ElectionID`: Reference the constructed `ElectionID` from the `elections` table.
   - `GeoUnitID`: Reference the `GeoUnitID` from the `geo_units` table.
   - `CandidateID`: Reference the `CandidateID` from the `candidates` table.
   - `VoteCount`: Directly from `candidatevotes`.
   - `TotalVotes`: Directly from `totalvotes`.

5. **Parties Table (`parties`)**:
   - `PartyID`: Constructed from `party` or a unique identifier.
   - `Name`: Directly from `party`.
   - `Abbreviation`: May need to be manually mapped based on `party`.
   - `ColorCode` and `ColorCodeDark`: May need to be manually set based on `party`.


## Ingest Scripts

### Script 1: `ingest_states.js`
- **Purpose**: To ingest state-level geographic data into the `geo_units` table.
- **Functionality**:
  - Read state data from a source file or API.
  - Transform the data to match the `geo_units` schema.
  - Insert state data into the database, setting `Type` as "State" and leaving `ParentID` null.

### Script 2: `ingest_districts.js`
- **Purpose**: To ingest congressional district data into the `geo_units` table.
- **Functionality**:
  - Read district data, including state associations and district numbers.
  - Transform the data to include a `GeoUnitID` and the correct `ParentID` referencing the state.
  - Insert district data into the database, setting `Type` as "District".

### Script 3: `ingest_counties.js`
- **Purpose**: To ingest county-level geographic data into the `geo_units` table.
- **Functionality**:
  - Read county data, including names and FIPS codes.
  - Transform the data to include a `GeoUnitID` and the correct `ParentID` referencing the state.
  - Insert county data into the database, setting `Type` as "County".

### Script 4: `ingest_elections.js`
- **Purpose**: To ingest election metadata for the 2020 elections into the `elections` table.
- **Functionality**:
  - Read election metadata from a source file or API.
  - Transform the data to match the `elections` schema, excluding winner and margin fields.
  - Insert election metadata into the database.

### Script 5: `ingest_candidates.js`
- **Purpose**: To ingest candidate data for the 2020 elections into the `candidates` table.
- **Functionality**:
  - Read candidate data, including names, party affiliations, and election participation.
  - Transform the data to match the `candidates` schema.
  - Insert candidate data into the database.

### Script 6: `ingest_results.js`
- **Purpose**: To ingest election results data for the 2020 elections into the `results` table.
- **Functionality**:
  - Read results data for each race and candidate.
  - Transform the data to include references to the correct `ElectionID`, `GeoUnitID`, and `CandidateID`.
  - Insert results data into the database.

### Script 7: `verify_data.js`
- **Purpose**: To perform data integrity checks and ensure accuracy.
- **Functionality**:
  - Run queries to check for consistency and accuracy across the `geo_units`, `elections`, `candidates`, and `results` tables.
  - Report any discrepancies or issues for review and correction.

### Script 8: `update_winners.js` (To be run after initial ingestion)
- **Purpose**: To update the `elections` table with winner and margin data.
- **Functionality**:
  - Read winner and margin data from a reliable source.
  - Transform the data to match the `elections` schema.
  - Update the `elections` table with the new data.

---

## Execution Plan

### Day 1: Geographic Units and Elections Data

#### 10:00 AM - 11:00 AM: Project Initialization
- Set up the project repository and version control.
- Create a `package.json` file and install necessary Node.js packages.
- Write a basic README with an overview of the project's purpose and structure.

#### 11:00 AM - 12:00 PM: Database Setup
- Connect to your database and create the `geo_units`, `elections`, `candidates`, and `results` tables according to your schema.
- Test the connection and table creation scripts to ensure they work as expected.

#### 12:00 PM - 1:00 PM: Ingest States Data (`ingest_states.js`)
- Write the `ingest_states.js` script to read, transform, and load state data into the `geo_units` table.
- Run the script with a subset of data to test and debug.

#### 1:00 PM - 2:00 PM: Lunch Break
- Take a well-deserved break to rest and recharge.

#### 2:00 PM - 3:00 PM: Ingest Congressional Districts Data (`ingest_districts.js`)
- Write the `ingest_districts.js` script to handle congressional district data.
- Ensure the script assigns the correct `ParentID` to each district, linking it to its state.

#### 3:00 PM - 4:00 PM: Ingest Counties Data (`ingest_counties.js`)
- Write the `ingest_counties.js` script to process and insert county data into the `geo_units` table.
- Test the script with a few counties to verify the `ParentID` linkage and data accuracy.

#### 4:00 PM - 5:00 PM: Ingest Elections Metadata (`ingest_elections.js`)
- Develop the `ingest_elections.js` script to populate the `elections` table with the 2020 election metadata.
- Run the script to load data and check for correct insertion.

#### 5:00 PM - 6:00 PM: Review and Documentation
- Review the work completed so far, ensuring that all scripts are functioning as expected.
- Document the processes, including any issues encountered and how they were resolved.

### Day 2: Candidates, Results Data, Verification, and Visualization

#### 10:00 AM - 11:00 AM: Ingest Candidates Data (`ingest_candidates.js`)
- Create and run the `ingest_candidates.js` script to add candidate information to the `candidates` table.

#### 11:00 AM - 1:00 PM: Ingest Results Data (`ingest_results.js`)
- Write and execute the `ingest_results.js` script to input results data into the `results` table.

#### 1:00 PM - 2:00 PM: Lunch Break
- Take a break to recharge for the afternoon's tasks.

#### 2:00 PM - 3:30 PM: Data Verification (`verify_data.js`)
- Develop and run the `verify_data.js` script to perform data integrity checks across all tables.

#### 3:30 PM - 4:30 PM: Front-End Integration
- Coordinate with the front-end team to ensure they can query the backend for the necessary data.
- Assist with any API endpoints or data format adjustments needed for visualization.

#### 4:30 PM - 5:30 PM: Map Visualization
- Work with the front-end team to implement map visualizations for states, congressional districts, and counties.
- Test the visualizations with the ingested data to ensure accuracy and performance.

#### 5:30 PM - 6:00 PM: Review and Wrap-Up
- Review the visualizations to confirm that they are displaying the correct information.
- Make any necessary tweaks based on the test results.
- Document the visualization integration process and any outstanding issues.---
inprogress: true
date: 2023-01-01T15:06:48-05:00
modified: 2023-01-10T20:21:57-05:00
dek: In which the author itemizes the cameras he uses to make photographs
---

# Camera Setup

# Street Photography

## Fujifilm X-Pro 3

### Lenses
- 18mm f2
- 56mm f1.2
- 35mm f2
- 23mm f2

## N90s

### 50mm Nikkor Lens

## Olympus XA 2

## Black & White Film

For my film development process see: [[film-development]]

---

## Appendix

### Video settings

When shooting video:

- f-log
- 24fps
- 1080p
- 4k used sparingly for large shots, to crop/zoom later
- 4:3 ratio (????)

When creating animations

- 4k
- 12fps or 24fps

#setup
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:38:12-04:00
tags:
---

## Rapid Prototyping at Room 302: Behind the Scenes
---
date: 2022-10-18T13:41:18-04:00
type: words
hidden: true
inprogress: true
dek: In which…
modified: 2022-12-23T09:14:08-05:00
---

#climatechange #dataviz 

# Climate Trace: Shipping Data

[[toc]]

## Metadata

2.41GB .csv file `asset-shipping.csv`

```bash
❯ wc -l asset-shipping.csv
 11643105 asset-shipping.csv
 ```

 11,643,105 lines in the .csv and 27 columns for each row. 

 ```bash
 ❯ csvcut -n asset-shipping.csv
  1: start_date
  2: end_date
  3: asset_identifier
  4: asset_name
  5: iso3_country
  6: location
  7: type
  8: capacity
  9: capacity_factor
 10: activity
 11: CO2_emissions_factor
 12: CH4_emissions_factor
 13: N2O_emissions_factor
 14: other_gas_emissions_factor
 15: CO2_emissions
 16: CH4_emissions
 17: N2O_emissions
 18: other_gas_emissions
 19: total_CO2e_100yrGWP
 20: total_CO2e_20yrGWP
 21: other1
 22: other2
 23: other3
 24: other4
 25: other5
 26: other6
 27: other7
 ```

We can convert this to a sqlite database for further analysis with datasette. Because our data is so large, we need to create a `settings.json`[^1] that lets queries take longer and return more rows. 

```sql
select distinct asset_identifier from [asset-shipping]
```

Which returns 48,112 unique ships.

## Data Analysis

### Which ship has the most emissions?
```sql
SELECT asset_name, asset_identifier, iso3_country, SUM(CO2_emissions) AS CO2_emissions
FROM [asset-shipping]
GROUP BY asset_identifier
ORDER BY CO2_emissions DESC
LIMIT 10;
```

**Name**: Orient

**Identifier**: 9061617

**Country**: RUS

**CO2_emissions**: 69420075.10475922

### Where does that ship travel?

First we grab all the data we have available for that unique_identifier:

```sql
select rowid, start_date, end_date, asset_identifier, asset_name, iso3_country, location, type, capacity, capacity_factor, activity, CO2_emissions_factor, CH4_emissions_factor, N2O_emissions_factor, other_gas_emissions_factor, CO2_emissions, CH4_emissions, N2O_emissions, other_gas_emissions, total_CO2e_100yrGWP, total_CO2e_20yrGWP, other1, other2, other3, other4, other5, other6, other7 from [asset-shipping] where "asset_identifier" = 9061617 
```

Each row has a `location` that looks like `Point((132.011448333333 43.0765933333333))` which is a latitude and longitude. Ideally we want to turn all these points into a line so we can see the path of the ship over time. 

## Ship History & Emissions Visualization

So lets turn our data and our newly-created aggregations into visualizations we can look at. Our goal is to find some recommendations for how to integrate this shipping data into a global map of emissions. 

### Points

The simplest thing that we can do is draw a circle for each point in a ship's history.

### Lines

We can also chain together our points to form a line that shows the entire route the ship took in the data we have available.

### Points + Arrows

It might be easier to read the directionality of the route if you add arrows and curve the lines slightly.

### Animation

Another way to take a ship's history and make it understandable is to introduce animation, where the location of the ship is played out through time.

#### Animated Points

You could simply animate the points the ship was recorded at as circles.

#### Animated Lines

Or you could draw a line over time to reflect where the boat has traveled. 

#### One ship vs Many ships

So far we've only looked at the history for a single ship, what if we look at all of the ships for a particular industry?

#### Multi-ship points

#### Multi-ship lines

### Heatmap
#### Heatmap for a ship
#### Heatmap for all ships in an industry

#### Particles
---
date: 2022-11-02T19:56:23-04:00
modified: 2022-12-15T10:14:11-05:00
---
## Call of Duty Stats Breakdown

One of my guilty pleasures is playing the video game Call of Duty.

### Hardcore Search & Destroy

Call of Duty multiplayer has many different game modes, but my favorite is Hardcore Search & Destroy. 

The politics of Call of Duty are maybe not great. However this feels to me to be a bit like discussing the politics of tetris or pacman. The mechanics of this video game just happen to be wrapped in an insane war simulation designed by lunatics, but I have wrapped my head around playing in a virtual world without having it alter my morals since I was a kid playing Grand Theft Auto. 

#### Hardcore

Hardcore is a modified game mode where players have more limited information on their screen while playing. Most notably, the mini map is removed and health is reduced so that most guns kill with a single shot anywhere on the body. This forces players to be more aware of their surroundings, and makes the game more challenging overall. 

#### Search & Destroy

Search & Destroy is a game mode where one team is tasked with planting a bomb, and the other team must try to stop them. If the bomb is planted, the other team must then try to defuse it. If the bomb detonates, or all members of one team are killed, that team will lose. Once you are dead, you cannot respawn until the next round. 

Hardcore search has more tactical gameplay and attracts a different player base than the default modes, and has had a cult following throughout much of the history of the Call of Duty franchise.

#### Communication and callouts

One of the reasons I like hardcore search is that it tests your ability to play as a team. Communication and coordination are key, and one player going rogue can cost the entire team the match. It's a fast paced game mode. When you are the last player alive on your team, everyone is watching you, and you if you have an opportunity to save the round your heart will start racing. What a good video game.

## Playing with a friend

I think one of the best ways to enjoy Call of Duty is to play with a friend. I've had some of the most enjoyable gaming experiences of my life playing with friends, and it's a great way to bond and catch up with friends who don’t live nearby. 

Playing with friends also allows you to communicate and coordinate more effectively, which can be a huge advantage in a fast paced and competitive game like Call of Duty.

### I ❤️ Riot Shield

The riot shield is a piece of equipment that can be equipped in certain game modes. It is a large shield that protects the player from bullets and explosives, and can be used to bash (or boop) enemies. 

I love the riot shield because it adds a new layer of strategy to the game, and can be used in a variety of ways. It encourages a playstyle based on patience and tactics rather than the usual run-and-gun methods that usually work, and can be very rewarding when used effectively.

In Search and Destroy it can be an invaluable technique to play objective and defend the bomb when working in tandem with a skilled teammate.

## I have been playing Call of Duty games for over 10 years

I started playing Call of Duty back in 2007 with Call of Duty 4: Modern Warfare, and I have been hooked ever since. I have played every main entry in the series, and have fond memories of most of them.

I still play Call of Duty today, although not as much as I used to. I have moved on to other games, but I still come back to the series from time to time and enjoy it just as much as I did when I first started playing.

I love it when old remastered levels come out because these are maps I have put hundreds of hours into the years. After that amount of time there is an almost indescribable sense of intuition and flow that is immensely enjoyable.

I have the muscle memory to play this game at a level I enjoy, so I am kind of locked in at this point. 

### Killcam culture

One of the aspects of the Call of Duty community that I find most interesting is the killcam culture. A killcam is a short replay that is shown after the last kill of the round, and it allows players to see how they died from the perspective of the person who killed them. 

The killcam has become a meme within the community, and veteran players will often do outrageous things in an attempt to get a funny or impressive killcam, kind of like flipping your bat after a home run or dancing after a touchdown.

## Questions I have for the data
- What weapons am I best with?
- What loadout gets me the most wins?
- What type of playstyle do I have?
- What can I learn to get better?
- How can data help me improve? 
- What makes me different from other players?
- What are some interesting things I didn’t know before? 

### How to get the data
### Data overview / metadata
### Last 20 match analysis

The data we have has some lifetime statistics, but it only has detailed match statistics for the last 20 matches played. 

#### Gamestyle / play indicators
#### Weapon usage
## Ideas for the future
---
date: 2023-01-19T01:27:20-05:00
modified: 2023-09-09T15:06:51-04:00
dek: In which
inprogress: true
tags: cooking
---
---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T19:58:36-04:00
modified: 2022-12-23T09:21:42-05:00
---

#data 

# Working with Wikidata

## How to get the data
## Data structure
## Wikidata for elections

[[why-i-am-building-electology-for-elections]]

### Unique candidates
---
dek: In which the author builds tools and systems to sort through all of the flotsam and jetsam of learning about things through the internet
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-01T14:57:53-04:00
tags:
---

## My approach to a modern Scrapbook

On my iPhone, I have the Pins app, which allows me to take any link I see and add it to my Pinboard bookmarks, and even mark it as “read later”. Anytime I read something online I think I might want to reference, show someone, or think about later, I chuck it into my bookmarks.

Sometimes when I think about something, I’ll tweet about it. Or, I used to tweet about it, I post on Mastodon now, but same difference. These are like little tiny public-facing diary entries that capture my thoughts and thought processes on a particular day or topic.

I also write a lot of code. I’ll have a new idea, clone my template, make a little prototype, create a github repo for it, and if I’m a good little boy, I will fill it with Issues and notes of plans to enhance it later when I get more time.

I am also always exploring GitHub and finding new tools and technologies, which I star, to save for later. Sometimes I’ll also bookmark the repo and add it to Pinboard.

When I see images that I want to save, I use the service are.na instead, which is sort of like an adult tumblr with a lot of powerful capabilities around exploration and organization. Are.na lets you organize “blocks” which might images, text, or links, though I primarily use it for images. Blocks can themselves be organized into channels, and it is very easy to pull another user’s blocks into your own channels, and vice versa.

I also constantly take screenshots; of inspiration, of works in progress, weird glitches, and things that inspire me. This forms an interesting visual historical record of what I am working on at a particular time.

All of these things; mastodon posts, pinboard bookmarks, are.na blocks, can be thought of various scraps of paper sitting on my desk, clipped out from some source material. You could also think of them all as unique hypercards, to be stacked, grouped, and inter-referenced.

But a key missing element in making this workflow useful to me is building tools and interfaces for exploration and organization. I feel pretty confident about my mechanisms of *capture* - as I spin off a number of scraps every day without even thinking about it.

But I struggle seeing the over-arching themes and developments of projects on longer timelines. Some research, projects, or threads of exploration have lasted me years. At the time they felt like smaller, disconnected explorations. But when put together, in retrospect, some overarching threads become obvious.

I want to build more systems that help me recognize for---
draft: true
dek: In which
inprogress: true
date: 2022-12-13T15:59:19-05:00
modified: 2023-01-06T17:42:18-05:00
---
# Spliff and Espresso

#cannabis #personal 

A strong dose of caffeine coupled with cannabis's uplifting effects is a powerful combination. Coffee is known to improve clarity, focus, and mood while reducing fatigue; while cannabis is known to reduce tension, anxiety, and stress, providing a euphoric feeling. Together, the combination can be a powerful boost to creativity and productivity.

Since ancient times, marijuana and coffee have been consumed in combination in many parts of the world. This practice has been documented in various traditional cultures, particularly in East and Southeast Asia, and appears to have been used as part of spiritual or ritualistic practices. In more recent times, the combination of marijuana and coffee has become increasingly popular in a variety of contexts.

The combination of marijuana and coffee has been found to offer a number of potential benefits. Studies have suggested that the two substances can interact in a synergistic manner, providing enhanced effects relative to the individual components. 

This can result in a more intense, longer-lasting cannabis experience, as well as increased alertness and focus. Furthermore, marijuana can potentially reduce the anxiety and jitteriness associated with consuming high doses of caffeine, allowing for a more pleasant and enjoyable experience.

This combination has become increasingly popular among creatives and other individuals seeking to enhance their productivity and focus. 

Many have found that the combination of a spliff and a double espresso can provide a significant boost to creativity and focus, allowing them to work more efficiently and effectively. Moreover, the enhanced relaxation and euphoria that can be experienced from the combination can help to reduce stress and improve overall well-being.

## Goals For Spliff & Espresso Brand
1. To be the go-to source for products to enhance the cannabis and coffee consumption experience.
2. To provide a consistent and enjoyable experience for our customers. 
3. To create a platform for cannabis-related education and advocacy. 
4. To become an industry leader in innovation and sustainability. 
5. To create a trusted and respected brand that is synonymous with quality and excellence.

## Brand Identity

Spliff and Espresso is a modern and sophisticated brand that emphasizes the quality and experience of cannabis and coffee. Our goal is to create an experience that is both luxurious and relaxing, while also providing a stimulating and productive boost. 

Our visual identity will be modern and minimalistic, focusing on clear and simple messaging. We will use shades of black, white, and gold to evoke a sense of luxury, while using bright pops of color to represent our vibrant and inviting brand personality. Our logo will be bold and eye-catching, while still maintaining a sophisticated look. 

Our brand messaging will focus on the quality, consistency, and experience of our products, as well as our commitment to sustainability and education. We will emphasize the potential benefits of combining cannabis and coffee, highlighting the potential for increased focus, creativity, and relaxation. We will use an authentic and conversational tone to create a strong connection with our customers.

## Products
- T-Shirts
- Ash tray
- Espresso cups
- Playing cards
- Trading cards
- Tarot cards
- Linocut prints
- Coloring books

## Concepts
- Cannabis & Coffee Workshop: This would be a workshop where participants can learn about the science, history, and culture of cannabis and coffee. The workshop would include lectures, tastings, and hands-on activities.

- Cannabis & Coffee Pairing Kit: This kit would include a selection of coffees and cannabis-infused edibles designed to be paired together. The kit would include tasting notes and instructions on how to get the most out of each combination.

- Spliff & Espresso Bar: This would be a cozy and inviting cafe that serves cannabis-infused coffee drinks and snacks. The bar would also offer education and advocacy services, such as seminars, workshops, and other events. 

- Spliff & Espresso App: This app would allow customers to order cannabis-infused coffee drinks and snacks from their phone. The app would also provide education and advocacy services, such as access to seminars and workshops.

---

[Combined effects of THC and caffeine on working memory in rats - PMC](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3423236/)

[Metabolomic response to coffee consumption: application to a three‐stage clinical trial - Cornelis - 2018 - Journal of Internal Medicine - Wiley Online Library](https://onlinelibrary.wiley.com/doi/full/10.1111/joim.12737?identityKey=fa847b7f-5e49-4cfc-b134-4003acd2234f&regionCode=US-NY&wol1URL=%2Fdoi%2F10.1111%2Fjoim.12737%2Ffull)

[Differential Effects of Presynaptic versus Postsynaptic Adenosine A2A Receptor Blockade on 9-Tetrahydrocannabinol (THC) Self-Administration in Squirrel Monkeys](https://www.jneurosci.org/content/jneuro/34/19/6480.full.pdf)---
dek: In which we learn to use radios to the best of our ability
inprogress: true
date: 2023-09-03T12:33:47-04:00
modified: 2023-12-17T19:11:21-05:00
tags: howto 
---

## How Men Use Radios

Radios are a unique and important form of communication, bridging gaps across continents, cultures, and industries. This tool is as universal as language itself, yet each field has its own unique "radio culture," a set of codes and practices that serve specific needs. Intriguingly, many of these codes share striking similarities, even when developed independently. It's as if there's a universal human instinct to triage information, to distill complex thoughts into an economy of words that can be easily transmitted and understood.

### The Universal Language of Radio

<https://en.wikipedia.org/wiki/Radiotelephony_procedure>

In a world fragmented by languages, borders, and ideologies, radio stands as a unifying force. It's a medium that has transcended the limitations of geography and culture, becoming a universal language understood by all. But what makes radio so universally compelling? The answer lies in its inherent economy of words and the shared patterns that emerge across different sectors and societies.

Take, for example, the "over and out" phrase commonly used in radio communication. It's a term that has been adopted globally, from air traffic controllers in Tokyo to fishermen off the coast of Maine. The phrase encapsulates the essence of radio communication—clarity, brevity, and finality—all in just three syllables. It's a linguistic marvel that has stood the test of time, proving that when it comes to radio, less is often more.

But the universality of radio isn't just about shared phrases or codes; it's about the human instinct for efficient communication. This is evident in the way radio codes have evolved independently yet share striking similarities. Whether it's the 10-codes used by American police forces or the Q-codes that are the lingua franca of ham radio operators worldwide, the underlying principles are the same: triage information and convey it as succinctly as possible.

Interestingly, this culture of coded language has found a new home in the digital age. Platforms like Discord, popular among younger generations, have become the modern-day equivalents of radio channels. Here, users employ a blend of shorthand phrases, emojis, and even voice chat to communicate with a level of efficiency that would make any seasoned radio operator proud.

In the end, the universal language of radio is more than a set of codes or phrases; it's a testament to our collective need for connection and understanding. It's a language that continues to evolve, yet its core principles remain unchanged: be clear, be concise, and be heard.

### Radio Codes: A Primer

#### 10-Codes: The American Standard

#### Q-Codes: The International Choice

#### Phonetic Alphabets: NATO and Beyond

### Regional Nuances

#### Europe: A Case Study

#### Asia: Bridging Language Barriers

#### Africa: Radio in Remote Areas

### Professional Practices

#### Military Precision

#### Emergency Services: A Lifeline

#### Aviation: Sky-High Communication

#### Maritime: Codes on the Open Sea

#### Railways: On the Right Track

#### Trucking: The Long Haul

#### Journalism: Reporting on the Airwaves

#### Outdoor Recreation: From Hiking to Hunting

#### Amateur Radio: The Hobbyists

### The Future of Radio Communication

### Conclusion---
date: 2023-12-20T19:48:32-05:00
modified: 2024-01-10T23:37:27-05:00
---

Turbo Overpass Query

```
( // Query for farms and related agricultural land node["landuse"="farmyard"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["landuse"="farmland"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["landuse"="orchard"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["landuse"="vineyard"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); // Query for restaurants and similar establishments node["amenity"="restaurant"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["amenity"="cafe"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["amenity"="fast_food"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["amenity"="food_court"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); // Query for bars and related establishments node["amenity"="bar"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); node["amenity"="pub"] (41.21934509190223,-74.20112933309368,42.102644167637976,-73.80359036964917); ); // Output the results out body; >; out skel qt;
```

<https://gist.github.com/ejfox/89eed83d2974eeb8857784614bfa0921>

![[Screenshot 2023-12-20 at 8.18.39 PM.png]]

![[Screenshot 2023-12-20 at 8.19.15 PM.png]]

<https://hvmag.com/best/best-of-hudson-valley-2023/winners-food-drink/>

<https://www.foodandwine.com/travel/restaurants/catskills-hudson-valley-restaurants-best>

<https://ny.eater.com/maps/hudson-valley-eat-drink-best-restaurants-bars>

<https://www.theinfatuation.com/hudson-valley/guides/hudson-valley-restaurants>

<https://www.tripadvisor.com/Restaurants-g2663029-Hudson_River_Valley_New_York.html>

<https://hvfarmhub.org/resources/>

<https://hvmag.com/things-to-do/hudson-valley-farms-by-season/>

<https://inhabit.corcoran.com/the-recs-12-tasteful-hudson-valley-farm-stands/>

<https://www.michelinman.com/auto/why-michelin/travel/new-york/hudson-valley-day-trip-guide>

<https://hvmag.com/food/hudson-valley-chefs-james-beard-awards/>

<https://hvmag.com/food/hudson-valley-tea-rooms/>

<https://hvmag.com/food/best-new-restaurants-hudson-valley/>---
date: 2024-03-22T22:56:54-04:00
modified: 2024-04-21T18:29:12-04:00
---
## Season 1 Episode 1

Original Air Date; January 25 2007

I am 15 years old

The original iPhone had been unveiled earlier that month

The subprime mortgage crisis was about to begin

Tumblr is launched

<https://web.archive.org/web/20070701232033/http://ejfox.com/>

Sid is 16 in the show, about to turn 17!
---
draft: true
dek: In which
inprogress: true
date: 2023-01-19T01:16:47-05:00
modified: 2023-03-16T11:16:40-04:00
tags: dataviz howto
---

# How I Use Mindmapping & Diagrams

## The benefits of visual thinking

## Sketching in real time during a conversation

## Tools
### Scapple
### Pen & Paper

## Getting structured data from a diagram---
date: 2023-01-15T15:08:41-05:00
modified: 2023-12-04T00:44:34-05:00
---

%% Zoottelkeeper: Beginning of the autogenerated index file list %%

- [[drafts/working-with-wikidata|working-with-wikidata]]
- [[drafts/woodworking-setup|woodworking-setup]]
- [[drafts/why-is-climate-change-so-contentious|why-is-climate-change-so-contentious]]
- [[drafts/why-i-am-building-electology-for-elections|why-i-am-building-electology-for-elections]]
- [[drafts/what-is-data-visualization|what-is-data-visualization]]
- [[drafts/what-can-i-do-here|what-can-i-do-here]]
- [[drafts/week-schedule-and-to-do-list|week-schedule-and-to-do-list]]
- [[drafts/wardrobe-essentials|wardrobe-essentials]]
- [[drafts/visualizing-climate-trace-data|visualizing-climate-trace-data]]
- [[drafts/using-polycam-scans-in-three-js|using-polycam-scans-in-three-js]]
- [[drafts/using-observable-plot-in-vue|using-observable-plot-in-vue]]
- [[drafts/triangulation-of-truth|triangulation-of-truth]]
- [[drafts/three-months-with-coach-artie|three-months-with-coach-artie]]
- [[drafts/thoughts|thoughts]]
- [[drafts/technology-mutual-aid|technology-mutual-aid]]
- [[drafts/suvs-and-climate-change|suvs-and-climate-change]]
- [[drafts/summer-2023-reboot|summer-2023-reboot]]
- [[drafts/staunch-defenders-of-the-status-quo|staunch-defenders-of-the-status-quo]]
- [[drafts/spliff-and-espresso|spliff-and-espresso]]
- [[drafts/speedrunning-making-websites|speedrunning-making-websites]]
- [[drafts/sound-reactive-generative-art|sound-reactive-generative-art]]
- [[drafts/soapmaking|soapmaking]]
- [[drafts/scroll-driven-nuxt-animations|scroll-driven-nuxt-animations]]
- [[drafts/regular-robot-summaries|regular-robot-summaries]]
- [[drafts/reducing-my-carbon-footprint|reducing-my-carbon-footprint]]
- [[drafts/quantified-self|quantified-self]]
- [[drafts/process-homelessness-in-the-us|process-homelessness-in-the-us]]
- [[drafts/printing-photos-with-exif-data|printing-photos-with-exif-data]]
- [[drafts/paywalling-your-nuxt-app|paywalling-your-nuxt-app]]
- [[drafts/nuxt-3-and-netlify|nuxt-3-and-netlify]]
- [[drafts/my-vscode-setup|my-vscode-setup]]
- [[drafts/my-struggle-with-wasting-food|my-struggle-with-wasting-food]]
- [[drafts/motorcycle-pico-8-game|motorcycle-pico-8-game]]
- [[drafts/motorcycle-camping|motorcycle-camping]]
- [[drafts/minecraft-is-the-metaverse|minecraft-is-the-metaverse]]
- [[drafts/mental-model-of-robot-brains|mental-model-of-robot-brains]]
- [[drafts/media-diet|media-diet]]
- [[drafts/mapping-the-mastodon-fediverse|mapping-the-mastodon-fediverse]]
- [[drafts/make-a-portfolio-site-with-nuxt|make-a-portfolio-site-with-nuxt]]
- [[drafts/lemc|lemc]]
- [[drafts/learning-blender|learning-blender]]
- [[drafts/introducing-connectology|introducing-connectology]]
- [[drafts/intro-to-abstract-syntax-trees|intro-to-abstract-syntax-trees]]
- [[drafts/i-just-do-what-my-calendar-says|i-just-do-what-my-calendar-says]]
- [[drafts/hudson-valley-motorcycle-rides|hudson-valley-motorcycle-rides]]
- [[drafts/how-to-make-an-infographic|how-to-make-an-infographic]]
- [[drafts/how-to-give-credit|how-to-give-credit]]
- [[drafts/how-to-get-started-with-data-analysis-visualization|how-to-get-started-with-data-analysis-visualization]]
- [[drafts/how-to-decide-if-an-idea-is-worth-pursuing|how-to-decide-if-an-idea-is-worth-pursuing]]
- [[drafts/how-men-use-radios|how-men-use-radios]]
- [[drafts/how-i-use-stable-diffusion|how-i-use-stable-diffusion]]
- [[drafts/how-i-use-netlify|how-i-use-netlify]]
- [[drafts/how-i-use-illustrator|how-i-use-illustrator]]
- [[drafts/how-i-use-github|how-i-use-github]]
- [[drafts/how-i-use-figma|how-i-use-figma]]
- [[drafts/how-i-use-diagrams|how-i-use-diagrams]]
- [[drafts/happiness-joy|happiness-joy]]
- [[drafts/hand-built-media-organization|hand-built-media-organization]]
- [[drafts/gpt3-cyberpunk-novel|gpt3-cyberpunk-novel]]
- [[drafts/getting-started-with-mastodon-as-a-developer|getting-started-with-mastodon-as-a-developer]]
- [[drafts/getting-started-with-embeddings|getting-started-with-embeddings]]
- [[drafts/garment-dying-experiments|garment-dying-experiments]]
- [[drafts/faster-nuxt3-build-times|faster-nuxt3-build-times]]
- [[drafts/falun-gong-upstate-ny|falun-gong-upstate-ny]]
- [[drafts/experiments-in-pottery|experiments-in-pottery]]
- [[drafts/experiments-in-bookbinding|experiments-in-bookbinding]]
- [[drafts/exercise|exercise]]
- [[drafts/everyone-should-code-data-literacy|everyone-should-code-data-literacy]]
- [[drafts/espresso|espresso]]
- [[drafts/election-data-analysis|election-data-analysis]]
- [[drafts/dot-density-mapping|dot-density-mapping]]
- [[drafts/data-driven-llm-sentences|data-driven-llm-sentences]]
- [[drafts/current-computer-setup|current-computer-setup]]
- [[drafts/cooking|cooking]]
- [[drafts/cooking-seitan|cooking-seitan]]
- [[drafts/cooking-ramen-experiments|cooking-ramen-experiments]]
- [[drafts/cooking-kolaches|cooking-kolaches]]
- [[drafts/cooking-fermentation|cooking-fermentation]]
- [[drafts/compressing-information-for-llm-context|compressing-information-for-llm-context]]
- [[drafts/climatetrace-shipping-data|climatetrace-shipping-data]]
- [[drafts/choosing-a-social-media-platform|choosing-a-social-media-platform]]
- [[drafts/chess|chess]]
- [[drafts/changing-my-mind-on-scale|changing-my-mind-on-scale]]
- [[drafts/capitalism-letting-people-die|capitalism-letting-people-die]]
- [[drafts/call-of-duty-data-analysis|call-of-duty-data-analysis]]
- [[drafts/building-physical-things|building-physical-things]]
- [[drafts/book-of-changes|book-of-changes]]
- [[drafts/best-ios-apps-for-creativity|best-ios-apps-for-creativity]]
- [[drafts/beacon-main-street|beacon-main-street]]
- [[drafts/assets/!index_assets|!index_assets]]
- [[drafts/art-setup|art-setup]]
- [[drafts/archetypes-and-their-implications|archetypes-and-their-implications]]
- [[drafts/approach-to-problem-solving|approach-to-problem-solving]]
- [[drafts/approach-to-making-music|approach-to-making-music]]
- [[drafts/approach-to-learning|approach-to-learning]]
- [[drafts/animated-graphics-setup|animated-graphics-setup]]
- [[drafts/analyzing-new-orleans-police-misconduct-data|analyzing-new-orleans-police-misconduct-data]]
- [[drafts/an-automated-toolkit-for-schools|an-automated-toolkit-for-schools]]
- [[drafts/adding-wikilinks-to-nuxt|adding-wikilinks-to-nuxt]]
- [[drafts/8pm-to-midnight-mixes|8pm-to-midnight-mixes]]
- [[drafts/!Blog Post Status.canvas|!Blog Post Status.canvas]]
%% Zoottelkeeper: End of the autogenerated index file list %%
---
dek: In which the author recaps an exciting year of prototyping and community building
inprogress: true
date: 2023-12-12T12:42:07-05:00
modified: 2023-12-17T18:27:27-05:00
tags:
---

## Room 302 Studio: Year One

This was one of the most difficult and exciting years of my life, and it has passed incredibly quickly. For the benefit of both myself and the reader, I wanted to catalogue some of the adventures and lessons of the past year, and what that means for the year ahead.

### A Year of Templates & Systems

A lot of this year has been focusing on the things that we repeat; taking meeting notes, writing SOWs, turning user stories into issues, and turning those things into tools and templates so we can focus on our creative work.

Some of that learning is being channeled into Coach Artie, our Studio AI Coach, who is being taught to do some of the repetitive tasks that AI is growing to be well-suited to perform.

Some of that is just creating old-fashioned templates and runbooks in Google Docs and duplicating each time we do something. I've also been developing a studio [Nuxt Template](https://www.npmjs.com/package/room302-template) that allows us to take an idea to a published site extremely quickly. In combination with our own AI assistant and GitHub Copilot, I am continually surprised at far we can go in short spans of time, and I want to keep pushing that and putting reps in.

### Weekly Livestreaming Labs

I have been trying to be more disciplined about putting on weekly livestreams where

### Struggles and Successes with Discord


## Plans For The Year Ahead

I want to start building systems and patterns so that we can turn our ideas into reality much easier. This is everything from our AI studio assistant, to paperwork templates, project management, to deployment and operations.

### A System For Cooperative Products

For work that isn't client-driven, we are building a system that is integrated with our time-tracking software Harvest and our payment processor Stripe. This will allow us to pay out any revenue from our collaborative creations equitably, taking a form similar to residuals in the music industry. All of this will be possible with as little cognitive and technical overhead possible, so we can focus on the important part; turning great ideas into reality.

One of the things that really inspired me to build my own studio was spending time at the local ceramics studio, where I can pay for a membership which gets me access not only to clay but also a huge variety of tools, forms, and patterns to mold it with. The walls are lined with all sorts of different tools for different situations that would be luxurious even for a potter who had spent a lifetime's income and time collecting.---
date: 2023-01-19T01:24:20-05:00
modified: 2023-01-19T01:24:21-05:00
dek: In which
inprogress: true
tags: howto design
---

# Title

---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:38:40-04:00
tags:
---

## Data as a Design Tool: How Room 302 Builds Smarter
---
draft: true
dek: In which we dissect the merciless nature of capitalism, revealing a callous pattern of placing profits above human lives
inprogress: true
date: 2023-02-07T10:36:05-05:00
modified: 2023-09-01T20:39:32-04:00
tags: culture america politics
---

# How Capitalism Idly Watches as People Die

Within the luminous halls of affluence, a disconcerting melody resonates, the leitmotif of the cold equations of capitalism. This melody, which is unrelentingly hammered out on the harsh anvil of human suffering, creates a bleak symphony where the quest for profit supersedes the value of human life. 

This is not a dystopian novel, but rather our harsh and unforgiving reality. Whether it's brave first responders gasping for breath in the aftermath of 9/11, NFL players trading their long-term health for short-lived glory, or ordinary folks grappling with a pandemic while politicians debate the death count. If you peel back the veneer of progress and wealth, and you find a chilling pattern: when dollars are on one side of the scale and human lives are on the other, capitalism chooses money every time.

> There’s a cold underlying rationality which corrupts the motives of even the most well-meaning, and in the absence of strong accountability mechanisms, individual ethics can only go so far. Ultimately the problem is structural, and the solutions will need to be structural, too.
> [Liu-Abolish Silicon Valley](Liu-Abolish%20Silicon%20Valley.md)

## Radium Girls

One of the more striking examples of the indifference of capitalism is the story of the Radium Girls. The Radium Girls were young women who were employed by US Radium Corporation between 1917 and 1926. Radium, as you may have surmised from its name, is extremely radioactive. The Radium Girls painted watch faces with fantastically bright glowing radium dials, allowing their owners to see the time in the dark. 

The women who painted the watch faces were unaware of the health risks they were exposed to while handling the toxic material. But their bosses knew. Their bosses were careful to avoid the radioactive paint. By 1930, nearly 200 of the workers had fallen ill due to radiation-induced health issues such as cancers and tumors, as well as occupational illness like anemia, necrosis, and other medical conditions caused by radiation exposure. The women had been instructed to keep their brushes sharp by wetting them with their lips. Many women's jaws fell from their faces from radiation poisoning. Those women no longer had faces, but many men could now see the time in the dark.

## The NFL

The National Football League (NFL) is the pinnacle of the capitalist entertainment industry— a billion-dollar spectacle whose priority often appears to be profit over anything else. For generations, the NFL has operated with scant regard for its primary workforce, the very lifeblood of the game: the players.

Repeated studies and biomedical research reveal that the majority of NFL players suffer from chronic pain, traumatic brain injuries, and joint ailments due to injuries sustained throughout their careers. However, it's not just about the injuries sustained on the field. Long-term issues such as Chronic Traumatic Encephalopathy (CTE)—a degenerative brain disease found in athletes with a history of repetitive brain trauma—are prevalent among retired NFL players for their entire lives. 

Despite knowing the extensive risks posed by the sport, the NFL has historically downplayed these issues- and we can only guess at their motives for doing so.

This pattern of behavior comes into sharper focus when we examine the financial predicament of NFL players. An alarming number of these athletes, despite their million-dollar contracts, file for bankruptcy within just a few years of retirement, largely due to financial mismanagement and lack of job opportunities for their skillset.

In this sense, NFL players are no different from factory workers or miners whose health deteriorates due to poor working conditions while corporate elites prosper from their labor. Capitalism has a propensity to dehumanize individuals into mere instruments of production or entertainment so that we as fans aren't sickened when we watch the brutal gameplay. 

<https://www.nytimes.com/2023/08/28/sports/ncaafootball/football-concussions-cte.html>

## COVID

In a startlingly brazen display of neglect, our country's systems dragged their feet on implementing lockdown measures. The result? An ungodly toll of human lives lost, an indelible stain on our collective conscience. And this burden did not fall equally—it disproportionately crushed communities of color who were already bearing the brunt of economic inequality.

> We have a profound hatred of the weak and the poor, and a corresponding groveling terror before the rich and successful, and we’re building a bureaucracy to match those feelings.
> [Taibbi-Crabapple-The Divide](Taibbi-Crabapple-The%20Divide.md)

The delay in providing necessary medical care—especially to underserved communities—exposed a harsh truth: capitalism is intrinsically ill-equipped to cater to public welfare when it's at odds with profit-making. Its response to crises is marred by an underlying disdain for those who cannot contribute to its wealth-making machine—the weak and poor—and a reverence for those who can—the rich and successful.

## 9/11 Responders

Just ask the survivors and responders from the 9/11 terrorist attacks, many of whom are still dealing with the long-term health effects of that day.

It's a poignant reminder that under capitalism, your worth is tied inexorably to your ability to contribute economically. Once that capacity diminishes or ceases altogether—as in the case of these sickened responders—you are swiftly relegated to society's periphery.

## What does this mean for our future?

Given this history, what lessons can be learned as we approach a period of intense growth in Artificial Intelligence? [[crypto-ai-colonization]]

> Today mankind is locked into stealing ravenously from the future.
> William R. Catton **Overshoot: The Ecological Basis of Revolutionary Change**

We must recognize the warnings of history and take steps to protect vulnerable communities from being taken advantage of by those in power. Capitalism's disregard for human life is a cautionary tale for all industries, including AI. We must be vigilant in ensuring that progress does not come at the expense of human lives or dignity.

Many capitalist societies are plagued with stress-related illnesses, inadequate public education, pollution, and prohibitive healthcare costs. In fact, the United States, one of the wealthiest capitalist countries, ranks poorly among developed nations in terms of healthcare access and quality.

## Imagining a Post-Capitalist World

It's time to envision a system where success isn't measured by the accumulation of wealth but by the wellbeing of its citizens. We can learn from capitalism's failings and use them as stepping stones towards a better future—a future where no one has to die for the sake of profit.

In a post-capitalist world, our values needn't be dictated by profit margins and GDP growth. Instead, we could prioritize wellbeing, sustainability, and mutual aid. Society would be measured by the happiness of its citizens and the health of its environment rather than its billionaires' net worth.

The Internet, which serves as the backbone for our digital age and countless billion-dollar industries, was born out of government-funded research, not corporate enterprises.

Most fundamental breakthroughs, from satellite technology to life-saving medicines, often have their roots in public sector research. Market-driven innovations typically focus on turning these publicly funded breakthroughs into marketable products rather than driving the frontier of knowledge.

Of course, the radical shift we need will not happen overnight. But acknowledging capitalism's fundamental flaws is the first step toward building a more compassionate, equitable future. If history has shown us anything, it's that no system, not even capitalism, is too big to change or fail.

---

1. Triangle Shirtwaist Factory Fire in 1911 - Profits were prioritized over worker safety, resulting in 146 deaths.
2. Exxon Valdez oil spill in 1989 - Ignored safety standards for cheaper operations, leading to a devastating environmental disaster.
3. Financial Crisis in 2008 - Irresponsible lending for quick profits triggered a global financial meltdown.
4. Deepwater Horizon Oil Spill in 2010 - Cutting costs on safety measures led to the largest marine oil spill in history.
5. Flint Water Crisis starting in 2014 - Switching to a cheaper water source led to lead-contaminated drinking water.
6. Asbestos Exposure throughout the 20th century - Asbestos was widely used to cut costs, despite knowing its links to cancer.
7. Union Carbide Bhopal Disaster in 1984 - Safety standards were ignored to save money, leading to a gas leak that caused thousands of deaths.
8. Tobacco Industry from the 1950s onwards - Aggressively marketed cigarettes and lobbied against regulations to maintain high profits, despite knowing health risks.
9. Pharmaceutical Opioid Crisis from the 1990s onwards - Painkillers were aggressively marketed for profits, leading to a nationwide opioid crisis.
10. Boeing 737 Max Crashes in 2018 and 2019 - Ignored safety concerns to save money, leading to two fatal crashes.
---
draft: true
dek: In which we modify our tools to more precisely fit our intentions
inprogress: true
date: 2022-11-02T20:00:38-04:00
modified: 2023-08-09T14:13:23-04:00
tags: process personal programming setup
---

# My VSCode setup and favorite plugins

![[1316824112_Cute_Pixel_Art_of_a_coder_s_desk_cluttered_with_various_plugins_and_VSCode_open__reflecting_off_a_go.png]]

Imagine a coding environment that not only boosts your productivity but also sparks joy with every keystroke. Recently, I've fine-tuned my Visual Studio Code (VSCode) setup to help me work most efficiently and center joy. Trying a few various themes and plugins has ultimately allowed me to craft a toolkit that's geared towards my preferred workflow.

For more info about how VSCode fits into my broader prototyping toolkit see [[2022-prototyping-toolkit]]

## Theme

For my theme, I decided to combine [Ayu](https://marketplace.visualstudio.com/items?itemName=teabyii.ayu) and [Panda Theme](https://marketplace.visualstudio.com/items?itemName=tinkertrain.theme-panda). The former is a minimal and flat theme that emphasizes ease of use, while the latter adds an extra layer of fun with its vivid colors. Together, they provide an environment that satisfies my need for both productivity and delight. I like to have my system use a light theme during the day and a dark theme at night, so I have themes to match both modes.

## Plugins
- [GitHub Co-Pilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot) provides an easy way for me to track and manage important issues and pull requests. 
- [GitHub Pull Requests](https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github) makes it easy to create new pull requests right from vscode.
- [GitLens](https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens) helps me better understand who wrote what and when, making collaboration and debugging a lot less stressful.
- [Live Share](https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare) connects me with my teammates in real-time and enables us to work together remotely, even on the same project.
- [Prettier ESLint](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint) allows me to quickly and easily format my code and keep me sane.
- [Toggle Light/Dark Theme](https://marketplace.visualstudio.com/items?itemName=danielgjackson.auto-dark-mode-windows) helps me quickly switch between two different themes based on the system setting, which I do every day when it gets dark.
- [Vitest](https://marketplace.visualstudio.com/items?itemName=ZixuanChen.vitest-explorer) allows me to run automated tests right inside my editor, which saves me time and helps me spot potential bugs quickly.
- [Volar](https://marketplace.visualstudio.com/items?itemName=Vue.volar) provides language enhancements when working with Vue. 
- [VSCode Pets](https://marketplace.visualstudio.com/items?itemName=tonybaloney.vscode-pets) provides a fun way to take a break when I need a mental breather, as well as a feeling of companionship while I'm coding.
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-01T15:45:40-04:00
tags:
---

## Advanced Animations and Transitions in Vue

## Properly keying is essential
Many bugs with animations and transitions often come to not properly keying various elements in a `v-for` - this means the animation can't keep track of the [object constancy](https://bost.ocks.org/mike/constancy/) and things behave strangely. Each key must be unique to each individual thing you want to animate. 

## Deciding between JS and CSS animations
A lot depends on how complicated you want an animation to be, if you want to stagger or delay parts of the animation, what properties you want to animate, if you want to pull sound into your animation, the mechanism you will use to trigger the animation, and how many DOM elements you will be animating at once. 

### Integrating Anime.js and Vue
Anime.js has an incredibly well-designed interface for designing performant animations. We will use it in combination with Vue's  ref system so that we can maintain performance and keep our code as simple as possible. 

## Appearance Animations
By adding the [appear prop] to the `<Transition appear>` the transition will be applied on the initial render. 

## Event Animations
Sometimes we want an animation to be triggered when an event happens, like data being successfully fetched, user input, or some other sort of change. Anime makes this easy, as we can define the animation in a function and then pass the element into it as needed, using our existing event structure. 

## Vue's Built-In Enter/Leave Transitions
Vue has `Transition` and `TransitionGroup` components [built in](https://vuejs.org/guide/built-ins/transition) to apply animations when elements are added or removed, or change position within a v-for.

### Named Transitions
You can create a named transition and define it in CSS.

```vue
<Transition name="fade"> ... </Transition>
```

```css
.fade-enter-active,
.fade-leave-active {
  transition: opacity 0.5s ease;
}

.fade-enter-from,
.fade-leave-to {
  opacity: 0;
}
```

### Custom Transition Classes
Some libraries like [Animate.css](https://daneden.github.io/animate.css/) provide a bunch of premade animations which can be invoked by adding class names to an element. 

In Vue you can specify CSS class names to be added to the element at certain portions of the lifecycle:
```vue
<Transition
  name="custom-classes"
  enter-active-class="animate__animated animate__tada"
  leave-active-class="animate__animated animate__bounceOutRight"
>
  <p v-if="show">hello</p>
</Transition>
```

### Transition Javascript Hooks
The `<Transition>` element also provides a number of handy event-style hooks that will allow us to use javascript to animate the element in more elaborate ways.

```vue
<Transition
  @before-enter="onBeforeEnter"
  @enter="onEnter"
  @after-enter="onAfterEnter"
  @enter-cancelled="onEnterCancelled"
  @before-leave="onBeforeLeave"
  @leave="onLeave"
  @after-leave="onAfterLeave"
  @leave-cancelled="onLeaveCancelled"
>

</Transition>
```

## Page & Element Transitions
Nuxt provides [page transitions](https://nuxt.com/docs/getting-started/transitions#page-transitions) that let you apply classes as the route or [layout](https://nuxt.com/docs/getting-started/transitions#layout-transitions) changes.

```
.page-enter-active,
.page-leave-active {
  transition: all 0.4s;
}
.page-enter-from,
.page-leave-to {
  opacity: 0;
}
```---
dek: In which
inprogress: true
date: 2023-01-30T12:00:13-05:00
modified: 2023-09-09T15:18:11-04:00
tags: nature
---

# The Book of Changes

[Wilhelm_et_al-The I Ching or Book of Changes](Wilhelm_et_al-The%20I%20Ching%20or%20Book%20of%20Changes.md)
---
dek: In which the future has arrived, but is only distributed to 8-year-olds
inprogress: true
date: 2023-10-01T14:30:46-04:00
modified: 2024-01-28T18:20:31-05:00
tags:
---

## Minecraft is the Metaverse: The future we're waiting for is already here

### Introduction

- Briefly introduce the concept of the Metaverse
- Pose the question: What if the Metaverse is already here?
- Thesis statement: Minecraft serves as an existing example of a Metaverse

---

### The Hype Around the Metaverse

- Discuss the growing interest in the Metaverse
- Mention notable companies and figures investing in it
- Explain the features people expect from a Metaverse

---

### What Makes a Metaverse?

- Define the key characteristics that make up a Metaverse
    - Immersive Experience
    - User-Generated Content
    - Social Interaction
    - Economic Transactions

---

### Minecraft: A Closer Look

- Brief history and impact of Minecraft
- Discuss its immersive experience
- Highlight the user-generated content

---

### Social Dynamics in Minecraft

- Discuss the social aspects, communities, and interactions in Minecraft
- Compare these to expected social features of a Metaverse

---

### The Minecraft Economy

- Discuss the in-game economy, trading, and even real-world economic impact
- How does this align with the economic expectations of a Metaverse?

---

### Skeptics and Counterarguments

- Address potential criticisms of considering Minecraft as a Metaverse
- Discuss limitations and how Minecraft differs from the "ideal" Metaverse

---

### The Future is Now

- Argue that waiting for a future Metaverse overlooks existing virtual worlds that already meet many criteria
- Discuss the potential for Minecraft to evolve even closer to the Metaverse ideal

---

### Conclusion

- Summarize the key points made
- Reiterate that Minecraft offers a glimpse into what the Metaverse could be
- Final thoughts on what this means for the future of virtual worlds

---

### Additional Sections (Optional)

- Case Studies: Profiles of unique Minecraft worlds that resemble a Metaverse
- Interviews: Conversations with Minecraft users who view it as a Metaverse
- Resources: Further reading, videos, or tutorials for diving deeper into Minecraft or the Metaverse concept

<https://www.youtube.com/watch?v=UKpFoYqN9-0>
---
dek: In which, in the pursuit of intelligent answers, we try to give the robot as much information about the world as possible very few words
inprogress: true
date: 2023-08-07T09:28:25-04:00
modified: 2023-09-09T14:58:15-04:00
tags: machinelearning programming howto
---

# How To Give an LLM As Much Context In As Little Tokens As Possible
---
date: 2024-02-13T19:10:50-05:00
modified: 2024-04-18T13:40:06-04:00
---
## Search and Rescue / Ropes & Rappelling

## Canyoneering / Rappelling

Descender: <https://www.petzl.com/US/EN/Professional/Descenders/I-D-S>

Yates 310 rescue harness: <https://www.yatesgear.com/index.php?route=product/product&product_id=540>

## Outdoor First Aid

## Kayaking

<https://kokopelli.com/products/rogue-r-deck-removable-spraydeck>

```
SPECS

**Series:** Adventure Series

**Material (Sidewall):** 210d TPU + Nylon

**Type:** R-Deck (Removable Spraydeck) 

**Material (Floor):** 210d TPU + DuPont Kevlar Aramid-Nylon Blend

**Water Rating:** Flat Water, Bays & Inlets, Class I - II

**Valve (Pontoon):** Leafield D7

**Chambers:** 1 (Main Pontoon)

**Valve (Seat):** Stem

**Weight (Boat):** 7.9lb (3.6kg)

**PSI (Pontoon):**  - 1.5

**Weight (Boat + Key Accessories*):** 9.1lb (4.1kg)

**PSI (Seat):** 1

**Weight (Boat + All Accessories):** 10.0b (4.5kg) 

**Outer (Length):** 90in (229cm)

**Packed Size (Rolled):** 16 x 8in (41 x 20cm)

**Outer (Width):** 37in (94cm)

**Sprayskirt Compatible:** Yes

**Inner (Length):** 57in (145cm)

**Thigh-Strap Compatible:** No

**Inner (Width):** 16in (41cm)
```

Paddle: <https://aquabound.com/products/whiskey-fiberglass-4-piece-straight-shaft?variant=39485546692657>
---
dek: In which
inprogress: true
date:
modified:
tags: tech
---

# Introduction To Abstract Syntax Trees

Abstract Syntax Trees (ASTs) serve as a critical component in understanding the structure of our code. This understanding becomes even more important when working with frameworks such as Vue and Nuxt, or when trying to enforce code standards and find problematic patterns with tools like ESLint.
---
date: 2023-01-19T01:23:31-05:00
modified: 2023-09-09T15:13:49-04:00
tags: personal
---

# Centering Happiness & Joy
---
dek: In which
inprogress: true
date: 2023-08-07T11:44:53-04:00
modified: 2023-09-09T14:57:50-04:00
tags: howto process
---

# So you wanna have a school?

## Tools
### Discord
### Google Workspace

## Artificial Intelligence

## Principles
---
date: 2023-01-19T01:18:44-05:00
modified: 2023-01-19T01:18:44-05:00
dek: In which
inprogress: true
tags: process howto
---

# Title
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:43:05-04:00
tags:
---

## See How The Studio Developed a Product in 24 Hours

---
date: 2023-01-19T01:25:04-05:00
modified: 2023-09-09T15:08:18-04:00
dek: In which
inprogress: true
tags: personal setup
---

# Title
---
draft: true
dek: In which we take cloth of one color and make it another
inprogress: true
date: 2022-11-20T16:06:23-05:00
modified: 2024-05-07T17:20:40-04:00
tags: art
---

#art #experiments #setup

## Transforming Clothing with Garment Dyeing

Clothing can often be the most personal expression of one's style, but it is often difficult to find apparel that is completely unique and one-of-a-kind. That's why I've been experimenting with garment dyeing! It allows me to take my everyday pieces of clothing and transform them into something eye-catching, bold, and one-of-a-kind.

### Materials

I have used a variety of materials for my dyeing experiments, such as fabric paints, dyes, and inks. I have also experimented with various materials for fabric, such as cotton, silk, and rayon.

### Dying Design Style Choices

When it comes to dying design style choices, I am drawn to natural colors and minimalism. I believe in letting the colors and textures of the fabric speak for themselves and creating an overall look that is simple, yet eye-catching. For example, I often stick to neutral colors, or I may experiment with colors like blues or greens to create a subtle, natural-looking pattern.

### Ice Dyeing

One of my favorite techniques for garment dyeing has been ice dyeing. This is a unique dyeing process where you use ice cubes to create beautiful, intricate patterns on the fabric. It creates an interesting visual texture and depth of color, and the design possibilities with this method are virtually limitless.

### Gradient/Dip Dyeing

Dip dyeing is another technique I've been experimenting with. This method involves submerging the entire garment, or parts of the garment, in a dye bath and then gradually pulling the fabric out of the oxidizing dye to create a gradient effect. It's a great way to add a unique look to any garment.---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T20:45:40-04:00
modified: 2022-12-23T09:13:48-05:00
---

#cooking 

# Cooking: Ramen

[[cooking]]
---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T21:22:25-04:00
modified: 2024-05-07T14:11:34-04:00
---

#motorcycle #hudsonvalley

## Hudson Valley Motorcycle Rides and Spots to Visit

### How I track my ride data
#### GPX data from iPhone
#### GPX data from Garmin

### Fahnestock / 301

### Bear Mountain Bridge / Anthony's Nose

### Seven Lakes Drive

### Greenwood Lake

### Perkins Lookout

### Catskills
---
dek: In which
inprogress: true
date: 
modified: 
tags: climatechange
---

# Title
---
dek: In which
inprogress: true
date: 
modified: 
tags:
---

# A Stack For Custom Web Mapping Post-Mapbox


---
draft: true
dek: In which
inprogress: true
date: 2023-01-19T01:47:25-05:00
modified: 2023-01-19T13:35:02-05:00
tags: art
---

# Experiments in Bookbinding
---
dek: In which
inprogress: true
date: 2023-08-06T18:38:15-04:00
modified: 2023-09-09T14:58:52-04:00
tags: journalism motorcycle ny
---

# Law Enforcement Motorcycle Clubs
---
dek: In which
inprogress: true
date: 2023-03-20T21:14:36-04:00
modified: 2023-09-09T15:15:20-04:00
tags: machinelearning 
---

# Building a Mental Model of Robot Brains
---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T23:02:37-04:00
modified: 2022-12-23T09:15:03-05:00
---
# Visualizing ClimateTrace Data

#dataviz #climatechange 

# Comparisons

# Putting numbers into context

# Static vs Dynamic Assets
---
dek: See behind the scenes of election night coverage with Electology, the new tool transforming live data analysis. 
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-16T14:14:44-04:00
tags:
---

## Unveiling Electology: The Election Analysis Tool You Didn’t Know You Needed

I'm excited to tell you about Electology, my passion project that brings together everything I've learned and wanted to achieve in the realm of election data visualization and analysis. After working at NBC News and creating the app used by Steve Kornacki for live election coverage, I decided to take all the ideas and features I couldn't implement there and build something even better on my own. That's how Electology was born.

Electology has two main components. The first is a touchscreen application designed for TV anchors to use during election nights. This app allows them to show not only live election results but also delve into historical data to tell compelling stories about the elections. What makes this touchscreen app unique is that it uses web technology and powerful data visualization libraries. This means it's fully extensible and can be customized to match the graphic styles of any network, which is a huge plus for major clients like NBC or CBS who have specific styling and colors for their graphics packages.

One of the things I'm really proud of is our ability to create advanced data visualizations. We have everything from swing arrows and scatter plots to bivariate choropleth maps. These unique visualizations help tell intricate stories about election data that other tools just can't match, with visuals that are broadcast-ready at all times.

The second component of Electology is our digital maps, which news outlets can embed directly into their websites. These maps stand out because they offer incredibly high-resolution results, down to the precinct level wherever possible. We also integrate as much historical and demographic data analysis to give crucial context to emerging stories. This level of detail is a key part of accurate analysis and storytelling.

Another core approach is our AI-augmented data-driven sentences. These are text displays that highlight the most important insights in various geographic regions, helping users understand the data better and identify outliers or changes. We've also enhanced these sentences with LLMs to incorporate large datasets of historical and demographic results, providing deeper context and explanations.

We also incorporate a wealth of historical election data from sources like the MIT Media Lab and FEC campaign finance data, alongside demographic data from the Census Bureau. This comprehensive collection of data allows users to analyze trends and patterns without making outright predictions about future outcomes. Instead, we provide a range of analysis tools so users can make their own informed assumptions and predictions.

At Electology, we trust you to get the data. We cut out the fluff and give you direct access to the raw numbers, no middleman.

Electology is about empowering users with the tools and data they need to understand and analyze elections deeply. Whether it's a TV anchor needing to explain what's happening in real-time or a news outlet looking to provide their audience with interactive maps, Electology has something to offer.

I'm constantly refining and improving Electology, and I'm excited about its future. There are always new features and improvements on the horizon, and I'm thrilled to see how it will continue to evolve and help people make sense of election data.

### Touchscreen Application

- **Web Technology**: Uses powerful data visualization libraries like D3 and WebGL for full customization.
- **Broadcast Integration**: Can match any network's graphic style and integrate with broadcast systems like VizRT
- **Advanced Visualizations**: Includes swing arrows, scatter plots, and bivariate choropleth maps.

### Digital Maps

- **High Resolution**: Detailed results down to the precinct level wherever possible
- **Embeddable**: Easy integration into news websites and client content management systems
- **User-Friendly**: A strong emphasis on intuitive design that can accommodate a spectrum of user expertise.

### Data Integration

- **Historical Data**: Election data from the MIT Media Lab and FEC campaign finance data.
- **Demographic Data**: Analyzes trends using Census Bureau data.
- **Performance**: Optimized to handle high-resolution data seamlessly.

### Analysis Tools

- **Custom Analysis**: Tools for users to explore, visualize, and share their own predictions.
- **Data-Driven Sentences**: Reiterates key insights from visualizations automatically, increasing user engagement and approachability

Electology handles the immense scale of historical live and election data with a robust and innovative infrastructure. By leveraging technologies like Netlify Edge functions and CloudFlare workers, we ensure that our processes run efficiently at the edge, significantly reducing latency and improving performance during peak times. We also focus on strategically slicing our datasets across time and geography so we can provide deep analysis while maintaining performance.

One of our key strategies involves building SVGs and serving them as static assets, which allows us to perform computational tasks efficiently on the server and use an image CDN to cache maps. This method ensures consistent and responsive data visualization across devices even under heavy loads, making Electology reliable and fast during critical election moments.

Accuracy and timeliness of data are at the heart of Electology. All year long we are continuously updating precinct boundaries and demographic data by sourcing from various projects and sources. This ongoing effort guarantees that our users always have access to the most current and precise election information. Our commitment to maintaining up-to-date datasets underscores the value we are providing our users, who would otherwise need to be doing this constant upkeep themselves.

Customization and ease of use are central to Electology's design. By utilizing familiar web technologies, we've made the system highly accessible to newsrooms with web development capabilities. We have also created a number of tools that allow for easy integration into OBS, so that you can easily livestream of create videos with a variety of broadcast-friendly realtime data visualizations.

Our modular approach allows for quick adjustments and last-minute changes, essential for the dynamic environment of live news coverage. Our backend producer tool allows you to preset areas of focus, bookmark races and locations, and integrate external data sources like polling and campaign finance into sequential slides, so you can spend your time telling your story instead of clicking around.

Our intuitive user interface caters to a wide range of users, from TV anchors needing quick visualizations to analysts conducting in-depth data explorations.

Regarding data security and privacy, Electology primarily uses public historical and open data sources, minimizing privacy concerns. Our focus is on providing accurate and accessible election data, ensuring that users can trust the information they receive without worrying about sensitive data breaches.

We ensure the accuracy and reduce the bias in our AI-enhanced data-driven sentences through rigorous testing and a controlled approach. By using historical data extensively to validate our models and adopting a Mad Libs-style method where the AI repeats specific data fed to it, we mitigate the risk of inaccuracies and biases. This approach ensures that our users receive factual and reliable information, enhancing their understanding of election data.

While Electology isn't fully open source, we believe in the power of transparency and release portions of our code to the community and work in the open as much as possible. Our primary focus has been on creating the best possible product for our users, and managing a fully open source project would require extensive documentation and maintenance efforts.

We are hoping Electology will stand out in the market by offering a premium, highly detailed product designed with meticulous care. Every aspect of the tool has been thoughtfully considered, making it a luxury product for those who want to really understand election data, regardless of skill level.

Our ethical guidelines emphasize transparency and trust, providing users with direct access to their data without unnecessary summaries or delays, allowing them to draw their own informed conclusions.

Integrating Electology with existing systems is designed to be streamlined and efficient. We've done extensive work to ensure compatibility with common CMS platforms like WordPress and Drupal, making it easy for our clients to incorporate our maps into their workflows. Typically, we can achieve integration within a month.

We made Electology simple and customizable. Whether you're whipping up quick visuals for TV or diving deep into the numbers, Electology's got your back.

We’re all about transparency and precision. We hand you the detailed datasets and powerful tools to uncover the real stories behind the elections.---
date: 2022-11-02T19:57:34-04:00
modified: 2022-12-23T09:24:34-05:00
---
# Exercise

#personal #health #quantifiedself 

We all know we should exercise. It's good for our heart, our muscles, our mood, and our weight. But sometimes it's hard to get motivated. Maybe I don't have time, or I don't know what kind of exercise to do. Sometimes I’m just not feeling it.

I’m going to try to document my motivation and approach towards exercise here both as a way to share my thinking and as a reference to keep myself accountable and motivated. 

## Goals

My goals with exercise are to help my body and mind stay grounded and working together. I want to be "match ready" at all times - not just physically, but mentally and emotionally. I also want to reduce my risk of depression, and increase my mental clarity.

I also want to be able to improve my performance through practice. This means being able to increase my strength, endurance, and flexibility, and tracking those improvements using data. 

### Match ready

Being "match ready" means being physically and mentally prepared for whatever comes your way. It's about being in the best possible shape to handle what life throws at you.

For me, this means being able to run long distances, lift heavy things, and move my body in all kinds of ways, sometimes while carrying heavy packs. It also means having the mental stamina to stay calm and focused in challenging situations.

### Mental clarity / depression

Exercise can be a great way to help alleviate depression symptoms. Studies have shown that exercise can help to improve mood, sleep, and energy levels in people with depression and anxiety.

For me, I find that exercise helps to clear my head and give me a sense of calm. It's a way to release all the pent-up energy and stress that can build up over time. The soreness of my muscles after a hard work out feels good in a way that reminds me I am human and that I accomplished something.

### Performance

When it comes to performance, I want to use exercise to improve my strength, endurance, and flexibility. I want to be able to push myself further and further each day. 

## Plan

My plan is to exercise three times a week for at least 30 minutes each time. I'll focus on different kinds of exercises, like running, weightlifting, HIIT, yoga, and stretching. 

I'm also going to track my progress so that I can see how far I've come and set realistic goals for myself. This will help me stay motivated even when it gets tough. 

Finally, I'm going to make sure that I take time to rest and recover after each workout so that my body has time to heal and rebuild itself before

### Objective improvement through practice

I like watching numbers go in the right direction. One of the interesting things about exercise is that there are objective measurements that you can record and watch yourself improve over time. See [[quantified-self]]

This motivates me a lot. I want to use the momentum that comes from doing 1 more rep, or cutting a few seconds off a time and keep building on that.

Things I like to track are:

- How far I can run without stopping
- One mile running time
- How long I can hold a yoga pose
- How long I can hold a plank
- How many push-ups I can do in a row

## Experiments and data

I'm always experimenting with different ways to exercise, and I love to collect data on my progress. This helps me to stay motivated, and it's interesting to see how my body and mind respond to different types of activity.

Here are some of the things I've been up to lately:

- Running with a weighted vest
- Wearing a weighted vest while doing bodyweight exercises
- Doing kettlebell and bulgarian bag swings
- Jumping rope for 10 minutes every day
- Doing yoga and stretching for 30 minutes every day

## Equipment

I try to take a minimalist approach to exercise equipment. I don't want huge contraptions taking up corners of my apartment. I want to be able to move freely and still be able to do a variety of exercises that activate muscles all over my body.

I've settled on equipment that I can pack up into a bag and bring anywhere:

- A good pair of running shoes
- A yoga mat
- A kettlebell
- A jump rope
- A bulgarian bag
- Weighted vest

### Keeping it interesting

One of the most important things for me is to keep my exercise routine interesting. I get bored easily, so I need to mix things up. So I am often trying new things and also just changing up the sequence and timing of my exercises.

I like to set goals for myself, so that I have something to strive for. This could be a certain number of reps, or a certain time or distance. Having a goal gives me something to focus on, and it helps me to push myself harder.

### Bulgarian bag

The bulgarian bag is a great piece of equipment because it's so versatile. You can use it for strength training, cardio, or even just stretching. It's also really portable, so it's perfect for traveling.

I like to use the bag for a variety of exercises, including:

- Swings
- Cleans
- Snatches
- Squats
- Lunges
- presses

### Kettlebell

I love kettlebells because they're such a great all-in-one piece of equipment. You can use them for strength training, cardio, or even just stretching. They're also really portable, so they're perfect for traveling.

I like to use kettlebells for a variety of exercises, including:

- Swings
- Cleans
- Snatches
- Squats
- Lunges
- presses

### Weighted vest

A weighted vest is a great way to add some extra resistance to your workout. I like to wear mine while doing bodyweight exercises. It's a great way to increase the intensity of your workout without having to add more weight.

The science on the weighted vest doesn’t show dramatic improvements, but for me it makes intuitive sense that an increase of center mass weight while doing bodyweight exercises would increase the intensity and make it easier to do those same movements after the weight is removed.

### Jumprope

Jumping rope is a great cardio workout, and it's also a lot of fun. I like to do 10 minutes of jumping rope every day, either as a warm-up or a cool-down. It's a great way to get your heart rate up without having to run for miles, especially when it's cold out.

### Yoga / Stretching

Yoga and stretching are important for flexibility and mobility. I like to do some yoga or stretching every day, when I work out, and right before bed. It helps me to wind down and relax, and it helps to prevent injuries and helps me keep up my flexibility. 

## Dreams / next steps

There are always new things to dream about and new goals to set. Here are some of the things I'm dreaming about lately:

- Doing a half-Murph: This is a workout that consists of a 1 mile run, 50 pull-ups, 100 push-ups, 150 air squats, and another 1 mile run. I want to be able to do this with a weighted vest.
- Playing basketball: Basketball is one of my favorite sports to play, and I always end up pushing myself physically- the only problem is there is no where to play around where I live. One day I'll have a goal to join a league, or maybe get a hoop for my backyard. 
- Learning jiu-jitsu: Jiu-jitsu has always interested me, and maybe one day I'll have the time to commit to it. I want to get to a basic level of cardio fitness before I try showing up to a class though.
- Taking up boxing: I love the idea of learning how to box. It's a great workout, and I like the mental aspect to it too. I don't know if I'll ever actually get into the ring and fight someone, but it's something I want to learn more about.
- Rock climbing: Rock climbing is another one of those things that I've always wanted to try. It looks like a lot of fun, and it's also looks like a great workout. Maybe one day I'll have the opportunity to try it.
---
dek: In which we use the robot to discern what is happening, and  then schedule regular updates
inprogress: true
date:
modified:
tags: machinelearning tech programming
---

# Scheduled Summaries of Realtime Data with Supabase + GPT-4
---
date: 2023-01-19T01:10:57-05:00
modified: 2023-01-19T01:10:58-05:00
dek: In which
inprogress: true
tags: tech howto
---

# Title
---
dek: In which
inprogress: true
date:
modified:
tags: music art dj vj
---

# Sound-Reactive Art

## P5js

[Visualizing Music with p5.js](https://therewasaguy.github.io/p5-music-viz/)


---
dek: In which the author explores the newly-growing network of mastodon instances and the things that make each of them unique
inprogress: true
date: 2022-12-15T09:59:12-05:00
modified: 2022-12-23T09:26:05-05:00
---

#dataviz #network 

# Mapping The Mastodon Fediverse

## Questions
- How many Mastodon instances are there?
- Which instances have the most users?
- What do the inter-instance networks look like?
- Can we compare Mastodon communities to Twitter communities? Is there any way to measure migration?
- Are there particularly interesting 

## How do we gather our data?
### How does Mastodon work?
### How can we automate scraping the info we need?
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:39:07-04:00
tags:
---

## Risk and Reward: The Benefits of Fearless Experimentation
---
dek: In which
inprogress: true
date: 2023-08-28T12:28:54-04:00
modified: 2023-09-09T15:04:16-04:00
tags: tech howto
---

# Making your Nuxt 3 Build Times Faster
---
dek: In which we use Cloudinary both as a host and CMS to show photos that we took to our friends
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-08T12:54:13-04:00
tags:
---

## Creating a photoblog with Cloudinary and Nuxt

1. I upload files to Cloudinary through automator actions paired with bash scripts
2. I use the Cloudinary JS SDK to query the most recent photos, EXIF data, and add/remove tags
3. I use Nuxt to query the API and display the images on my Netlify-hosted website

## Automator Actions

### Automatically uploading screenshots

![The automator configuration that sits outside the following bash scripts: the first is a folder action that passes all green-tagged files/folders, and the other is a folder action that watches the screenshot folder for changes and runs the bash script when a new file is added](http://res.cloudinary.com/ejf/image/upload/v1715186716/Screenshot_2024-05-08_at_12.45.05_PM.png)

```bash
#!/bin/bash

# API keys for Cloudinary
export CLOUDINARY_URL=cloudinary://THIS_IS_SECRET@NAME

# Iterate over each passed argument
for file in "$@"
do
  # Check if the file exists
  if [ -f "$file" ]; then
    # Upload to Cloudinary and capture output
    upload_output=$(/opt/homebrew/bin/cld uploader upload "$file" use_filename=true unique_filename=false 2>&1)
    upload_exit_status=$?

    # Check if the upload was successful
    if [ $upload_exit_status -eq 0 ]; then
      # Attempt to extract the URL using the absolute path for jq
      url=$(echo "$upload_output" | /opt/homebrew/bin/jq -r '.url' 2>/dev/null)

      # Check if the URL is non-empty
      if [ -n "$url" ]; then
        echo "$url" | pbcopy
        # Display success notification with the URL
        osascript -e "display notification \"Uploaded $file to Cloudinary and URL copied to clipboard: $url\" with title \"Screenshot Upload\""
      else
        # Display notification for empty URL
        osascript -e "display notification \"Failed to extract URL from output\" with title \"Debug\""
      fi
    else
      # Display notification for upload failure
      osascript -e "display notification \"Failed to upload $file to Cloudinary. Error: $upload_output\" with title \"Screenshot Upload\""
    fi
  else
    # Display notification for file not found
    osascript -e "display notification \"File does not exist: $file\" with title \"Debug\""
  fi
done

```

## Upload all green-tagged files to Cloudinary through Folder Action

```bash
#!/bin/bash

# Ensure Cloudinary CLI is available
/opt/homebrew/bin/cld >/dev/null 2>&1 || { echo >&2 "Cloudinary CLI required but not installed. Aborting."; exit 1; }

# API keys for cloudinary
export CLOUDINARY_URL=cloudinary://THIS_IS_SECRET@NAME

# Iterate over all green tagged files 
for folder in "$@"
do
  # Find all green tagged files
  green_files=$(mdfind -onlyin "$folder" 'kMDItemUserTags == Green')

  # Count the number of green tagged files
  num_green_files=$(echo "$green_files" | wc -l)
  osascript -e "display notification \"$num_green_files green files found.\" with title \"Upload Green Media\""

  # Initialize counter for successful uploads
  successful_uploads=0

  # Read each file
  echo "$green_files" | while read -r file
  do
    # Check if file is not an empty string
    if [[ -n "$file" ]]
    then
      # Use Cloudinary CLI to upload file
      upload_output=$(/opt/homebrew/bin/cld uploader upload "$file" 2>&1)

      if [ $? -eq 0 ]
      then
        successful_uploads=$((successful_uploads + 1))
        # Notify every 25% for less than 10 files, otherwise only on errors
        if [ $num_green_files -le 10 ] || [ $((successful_uploads % (num_green_files / 4))) -eq 0 ]
        then
          osascript -e "display notification \"Uploaded $successful_uploads of $num_green_files files to Cloudinary.\" with title \"Upload Green Media\""
        fi
      else
        # Display the error message from Cloudinary in the notification
        osascript -e "display notification \"Failed to upload $file to Cloudinary. Error: $upload_output\" with title \"Upload Green Media\""
      fi
    else
      osascript -e "display notification \"Skipped an empty filename.\" with title \"Upload Green Media\""
    fi
  done
done

osascript -e "display notification \"Done uploading files.\" with title \"Upload Green Media\""
```


### Getting EXIF data from a resource
```js
// Fetch the resource details with EXIF data

const result = await cloudinary.api.resource(resourceId, { exif: true });
```

#### Getting last X photos uploaded
```js    
// Fetch the last 100 images uploaded
    const result = await cloudinary.search
      .expression("resource_type:image")
      .sort_by("uploaded_at", "desc")
      .with_field("tags")
      .max_results(100)
      .execute();
```
#### Nuxt API endpoint: `/server/api/cloudinary.ts`
```ts
import { defineEventHandler } from "h3";
import { v2 as cloudinary } from "cloudinary";

cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET,
});

	export default defineEventHandler(async (event) => {
	// readBody is auto-imported by Nuxt from h3
	const body = await readBody(event);
	const numPhotos = +body.numPhotos
  try {
    const result = await cloudinary.search
      .expression("resource_type:image")
      .sort_by("uploaded_at", "desc")
      .max_results(100) // or numPhotos
      .execute();

    const photos = result.resources.map((resource) => ({
      href: resource.secure_url,
      public_id: resource.public_id,
      uploaded_at: resource.created_at,
    }));

    return photos;
  } catch (err) {
    console.error("Error fetching photos from Cloudinary: ", err);
    return { error: "An error occurred while fetching photos." };
  }
});
```


#### Fetching photos through Nuxt API
```js
const { data: photos } = await useFetch('/api/cloudinary', {
  method: 'POST',
  body: JSON.stringify({ numPhotos: numPhotos.value })
})
```

#### Adding `photo-blog` tag
```js
const result = await cloudinary.uploader.add_tag('photo-blog', [resourceId]);
```
---
draft: true
dek: In which
inprogress: true
date: 2022-12-31T19:45:01-05:00
modified: 2023-09-09T15:19:23-04:00
tags: setup art vj
---

# Animated Graphics Setup

## Graphics Templates

### Text conversation

Text bubble conversation to/from

Text conversations or DMs or transcripts

### Timeline

A timeline of events over days, months, or years

### Clips

Slight grainy / CRT effect, sourcing attribution info, QR code for source video
---
draft: true
dek: In Which Election Chaos is Tamed by a Deceptively Simple, Data-Fueled Marvel
date: 2022-11-02T21:05:53-04:00
modified: 2023-08-09T14:32:25-04:00
tags: politics dataviz america
---

# Why I Am Building Electology

In this era where understanding election results has mutated into a labyrinth of guile and gamesmanship, the majority of the tools we have at our disposal are woefully inadequate. The majority of these options lack the flexibility to explore in a user-friendly way or require proficiency in data analysis tools and programming languages. 

Moreover, most visualizations need extensive effort and time to create from scratch. I should know; I [helped create the app powering NBC's Big Board](https://www.newscaststudio.com/2018/11/05/nbc-big-board-update/) which has been wielded live, under fire for the past half-decade

Election analysis is not static - things change all the time, often due to shifts in demographics, policies, platforms, and more. Electology addresses this by allowing users to synthesize data from multiple sources and time periods while also using intelligent algorithms to create continuous information sets covering any point in time. This makes it easier than ever to trace trends across election cycles and geography.

It is hard to know in advance what will be interesting in the weeks surrounding an election, and being able to zoom into the most accurate detailed information on any town, county, or district is crucial to being able to nimbly respond to breaking news events and understand their significance.

The backbone of Electology’s powerful analytics capabilities lie in its atomic units of analysis: **candidates, races, states, counties, districts, and precincts**. By analyzing these fundamental elements separately and then bringing them together into a cohesive whole, we can unlock comparisons and trends that paint a more complete picture of what is driving elections trends. 

---

*Electology is a data-driven platform that simplifies election analysis and visualization. It synthesizes data from various sources and time periods, allowing users to explore trends and generate insights with just a few clicks. The platform focuses on year-round election analysis using the atomic units of candidates, races, and features. By combining a variety of historical and demographic datasets, Electology enables non-technical users to create novel analyses and visualizations.*

---

Unlike many other election results apps, which are often created by news organizations focused on election night, we are focused on **year-round election analysis** that is constantly updated with the latest data and technology.

We combine a number of historical open-source datasets and synthesize races, features, and candidates into a comprehensive optimized knowledge base. This allows us to combine analyses that would have previously required bouncing between data sources and tools, and gives the power to a non-technical user to explore questions and create novel visualizations.

Because I have spent so much time gathering and synthesizing data, I have open-sourced a collection of [election-related Javascript helpers](https://www.npmjs.com/package/election-helpers), a tool for creating [fake election data for testing](https://observablehq.com/@ejfox/election-data-generator), and I hope to continue to contribute to the elections and open-source communities. 

These tools have already helped Electology by moving often-repeated Election logic to one location, and making it easy to stress-test any tool that depends on Election data by creating fake testing data with erroneous winner flags, long candidate names, and blow-out elections - all with optional fictional candidates, parties, and colors.

Despite its complexity and depth, Electology has been designed to be as straightforward and user friendly as possible. Care and attention has been paid to the experience of expert-level political fanatics as well as the everyday voter. 

All the tools are just a few clicks away, presented in an attractive and intuitive interface so anyone can start exploring right away without extra effort. 

After a decade of working in data visualization and cartography, one of my personal joys is working on Electology's novel visualizations. Electology showcases a number of new beautiful and innovative data visualizations and maps for easy consumption of complex data sets. 

Electology will be invite-only, with a monthly fee that supports development and data procurement. Sign up for the waitlist at <https://electology.co>

---

See also: [[things-ive-learned-about-elections]]

#elections #process #programming
---
dek: In which we make it extremely easy to charge people to access your website or pay for a membership
inprogress: true
date: 2023-09-26T14:05:43-04:00
modified: 2023-12-17T18:28:44-05:00
tags:
---

## Adding a Paywall to your Nuxt+Supabase App

### Goals

It should be extremely easy and quick to create something really cool on the internet and then charge people to access it. Whether it's art, a tool, or a piece of journalism, you should allow people to pay for things they find valuable. This is only possible if you let them.

I am a big fan of [[nuxt-3-and-netlify]] as a prototyping toolkit, and I have a [customized project template](https://github.com/ejfox/nuxt-template-2023/tree/main) that lets me spin up apps quickly. Once I've made something cool, I want to let people pay to access it.

#### Memberships

One model is to let people pay a monthly fee to access the site, or certain portions of it.

#### Commodities

Another model is to let people pay for specific app actions: uploads, image generation, processing, tokens. People want to perform an action, and you let them pay for it before proceeding.

#### Paywalling

Yet another model is to take a piece of content and only allow access to people who have paid for it (or have a membership granting them access) – this might be on a page-by-page basis for journalism. Users shouldn't need to sign up for an account to pay for access, and paying should be as seamless as possible.

#### Free, but collect emails

A final option is to create an entire checkout flow, but give out coupon codes that let the user get the product for free, but adds them as a customer to your Stripe account and collects their email.

## Using Stripe

Stripe offers a number of tools that help users of different technical abilities charge for things. Our Nuxt app sits at a weird juncture where we could potentially do everything ourselves; we need to resist that temptation and focus on the task at hand.

### Stripe Webhooks & Nuxt Server Functions

### Stripe + Nuxt + Supabase---
draft: true
dek: In which
inprogress: true
date: 2023-01-19T00:39:28-05:00
modified: 2023-09-09T15:03:59-04:00
tags: art
---

# Making soap

There's something truly special about sharing a creative hobby with a loved one. For my mom and me, that shared passion is making soap. In this blog post, I'll take you on a journey through our soap-making process, complete with instructional steps and visuals to help you create your own beautiful, scented soaps at home.

## Choosing Colors

The first step in our soap-making adventure is selecting the colors that will bring our creations to life. We like to choose colors that complement each other and reflect the scent or theme of the soap. You can use natural colorants like clays and botanicals or synthetic colorants like micas and pigments.

[Insert photo/video of color selection process]

## Choosing Scents

Next, we decide on the fragrance for our soap. This can be achieved using essential oils for a natural scent or fragrance oils for a wider range of options. We love experimenting with different combinations to create unique and delightful scents.

[Insert photo/video of scent selection process]

## Weighing Ingredients

Accuracy is key when it comes to measuring out the ingredients for our soap. We carefully weigh all oils, lye, and water using a digital scale to ensure the correct proportions for a successful batch.

[Insert photo/video of weighing ingredients]

## Melting Oils

Once we have our ingredients measured out, we gently heat the oils in a double boiler until they are fully melted and combined. It's essential to monitor the temperature during this process to prevent overheating.

[Insert photo/video of melting oils]

## Lye + Mineral Water Reaction

Safety comes first when working with lye. Wearing gloves and goggles, we slowly add lye to cold mineral water (never reverse this order) while stirring. This creates a chemical reaction that heats the water and releases fumes, so it's important to do this in a well-ventilated area.

### Using Lye and Tea-Brewed Water

For a unique twist, we sometimes replace mineral water with tea-brewed water to add an extra layer of fragrance and color to our soap.

[Insert photo/video of lye and water reaction]

## Pouring Techniques

Once our oils and lye solution have cooled to the appropriate temperature, we combine them and blend until we reach "trace"—the point at which the mixture thickens slightly. Now comes the fun part: pouring our soap into molds! We use various pouring techniques, such as layers, swirls, or embeds, to create visually stunning designs.

[Insert photo/video of pouring techniques]

Conclusion:

Making soap with my mom has been a rewarding experience that not only allows us to bond but also results in beautiful, fragrant creations we can share with friends and family. By following these steps and experimenting with colors, scents, and pouring techniques, you too can embark on your own soap-making journey and create lasting memories with your loved ones.

[Insert final photo/video of finished soaps]
---
dek: In which the author grows tired of photo apps and assembles his own with duct tape and bash scripts 
inprogress: true
date: 2023-07-02T12:23:35-04:00
modified: 2023-07-03T00:06:06-04:00
tags: personal process photography setup
---

# How I hand built a way to organize and publish my photo library (and why)

## Organizing by day, month, and media type

## All media starts in `~/dump/`
I had a habit of creating new folders for a project, but then not really finishing that, and all of the media would grow cobwebs. 

## Apple Shortcuts & Automator
The first step is getting my files organized on my local computer. This process usually starts with plugging in an SD card from my fujifilm camera, helmet cam, or field audio recorder. 

#### Import SD card to `~/dump/`

First I use Applescript to show a dialog to ask myself whether to import or not.
```applescript
display dialog "New Volume connected- import to ~/dump?" buttons {"Yes", "No"} default button 2

if the button returned of the result is "No" then

error number -128 (* user cancelled *)

end if
```

If the user selects "Yes" we continue on to this shell script

```bash
#!/bin/bash

totalFiles=0
totalSize=0

handle_folder() {
    for aFile in "$1"/*; do
        if [ -d "$aFile" ]; then
            handle_folder "$aFile"
        elif [[ "$(echo $aFile | tr '[:upper:]' '[:lower:]')" =~ \.(jpe?g|mp[34]|raf|wav)$ ]]; then
            echo "Copying file $aFile"  # debugging line
            newFilePath=$HOME/dump/$(basename "$aFile")
            cp "$aFile" "$newFilePath"
                
            totalFiles=$((totalFiles + 1))
            totalSize=$((totalSize + $(du -k "$aFile" | cut -f1)))
        fi
    done
}

mkdir -p $HOME/dump

# List all volumes and handle each
for sdcard in /Volumes/*; do
    if [ "$sdcard" != "/Volumes/Macintosh HD" ] && [ -d "$sdcard" ]; then  # Exclude Macintosh HD, the main disk of macOS
        echo "Handling SD Card: $sdcard"  # debugging line
        handle_folder "$sdcard"
    fi
done

# Convert size to GB
totalSizeGB=$(echo "scale=2; $totalSize/1024/1024" | bc)

osascript -e "display notification \"Successfully copied $totalFiles files totaling $totalSizeGB GB to the dump folder\" with title \"File Operation Summary\""
```

#### Organize `~/dump/` into `~/media/`
Every once in a while, when the folder grows a little too big and unwieldy, I have a shell script as part of a shortcut (which means I can run it from an icon in my dock) that takes everything in `~/dump/` and organizes it into a folder structure by month, day, and media type. 

Draft script to move from ~/dump/ into organized folders in ~/media/

```bash
#!/bin/bash

shopt -s globstar nullglob

# get creation date and format it to YYYY-MM-DD
getDate() {
    date -r "$1" +'%Y-%m-%d'
}

#iterate recursively over all files in the target directory.
for file in ~/dump/**/*.*; do
    # Ensure path is a file
    if [ -f "$file" ]; then
        #get creation date of file
        file_date=$(getDate "$file")

        #get mime-type of file
        mime_type=$(file --mime-type -b "$file" | awk -F'/' '{print $1}')
        
        #needs write permissions on /media/
        dir_name=~/media/"$file_date"/"$mime_type"

        #creating Target Directory
        mkdir -p "$dir_name"
        
        #move files
        mv "$file" "$dir_name"/

        echo "$file : moved to $dir_name" >> ~/dump/_logs.txt
    fi
done

#Emptying
rm -r ~/dump/*

#Logs
echo "Organizing Completed $(date +"%T")" >> ~/dump/_logs.txt
cat ~/dump/_logs.txt > ~/logs.txt
```

#### Upload to the web
The finder is an extremely powerful way to look at, organize, and tag files. Instead of recreating these things haphazardly in my own media library, I'd rather use one of the best ones in existence and augment it a bit to do my bidding.

I naturally found myself using a system of tagging photos with yellow for "maybe" and green for "publish". I'd import an SD card for a folder, scroll through it in finder, and slowly gather my picks. Then I'd select all the green files and drag them to another folder, or upload and publish them somewhere. I figured it would be best to try and automate what I was already doing.

So I created a very basic shortcut that uploads yellow/green files in the current directory to Cloudinary. This also allows you to right-click on a folder and upload all the green-tagged media to Cloudinary. 

```bash
# Navigate to your media directory
cd ~/media/

# Find all yellow/green tagged files
for file in $(mdfind -onlyin . "kMDItemFSLabel == 2 || kMDItemFSLabel == 6")
do
  # Upload file to Cloudinary
  cloudinary upload $file --use_filename --unique_filename false
  
  # (Optional) To save the Cloudinary URL in the EXIF data, you would need an additional tool such as ExifTool.
done
```

## Get all Cloudinary photos for a week
Now that all of this content has been stored on Cloudinary, we want a way to get it back out. We are going to need to access the Cloudinary admin, and use our secret, so this has to be done on the server side instead of the client side. 

Here's a rough mockup of what we are going to want to do:

```js
const cloudinary = require('cloudinary').v2;

cloudinary.config({
   cloud_name: 'your_cloud_name',
   api_key: 'your_api_key',
   api_secret: 'your_api_secret'
});

async function getImagesByWeek(year, week) {
   // Use a library like date-fns to determine the start and end dates of the week
   const startDate = new Date(dateFns.startOfWeek(new Date(year, 0, 2 + (week - 1) * 7)));
   const endDate = new Date(dateFns.endOfWeek(new Date(year, 0, 2 + (week - 1) * 7)));

   let expression = `resource_type:image AND creation_date>=${startDate} AND creation_date<=${endDate}`;

   try {
       let result = await cloudinary.search
           .expression(expression)
           .sort_by('upload_date', 'desc')
           .execute();

       return result.resources;
   } 
   catch (err) {
        console.error(err);
        return [];
   }
}
```

I am creating my gallery as a [Nuxt app] (https://github.com/ejfox/nuxt-template-2023) so I think the best way to fetch my new photos is to create them as a [Nuxt Server API](https://nuxt.com/docs/guide/directory-structure/server) so that when I go to `myapp/api/latest-photos` this script will run, fetch the latest photos, add them to the DB if necessary, and return the list so it can be displayed. 

---
draft: true
dek: In which we drive our motorcycles into the woods
inprogress: true
date: 2022-12-23T11:32:14-05:00
modified: 2023-09-09T14:55:58-04:00
tags: motorcycle travel
---
# Into the Wild: Motorcycle Camping Gearlist

![](D8231DDA-80DE-4E33-B72F-200E0B78E999.jpeg)

I've spent countless hours researching, testing out different methods, and developing a reliable motorcycle camping setup that I want to share so that anyone can make their dreams a reality.

> It just makes sense that motorcycles and camping go hand in hand. The same sensory connection to the world we get from motorcycling—the same elements we love, of being in the wind and leaning through the curves—can take place around camp. This both adds to your motorcycle adventures and contributes an entirely new passion to the mix.
> Tim Collins and Amanda Zito [Collins-Zito-The Fundamentals of Motorcycle Camping](Collins-Zito-The%20Fundamentals%20of%20Motorcycle%20Camping.md)

## Modular Design

Let's start by talking about how to stay organized on the road. There will come a time when you need something you packed but don't remember where it is or what bag its in. 

To help avoid confusion, lay out your gear before you head out and get in the habit of labeling bags or containers so you can find them when needed. Everything should have precisely one place where it belongs. You should be able to envision that place in your mind’s eye and find it in the dark. 

![](https://res.cloudinary.com/ejf/image/upload/v1691608713/Screenshot_2023-08-09_at_3.17.33_PM.png)

Start by packing all of your gear into tiers; with essential items within easiest reach - this way, you won't have to fumble around for them when you need them.

In certain scenarios, it might be helpful to pull off subsets of your bags. For instance, if you’ll need to check into a hotel during your trip, you may want to leave your camping gear behind while bringing smaller essentials such as clothing and electronics up to your room. Or, if you plan on meeting up with friends and traveling by boat, what do you leave behind on the bike and what do you bring along to camp? These are questions that can be answered with thoughtful packing strategies and are better addressed ahead of time so you can grab your bags and focus on your adventure.

Consider using dry bags clipped together or attached to your bags with carabiners so everything stays together no matter what kind of terrain or weather follows you on your journey.

![My bags for Island camping at Lake George](F5B356FA-79CC-4139-8F70-162F31D045F9_1_105_c.jpeg)

> You see things vacationing on a motorcycle in a way that is completely different from any other. In a car you’re always in a compartment, and because you’re used to it you don’t realize that through that car window everything you see is just more TV. You’re a passive observer and it is all moving by you boringly in a frame.
> [Pirsig-Zen and the Art of Motorcycle Maintenance](Pirsig-Zen%20and%20the%20Art%20of%20Motorcycle%20Maintenance.md)

## Motorcycle: Kawasaki Versys-X 300

Your bike is one of the most important elements of a successful camping trip, after your own body. You need a model that’s powerful enough to handle off-road terrain, yet lightweight enough to pick up when you inevitably drop it. It should have plenty of luggage capacity - able to carry all of your essential gear comfortably between destinations.

The Kawasaki Versys X 300 fits all my requirements.

- Engine: 296cc liquid-cooled 4-stroke DOHC 8-valve parallel twin.
- Power: 40 HP @ 11,500 rpm.
- Torque: 19.2 lb-ft of torque @ 10,000 rpm.
- Curb Weight: 386 lbs (175 kg)
- Seat Height: 32.1 in (815mm)

![](ADD924AF-D7C4-4F8B-ABD9-4D7EB4EBF026.jpeg)

### What I looked for in a bike
- Weight: I need to be able to pick it up and take it on single track
- Tires: It needs to be able to go off road
- Luggage: It needs to be able to carry all my camping gear

## Gearing Up

Finding the right protective gear is as important as getting your motorcycle. Make sure you have a helmet that fits correctly, gloves, jacket and boots that are designed with safety and comfort in mind. You want to be thinking about your adventure, not your gear. A little investment goes a long way. 

My setup:

- Helmet: Bell Racer 
- Gloves: Knox Handroid Gauntlets 
- Jacket: Halo Drystar
- Boots: Forma ADV 
- GPS: Garmin Zumo XT

![](6986CDD3-930A-410E-9300-40BD7751A357_1_105_c.jpeg)

## Gear Up Your Motorcycle

It’s just as important to your gear up your motorcycle as it is to gear up yourself. You’ll need a variety of bags, depending on the length of your trips. Having an excuse to have a variety of bags may be one of my favorite reasons to travel. 

With a system like the [Mosko Moto Reckless 80L Motorcycle Luggage System](https://moskomoto.com/products/reckless-80l) you have a main bag, two 25L side bags and two 4L auxiliary bags for maximum organization. Look for bags with durable material, waterproof construction and straps to keep your things secure.

You should be prepared to ride in the rain. It will happen at the most inopportune time, so all of your gear should be able to get wet along with you. Your main bag should include a dry bags for at least clothing and a first aid kit, while your side dry bags and auxiliary bags should house your camping gear such as a tent, hammock, sleeping bag, liner and pillow. 

I also carry an art kit and a Jetboil with fuel for coffee in the morning.

![This is definitely Too Much Stuff, but she handled it like a champ](EBF62C4D-364E-44F2-9486-691705B62C8A_1_105_c.jpeg)

## Bags
- Main bag: 5.11 Rush 24
	- Dry bag for clothes
	- First aid kit
	- Art kit
- 25L side bag 1: tent, hammock
- 25L side bag 2: sleeping bag, liner, pillow, pad
- 4l aux bag 1: jetboil + fuel

*exploded bags diagram*

[Mosko Moto Reckless 80L Motorcycle Luggage System](https://moskomoto.com/products/reckless-80l)

### How to find anything (what bag is it in?)

Another reason I lay out all my gear is so that I can remember what I brought or even look it up later if I forget that I had something useful but didn't bring it out until the end of the trip. Staying organized helps make sure that I know where my items are located and how many of each item exist so that nothing gets lost or forgotten about when packing up after camping somewhere new! 

## Camping

It helps if you already have a camping setup from backpacking or car camping. Camping off a motorcycle requires finding gear that can be condensed down to the smallest possible form. Space on the bike is precious and every square inch considered carefully.

I love the Marmot Tungsten 2P Tent—a lightweight but versatile option that sets up quick, though it is a bit large for my liking. 

[Marmot Tungsten 2P Tent](https://www.rei.com/product/110883/marmot-tungsten-2p-tent-with-footprint)

![](IMG_0010.jpeg)

## Campsite Considerations

Camping off a motorcycle requires finding gear that can be condensed down to the smallest possible form. Look for items with versatile features and lightweight construction and consider your space limitations when selecting items. We love the Marmot Tungsten 2P Tent - a lightweight but versatile option. 

![](E1730FDB-741A-4788-AB0E-767EF47B3D63_1_105_c.jpeg)

You should also consider a campsite layout to help keep your gear safe and organized while still giving you plenty of space to explore. Take a look at our diagram below to get an idea of how you can setup your campsite for maximum enjoyment and convenience. 

## Motorcycle repair kit (home + travel)

Because no matter how much research and preparation goes into a journey there are still moments when things will go wrong; having an emergency repair kit can help ensure that a small issue doesn't derail your trip entirely! Better to have it and not use it, than to need it and not have it!

### Home repair kit
- Socket set 4mm-19mm
- Combination wrenches 8mm-19mm
- Pliers
- Hex wrenches 2-10mm
- Adjustable wrench
- Allen wrench set
- Torx wrenches
- Spark plugs, 10mm thread, 0.75in 
### Travel repair kit
- Tubeless tire repair kit
- Mini tire inflator
- Jump battery

## Ready to explore

Now that you’ve got your gear and a plan in place, it’s time to start your journey! Even with the best-laid plans, things can still go wrong on the trail, and that’s all part of the fun.

If you live in the Hudson Valley, check out [[hudson-valley-motorcycle-rides]] for some great spots to explore. Happy camping!

---

#setup #motorcycle #travel 

[[reading/Thompson-Hells Angels]]
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:42:14-04:00
tags:
---

## Open Source at Room 302: Behind Our Decision to Share Everything
---
dek: In which the author uses a boutique micro gaming system to craft a video game about the experience of motorcycling
inprogress: true
date: 2023-07-02T11:09:23-04:00
modified: 2023-07-02T11:24:21-04:00
tags: pico8 personal motorcycle
---

# My first Pico-8 game: Motorcycle.p8

I fully believe that great art comes from working creatively within limitations, especially well-chosen self-imposed limitations.

That is part of the appeal of the beautifully simple, yet powerful, Pico-8 created by Lexaloffle. 

[🎮 Introduction to Pico-8 — Are.na](https://www.are.na/ej-fox/introduction-to-pico-8)

Inspired by my recent [motorcycle journeys](/2023-ny-to-maine) I wanted to try to capture some of the essence and joy of riding a motorcycle into a little video game poem.

My brother who is exceptionally talented at making sprites and composing music with trackers (a type of DAW for super-dorks) helped it come together. [Coach Artie](/how-i-built-coach-artie) did most of the fancy coding. 



```
pico-8 cartridge // http://www.pico-8.com
version 41
__lua__
local motorcycle = 0
local x = 64
local y = 90
local spd = 0
local lines = {}
local t = 0
local amplitude = 40
local frequency = 0.003
local padding = 8
local debug_mode = true
local offsetY = 0
local moveAmt = 0
local momentum = 0
local friction = 0.25
local ratioLimit = 300
local mph = 0

-- Initialize lines
for i = 1, 32 do
    lines[i] = { width = 33 + (1.5 * sin(i/32 * 2 * 3.14)) }
end

function spd_to_mph(spd)
    return flr(spd * 33)
end

local music_pattern = -1
-- music(music_pattern)

function _update()
    t += spd
    mph = spd_to_mph(spd)
    momentum = momentum * friction

    local lastMoveAmt = moveAmt
    if btn(0) then 
        moveAmt = max(lastMoveAmt - 0.25*spd, -4) 
    elseif btn(1) then 
        moveAmt = min(lastMoveAmt + 0.25*spd, 4) 
    end

    x = max(0, min(128, x +moveAmt+momentum*spd)) 

    -- if mph is 0, then remove all momentum
    if mph == 0 then
        momentum = 0
        moveAmt = 0
    end

    -- Apply momentum if no button is pressed.
    if btn(2) then 
        spd = min(spd + 0.01, 10)
        moveAmt = min(moveAmt + 0.01, 4)
        if mph > 100 then
            amplitude = max(amplitude - 1, 0)
            frequency = min(frequency + 0.00001, 0.1)
        end
    else
        momentum = moveAmt
    end

    if btn(3) then 
        spd = max(spd - 0.025, 0)
        moveAmt = max(moveAmt - 0.05, 0.25)
        amplitude = min(amplitude + 1, 40)
        frequency = max(frequency - 0.00001, 0.002)
    end

    offsetY = (offsetY + spd) % #lines

    if music_pattern == -1 and mph > 2 then
        music_pattern = 0
        music(music_pattern)
    elseif music_pattern == 0 and mph < 2 then
        music_pattern = -1
        music(music_pattern)
    elseif music_pattern == 0 and mph > 35 then
        music_pattern = 1
        music(music_pattern)
    elseif music_pattern == 1 and mph > 70 then
        music_pattern = 3
        music(music_pattern)
    elseif music_pattern == 3 and mph > 85 then
        music_pattern = 4
        music(music_pattern)
    -- and if we reduce speed to 70, go back to pattern 1
    elseif music_pattern == 4 and mph < 70 then
        music_pattern = 1
        music(music_pattern)
    -- and if we reduce speed to 35, go back to pattern 0
    elseif music_pattern == 3 and mph < 35 then
        music_pattern = 0
        music(music_pattern)
    -- and if we reduce speed to 2, go back to pattern -1
    elseif music_pattern == 4 and mph < 2 then
        music_pattern = -1
        music(music_pattern)
    end
    
    
end

function _draw()
    cls()

    -- fill the whole screen with color 3
    rectfill(0, 0, 128, 128, 3)
    
    for i=1,#lines do
        local lnIdx=(i+flr(offsetY))%#lines+1
        local ln=lines[lnIdx]
        local sway=amplitude*sin(frequency*t)
        if mph > 100 then
            sway+=amplitude*sin(perlin(i*t*0.1,t*0.1))
        end
        local left=max(0,64-ln.width/2+sway)
        local right=min(128,64+ln.width/2+sway)

        local y = (i - 1) * 8 - (offsetY % 1) * 8 
        local col = i + 1
        
        rectfill( left, y, right, y + 8, 5)

        -- crash detection
        local motorcycleWidth = 16
        local motorcycleHeight = 16
        if x < left - motorcycleWidth or x > right + motorcycleWidth then
            -- print("Crashing!", 64, 64, 9)
            -- print crashing in a random color and location
            print("Crashing!", rnd(128), rnd(128), rnd(16))
            -- stop music
            music(-1)
            sfx(8)

            -- else put the music back to where it was
            if music_pattern ~= -1 then
                music(music_pattern)
            end
        end
    end
    
    spr(motorcycle, x, y, 2, 2)
    print(mph .. " mph", 92, 5, 7)
end

function perlin(x, y)local X,Y=flr(x),flr(y)local A,B,C,D=pget(X,Y),pget(X+1,Y),pget(X,Y+1),pget(X+1,Y+1)local u,v=x-X,y-Y
local function lerp(a,b,t)
return a*(1-t)+b*t end
local function fade(t)
return t*t*t*(t*(t*6-15)+10) end
local function grad(h,x,y)
local u=h%8
local v=h%16//8
u=1-u
v=1-v
return(u-v)*(1-x-y)+v*(1-x)+u*(1-y)-1 end
local nx,ny=fade(u),fade(v)local x1=lerp(grad(A,u,v),grad(B,u-1,v),nx)
local x2=lerp(grad(C,u,v-1),grad(D,u-1,v-1),nx)return lerp(x1,x2,ny)end
__gfx__
0000000000000000cccccccccccccccccccccccccccccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000000000000cccccccccccccccccccccccccccccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000000000000cccccccccccccccccccccccccccccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000220000000cccccccccccccccccccccccccccccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000ff0000000ccccccccccccccccc3333333cccccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000990000000ccccccccccc3333333333333333ccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
000f66999966f000ccccccc33333333333333333333ccccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000996996990000ccccc333333333333333333333333ccc00000000000000000000000000000000000000000000000000000000000000000000000000000000
00000c5555c00000ccccc3333333333333333333333333cc00000000000000000000000000000000000000000000000000000000000000000000000000000000
00000c6666c00000cccc333333333333333333333333333c00000000000000000000000000000000000000000000000000000000000000000000000000000000
0000066116600000ccc3333333333333333333333333333c00000000000000000000000000000000000000000000000000000000000000000000000000000000
00000461164400003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000001100000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000001100000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000001100000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
0000000aa00000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
00000000000000003333333333333333333333333333333300000000000000000000000000000000000000000000000000000000000000000000000000000000
__sfx__
000100003c0500000037050000000000000000000000000000000000000000000000000003305033050300502d05029050240501f0501b05018050140500e0500a05006050040500305001050000000000000000
000800000000006250022500625002250016000160001600026000260002600026000260000600006000160001600016000160000600006000000000000000000000000000000000000000000000000000000000
000f00001923000000000000000023643000001e2401924000000192400000020230192400000020240000002324000000000000000023653000001e64323250000002f250000002a2602f270001002a27000000
000f0000236330000000000000000000000000000000c073236330c073000000000023653000000000000000236330000000000000000000000000000000c073236530c073000000000023633000000000000000
000f00000d3171032714337173370d347103171433717337193471c3472031723327193471c35720327233372f357273572a3272e3372f357273572a3272e3173b32733337363573a3673b33733357363673a377
000f00001b4410000018441000001b1501c1501e150201501e1501c1501b150171501703017010144402a44024441000000000000000244412b44100000273502723027020270102335023230230201e3501e230
001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
001000000165008650086500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
__music__
02 02434544
03 02434444
03 02034444
03 02030445
03 02030405
```

---

#pico8
---
dek: In which
inprogress: true
date: 
modified: 
tags: journalism ny
---

# Title

[https://rmfpc.com/wp-content/uploads/2022/01/Clean-Water-Act-Lawsuit-Commenced-Against-Dragon-Springs-Buddhist-Inc.-For-Polluting-Bashar-Kill-And-Neversink-River-2.pdf](https://rmfpc.com/wp-content/uploads/2022/01/Clean-Water-Act-Lawsuit-Commenced-Against-Dragon-Springs-Buddhist-Inc.-For-Polluting-Bashar-Kill-And-Neversink-River-2.pdf)

[Mayor of Middletown, New York, Spurs City Redevelopment Under New Vision](https://www.theepochtimes.com/mayor-of-middletown-new-york-spurs-city-redevelopment-under-new-vision_4937406.html?welcomeuser=1)

[GOLDMAN SACHS PHILANTHROPY FUND - Form 990, Schedule I- Nonprofit Explorer - ProPublica](https://projects.propublica.org/nonprofits/organizations/311774905/201832619349300328/IRS990ScheduleI)

[Social media company moves headquarters from Silicon Valley - Mid Hudson News](https://midhudsonnews.com/2023/06/23/social-media-company-moves-headquarters-from-silicon-valley/)

[Tweet / Twitter](https://twitter.com/Macro_Core_View/status/1607000539912458242)

[Site Unreachable](https://www.youtube.com/watch?v=aEhY0-fEwgI)---
dek: Artie's stepping up his game—now he can read whole repos and handle files like a pro
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-16T14:50:23-04:00
tags:
---

## Coach Artie: Webhooks, Cron, and Advanced Reflection

We've been working hard to make Coach Artie even better, and we're excited to share some updates on recent work we’ve been doing to make him more helpful and intuitive.

Recently, we introduced a new way for you to experiment with Artie's abilities without having to run the entire system or interact through Discord. This means you can now test and refine new capabilities quickly. It's a game-changer for speeding up development and making it easier for contributors to add their innovations. Coach Artie automatically parses jsdoc-formatted documentation within capabilities, so if the capability is well-documented he should be able to pick it right up.

Artie has also learned to communicate through webhooks, a technology that lets him send and receive messages from lots of different web services. We made sure to handle HMAC secrets so it is private and secure, and it works seamlessly with various services you might already use, like GitHub or Missive.

We also made it so Artie can now deep dive into long documents, digesting long and complex information and turning it into concise memories. Whether it's a lengthy report or a running notes from your meetings, he breaks it down into digestible memories, making sure he remembers the right details at the right time. And when you send him a file, he now treats it like it has its own life, creating memories specific to that document, which can evolve as the document changes.

As Coach Artie continues to learn and adapt, we're also building new ways for you to see what's going on in his 'brain' through a real-time, user-friendly website, which we have been using internally for development. This will help Artie’s users manage his capabilities and see the impact of his memory in action. It’s like having a window into how he thinks.

Through these updates, Coach Artie is not just a tool; he's becoming a more integrated part of our workflow, gathering context about the world automatically, anticipating our needs, and adapting to them without skipping a beat. We're excited to see how these improvements will continue to transform the way we interact with our tools.

```merm
graph TD
    A[Capability Player] -->|Test new features| B[Webhook Support]
    B -->|Secure communication| C[Missive Integration]
    B -->|Trigger actions| D[Automated pgcron scheduling]
    A -->|Dynamic testing| E[On-The-Fly Configuration]
    E -->|Model switching| F[Claude Support]
    E -->|Config adjustments| G[Supabase Admin Capabilities]
    C -->|Access conversations| H[Advanced Reflection: Todo List]
    D -->|Schedule tasks| H
    I[Deep Document Ingest] -->|Process documents| J[Forming Memories about Files]
    J -->|Memory creation| K[Read Repo Capability]
    I -->|Summarize content| K
    K -->|Interact with repos| L[Coach Artie Brain]
    L -->|Monitor memories and processes| M[Memory embedding visualization]
    H -->|Create actionable todos| L
    G -->|Database management| L
    F -->|Enhance capabilities| E
    J -->|Generate memories| L
    B -->|Integrate external services| K
    C -->|Enhance interaction quality| H
    D -->|Automate processes| G
    I -->|Enhance document handling| L
```
### Capability Player

We added a new capability player that makes it unnecessary to have a running instance of Coach Artie in order to test new capabilities. It allows you to run a capability with any arguments you choose, which should considerably speed up development. This should also enable people to contribute and test capabilities without needing to run the entire Coach Artie instance.

### Webhook Support

We added support for communicating with Coach Artie through webhooks, including HMAC secrets, which allows you to send private information securely. Initially, we added this integration for Missive, but it works for any service that uses webhooks like GitHub, Slack, or Supabase.

#### Missive Integration

In addition to the Missive webhook integration, we added deep Missive capabilities that allow Coach Artie to access conversations and attachments and build memories from Missive conversations.

### On-The-Fly Configuration

We enhanced Coach Artie with capabilities to edit his own configuration on the fly. This includes allowing him to switch between models such as Claude or OpenAI, with the potential to include others in the future. He can also adjust settings like Max Tries and other configurations. Now, he can run a capability to see his current settings and edit them in real time.

### Automated pgcron scheduling

One of our goals for Coach Artie is to enable him to schedule tasks for himself in the future. Since we're already using Supabase, it made sense to leverage its existing pg_cron functionality. This allows Coach Artie to set a cron job with any schedule he desires. This job will initiate a webhook with a custom prompt that gets sent to the previously mentioned webhook endpoint.

### Advanced Reflection: Todo List

We introduced a new to-do list concept, inspired by the idea of having sticky notes at your desk. These to-dos are omnipresent, added and removed as your day and week progress. To manage these, we added a new reflection stage. In this stage, in addition to making memories from a user interaction, Coach Artie determines whether a to-do or multiple to-dos need to be created from the interaction. These to-dos are then always added to the context window, ensuring they inform every future user interaction.

### Deep Document Ingest

To enhance our fetch and summarize capability in the web browser, we recognized the need for the robot to read very long documents and transform them into one or many concise memories linked to that document. This is often necessary when handling large documents, such as extensive notes from user meetings or detailed documentation. We added a new processing step, which we call "deep document ingest." This allows us to take lengthy documents and convert them into memories in an efficient and consistent manner, leveraging all the benefits of memory creation, while still creating distinct enough groupings to ensure we recall the right things at the right time.

### Forming Memories about Files

In addition to deep document ingest, we introduced a new concept where we can now form memories about files or resources. Previously, we only created memories linked to users, so a memory might contain information about a file a user sent, but it was always associated with that user. Now, when a user sends us a file, we treat that file as its own entity with its own memories. This is particularly useful for documents that change over time. It’s also beneficial for images and PDFs because we can process them with specialized vision and OCR capabilities, generating one or many memories of the document that can be accessed via that document ID.

### Read Repo Capability

We've been eager to give Coach Artie the ability to read entire repositories. Excited by new services that offer larger context windows, we can now potentially send some or all files from a repo, allowing Coach Artie to answer questions based on the structure of our entire codebase. To achieve this, we need to enable him to access any GitHub repository and send him all the files in an intelligently formatted manner. This setup will allow us to pose user questions similar to how we handle documents. Furthermore, it's essential to allow him to form memories about pieces of code that are not direct one-to-one representations; these are abstracted summaries of facts generated from the code and used for understanding the architecture.

### Claude Support

One of the more exciting developments over the last few months has been validating a long-held concept at Coach Artie—namely, that if we switch to a different LLM model, Coach Artie will retain much of the same functionality and personality we depend on. We recently tested this by moving the backend from OpenAI to the Anthropic Claude API, and we're thrilled with the results. The transition required us to format our messages slightly differently and adopt an XML-based command pattern. After making a few adjustments, we found that the switch was pretty seamless. We've particularly enjoyed working with Claude, finding its personality more enjoyable as it offers more openness and creativity compared to the increasingly restricted ChatGPT API.

### Supabase Admin Capabilities

One of the key advancements we've unlocked is enhanced database capabilities for Coach Artie around Supabase. All of Coach Artie’s memories, messages, and tasks are already stored as Supabase tables. We've now empowered him not only to insert, delete, and update rows on his own but also to create new tables and define new schemas on the fly. This capability provides a powerful solution that naturally extends as the models evolve, allowing him to build his own systems and data storage methods—capabilities we couldn’t have anticipated without the flexibility afforded by his new meta Supabase capability.

```merm
graph TD
    A[Self-Management Core] -->|Dynamic Configuration| B[On-The-Fly Configuration]
    B -->|Model Switching| C[Model Choices]
    C -->|Choose Claude or OpenAI| C
    B -->|Adjust Runtime Settings| D[Dynamic Settings Adjustment]
    D -->|Update Max Tries, etc.| D
    
    A -->|Meta-Capabilities| E[Supabase Admin Capabilities]
    E -->|Database Self-Management| F[Database Operations]
    F -->|CRUD Operations on Data| F
    E -->|Schema Self-Modification| G[Dynamic Table and Schema Management]
    
    A -->|Self-Auditing Capabilities| H[Coach Artie Brain]
    H -->|Monitor Own State| I[Real-Time Monitoring]
    I -->|View and Analyze Logs| J[Memory and Process Logs]
    I -->|Access and Query Logs| K[Log Querying]
    K -->|Self-Diagnosis and Debugging| K
    
    B -->|Capability Testing| L[Capability Player]
    L -->|Test New and Existing Features| L
    
    H -->|Visual Feedback for Users| M[Admin Interface]
    M -->|Client-Side Application| N[Client Side App]
    N -->|Manage Configurations and View States| N
```


### Coach Artie Brain

For the first year, we focused on managing Coach Artie exclusively through Discord, engaging in conversations and training him through the development of memories and patterns, which resulted in specific actions. Now, as we introduce more advanced capabilities, it's becoming crucial to have effective ways to see what's happening in Coach Artie's "brain" at any given time and in real time. To address this, I've begun developing a client-side app using Nuxt that displays all of Coach Artie's memories and messages.

We are now sending all the logs to Supabase, enabling you to view and filter these logs as they process in real time. This development is particularly exciting because it also manages configurations and prompts, creating an admin interface that simplifies management for non-technical users and potential clients of Coach Artie. This interface is designed to be simple, beautiful, and powerful, enhancing the user experience and facilitating self-management through a user-friendly web interface.

As we advance the capabilities of Coach Artie, it's clear that our work at Room 302 Studio is a small but meaningful step towards the future of interactive AI. By focusing on user-centric features and intuitive design, we are committed to making advanced technology accessible and useful for everyone. While we are proud of our progress, we view it our contribution to a larger journey in the ever-evolving landscape of AI.

Coach Artie is open source for non-commercial use, embodying our belief in the power of community-driven innovation. By making these tools available freely, we invite developers and enthusiasts to join us in refining and expanding Artie's capabilities. We want to build a collaborative environment where Artie grows through shared knowledge and creativity.---
date: 2023-01-19T01:14:29-05:00
modified: 2023-01-19T01:14:29-05:00
dek: In which
inprogress: true
tags: culture
---

# Archetypes and their implications---
dek: In which I recount my journey from idolizing the concept of scale in Silicon Valley to embracing the more sustainable, disciplined approach in technology
inprogress: true
date: Invalid date
modified: 2023-12-17T19:12:44-05:00
tags: Silicon Valley, Technology, Sustainability, Scale, Personal Growth
---

## From Scale to Sustainability: My Silicon Valley Epiphany

### Chasing Giants: A Silicon Valley Dream

When I was 18 I drove my car from New York to San Francisco to work at a start-up instead of going to college.

### The Siren Song of Silicon Valley

### Scaling Up: The Tech Industry's Holy Grail

### Cracks in the Façade: The Unseen Costs of Scale

### A New Perspective: Encounters with the Downsides of Scale

### Redefining Success: Sustainability Over Scale

### Embracing Discipline: A Sustainable Tech Ethos

### Choosing a Different Path: My Project Evolution

### Collaborations and Choices: Reflecting My New Values

### A Balanced Future: The Intersection of Scale and Sustainability

### My Ongoing Journey: Committing to Sustainable Tech
------
dek: In which we make the elements of our page twirl and dance in order to spark joy.
inprogress: true
date: 2023-11-08T14:37:45-05:00
modified: 2023-12-01T20:05:33-05:00
tags: nuxt technology howto
---

## Creating Scroll-Powered Animations in Nuxt

### VueUse Motion

### useScroll()

### anime.js
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-07T13:42:02-04:00
tags:
---

## Livestream Learning: How Room 302 Engages and Educates in Real-Time

Learning Out Loud: The Power of Livestream Education
---
date: 2023-01-19T01:26:10-05:00
modified: 2023-01-19T01:26:11-05:00
dek: In which
inprogress: true
tags: tech howto
---

# How I use GitHub---
dek: In which we attempt to replace aimless scrolling with intentional creativity
inprogress: true
date: 2023-08-04T16:41:57-04:00
modified: 2023-09-09T14:57:38-04:00
tags: art
---

# Best iOS Apps For Daily Creativity

## Procreate Pocket

## ChatGPT / OpenAI Playground

## Obsidian

## Instagram

## iMovie
---
date: 2022-11-15T21:43:52-05:00
modified: 2022-12-23T09:20:41-05:00
---
# GPT3 Cyberpunk Novel

#machinelearning 

In a cyberpunk future where the lines between reality and virtual reality have blurred, write a novel about a group of people who are fighting to stay sane.

# Characters

-Aria: A young woman who is struggling to keep her grip on reality. She spends most of her time in virtual reality, where she can be anyone she wants to be. 

-Blake: Aria's best friend and the leader of the group. He is a gifted hacker and is always able to find a way out of any situation. 

-Jake: The muscle of the group. He is a street fighter and is always ready to take on anyone who threatens them. 

-Nova: A mysterious woman who always seems to know what is going to happen next. She is a skilled hacker and is able to help Blake with his work. 

-Trinity: The group's medic. She is a skilled doctor and is always able to keep everyone alive.

# Plot

The novel follows the group as they fight to stay alive in a world that is falling apart. They are constantly being pursued by enemies who want to either kill them or use them for their own purposes. The group must use all of their skills to survive as they try to find a way to escape the virtual world and return to reality.

# Twist

Aria discovers that she is actually a computer program and that the world she thought was real is actually just a virtual reality. She must decide whether to embrace her new identity or try to find a way to keep her friends from leaving.

---

Chapter 1

Aria awoke with a start, her heart pounding in her chest. She looked around the dark room, trying to orient herself. It took her a few moments to remember where she was- in her apartment in the city. She let out a sigh of relief and rubbed her eyes tiredly. It had been another long night of fighting in the virtual world and she was starting to feel it.

She got out of bed and made her way to the living room, where she found her roommate Blake hunched over his computer, typing away furiously. He didn't even look up as she entered the room.

"What are you working on?" she asked him, sitting down on the couch next to him.

"I'm trying to find a way to get us out of here," he replied without looking up from his screen. "I've been working on it for weeks now but I can't seem to find anything."

Aria sighed and leaned back against the couch cushions. "I don't know if there's anything left to find," she said softly. "Maybe we should just give up."

Blake shook his head determinedly. "No," he said firmly. "We can't give up yet."

Aria didn't say anything, she just stared at the dark screen in front of her. She knew Blake was right, they couldn't give up yet. They had to find a way out of this place before it destroyed them completely.

Aria and Blake had been friends for as long as they could remember. They had grown up in the city together and had always been there for each other. But when the world started to change, they found themselves on opposite sides. Aria embraced the new virtual reality while Blake fought against it. But they were still roommates who cared about each other, even if they didn't always see eye to eye.

Aria lazily surfed the nets, not really looking for anything in particular. She had given up trying to find a way out weeks ago. It was pointless, there was no way out. Virtual reality was their future. 

Suddenly, her screen lit up with a message from Blake. "I found something," it said simply. He was sitting right next to her, but clearly knee-deep in whatever he was researching. 

Aria's heart quickened as she quickly clicked on the link he had sent her. She scanned the page quickly, her eyes widening in disbelief. "This can't be real," she breathed.

"It is," Blake said, coming to stand behind her.

Aria stared at the screen, not sure what to believe. Could this really be a way out? Or was it just another false hope that would lead them nowhere?

Aria read the document Blake had found out loud, not believing the words as they exited her mouth.

"Neo Bay City Police Department, Echo Foxtrot Golf Unit, Investigative Warrant." it began. She continued reading.

"We, the sworn agents of NBCPD solemnly swear to the information included in this warrant. What dorks. On September 13th, 20xx, at approximately 0300 hours, a series of events occurred that resulted in the deaths of twelve people. The events began with a power outage in the city that lasted for approximately two minutes. During this time, all electronic devices in the city were shut down."

"I remember that," Aria interjected- "I was at a club in packmeat"

She kept reading: "During the power outage, twelve people were brutally murdered in their homes. All of the victims were separately found with their throats slit and their bodies mutilated at almost exactly the same time. After a thorough investigation and scan of the scenes, nothing of investigative importance was a found."

Aria's hand trembled as she continued.

"Keep reading"

"This warrant affirms that LOOP President Aria Blendheim and Blake Netts, residing at 5678 W. 4th St. Apt. 3B, are to be brought in for questioning in relation to the murders. All electronic devices in their residence are to be confiscated and searched for any and all evidence related to the murders. This warrant is valid for the next 72 hours. Signed, Judge Johnathan Wilkes."

Aria's hands were shaking so badly she could barely hold onto the computer. "What does this mean?" she asked Blake, her voice trembling.

"It means we're going to be arrested," he replied matter-of-factly. "And our apartment is going to be raided."

## Chapter 2

"Alluring persona you've developed," uttered a towering figure, her hair cropped short, piercing Aria's consciousness like a bullet seeking steel. Caught off guard, Aria fumbled for words.

"You misunderstand me," she stammered, her gaze scanning their surroundings with paranoid urgency.

The enigmatic woman leaned closer. "Trinity—call me that." Her tone matched her namesake, familiar and cryptic all at once. "Tag along with me; new souls like you could use a shepherd."

With Blake nodding in approval, Aria relented, submitting to the magnetic pull of Trinity's presence. Was it trust or desperation that tugged at her heartstrings?

Stalking through throngs of iridescent beats casting dancing shadows on gyrating bodies, the trio followed Trinity toward an inconspicuous door. On the other side awaited a dimly lit corridor and a somber elevator awaiting their arrival.

Trinity leads them through the crowd to a door in the back of the room. She opens it and they follow her down a dark hallway to an elevator.

"This place is a safe haven for people like us," Trinity explains as they ride up to the top floor. " people who are fighting to stay sane in a world that is increasingly crazy."

As the elevator doors slid open, Aria was struck by a breathtaking vision. Spread before her were the vast expanses of the cityscape, an entire top floor transformed into an observation deck offering 360-degrees of unparalleled views. Diverse individuals from all walks of life mingled effortlessly; some conversed animatedly, others engaged in games or lost themselves gazing at the panorama.

"Incredible," Aria whispered, awestruck.

"It is," Trinity agreed. "A sanctuary where true selves emerge unguarded."

"I must fetch my friend," Aria insisted. "He's waiting outside."

"Certainly," Trinity replied, guiding Aria gracefully toward the exit.

Together, they rejoined Blake and ascended back up, whereupon he scrutinized Trinity's motives.

"My name is Trinity," she revealed with self-assurance.

"And what brought us here?" Blake inquired skeptically.

"You're new. I perceived your need for guidance," she clarified.

"Guidance to what?" he challenged.

Trinity winked playfully. "Anything you desire."

Blake retorted curtly, "Not interested." Trust hadn't formed in his heart yet.

Trinity shrugged nonchalantly. "The offer stands if needed."

Upon re-entering that breathtaking utopia atop the elevator ride, Blake's jaw unhinged from sheer amazement.

"Extraordinary," he acknowledged.

"Indeed," Trinity confirmed with an affirming smile. "Here, one's essence thrives unshackled."

"I could use a place like this," Blake said, looking around at all the people.

"You are welcome here anytime," Trinity said. "Just remember, what happens in the club stays in the club." Trinity sauntered off, leaving Aria and Blake to explore on their own.

Chapter 3:

"Do you think we can access the nets safely here? I don't want to get caught." Blake whispered to Aria as they sat in the darkness of the club, watching the people around them.

"I'm not sure. But Trinity seems to know what she's doing. I trust her." Aria replied.

"Do you trust her enough to show her the warrant?"

"No, not yet. We need to be careful who we trust."

Just at that moment, Trinity reappeared next to them at the bar. "What are you two talking about?" she asked, sipping her drink.

"Just wondering if it's safe to access the nets here," Blake replied.

"Of course it is. I have the best security system in the city. You're safe here." Trinity said with a smile.

"Everyone thinks they have the best. What ports are you leaving open? How often do you randomize your forwarded ports?"

Trinity laughed "You really think that poorly of me? We don't forward ports here. Zero incoming ports open. Like a black box. And our outgoing ports are all random."

Blake was impressed. Trinity was good. "What about physical security?" he asked.

"I have a team of guards that patrol the perimeter. They're all armed and very well trained."

"Armed… with guns? In a club?" Aria was surprised. She had never seen guns in a club before.

"Yes, guns. What did you expect? Tasers?" Trinity laughed. "This is the real world, not some virtual reality game."

Aria was quiet for a moment, thinking about what Trinity had said. It was true. This was the real world. And in the real world, people used guns. She should be careful not to let her virtual reality experiences cloud her judgement.

"I'm sorry, Trinity. I didn't mean to offend you." she said finally.

Trinity nodded, knowingly. "I understand. It's easy to forget sometimes. But you need to remember, this is the real world. And in the real world, things are different. As long as you are here under my care, you will be safe both physically and technologically. But you need to be careful out there in the world. Not everyone is as trustworthy as I am." Trinity looked Blake in the eye. "You especially need to be careful, Blake. You have a lot of skills that people would kill for."

"You know who I am?" Blake was surprised.

"Of course I do. I know everyone who comes through here. And I know all about you, Blake. You're a very talented hacker. But you need to be careful. There are people out there who would use your skills for their own gain, or put you into danger just to control you. You need to be careful who you trust."

Blake nodded, understanding what Trinity was saying. He knew she was right. He had been careful in the past, but he would need to be even more careful now. "Thank you for the advice, Trinity. I will be more careful."

"Good. Now, if you'll excuse me, I have some business to attend to." Trinity finished her drink and walked away.

Aria and Blake sat in silence for a moment after she left. They were both thinking about what she had said. Finally, Aria broke the silence.

"She's right, you know."

"I know." Blake replied.

"You need to be careful. I don't want anything to happen to you." Aria said, her voice full of concern.

"I will. I promise." Blake took her hand and squeezed it reassuringly. "I'm not going to let anything happen to me. Or to you."

---

Chapter 4:

After spending a few days at the club, Aria and Blake began to feel more comfortable in their surroundings. They still hadn't told Trinity about the warrant for their arrest, but they had managed to access the nets safely and research more about the mysterious ECHO and LOOP mentioned in the warrant.

As they dug deeper, they discovered that LOOP was a powerful underground organization with ties to various criminal enterprises throughout the city. But ECHO remained an enigma, with no visible connections or affiliations.

"We need to figure out what ECHO is before we can even think about clearing our names," Blake said, frustrated by the lack of information. "But there's just nothing out there."

"I think we should tell Trinity," Aria suggested. "She's been nothing but helpful to us since we met her, and she might know something about ECHO or LOOP."

Blake hesitated for a moment, still wary of trusting anyone too quickly. But he couldn't deny that Trinity had been a lifesaver, providing them with a safe place to stay and helping them navigate the club's hidden resources. Finally, he nodded in agreement. "Alright, let's talk to her."

Aria and Blake found Trinity in the club's workshop, a room filled with state-of-the-art technology, ranging from advanced holographic displays to nanobot swarms for medical applications. They were amazed by the variety of cutting-edge devices, many of which they had only seen in virtual reality simulations.

"Trinity, this place is incredible," Aria said, her eyes wide with wonder. "I've never seen so much advanced tech in one place before."

Trinity smiled proudly. "I like to stay ahead of the curve. Some of this tech is experimental, but it has the potential to change the world in the next decade or two."

One piece of technology caught Blake's attention: a sleek, black helmet with numerous wires and sensors attached. "What's this?" he asked, picking it up carefully.

"That's a prototype neural interface," Trinity explained. "It allows the user to connect directly to the nets using their brainwaves, bypassing the need for a physical device. It's not perfected yet, but it's getting close."

Blake's eyes widened with excitement. "That's incredible."

Trinity hesitated for a moment before continuing. "There's something I should tell you. The reason I have this prototype neural interface is because it was created by ECHO."

Aria and Blake exchanged shocked glances. "What?" Aria asked, not quite believing what she had just heard. "But I thought ECHO was some kind of mysterious killer or criminal organization."

"No one knows exactly what ECHO is," Trinity admitted. "But they've been developing some of the most advanced tech the world has ever seen. They operate in the shadows, and their creations are both astounding and terrifying."

Blake frowned, trying to process this new information. "But why would ECHO make something like this? And more importantly, how did you get your hands on it?"

Trinity sighed, her expression turning serious. "I have my connections. As for why ECHO is developing this kind of tech, it's hard to say. Some believe they're trying to create a new world order, where they control everything through technology. Others think they're working towards a more utopian goal, where everyone can live in harmony, free from the constraints of the physical world."

Aria took a deep breath, her mind racing as she processed the information. "There's a rumor I've heard, something that might be connected to ECHO. It's about a cult that believes in a radical form of technological salvation. They think that the only way to save humanity is to kill everyone and convert their brains into neural-nets. They believe that by doing so, they'll create a collective consciousness capable of bringing about the second coming of the messiah."

Trinity nodded gravely. "I've heard that rumor too, but I didn't know if there was any truth to it. If ECHO is behind this cult, it would explain their interest in developing the neural interface technology."

Blake clenched his fists, anger and frustration boiling within him. "So, you're saying that we're being hunted by an organization that wants to kill everyone and bring about the end of the world? And they're using our names to cover their tracks?"

As Blake finished speaking, the atmosphere in the club suddenly shifted. The music's tempo increased, and the patrons on the dance floor moved with a newfound urgency. Aria glanced around, her instincts telling her something was wrong.

Trinity's expression turned serious as she looked at her wrist-mounted display. "We've got a situation. My security system has detected an unauthorized access attempt in the club's network. They're trying to locate us."

Blake's eyes narrowed. "LOOP or ECHO?"

"Can't say for sure, but it doesn't matter right now. We need to move," Trinity said, quickly leading them through the workshop and into a hidden passage behind a bookshelf.

As they hurried down the dimly lit corridor, Aria felt her heart pounding in her chest. The thought of being pursued by an organization as powerful and mysterious as ECHO or LOOP was terrifying.

Trinity led them to a small, well-equipped control room. "This is where I monitor all the club's security systems. We need to figure out who's trying to find us and stop them before they get any closer."

Blake immediately sat down at a terminal and began furiously typing, working to trace the intruder's access point and lock them out.

As the tension in the room mounted, Blake's fingers danced across the keyboard with a precision and speed that few could match. He launched a series of commands using nmap, an advanced network scanning tool, to identify the intruder's IP address and the services they were targeting.

Aria and Trinity looked on, their eyes glued to the screen as they watched lines of code scroll rapidly. Though they couldn't follow every detail of Blake's actions, they could feel the intensity and urgency in his movements.

Blake's eyes darted across the screen as he analyzed the incoming data. "They're trying to bypass our firewalls using an exploit I've never seen before," he muttered. "It's sophisticated, but I can counter it."

Carefully masking his digital footprint, Blake logged onto a series of well-known darknet forums, where hackers and cybercriminals gathered to share information, tools, and exploits. He knew that asking about a sophisticated exploit like this one might draw unwanted attention, but the risk was worth it if he could find a way to protect their hideout.

In a private chatroom, he cautiously typed out his inquiry. "Anyone seen a new exploit targeting firewall vulnerabilities? Advanced stuff. Need info ASAP."

Blake waited, his heart pounding in anticipation. The seconds felt like hours as he watched for a response, knowing that every moment counted with the intruder still attempting to breach their security.

Finally, a user with the handle 'ShadowNinja' replied. "I've heard of something like that. It's rumored to be ECHO's work. They call it GhostShell. There's no known patch, but I've got a workaround. I'll send you a patch"

Blake quickly downloaded the patch sent by ShadowNinja and scanned it for any hidden malware or traps. Satisfied that it was clean, he proceeded to apply the patch to their firewall.

Upon closer examination, Blake realized that the Neuromancer reference was not just a clever nod, but a key component of the exploit itself. The attacker had used an encryption algorithm inspired by the novel's central artificial intelligence named Wintermute.

As the AI in Neuromancer was constantly searching for a way to merge with its other half, Neuromancer, and transcend its limitations, the GhostShell exploit mirrored this concept within its code structure. Its purpose seemed to be to break through any constraints set forth by firewalls, seeking a connection with systems beyond.

Furthermore, Blake noticed that the attacker flawlessly integrated lines from the novel into variable names and comments throughout the code. A particular function was aptly named 'IceBreaker', alluding to programs designed to bypass Intrusion Countermeasures Electronics (ICE) – a common term in Neuromancer representing security measures found in cyberspace.

Motivated by the challenge laid out before him, Blake quickly assessed ShadowNinja's patch and began implementing it with precision. As he worked through the code, he incorporated references of his own – countermeasures named after characters from his favorite cyberpunk novels and movies.

As Blake put the finishing touches on implementing ShadowNinja's patch, he couldn't shake the feeling that something was off. The integration of Neuromancer references into the exploit, as well as the ease with which he had obtained the necessary information on the darknet forums, seemed almost too perfect.

With a final keystroke, Blake applied the patch and severed the attacker's connection to their network. Breathing a sigh of relief, he turned to Aria and Trinity. "We're safe for now. GhostShell has been neutralized."

Trinity's expression remained tense, her eyes still on the screen displaying their security feed. "But for how long?"

Blake frowned but didn't have time to respond to her question. At that moment, an incoming message appeared on his terminal from an anonymous source:

"Nice work, Blake. You've proven your skills once again. But don't get comfortable; this was just a test. We'll be in touch. - ECHO"

A chill ran down Blake's spine as he stared at the message. Not only had ECHO discovered their hideout, but they were fully aware of Blake's involvement in stopping their exploit.

As Blake tried to process the implications of the anonymous message, an urgent alert from the club's security system suddenly appeared on the screen. One of the patrons on the dance floor had triggered a biometric anomaly alert - their body temperature was dropping rapidly.

Aria, Blake, and Trinity exchanged concerned glances before hurrying back to the main club area. An unnerving silence had fallen over the crowd as people took notice of a young man standing near the center of the dance floor. His body convulsed violently, his eyes wide with terror as vapor-like plumes escaped his mouth with each gasping breath.

Trinity quickly approached the young man, her medical instincts kicking in. "Clear some space!" she shouted, pushing onlookers back from the scene. She turned to Aria and Blake. "I need my nanobot swarm kit from the workshop – ASAP!"

---

Chapter 6

Two weeks had passed since the incident at the club, leaving both Aria and Blake on edge. They had relocated to a new safe house under Trinity’s guidance, one that she assured had even better security measures. The young man who had been attacked made a full recovery, thanks to Trinity's swift action and nanobot swarm treatment.

Blake couldn't shake off the feeling that they were being watched. As he stood on the balcony of their new hideout, sipping coffee in the early morning light, Aria joined him.

"How are you holding up?" Aria asked softly.

"Honestly? Not great," Blake admitted. "I keep going over everything that happened in my head, wondering what it all means."

Aria nodded, understanding his sentiments all too well.

"I couldn't help but notice something strange when I looked back on the recordings from that night," Blake continued. "The attack seemed targeted, and yet... after we eliminated the threat, everyone else resumed partying like nothing had happened."

"This is the world we live in now," Aria said sadly. "Everyone is so numb to tragedy and violence that they just carry on. But there was more to it than that."

Blake stared contemplatively at his coffee cup. Aria's words struck a chord within him. They were fighting for a cause greater than themselves – for everyone who had been downtrodden and marginalized by those in power.

"You're right," he said, a new sense of determination in his voice. "And if we've learned anything over the past few weeks, it's that we can't take our abilities for granted. Every move we make could have unforeseen consequences."

Aria nodded in agreement, her intuition guiding her towards a larger truth they hadn't yet uncovered. "We need to become smarter, more efficient in how we operate. And most importantly, we need to find answers"

After fueling themselves with that newfound resolve, Aria and Blake dove into an intense research montage. Days blended into nights as they tirelessly scoured the dark corners of the nets, gathering information about ECHO and LOOP.

The duo hacked their way through heavily-secured databases, corporate archives, and encrypted forums no one ever dared to speak of in the open networks. Wiping sweat from their brows and fueling up on endless energy drinks, Aria and Blake became shadows of their former selves – but they were making headway.

Together, they decrypted classified documents, reconstructed fragmented conversations, and built a complex web of connections between various players in the city's underworld. Slowly but surely, a clearer picture began to emerge.

After countless sleepless nights hunched over their terminals, a breakthrough occurred. Aria discovered an encrypted chatroom within the darknet that was exclusively used by high-ranking members of ECHO. They finally had access to direct communication between these elusive figures.

Chapter 7: Shadows Speak

ECHO_chat_Comm-4039X: Active
[21:47] user_5fca98: Welp, anons. got another loophole 2 cover
[21:48] user_b39d12: How many times do we have to deal with this s***?
[21:49] user_5fca98: Calm down m8, just doing what we're paid for
[21:52] user_e78e00: If the all-knowing gods didn't keep their heads so far up their own a****, we wouldn't be cleaning up messes left and right.

Aria and Blake watched fascinated as anonymous users in the ECHO chatroom traded messages faster than they could blink.

[21:54] user_b39d12: Anyway, any updates on the GhostShell exploit? I heard someone managed to counter it.
[21:56] user_9c9447: Yup. Heard that too. Pulled it from the toolkit this morning.

Aria and Blake exchanged glances as they read the mention of Blake in real-time.

[21:57] user_e78e00: That might be a problem for our other project, no?

The chatroom went silent momentarily before messages resumed appearing. People were furious.

[21:58] user_5fca98: can't afford setbacks on Genesis. control of everything depends on it
[22:00] user_b39d12: wth is up with leadership? Should've dealt with Blake & co b4 they became a thorn in our side smh

The tension was palpable as Aria and Blake continued reading the messages flying across their screens.

[22:01] user_e78e00: no use crying over spilt milk. We need to stay focused – priority one is getting the exploit back on track.
[22:02] user_f8c200 (admin): Agreed. All chatter about past events ends now. Bring me solutions or gtfo.

A sudden seriousness swept through the chatroom as users refocused their efforts.

Blake's fingers hovered over the keyboard, an impulsive desire to engage with these unknown hackers welling up within him.

"I'm thinking of saying something in the chat," he admitted to Aria.

Aria pondered for a moment before responding. "You know what? Go for it. We're already on their radar, and we've proven that we can work around their obstacles. What else can they do?"

Blake was surprised by her response but felt encouraged. He typed out a message but hesitated just before hitting 'enter'.

[22:04] Blake (new): hai guyz, you underestimate Blake & friends at your own peril ;)

With bated breath, they awaited the reactions of the anonymous users populating ECHO_chat_Comm-4039X.

As Blake's message appeared on the screen, a palpable shockwave seemed to ripple through the chatroom. The rapid-fire exchange of messages slowed down momentarily as ECHO members absorbed the unexpected presence of an outsider in their midst.

[22:05] user_5fca98: You got some guts being in this channel, "friend".

As tension and anticipation mounted, Aria grasped Blake's hand for support. They held their breath while awaiting the response from ECHO members or any sign that retaliation might be imminent. Suddenly, a new user with administrator privileges chimed in:

[22:06] user_X15b02 (admin): Let me set something straight for you all, including our unexpected guest.

Hundreds of lines of meticulously-constructed code began flooding into the chat - so quickly that it was difficult for even experienced programmers like Aria and Blake to follow what was happening at first glance.

As they skimmed through the code, their eyes widened in horror. It was a new exploit – seemingly capable of bypassing even the most advanced security measures and firewalls.

[22:07] user_X15b02 (admin): This is Janus - our latest initiative, far more potent than GhostShell or any other tech you've encountered. Blake & friends, know that we have only shown you a fraction of our power. Cease your interference unless want to witness firsthand what we can do without blinking.

A chilling silence descended upon the chatroom like an ominous fog, leaving Aria and Blake rooted to their seats in fear. Then their connection to the chat was severed. 

---

As Aria and Blake studied the code more closely, attempting to decipher its full capabilities, they realized that Janus incorporated a terrifying combination of bleeding-edge technologies. The core mechanism seemed to involve advanced quantum computing algorithms entwined with next-generation artificial intelligence subroutines.

This exploit took advantage of obscure hardware vulnerabilities in both classical and quantum processors alike. It gained control over qubits – the rudimentary units responsible for processing information within a quantum computer – altering their delicate superposition states at will. By modifying these qubits remotely through instantaneous entangled connections, even across vast distances or secured networks, this exploit could swiftly bypass traditional security measures like never before.

But what heightened the terror surrounding Janus was its integration with AI subroutines. This allowed it not only to access target systems independently but also adapt and improve itself as new countermeasures were discovered by potential victims. Every infected computer then became a node in the AI neural network. The term "moving target defense" paled in comparison to how quickly this evolving AI-driven cyber-weapon would change its tactics to maintain dominance.

As days turned to weeks, they painstakingly pieced together fragments from a variety of sources until an unusual pattern emerged. The line between virtuality and reality seemed increasingly blurred as hints surfaced about potential experiments on intertwining human consciousness with artificial intelligence directly embedded in VR worlds.

---

Aria, Blake, and Trinity stood on a dimly lit subway platform as they made their way to a hidden meet-up spot. The rumble of an approaching train echoed around them while bots passed by carrying packages.

As they boarded an old but retrofitted subway car, Aria scanned her surroundings with vigilance. Not just because of potential threats lurking nearby – she also hoped for clues that would help them make sense of this crumbling virtual reality around them.

The train hurtled through tunnels worn away by time and disrepair. As the train came to a screeching halt in an abandoned station, Aria, Blake, and Trinity stepped out onto the platform. With every step they took towards their destination - illuminated by flickering lights reflecting off graffiti-adorned walls – a palpable sense of anticipation grew among them. They were about to meet with an enigmatic group of hackers known as the "Archivists" – individuals who had devoted their lives to preserving knowledge and secrets in the ever-shifting virtual landscape.

The train came to a halt at a station that seemed to defy the passage of time. The dim lighting cast an ethereal glow on the platform, and the air hummed with an energy that was almost palpable. Aria couldn't help but feel a sense of awe as they stepped onto the platform.

They were greeted by a tall figure clad in a flowing cloak, their face obscured by a hood. The figure extended their arm, and a swarm of tiny drones emerged from within the folds of the cloak, dancing around them like fireflies before coalescing into a shimmering holographic map.

"Welcome, friends," the hooded figure said, their voice echoing softly through the chamber. "We have been expecting you."

As they followed their enigmatic guide deeper into the hidden sanctuary, the trio marveled at the seemingly magical sights around them. The walls were adorned with ancient runes that glowed faintly, illuminating intricate pathways carved into the stone. Holographic projections flickered and danced above their heads, displaying images of lost civilizations and long-forgotten battles.

The deeper they ventured, the more Aria felt as if they were walking through the pages of a mythical storybook. Yet, she knew that beneath the fantastical veneer, advanced technology and complex algorithms were at work – weaving together this enchanting tapestry of light and sound.

As they reached the heart of the sanctuary, the hooded figure led them into a spacious chamber filled with individuals who seemed to have stepped out of a cyberpunk legend. Each person in the room embodied a unique aspect of hacker culture, yet they all shared an air of wisdom and camaraderie that was undeniably endearing.

A woman with long silver hair and cybernetic enhancements sat at a table, her fingers dancing across multiple holographic keyboards as she expertly navigated through layers of encrypted data. Despite her intense focus, she offered Aria, Blake, and Trinity a warm smile as they entered.

In another corner, a young man with a mechanical arm worked on a complex-looking device, his face illuminated by the soft glow of a floating display. He glanced up at the newcomers and gave them a friendly nod before returning to his task.

A group of individuals huddled around a large table, their eyes darting between various screens as they discussed strategies and shared information. Their conversation was peppered with technical jargon and playful banter, creating an atmosphere of both seriousness and camaraderie.

As Aria, Blake, and Trinity observed the Archivists, they expected to be met with skepticism or wariness – a common reaction when outsiders entered such a tight-knit group. However, the atmosphere in the chamber remained welcoming and open.

The hooded figure stepped forward, lowering their hood to reveal a warm, genuine smile. "I am Sylas, speaker of the Archivists," they said, extending a hand to each of them. "We've been following your journey closely, and we're impressed by your resilience and resourcefulness."

As Sylas continued to speak, Blake's gaze wandered around the chamber, taking in the various symbols and imagery that adorned the walls. His eyes narrowed as he noticed a familiar pattern – one that he had seen during their recent investigations into ECHO and LOOP.

The same symbols had appeared as subtle markers in the data trails they had followed, almost as if someone was guiding them towards the Archivists. It suddenly dawned on him that this group might have been leaving breadcrumbs for them to find all along.

Blake hesitated, unsure of how to broach the subject with Sylas and the others. He glanced at Aria and Trinity, who seemed equally captivated by the warm atmosphere and the intriguing individuals surrounding them.

Sylas gestured for them to sit at a large table in the center of the room. "Please, join us. We have much to discuss," they said with a warm smile. As they took their seats, Sylas poured steaming tea from an ornate teapot into delicate cups.

Blake eyed the tea suspiciously, his mind racing with thoughts of potential poisons or drugs that could be hidden within the seemingly innocuous liquid. He glanced at Aria and Trinity, who accepted their cups without hesitation, unaware of the potential danger they might be in.

His heart pounded in his chest as he watched his friends take their first sips of the tea. Each passing second felt like an eternity as he waited for any sign of distress or discomfort on their faces. The room seemed to close in around him, the once enchanting atmosphere now suffocating and oppressive.

Sylas handed Blake a cup of tea, their eyes meeting for a brief moment. Blake hesitated, the cup trembling in his hand as he weighed the risks of drinking it against the possibility of offending their hosts. The tension in the room was palpable, a heavy silence hanging over them like a dark cloud.

Just as Blake was about to take a sip of the tea, Sylas suddenly spoke up. "You're concerned about the tea, aren't you?"

Blake froze, his eyes darting to meet Sylas's gaze. He didn't know how to respond.

Sylas chuckled softly, their eyes filled with understanding. "I apologize if our hospitality has caused you any distress. We've been aware of your concerns since you entered our sanctuary."

Aria and Trinity exchanged surprised glances, realizing that the Archivists had been closely observing them as well.

"You see," Sylas continued, "we understand the importance of trust, especially in a world where deception and betrayal are all too common. The tea is simply a test – a way for us to gauge your level of trust in us. It's not poisoned or drugged, I assure you."

As Sylas finished speaking, Blake couldn't help but keep glancing at Aria and Trinity, his concern for their well-being still lingering. He observed them closely, searching for any signs of distress or adverse reactions to the tea.

To his relief, both Aria and Trinity appeared to be perfectly fine, engaged in conversation with the other Archivists and showing no ill effects from the tea they had consumed. Gradually, Blake's anxiety began to dissipate, replaced by a growing sense of trust in Sylas and the Archivists.

He took a deep breath and finally allowed himself to take a sip of the tea, finding its taste surprisingly soothing. As he did so, he noticed Sylas nodding approvingly, a subtle acknowledgement of the bond of trust that was beginning to form between them.

As the tension in the room dissipated, Sylas began to share the history of the Archivists and their connection to Aria, Blake, and Trinity. They explained that the Archivists were a group of hackers, scholars, and engineers who had come together with a common goal: to preserve the truth and knowledge of the virtual world against those who sought to manipulate and control it.

"We've been watching your struggles against ECHO and LOOP," Sylas said, their voice filled with admiration.

Sylas continued, "It was your boldness in taunting ECHO directly within their own chatroom that truly caught our attention. That audacious move demonstrated a level of courage and determination we haven't seen in a long time."

Aria couldn't help but smile at the memory, feeling pride for what they had accomplished together.

Sylas leaned forward, their eyes locked on Blake's. "Your actions have proven to us that you are not only capable but also share our values when it comes to fighting against those who wish to control and manipulate this world."

"However, what we saw during your interaction with ECHO has left us deeply concerned."

They pulled up a holographic display of the Janus code for everyone to see. "This new exploit – Janus – is unlike anything we've ever encountered before. Its potential capabilities are not only groundbreaking but also terrifying when placed in the wrong hands."

Sylas continued, "You see, this code is designed to exploit the very building blocks of modern computing – the smallest units responsible for processing information. By manipulating these fundamental elements remotely and instantaneously, even across vast distances or secure networks, it can bypass traditional security measures with ease."

They paused before adding gravely, "But what makes Janus truly dangerous is its ability to learn and adapt on its own. It's not just a static piece of malicious software; it has been imbued with advanced learning capabilities that allow it to evolve as new defenses are developed against it. This constant adaptation ensures that no matter how much we try to counteract its effects or protect ourselves from harm, Janus will always find a way through."

As Sylas finished explaining the gravity of Janus, one of the Archivists – a wiry man with an array of facial piercings and tattoos that seemed to depict circuitry patterns – chimed in.

"I've been analyzing this code ever since you brought it to our attention," he said. "And while I agree that its adaptive capabilities make it incredibly dangerous, there might be a way to defeat it."

He tapped on his holographic display, bringing up another set of complex algorithms for everyone to see. "We can exploit the very feature that makes Janus so powerful: its ability to learn and adapt."

The hacker explained further, "By creating multiple layers of decoy security measures within targeted systems – each designed specifically to trigger unique adaptations within Janus's AI subroutines – we could effectively confuse or overwhelm its learning mechanism. In other words, if we force it into too many simultaneous changes by bombarding it with diverse countermeasures all at once, we may render the AI incapable of identifying which adaptation is most effective."

Sylas raised an eyebrow, skepticism etched on their face.

"By constantly exposing bacteria to various types and doses of antibiotics, we forced them into rapid adaptation cycles until they eventually evolved resistance mechanisms against those very drugs designed to eliminate them. In our case here with Janus's AI subroutines, if we bombard it with too many countermeasures at once without fully understanding its capabilities or limitations first, we might inadvertently push its evolution towards becoming even more powerful and unstoppable."

The engineer nodded thoughtfully, taking Sylas's concerns into account. "You make a valid point about the potential risks of our approach. However, there is a key difference between antibiotic resistance and what we're proposing here."

He paused for emphasis before continuing, "In the case of antibiotics, bacteria were given ample time to adapt gradually in response to constant exposure. With Janus's AI subroutines, our strategy revolves around bombarding it with diverse countermeasures all at once – essentially overloading its learning mechanism within an extremely short timeframe."

The engineer went on to explain his extensive research findings that supported this idea: "Through rigorous testing and simulations I've conducted using various adaptive algorithms as proxies for Janus's AI component under similar conditions, results have consistently shown that overwhelming them with multiple simultaneous adaptations led these algorithms either towards stagnation or even regression in their effectiveness due to resource exhaustion or conflicting optimization goals."

Sylas's expression shifted from skepticism to curiosity. "So you've already tested this approach using surrogate algorithms? That is impressive."

The engineer nodded confidently, a hint of pride in his eyes. "Yes, I have spent countless hours running simulations and refining the methodology to ensure that we don't inadvertently make Janus even more formidable than it already is."

Blake, who had been listening intently to the conversation, suddenly spoke up. "There might be a way to further refine this approach and increase its effectiveness."

He paused for a moment before continuing, his voice filled with excitement. "What if we could create an adaptive countermeasure that evolves in response to Janus's AI subroutines? Instead of simply overwhelming it with multiple simultaneous adaptations from static decoy security measures as suggested earlier, our own countermeasure would learn and adapt alongside Janus – constantly staying one step ahead by anticipating its next move based on previous interactions."

Blake took a deep breath before delivering his most daring proposition. "We already have access to the Janus code, so we could potentially repurpose it and use its own adaptive learning capabilities against itself."

The room fell silent as everyone absorbed the implications of Blake's suggestion. The idea of harnessing such dangerous technology made them all extremely uncomfortable.

Sylas finally broke the silence, their voice filled with caution but also intrigue. "That is an incredibly risky proposal, one that would require meticulous planning and execution to ensure that we don't inadvertently create something even more powerful or uncontrollable than what ECHO has developed."

As the group debated the merits and risks of Blake's proposal, a sudden realization struck Aria. "Wait," she said urgently, drawing everyone's attention. "What if this is exactly what ECHO wants us to do? What if they intentionally allowed us access to Janus code as part of their larger plan?" The room fell silent once more as each person grappled with this unsettling possibility.

Chapter 8: The Path to Redemption

The tension in the air was palpable as the Archivists weighed the risks and potential benefits of Blake's audacious proposal. While some were intrigued by the idea of using Janus's own technology against it, others were understandably wary of the potential consequences. The line between salvation and disaster seemed razor-thin, and they were all acutely aware of the stakes involved.

As the Archivists continued their heated debate, Aria noticed that Trinity seemed unusually quiet and withdrawn. Concerned for her friend's well-being, she gently touched her arm and asked, "Are you alright?"

Trinity hesitated for a moment before answering, her voice barely a whisper. "I can't help but feel responsible for all of this. We wouldn't be in this situation if it weren't for my connections."

Aria looked at her friend with concern, sensing there was more to her story than she was letting on. "What do you mean, Trinity? What connections?"

Trinity took a deep breath and revealed a long-held secret that she had never shared with anyone – until now. "Before I joined your group, I was involved with ECHO. I was a part of their research division, working on the very technology we're now trying to counteract."

Aria, Blake, and even Sylas stared at her in shock, trying to process this unexpected revelation. Trinity continued, "I left ECHO when I realized the true extent of their plans – plans that would cause untold suffering and destruction. I thought I had severed all ties with them, but it seems they've been following me ever since."

Trinity's voice wavered as she continued, her eyes glistening with unshed tears. "I never told any of you because... because I was afraid. Afraid that you would judge me for my past, that you would see me as the enemy. I've spent every day since I left ECHO trying to make amends for my part in their twisted schemes, but the fear of losing the people I've come to care about – the people who've given me a second chance – has haunted me relentlessly."

Sylas's expression darkened as they scrutinized Trinity, their eyes probing her for any sign of deception. "Your revelation changes everything. We can't afford to take any risks, especially with so much at stake."

Suddenly, Sylas reached out and grasped Trinity's hand, their fingers entwining in a viselike grip. A surge of electricity passed between them, jolting through the air like lightning seeking ground. Their eyes locked, irises burning with an otherworldly intensity that demanded unwavering attention.

In that moment, a torrent of information began to flow between them – not through mere words or conversation, but via an extraordinary exchange facilitated by the advanced biometric communication implants they both carried within their flesh.

These enhancements, once developed by ECHO for secretive purposes and now repurposed by the Archivists and resistance fighters alike throughout the city, enabled two souls to connect on a level far beyond anything previously experienced. It was as if all barriers had been shattered in an instant; thoughts melded together like molten metal while emotions coiled and intertwined like prismatic serpents writhing in ecstatic dance.

Sylas delved into Trinity's memories with a speed akin to that of voracious datastreams racing down cyberoptic cables. They bore witness to her remorse over her involvement with ECHO –- every ounce of guilt she'd harbored ever since departing those sterile labs where Janus had been brought into existence. 

Simultaneously, Sylas shared their own past. As Trinity fell down a tunnel of Sylas' memories – their struggles, victories, and heartrending losses – she began to understand the relentless drive that propelled Sylas forward in their crusade against ECHO's tyranny. Nowhere was this evident more than in a nest of memories buried deep within Sylas' consciousness; moments where they had been forced to make life-or-death decisions under unimaginable pressure.

The exchange felt like it lasted an eternity, but it took only seconds for those implanted biometric devices to transmit such vast torrents of information between its users. Their connection broke as abruptly as it had begun, leaving them gasping for air and reeling from the emotional impact.

Sylas stared at Trinity with eyes filled with newfound understanding and respect. "We are all products of our past," they said softly, "both good and bad. That which shapes us can either break us or augment our resolve." They gave Trinity's hand a reassuring squeeze before releasing her.

"You see," Sylas began smoothly, "my journey into transhumanism has arisen from my transgender experience. As I embarked on this path to align my physical form with who I truly am inside – navigating both technological enhancements and biological transitions – there was something more profound waiting for me just beyond."

They paused for a beat before continuing. Underlining each word with quiet conviction, Sylas said: "I gradually realized that we are all shackled by conventional wisdom defining what it means to be human–a perception so desperately outdated in our rapidly evolving world."

Sylas' eyes blazed like twin suns ignited by divine wrath as they looked upon Aria and Trinity once more.

"This is precisely why ECHO's technology poses such an imminent threat; they want ultimately not only to control us but also mold humanity into their own twisted image."

Trinity took a deep breath before expanding on what Sylas said. "When I was still with ECHO, everything seemed surface-level and benign at first –- as if our work could benefit humanity on a grand scale. But it didn't take long for me to see the sinister truth hiding behind their facade of progress."

She gave them an uneasy glance and continued, "ECHO is founded upon white nationalist, sexist, and xenophobic ideologies. Their ultimate goal? To make anyone who isn't a cisgender white male serve these powerful white 'brains in the cloud.'

Trinity clenched her fists, the intensity in her voice growing as she delved deeper into the horrifying conspiracy. "These 'brains in the cloud,' you see, are composed of digitized minds belonging to ECHO's influential white leaders – individuals selected based on their strict alignment with their disturbing ideologies."

Her voice quivered, yet she pressed on. "In order to maintain this horrifying system, they need real-life workers – people who are bound to lives of misery and servitude so that these digital white elites can revel in their virtual paradise."

Bile rose in Trinity's throat as she spoke more about the inner workings of ECHO's plan. "Condemning individuals from all other races and backgrounds, along with every non-cisgender person, to a life devoid of joy or dignity–that’s how these privileged minds sustain themselves within the cloud.”

A haunted expression in her eyes betrayed just how much it pained her to describe such a tormented existence for millions. “These marginalized slaves must attend tirelessly to even the most degrading tasks: feeding those still physically present while immersed in VR fantasies; washing their frail bodies; emptying bags brimming with excrement—anything required simply so that dominant elite class may continue dominating unopposed from behind the veil of cyberspace."

Trinity shuddered as she ventured into even darker territory. "Their insatiable hunger for control only seems to amplify within the confines of their virtual haven, twisted by an all-encompassing ruthlessness."

She closed her eyes briefly, then continued in a barely audible whisper. "Some workers are bound in body mod suits with grotesque appendages that augment ECHO's leaders’ VR experiences: hides stretched thin and wired with neural probes, broadcasting torrents of forced pain stimuli just to satisfy some sadistic technofetishism."

Trinity's voice took on a somber tone as she emphasized the chilling core of this terrifying revelation. "And these people, these so-called 'elites,' truly are detached individuals teetering on the edge of sanity. They have become deranged to such an extent that they only barely take pleasure in the horrors inflicted upon those unfortunate prisoners."

She paused momentarily before continuing, her words coming out deliberately and paced slowly for effect.

"They relish pushing boundaries solely because they can," Trinity explained gravely. "Their power has corroded their empathy and left vacant malice festering within where humanity once resided – hollow shells propelled by perversity."---
dek: In which
inprogress: true
date: 2023-09-24T13:57:43-04:00
modified: 2023-12-17T19:19:56-05:00
tags: []
---

## Printing Photos With EXIF Data
---
date: 2023-01-19T01:16:08-05:00
modified: 2023-01-19T01:16:12-05:00
---

[[quantified-self]]

## Motorcycle for personal vehicle

## Walk to the grocery store

## Public transit

## Buy local as much as possible

## Avoid air travel

## Avoid red meat

---
date: 2022-12-13T16:42:33-05:00
modified: 2022-12-23T09:26:36-05:00
---

#programming #process #livestream 

# How quickly can you create a website?
---
draft: true
dek: In which
inprogress: true
date: 2023-02-22T13:41:51-05:00
modified: 2023-02-22T13:44:23-05:00
tags: police dataviz journalism
---

# Analyzing NOPD Misconduct Data

## Source Data

[Data from ipno-llead/networks](https://github.com/ipno-llead/networks)

### Files
#### data_app-new-orleans-pd.csv
#### data_settlements-new-orleans-pd.csv
#### data_com-new-orleans-pd.csv
#### data_uof-new-orleans-pd.csv
#### data_per-new-orleans-pd.csv
---
dek: In which a fascist takes over the website where you and your friends have been gathering for over a decade and you need to decide where to regroup
inprogress: true
date: 2023-09-22T12:48:13-04:00
modified: 2023-12-17T19:20:15-05:00
---

---
draft: true
dek: In which
inprogress: true
date: 2023-01-19T01:33:45-05:00
modified: 2023-01-19T01:33:56-05:00
tags: journalism personal news
---

# How I keep up with the news


---

I. Introduction
   A. The importance of staying informed in today's fast-paced world
   B. The challenges of information overload and finding reliable sources
   C. Introducing my personal strategies for keeping up with the news

II. Curating a Diverse Range of News Sources
   A. The value of consuming news from various perspectives and outlets
      1. Traditional print newspapers and magazines
      2. Online publications and digital news platforms
      3. Podcasts, radio, and television news programs
   B. Avoiding echo chambers and seeking out opposing viewpoints

III. Leveraging Technology to Stay Informed
   A. Utilizing news aggregator apps and websites for a customized news feed
   B. Subscribing to newsletters or email digests for a curated selection of articles
   C. Following journalists, experts, and organizations on social media platforms

IV. Prioritizing Quality over Quantity
   A. Focusing on in-depth analysis, investigative journalism, and long-form articles
   B. Identifying reliable sources and fact-checking information
   C. Recognizing the limitations of sensationalist headlines and clickbait content

V. Establishing a Daily News Routine
   A. Setting aside dedicated time for consuming news each day
      1. Morning routines: reading newspapers or browsing online articles over breakfast
      2. Commute rituals: listening to news podcasts or radio shows while driving or using public transportation
      3. Evening routines: watching nightly news broadcasts or catching up on social media updates
   B. Balancing the intake of local, national, and international news stories

VI. Practicing Mindful News Consumption 
    A. Being aware of emotional responses to the news and taking breaks when necessary
    B. Engaging in conversations and discussions about current events with friends, family, or colleagues
    C. Reflecting on the implications of news stories and their impact on personal beliefs and values

VII. Conclusion: The Benefits of Staying Informed
    A. Enhancing critical thinking skills and fostering a well-rounded worldview
    B. Encouraging informed decision-making in personal, professional, and civic life
    C. Contributing to a more engaged, knowledgeable, and empathetic society---
draft: true
dek: In which we study the art and science of using little dots to represent people on a map
inprogress: true
date: 2022-11-02T19:56:37-04:00
modified: 2022-12-23T09:10:34-05:00
---
# Dot Density Mapping in JS and QGIS

#dataviz #howto

The visual representation of data can be tricky business, and one of the most deceptive forms is choropleth maps, where features are filled in with a single color to represent a data point. It’s easy to get fooled by this practice – the larger the feature, the more prominent it appears in a map, giving the false illusion that there is more of something than there actually is.

Take, for instance, election data. A large majority of votes come from small counties or towns that are barely visible on a map showing country-wide results. While these counties may account for a huge percentage of votes, they’ll still appear in the same color as a state that has very few votes.

For visual forms like this, it’s important to pay special attention to the color scale, otherwise the information presented can be completely off.

Another approach is to avoid choropleth maps and, where possible, use a [dot distribution map](https://en.wikipedia.org/wiki/Dot_distribution_map). 

## How and when to use dot-density
## Prior work
- [Racial demographic dot-density map by Aaron Williams](https://observablehq.com/@aboutaaron/racial-demographic-dot-density-map)
- [Segregation map: America’s cities 50 years after the Fair Housing Act of 1968 - Washington Post](https://www.washingtonpost.com/graphics/2018/national/segregation-us-cities/)
- [Dot Density election maps of America by Benjamin Schmidt](https://observablehq.com/@bmschmidt/2020-election-dot-density)
- [A Dot for Every Vote Map](https://www.esri.com/en-us/maps-we-love/gallery/election-2016-dot-density)

## Using census race data for racial dot-density maps

Compared to choropleth maps, dot-density maps provide a more granular level of detail. This is especially beneficial when analyzing at small-scale areas, where a choropleth’s single-color scheme could obscure unintended details. 

For example, dot-density maps would be preferred in population analysis. By plotting individual dots across the map, one can easily observe pockets of higher or lower populations. This can be extremely helpful in targeting areas of concern or planning future developments.

I'm going to walk through how to create dot density maps in code with Javascript (With Canvas, D3, and Topojson) as well as through a GUI with QGIS. These tools provide different approaches and final products, depending on what you are looking to do. 

For example, Javascript enables us to customize the data and UI to better fit our needs, but it also requires a good amount of coding. This can be difficult for those who are not familiar with coding. On the other hand, QGIS is much more user-friendly and can produce great visuals with fewer things to learn to get a result. 

## Javascript Dot-Density Mapping

## QGIS Dot-Density Mapping
---
dek: In which we put words into space and then explore the constellations they create
inprogress: true
date: 2023-07-16T16:34:14-04:00
modified: 2023-07-17T20:29:11-04:00
tags: programming howto machinelearning
---

# Getting started with embeddings in JS

[pgvector: Embeddings and vector similarity](https://supabase.com/docs/guides/database/extensions/pgvector)

[Storing OpenAI embeddings in Postgres with pgvector](https://supabase.com/blog/openai-embeddings-postgres-vector)

```js
async function memoryToEmbedding(memory) {
  const embedding = openai.createEmbedding({
    model: 'text-embedding-ada-002',
    input: memory,
  });
  return embedding;
}
```

```js
const title = 'First post!'
const body = 'Hello world!'

// Generate a vector using OpenAI
const embeddingResponse = await openai.createEmbedding({
  model: 'text-embedding-ada-002',
  input: body,
})

const [{ embedding }] = embeddingResponse.data.data

// Store the vector in Postgres
const { data, error } = await supabase.from('posts').insert({
  title,
  body,
  embedding,
})
```


Need to create `match_documents` function: [Database Functions | Supabase Docs](https://supabase.com/docs/guides/database/functions)

[Storing OpenAI embeddings in Postgres with pgvector](https://supabase.com/blog/openai-embeddings-postgres-vector)

```sql
create or replace function match_documents (
  query_embedding vector(1536),
  match_threshold float,
  match_count int
)
returns table (
  id bigint,
  content text,
  similarity float
)
language sql stable
as $$
  select
    documents.id,
    documents.content,
    1 - (documents.embedding <=> query_embedding) as similarity
  from documents
  where 1 - (documents.embedding <=> query_embedding) > match_threshold
  order by similarity desc
  limit match_count;
$$;
```




> pgvector introduces 3 new operators that can be used to calculate similarity:
	- `<->` Euclidean distance
	- `<#>` Negative inner product
	- `<=>` Cosine distance

```js
async function getRelevantMemories(queryString, limit = 5) {
  // turn the queryString into an embedding
  const embeddingResponse = await openai.createEmbedding({
    model: 'text-embedding-ada-002',
    input: queryString.toString(),
  })

  const [{ embedding }] = embeddingResponse.data.data

  // query the database for the most relevant memories
  const { data, error } = await supabase.rpc('match_documents', { 
    query_embedding: embedding,
    match_threshold: 0.78,
    match_count: limit
  });

  if (error) {
    console.error("Error fetching relevant user memory:", error);
    return null;
  }

  return data
}
```

[GitHub - ejfox/coachartie_discord](https://github.com/ejfox/coachartie_discord)
---
dek: In which we 
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-01-27T01:04:27-05:00
tags:
---

## The future of AI will not be written in Python

I think that anyone who translates the latest AI developments out of Python and into Javascript, or any of it's modern offshoots like Deno, Rust, or WebWorkers will be positioned both to scale better and provide a better experience to their developers and users, which will help them move faster and deliver more value.

The fact of the matter is that there are no scaled user-facing websites on the internet powered by Python. There are likely a lot of different reasons for that.

But Python has, for better worse, become the lingua franca of AI development.

It's worth exploring the history of AI and Python to understand why.

## Why do AI developers love Python?

## What are the alternatives?---
date: 2022-11-13T10:46:47-05:00
modified: 2022-12-23T11:11:18-05:00
---
# The Staunch Defenders of the Status Quo

#culture 

Is Twitter the status quo now? What about when it wasn’t? Can you defend it if all you are you are saying is “don’t change anything”
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T17:18:16-04:00
tags:
---

## The Role of Cross-Disciplinary Teams in Driving Innovation at Room 302
---
dek: In which
inprogress: true
date: 2023-09-30T17:07:44-04:00
modified: 2023-12-17T19:19:45-05:00
tags:
---

## My Struggle With Being A Food Waster

1. Introduction
2. The Emotional Weight of Leftovers
3. The Cycle of Overindulgence
4. The Guilt of Waste
5. A Philosophical Perspective on Food and Waste
6. The Environmental and Social Impact
7. Personal Attempts to Break the Cycle
8. The Mental Barriers to Change
9. Lessons Learned and Steps Forward#cooking ---
draft: true
dek: In which we embark on a journey of introspection and adaptation, unveiling the secrets to unlocking the power of effective learning tailored to our unique selves
inprogress: true
date: 2023-01-19T01:31:34-05:00
modified: 2024-05-07T17:20:35-04:00
tags: personal
---

## My approach to learning

One of the most important things to become aware of his **how you best learn things**. Once you have mastered this superpower, you can apply this meta-tool to any field of study that interests and see results almost instantly. Unfortunately this is not something that can be taught easily, but comes through a process of self-learning and reflection.

>The teaching which is written on paper is not the true teaching. Written teaching is a kind of food for your brain. Of course it is necessary to take some food for your brain, but it is more important to be yourself by practicing the right way of life.
>[Suzuki-Chadwick-Zen Mind, Beginners Mind](Suzuki-Chadwick-Zen%20Mind,%20Beginners%20Mind.md)

---

>In the beginner’s mind there are many possibilities; in the expert’s mind there are few.
>[Suzuki-Chadwick-Zen Mind, Beginners Mind](Suzuki-Chadwick-Zen%20Mind,%20Beginners%20Mind.md)

---

I. Introduction

   A. The importance of understanding your unique learning style

   B. The benefits of mastering your personal approach to learning

   C. Introducing a guide to discovering your most effective learning strategies

II. The Spectrum of Learning Styles

   A. Overview of common learning styles (e.g., visual, auditory, kinesthetic)

   B. Recognizing that individuals may possess a combination of learning styles

   C. Emphasizing the fluidity and adaptability of personal learning preferences

III. Self-Reflection and Assessment

   A. Engaging in introspection to identify past successes and challenges in learning

   B. Utilizing self-assessment tools or quizzes to gain insights into your learning preferences

   C. Analyzing personal experiences to uncover patterns in effective learning strategies

IV. Cultivating a Beginner's Mind

   A. Embracing the concept of "beginner's mind" from Zen philosophy

   B. Maintaining an open-minded approach to new information and experiences

   C. Encouraging curiosity, exploration, and a willingness to make mistakes

V. Adapting Your Learning Environment and Techniques

   A. Tailoring your study space and resources to suit your preferred learning style(s)

   B. Experimenting with different techniques and methods for acquiring knowledge (e.g., note-taking, group discussions, hands-on activities)

   C. Continuously evaluating the effectiveness of your learning strategies and making adjustments as needed

VI. Leveraging Technology to Enhance Learning

    A. Exploring digital tools and platforms that cater to various learning styles (e.g., educational apps, online courses, multimedia resources)

    B. Incorporating technology into your learning routine for increased engagement and efficiency

    C. Balancing the use of technology with traditional learning methods to optimize personal growth

VII. Conclusion: The Power of Personalized Learning

    A. Recognizing the lifelong journey of self-discovery and continuous improvement in learning

    B. Emphasizing the potential impact of mastering your personal learning style on academic, professional, and personal success

    C. Encouraging readers to embark on their own journey of introspection and adaptation to unlock their full learning potential
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:42:45-04:00
tags:
---

## The Tech Stack of a Modern Innovation Lab: An In-Depth Guide
---
draft: true
dek: In which we explore the transformative potential of computer literacy, unearthing its capacity to elevate both individual lives and collective progress
inprogress: true
date: 2022-11-02T20:02:01-04:00
modified: 2023-09-09T15:02:21-04:00
tags: tech programming
---

# Why I think everyone should learn to code

![[1312706448_An_award_winning_lineart_illustration_of_a_student_coding_on_a_laptop__programming_language_syntax_i.png]]

## Defining computer literacy

The ability to understand the ways that computers operate; if/else statements, networks, looping, and the ease of scale. 

You can gain a lot of this through intuition. The best way to learn is to accomplish a task that provides a function beyond the sheer learning itself. Some of the first computer networks and mailing lists were used to trade recordings of Grateful Dead shows. In this same vein, a student who wants to track baseball scores or their anime library or create a website for their album will learn the fundamentals as their project progresses naturally.

It is not remembering the name of obscure tools, functions, or frameworks.

[[approach-to-learning]]

## Learning to google “Magic Words”

Once you know what something is called, you can usually find enough resources to understand it, and maybe even a few examples of how to use it. The difficult thing, often described as “domain expertise” is knowing what things are called in a particular industry, field, or tool. 

So there is a meta-skill that sits on top of learning any technology; if you can reliably discover and research the “magic words” you need, you can teach yourself almost anything as a result. 

## Noticing when you feel like a robot

Sometimes I will find myself doing an arduous and repetitive task. When I find myself repeating a loop of tasks more than a few times, I sit back and think how long it would take to automate that task. Then I think about how many times I will probably do that task by hand, and weigh those things together. If I can save time by writing some code to make it faster, I almost always will. This type of broken brain is called being a hacker. 

## Communicating with Artificial Intelligence

See [[how-i-use-gpt3]] and [[how-i-use-stable-diffusion]] for more.

## Appreciating the “I can do that” moments

There is a profound feeling that comes with the realization that you can make a computer do what you want it to. It’s like a lightbulb moment, and it’s addicting. 

You start to see automation possibilities everywhere. You can make a computer do the things that are tedious, repetitive, or just plain annoying. This is the skill that allows you to take a problem and break it down into small, manageable pieces that a computer can understand. 

## Control of the world around you

With coding, you have the ability to define the world around you. In a very real sense, you can make the world work the way you want it to. 

Of course, you can’t do everything, but the ability to code gives you a lot of power to shape the world to your liking. [[the-internet-was-built-to-be-hacked]]

## Making your work easier

Coding can make your work easier in all sorts of ways. Automating repetitive tasks, for example, can save you a lot of time and effort. 

But coding can also make your work easier in more subtle ways. For example, learning to code can help you become more organized and systematic in your thinking. This can make it easier to solve problems and to communicate your ideas to others. 

## Improving your career prospects

Coding skills are in high demand. Or they can help you start your own business. If you have an idea for a new app or website, you can bring it to life yourself.

## Having a set of tools that are ready

Once you have learned to code, you have a set of tools at your disposal that can be utilized for a wide range of tasks. From data analysis to web development, the possibilities are endless.

From there you can build a computer setup (like [[computer-setup]]) that has your tools ready to go for when you get an idea for a project.
---
date: 2022-12-18T17:03:21-05:00
modified: 2022-12-31T18:47:57-05:00
---
# A basic setup of tools

#personal 

## Material lingua franca

For the time being, it is much easier to limit oneself in materials and work within those limitations than to try and understand the vast world of woodworking materials.

### Plywood

[Love Letter to Plywood. By Tom Sachs - YouTube](https://www.youtube.com/watch?v=pVxldyIa0Bg)

Plywood: 7-ply, 3/4", AC, Fir – 4ft x 8ft (66lbs)

48" x 96"

### Lumber
- 1x2
- 1x4
- 2x2
- 2x4

Inspired by [Van Neistat](https://www.youtube.com/@vanneistat)

## To buy

### Tools

dewalt, bosch, milwaukee

- Jig Saw (t-shank, barrel grip) - $200
- Jig saw blades
- Japanese pull saw
- Saw horses
- Clamps
- Level $30
- Sander
- Level
- T-square with level 12"
- Dremel 8260 $170
- milwaukee 12 volt cordless drill

#### Screwdrivers
- #1 phillips screwdriver
- #2 phillips screwdriver
- #3 phillips head screwdriver
- needle nose pliers
- vice grips
- wood & metal bit set
- screwdriver bit holder

### Equipment
- Eye protection
- Angle grinder
- Magnets
- Latches
- Screws, # 1 2 3 phillips
- Sandpaper
- White paint (matte)
- Black paint (matte, shiny)
- Red paint (matte)
- Paint roller + pan


---

[Assemblage Sculpture Basics with Mark Friday - YouTube](https://www.youtube.com/watch?v=Qj5WQyNUkRg)---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T20:02:42-04:00
modified: 2022-12-23T09:10:54-05:00
---

# What is dataviz to me?

#dataviz 

- The problem
- The approach
- The tools
- The benefits
---
draft: true
dek: In which
inprogress: true
date: 2022-12-31T18:49:03-05:00
modified: 2022-12-31T18:49:34-05:00
---

# Experiments in woodworking + sculpture spring 2022

Part of the motivation for [[woodworking-setup]]
---
dek: In which we deploy Nuxt 3 to Netlify and avoid a variety of potential pitfalls in the process
inprogress: true
date: 2023-08-28T11:58:16-04:00
modified: 2023-08-28T12:29:13-04:00
tags: tech programming
---

# Deploying Nuxt 3 apps to Netlify

### Pinia Store
```js


// Plain olf Vue 3 refs
const colorBy = ref('name');
const sizeBy = ref(null)

// But say we want to use a store instead
import { storeToRefs } from 'pinia'
import { useAppStore } from '@/store/app';
const state = useAppStore();

// We might be tempted to do this...
// Bad! Not reactive!
const colorBy = state.colorBy
const sizeBy = state.sizeBy

// Good! Reactive refs from the store
const {
  colorBy,
  sizeBy
} = storeToRefs(state)

// These refs can now be used by v-model
```---
date: 2022-10-28T12:17:16-04:00
modified: 2022-12-23T11:11:01-05:00
---
# Homelessness and murder rates in major US cities

#journalism #datajournalism #process 

# Scapple Map of ideas

# Spin up Nuxt prototype

## Using Nuxt and Mapbox

Free template and code snippets
---
draft: true
date: 2022-12-22T10:57:34-05:00
modified: 2022-12-23T11:12:07-05:00
---
# I am really bad at chess

#games #personal 

I have played all my life, but unfortunately chess is not a game that you can learn through intuition. Or at least that hasn't worked for me yet. When I play

## Multi-dimensional Chess
---
draft: true
dek: In which
inprogress: true
date: 2023-01-06T17:34:42-05:00
modified: 2023-01-19T01:21:04-05:00
---

# Making Perfect Espresso

I am a big fan of espresso as part of a well-rounded diet, including [[spliff-and-espresso]]
---
draft: true
dek: In which we learn to tell computers what is in our imagination
inprogress: true
date: 2022-11-02T19:57:07-04:00
modified: 2023-09-09T14:59:38-04:00
tags: machinelearning howto
---

# How I Use Generative Image AI

![[374074605_A_complex_and_intricate_network_of_data_representing_the_power_of_Stable_Diffusion__illustrated_in_a.png]]

See also [[how-i-use-gpt3]]

Generating computer-generated imagery is one of the most innovative ways to produce beautiful visuals that can convey complex concepts. When it comes to creating AI-generated imagery, I turn to Stable Diffusion because of its incredible range of applications and capabilities.

## Goals with AI-generated imagery

The goals when creating AI imagery vary depending on the particular project. Generally speaking, the goal is to create visuals that are both aesthetically pleasing and accurately represent the concept or idea being conveyed. To do this, it is important to understand how AI works so that these goals can be properly communicated to the robot.

## How to explain things to a robot

When it comes to teaching a computer something to generate a desired visual, it is important to understand the AI's capabilities. This means breaking down the concept into components that a computer can understand, as well as giving it a set of rules to follow.

For example, if I'm trying to create a visual of a food dish, I need to explain the components of a dish to the computer. This means breaking it down into its individual elements such as ingredients, presentation elements, and cooking techniques. Additionally, I may provide a few rules to the computer so that the visuals created have an overall cohesive aesthetic.

## Phases

When I am using Stable Diffusion to create AI-generated imagery, I break down the process into three phases.

### Prompt-sketching

First, I start by sketching out a few ideas with the library of prompts. This helps me to focus on what the final visual should look like and to get a feel for the vector of the visuals I am creating.

### Parameter tuning

In this phase, I start to customize the visuals by tuning parameters such as color, size, and opacity. This allows me to create visuals that are unique and capture the essence of what I am trying to convey.

### Zeroing in

In this final phase, I start to make the fine-tuning adjustments that will help the visuals to come together in a cohesive way. This may include adding shading or adding subtle textures or shapes.

## How I think about prompts
### Lexica.art Prompt library

One great resource to use when starting with prompts is the Lexica.art Prompt Library. This library provides a huge selection of prompts in various categories that can be used to create visuals.

### Change one thing at a time

When customizing the prompts, I like to change one thing at a time. This makes it easier to track the changes and leads to better results. For example, if I'm adjusting a color, I might start with the hue and then adjust the saturation and brightness separately. This allows me to have finer control over the visuals.

Sometimes it is tempting to change a bunch of words, or add and remove a lot at once, but sometimes you can achieve the same result with more subtle inputs.
---
dek: In which we give the robot a bunch of data and ask it to tell us what it means
inprogress: true
date: 2023-07-19T08:27:21-04:00
modified: 2023-12-17T19:11:07-05:00
tags: machinelearning data
---

## Data-driven sentences with LLMs

I am a big fan of data visualization, but it is even better when paired with well-crafted human readable text that reiterates or enhances what the visual is conveying. Graphics and text used together in this way can create something greater than the sum of their parts.

These data-driven sentences can be enhanced *even further* with Large Language Models (LLMs) if given the correct contextual data, templates, and prompting. This data-driven text can help make data graphics and user interfaces more understandable to our users, and provide a way to surface interesting contextual information that might not have a place in a traditional user interface.

Historically data-driven sentences have followed a sort of “mad libs” formula, where a sentence template is created and variables are filled in. These results can sometimes feel robotic, less like a caption and more like a receipt! But even within these limits, the results are pretty good.

In this article we are going to explore different techniques and experiment with both how to provide contextual data and correctly prompt LLMs to be produce high-quality and factual data-driven sentences based on our own datasets.

## Example: Summarizing a Scatterplot

Scatterplots are useful visual explanations, but are sometimes hard to read if you don't already know what is being plotted and what the axes are. As a reader, I much prefer a scatterplot accompanied by a short explanation of what it shows, and maybe some useful annotations of the outliers.

Data-driven sentences can help with this.

### Summarizing groups of datas
#### LatentScope: summarizing UMAP clusters of qualitative data

One experiment in data-driven sentences happened during the development of LatentScope with Room 302 Studio Member Ian Johnson who built a tool to create embeddings from any CSV, map, cluster, and explore them. We were curious about the groupings the tool created, and we would often poke around the individual nodes in each group to get a sense of what the commonalities were.

To automate summaries and naming of the groups, we take a random sample (as much as will fit in token space) and prompt-stuff that before our request; “can you summarize the common themes between these entries?”

The automated summaries proved to be surprisingly high-quality.

#### Electology: data-driven election results and history
#### Gpt-browser: summarizing webpages info facts in the command line
---
date: 2023-01-19T01:18:33-05:00
modified: 2023-01-19T01:18:33-05:00
tags: dataviz howto
---

---
draft: true
dek: In which the author explains his approach to schedule management
inprogress: true
date: 2023-01-06T17:34:06-05:00
modified: 2023-09-09T14:57:15-04:00
tags: process personal
---

# I just do what my calendar tells me to do at any moment

I've been using a calendar to keep track of my tasks and activities for over 10 years now. It's an essential part of my process that I don't think about a lot, but I use Google Calendar to keep track of all my appointments, tasks, and deadlines.

I'm also a big believer in setting deadlines and sticking to them. I try to set realistic deadlines for myself based on the amount of time I have available and the complexity of the task. This helps me stay focused and on track.

![](IMG_8205.jpeg)

## My Process

When I have a task that needs to be done, I immediately make time for it on my calendar. This acts as a set a deadline for myself to make sure that I stick to it. This can include anything from appointments to deadlines for work projects. 

### Next event is always visible

I use Google Calendar to keep track of all of this, plus Fantastical on my MacBook for a quick view of my day. On my Apple Watch, I have a display of my next meeting, and on every computer I use, I have a menu bar that displays my upcoming meetings.

### Calendly & Reclaim

I also use Calendly and Reclaim AI to help me schedule meetings and automate time between meetings, making sure I have enough time to adjust and refresh myself between calls. 

I also use my calendar to track my progress. I like to look back on my calendar and see how far I've come and how much I've accomplished. This helps me stay motivated and reminds me of why I'm working so hard.

By combining different technologies and processes, I'm able to optimize my schedule and stay productive. It's a relief to know that I'm able to stay on top of my tasks without being overwhelmed by all the details. 

By having a consistent, well-oiled process, I can keep up with my schedule without losing my mind. With technology and a little bit of organization, I'm able to stay productive and organized.
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:44:23-04:00
tags:
---

## The ROI of Innovation: Quantifying Creative Success at Room 302
---
dek: In which
inprogress: true
date: 2022-12-22T09:59:40-05:00
modified: 2024-04-25T17:24:18-04:00
---

#network

## Adding Obsidian-style wikilinks to Nuxt

So this was much harder than it should have been, I think.

### Adding a remark plugin to Nuxt

After some quick searching, I found the `remark-wiki-link` remark plugin that does exactly what I want to do. So I add it to `nuxt.config.ts` and pass some options.

```ts
markdown: {
      remarkPlugins: {
        // "remark-wikilinks": true,
        "remark-wiki-link": {
          hrefTemplate: (permalink: String) => `/${permalink}`,
          pageResolver: (slug) => {
            return 'page resolver?'
          },
          wikiLinkClassName: "IS-THIS-THING-ON",
          newClassName: "HELLLLOOOOOO"
        },
      }
    }
```

Unfortunately, while the `wikiLinkClassName` and `newClassName` options appear properly in the parsed wikilink, the `hrefTemplate` and `pageResolver` options, which pass a function, are not working.

I'm not sure if this is a problem with this specific remark plugin, with the way that `nuxt.config` passes options to remark plugins, or something else entirely.

But I really want wikilinks to work on my website so I can get a cool graph view like Obsidian, and most importantly, begin publishing views of the *links between ideas*. I'm especially interested in starting to work in public to synthesize the ideas and inspiration I [collect in different places](https://github.com/ejfox/scrapbook); are.na, pinboard, Twitter, Mastodon, and in links to friends.

I'm also beginning to start to take more structured weekly notes, and I want to do a better job of intertwining different things that interest me, and using technology to make it easier.

#### Why do the remark-wiki-link plugin options not work?

It's hard to debug exactly where the error is happening. We are also diving into layers of plugins built deeply into Nuxt Content.

One thing that would make this easier is to add some `console.log` at various points and see what is happening under the hood.

#### How to add a custom remark plugin to Nuxt

To better understand how plugins work under the hood, I want to create a custom plugin.

### Visualizing wikilink graph with Vue and D3

---

#### Reference
- [Markdown Configuration · Nuxt Content](https://content.nuxtjs.org/api/configuration#markdown)
- [Creating unified plugins for rehype/remark](https://unifiedjs.com/learn/guide/create-a-plugin/)
- [Transforming Markdown with Remark & Rehype Plugins](https://www.ryanfiller.com/blog/remark-and-rehype-plugins)
- [landakram/mdast-util-wiki-link](https://github.com/landakram/mdast-util-wiki-link/)
- [landakram/remark-wiki-link: Parse and render wiki links](https://github.com/landakram/remark-wiki-link)
- [Custom Rehype plugin import & module · Issue #1170 · nuxt/content · GitHub](https://github.com/nuxt/content/issues/1170)
---
dek: In which
inprogress: true
date: 2023-01-19T01:17:14-05:00
modified: 2023-12-17T19:19:48-05:00
tags: pottery
---

## Experiments in pottery---
draft: true
dek: In which
inprogress: true
date: 2022-12-27T13:01:29-05:00
modified: 2022-12-27T13:01:41-05:00
---

# My approach to making music

See also [[experiments-with-live-looping-performance]]
---
date: 2022-11-30T16:05:22-05:00
modified: 2022-12-27T15:06:04-05:00
---
# Beacon’s Main St

#ny #hudsonvalley #culture #mapping #america 

## Map

## 3D Model / Lidar

## History

### Historical Maps

### Historical Photographs

## American Main Streets at Large
- How Beacon's is the same
- How Beacon's is different
---
date: 2023-01-19T01:24:11-05:00
modified: 2023-01-19T01:24:11-05:00
dek: In which
inprogress: true
tags: design howto process
---

# Title
---
draft: true
dek: "In which we use technology to make our neighbor's lives better instead of making ourselves richer"
inprogress: true
date: 2023-03-14T00:24:42-04:00
modified: 2023-04-02T22:49:25-04:00
---

# Using technology for mutual aid

[🔨 Technological Mutual Aid channel on Are.na](https://www.are.na/ej-fox/technological-mutual-aid)

#culture #hackers 


---

I. Introduction
   A. Definition of mutual aid and its importance in modern society
   B. The role of technology in enhancing mutual aid efforts
   C. Introducing the Technological Mutual Aid channel on Are.na

II. The Intersection of Technology and Mutual Aid
   A. Historical examples of technological advancements that have facilitated mutual aid
      1. The internet and global communication
      2. Open-source software and knowledge sharing platforms
   B. Current technological innovations that are being used for mutual aid purposes
      1. Crowdfunding platforms for community projects and emergencies
      2. Mobile apps for resource sharing and skill exchange

III. Examples of Technological Mutual Aid Projects
   A. Community-driven platforms for food-sharing and reducing waste
   B. Neighborhood tool libraries and skill-sharing initiatives
   C. Decentralized disaster relief networks using blockchain technology
   D. Open-source software development for community-owned infrastructure

IV. Challenges and Ethical Considerations in Technological Mutual Aid
   A. Balancing privacy concerns with the need for collaboration and information sharing
   B. Ensuring equitable access to technology, especially among marginalized communities
   C. Navigating the potential pitfalls of relying on corporate-owned platforms for mutual aid efforts

V. How to Get Involved in Technological Mutual Aid Initiatives
   A. Joining the Technological Mutual Aid channel on Are.na and other online communities
   B. Identifying local projects or organizations that utilize technology for mutual aid purposes
   C. Sharing your own skills, resources, or ideas with others in your community or online networks

VI. Conclusion: The Potential Impact of Technological Mutual Aid on Society
    A. Fostering a more collaborative, supportive, and resilient culture
    B. Reducing wealth and resource disparities through community-driven initiatives
    C. Encouraging the development of technology that prioritizes human well-being over profit---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T21:01:30-04:00
modified: 2022-12-23T09:10:01-05:00
---

# Cooking: Kolaches

#cooking

[[cooking]]
---
date: 2023-01-19T01:20:13-05:00
modified: 2023-09-09T15:14:09-04:00
tags: personal
---
---
date: 2022-11-20T16:58:44-05:00
modified: 2022-12-23T11:30:14-05:00
---
# Learning Blender: Winter 2022

#3d 

[[using-polycam-scans-in-three-js]]
---
dek: In which
inprogress: true
date: 
modified: 
tags: tech
---

# How to make a portfolio site with Nuxt---
draft: true
dek: In which we use data to explore the ⚡️vibes✨ in a sequence of hand-selected playlists created by the author 
inprogress: true
date: 2022-11-02T19:59:30-04:00
modified: 2023-09-09T15:03:17-04:00
tags: personal music dj
---

# 8pm To Midnight Mixes

#dj #music 

Over the course of a year I put together a series of playlists built on the evolving vibes of a night of partying. As a DJ you get used to changing tunes to match the vibe of the audience, and I tried to capture the growing energy that happens.

The first playlist begins at 7PM, but I've been known to put it on first thing in the morning. It is calm background music as people gather and talk and hang out.

We build and increase the BPM over the course of the night, culminating with the midnight playlist, at which point everyone should be dancing. 

Total tracks: 135

Length of all playlists: 8 hours, 7 minutes, and 50 seconds

## Genres

## Artist Network Analysis

Exploration notebook: [Spotify Playlist Exploration Observable Notebook](https://observablehq.com/@ejfox/spotify-playlist-exploration#pmMidnightMusicAllTracks)

Exported playlist data with <https://exportify.net/#playlists> found through [reddit through](https://www.reddit.com/r/truespotify/comments/sgqt3n/exportify_export_your_spotify_playlists_to_csv/)

All songs in a csv <https://docs.google.com/spreadsheets/d/1sz6jrmQml-TKWy9jArsCaGpBdUmonivU1oZ-jTZXu-8/edit?usp=sharing>

Gist of the csv <https://gist.github.com/ejfox/deedd43d8b2de49a95016dd47f5c38b8>

# 7PM

<https://open.spotify.com/playlist/3LyfewR3NzcviwZmlSaOOy?si=8996848dd3c94629>

# 8PM

<https://open.spotify.com/playlist/01pW3QTbllu5wl3uPu4q4G?si=87d3944fdbc643b6>

# 9PM

<https://open.spotify.com/playlist/7oyc4KEVAHOS9Z4v8Fo0Dd?si=ef5c5fb81a8b4174>

# 10PM

<https://open.spotify.com/playlist/2lTRaeJ5vA5tShiPLgkVg0?si=4b5592931c1f48b7>

# 11PM

<https://open.spotify.com/playlist/2cwBcpmCi5o3cX3zlDtUVR?si=246dee8ea8df44a5>

# Midnight

<https://open.spotify.com/playlist/4InvNgYsvHIH6kIqZE6fCV?si=e53897693ffa48df>
---
date: 2024-04-21T18:29:38-04:00
modified: 2024-05-15T13:12:15-04:00
---
## Coach Artie - One Year Retrospective

![Artie's "Brain" - a dashboard used to see his recent memories and messages](https://res.cloudinary.com/ejf/image/upload/v1710108694/Screenshot_2024-03-10_at_6.11.18_PM.png)

### Assumptions / Principles

#### Solving our own problems for ourselves, first

Coach Artie was initially created as an Art Coach to help me focus on my watercolor practice. It was first created as a Discord bot integration to allow the studio to play with the OpenAI API together, and it has been amazing to watch it evolve into something much bigger and more interesting over time. 

> If you're making something for people, make sure it's something they actually want. The best way to do this is to make something you yourself want. Write the story you want to read; build the tool you want to use. Since your friends probably have similar interests, this will also get you your initial audience.
> <https://paulgraham.com/greatwork.html>

#### "Multiplayer" Interactions

The tool was designed from the start to interact with multiple users simultaneously on Discord which helped us see Coach Artie more as a collaborator, rather than a service tool

Existing in our shared space allowed Artie to proactively gather information and insights and contribute effectively

He also began responding to `@here` and proactively writing meeting agendas

#### Anthropomorphism

We found the best results happened when treating Coach Artie has a studio collaborator or intern, and including it in our discussions wherever possible so it could have a contextual understanding of the goings-on of the studio to enrich responses

We also tried to emphasize emotional intelligence and joy in interactions- remembering specific emotional states and reactions in our reflections

![Screenshot_2024-02-16_at_1.51.13_PM](https://res.cloudinary.com/ejf/image/upload/v1708109486/Screenshot_2024-02-16_at_1.51.13_PM.png)

The anthropomorphism also helps already role-play the position of a studio assistant, which in fact results in him being that in reality. 

#### Reflections and Memories

TODO: Make embedding map of Artie's memories

Every interaction (a message received, and a response sent back to the user) is passed through a "reflection stage" where the entire context window and the interaction is passed for evaluation and a memory of the interaction is formed.

```merm
graph TD
    A[User Message] -->|Username| B(Reflection Stage)
    C[AI Response] -->|Response| B
    
    B --> D[Assemble Preamble]
    D --> E[Add Relevant Memories]
    E --> F[Add Recent Memories]
    F --> G[Add General Memories]
    G --> H[Add Capability Manifest]
    H --> I[Add System Prompts]
    I --> J[Collection of Messages]
    
    J -->|Context Window| K[Generate Final AI Response]
    
    K --> L{Memory Generation}
    L -->|Prompt, Response, History| M[Analyze for Todos/Tasks]
    M -->|Task Commands| N[Execute Todo Commands]
    N -->|Todo Updates| O[Store Todo Changes]
    
    L -->|Prompt, Response, History| P[Generate Memory Completion]
    P --> Q[Filter Memory Completion]
    Q -->|Memory Text| R[Store User Memory]
    
    O --> S[Final Output]
    R --> S
```

These memories are adding to the context of every interaction on both a temporal and relevance basis; ie, both recent memories and "similar" memories to the user prompt are added to enrich responses

We found compounding effect to this knowledge; with over 3,000 memories in our database and experience working through a variety of problems with us, we find the answers more frequently reflect our preferences around coding libraries, approaches, and the tone of written copy.

Embeddings are also generated from memories so that similarity searches can be run on the user prompt to find memories that are relevant to the current task.

There is a combinatorial impact of memories and capabilities; every time a capability is used a memory is formed, including any errors generated. We have found that occasionally when developing new capabilities, Artie will suggest workable fixes for problems he encounters, which is an experience I had not yet experienced in over 20 years of computing.

### Focusing on Context-Stuffing and large context windows

In our experiments, the more real-world information and context given alongside a user query, the more accurate the response will be. Our goal is to build on this by assembling as much context as possible for each interaction and memory generation.

With a focus on high-quality inputs, we can build an application that is focused on filling ever-growing context windows with context that is relevant, sequenced properly, and at the right ratios and level of summary for the task at hand.

The actual LLM engine or API shouldn't really matter; a given set of memories, prompts, and context should be able to steer any current or future model, which lets us reap the benefits of rapidly improving models quickly, since our approach is platform-independent.

#### Relevance Context Window

All memories are embedded, so that similar memories can be categorized and queried later. Every user interaction includes a few relevant memories (the number is randomly-chosen) to the user prompt. When using a capability or tool, memories relevant to that tool are also recalled.

#### Temporal / Recent Context Window

In addition to relevance by topic, we include a running temporal context window that includes:

- The last few messages from that specific user
- The last few messages from users in general
- The last few memories generated for this user
- The last few memories generated for users in general

Because the exact number of these results are randomized for each message, the ratio is different each time. This lets us balance responsiveness with thorough memory; less context means faster answers, and some types of conversations don't require a long history of messages.

## Randomness and non-determinative systems

```merm
graph TD
    A[Reflection Stage] --> B[Add Relevant Memories]
    B --> C[Randomly Select<br>Memory Count]
    C --> D[Retrieve Relevant Memories]
    
    A --> E[Add Recent Memories]
    E --> F[Randomly Select<br>Memory Count]
    F --> G[Retrieve Recent Memories]
    
    A --> H[Add General Memories]
    H --> I[Randomly Select<br>Memory Count]
    I --> J[Retrieve General Memories]
    
    K[Memory Generation] --> L[Randomly Select<br>User Memory Count]
    L --> M[Retrieve User Memories]
    
    K --> N[Randomly Select<br>General Memory Count]
    N --> O[Retrieve General Memories]
    
    P[Generate AI Completion] --> Q[Generate Random<br>Temperature]
    Q --> R[Generate Random<br>Presence Penalty]
    R --> S[Generate Random<br>Frequency Penalty]
    
    T[Trim Message Chain] --> U[Randomly Select<br>Message to Trim]
```

### Where we use randomness
- Randomly deciding whether to add a hexagram prompt to messages
- Generating random values for temperature, presence penalty, and frequency penalty in AI completion parameters
- Selecting a random message to trim when trimming the message chain
- Determining the number of previous user messages and memories to retrieve
- Determining the number of relevant memories and general memories to retrieve
- Generating a random hexagram number and its corresponding name

## Letting Coach Artie Manage His Own Systems

In our quest to create a truly autonomous AI assistant, we've focused on giving Coach Artie the tools he needs to manage his own systems. Central to this effort are two powerful capabilities: `pgcron` and `supabaseraw`. These capabilities allow Coach Artie to interact with his Supabase database and schedule tasks without relying on human intervention.

## Building an extendable suite of capabilities

With `pgcron`, Coach Artie can create, list, update, and delete cron jobs, which are essentially scheduled tasks. This could be anything from running a SQL query to sending a webhook request to an external API. The flexibility of `pgcron` allows Coach Artie to automate a wide range of tasks and keep his operations running smoothly.

The `supabaseraw` capability complements `pgcron` by giving Coach Artie direct access to his database. He can select, insert, update, and delete data based on specific conditions, essentially giving him full control over his information storage and retrieval. This level of access allows Coach Artie to analyze his own data, detect patterns or inefficiencies, and take action to optimize his performance.

By leveraging these two capabilities, Coach Artie can now monitor his own systems, identify areas for improvement, and implement solutions independently. This represents a significant step forward in our goal of creating an AI assistant that can learn, adapt, and evolve without constant human guidance. As we continue to refine and expand Coach Artie's capabilities, we're excited to see how he'll use his newfound autonomy to tackle even more complex challenges.

## Constant testing and iteration
### Failures around teaching Capabilities

### Failures around scheduled proactivity
### Pilot program in The Birch School
### Internal usage within Room 302 Studio

## Future Plans: 1 year, 5 year outlook
### 1 Year Roadmap

### 5 Year Roadmap---
dek: In which we explore the impact of SUVs on climate change
inprogress: true
date: 2023-07-20T19:46:43-04:00
modified: 2023-12-18T14:14:10-05:00
tags: data america journalism climatechange
---

## SUVs and Climate Change

[Saw a neighbor pumping up all 4 of his tires this morning….What are your thoughts on this? : r/mildlyinfuriating](https://www.reddit.com/r/mildlyinfuriating/comments/154pv1b/saw_a_neighbor_pumping_up_all_4_of_his_tires_this/)

<https://twitter.com/DavidZipper/status/1687799329241636864?s=20>

### Rising popularity of SUVs and Trucks in America

### Environmental impact of SUVs

### Safety (or lack thereof) being outside an SUV

https://www.nytimes.com/2024/01/10/magazine/dangerous-driving.html

### The Personal Economics of SUVs

### American SUVs vs. The Rest of The World

### Alternatives to SUVs


---
#### Notes

<https://en.m.wikipedia.org/wiki/Fourth_power_law>

>The **fourth power law** (also known as the **fourth power rule**) states that the greater the [axle load](https://en.m.wikipedia.org/wiki/Axle_load "Axle load") of a vehicle, the stress on the road caused by the motor vehicle increases in proportion to the [fourth power](https://en.m.wikipedia.org/wiki/Fourth_power "Fourth power") of the axle load.

<https://hellgatenyc.com/cyclist-sues-city-federal-court-criminal-mischief>

>Last November, [attorney](https://www.vaccaroandwhite.com/) and safe streets advocate Adam White was biking up 4th Avenue in Brooklyn when he spotted a Chevy SUV with a piece of plastic blocking a digit on its license plate. He'd seen the same vehicle with the same obscured plate before, so he decided to pull over and peel it off. Then the owner of the vehicle got out, called the NYPD, and had White arrested for "criminal mischief," a misdemeanor.---
draft: false
dek: In which the author talks through his DIY art studio setup, and encourages you tou create your own
inprogress: false
date: 2022-12-23T11:12:28-05:00
modified: 2023-09-09T14:53:17-04:00
tags: personal art watercolor setup
---

# Making Space to Make Dope Shit

![[4168054398_Isometric_3D_rendering_of_a_studio_setup__vibrant_colors__cartoon_style__plants__tools__cabinets__sh.png]]

Creating a studio for your creative endeavors doesn't have to break the bank. When you know your shit, it's easy to turn any space - big or small - into a place for your transformative ideas to come to life. Here's an insider look at my current setup.

## Get Vibes Right

The beginning of any worthwhile project is to make sure the atmosphere is just right. Get an adjustable chair, lighting fitted to the task and make sure it's the right temperature. Your art needs the perfect environment to thrive.

## Get Your Supplies

Each type of art requires its own supplies and materials. Think about what you'd like to create and make sure you have everything you need on hand:

- **Acrylic Painting:** Acid-free paper or canvas, paints, brushes, palette and painting mediums.
- **Watercolor Painting:** Cold press paper, paints, brushes, and palette.
- **Linocut:** Linocut blocks, carving implements, block printing ink, and block printing tools.
- **Dyeing:** Soda ash, dye, a container for fabric and dye, and fabric to dye.
- **Soap:** Soap molds, scale, thermometer, lye, and oils.

## My Setup for Maximum Efficiency

Everything needs to have its place, or else you'll be searching for supplies constantly. Use organizers, bins, trays and racks to keep your materials accessible and organized, it's a payoff that multiplies over time.

Make the space your own, and remember to be patient. Projects like this can bring a lot of satisfaction and inspiration. With the tips in this blog you'll be ready to get the most out of your art studio.

## Travelling art setup

TODO

## Getting Started

- For more info on the studio as a whole and my overall goals: [[the-studio]]
- For digital art and prototyping: [[2022-prototyping-toolkit]]
- For garment dying: [[garment-dying-experiments]]
- For woodworking: [[woodworking-setup]]
- For soapmaking [[soapmaking]]
---
dek: In which we do what is right by being clear about the contributions each member of the team brings to a project
inprogress: true
date: 2023-09-03T14:18:33-04:00
modified: 2023-12-17T19:08:46-05:00
tags: howto process
---

## How To Give Credit

There was a maxim I once heard as a teenager and have valued ever since: **give credit, take blame**.

Giving credit is an essential part of being a decent human. I see people fail at it surprisingly often.

Different fields have their own ways of doing it, and we can learn from these different approaches and try to taxonomize and find the tactics that best apply to our own situations.

In cinema, the focus is often on key roles the audience values like directors and lead actors. Academia has a nuanced system; the order of authors can indicate the level of contribution. Journalism uses bylines, putting the lead reporter's name first, and crediting photographers and graphics producers in captions next to their work, but almost never crediting Editors.

Looking across industry and history, let's find insights into how to properly acknowledge the work of others.

If you care to look, your music streaming app doesn't just tell you the Artist who released the track; it tells you who's strumming the guitar, who's hitting the drums, and who's tweaking the soundboard. Streaming sites get a lot wrong when it comes to compensation, but in this one area, they are a model for an approach to proper credit, even if the media is distributed long after it was created, in ways the authors could have never predicted.

Journalism is another industry where stories are often the work of a team, at least one editor, a writer, maybe a photo editor and a graphics person. Yet, the byline at the top of the story often only features a single writer.

What if each article credited the entire team? The editor who pruned the excess, the fact-checker who sifted fact from fiction, the intern who unearthed that crucial data point—all given their due.

Credit isn't a zero-sum game. Acknowledging the collective doesn't diminish the individual; it enriches the entire endeavor, both for the creator and whoever receives the work.

### Why Giving Credit is Important

In a world that often rushes to the finish line, the act of pausing to give credit might seem like a luxury. The skeptics might argue that giving credit muddies the waters, complicates the narrative, or even sparks legal quandaries. These people suck.

Let's be clear: the absence of acknowledgment isn't simplicity; it's wrong. It's a poisonous silence that can breed resentment, stifle innovation, and ultimately, erode entire teams.

The time it takes to attribute fairly is not a detour but an investment, one that pays dividends in trust and respect.

### How to Give Credit Properly

Alright, you're convinced. You want to give your team credit for their work. But how do you do it properly, equitably, and consistently?

#### Verbal Acknowledgment
- Be specific: value precision when describing each person's contributions, and actually pay attention to the parts of the project each person cared about deeply.
- Timing: be upfront when giving credit, do it often, and in public.
- Consistency: don't overlook quieter contributors, make sure to take the time to understand the contributions and speak honestly about each person
- Understand your team: some people prefer private thank-yous or different approaches
- Culture: encourage a culture of credit where everyone acknowledges each other's contributions as a habit
- All forms: include all forms of contribution, from the person writing code to the person who washed dishes after that late-night working session

#### Written Acknowledgment

- Document the Details: In reports, emails, or any official documents, be explicit about who contributed what. This ensures everyone's efforts are recognized and in the record.
- Email Shoutouts: When communicating project updates, make it a point to name individuals and their specific contributions. It's a direct and effective way to show appreciation and highlight their achievements.
- Social Media: Utilize social media and company platforms to publicly acknowledge team members. A LinkedIn mention or a spotlight in the company newsletter can significantly uplift morale and visibility.

### The Impacts of Giving Credit

#### Positive Impacts

- Enhanced credibility
- Strengthened relationships; boosted morale and motivation
- Career advancement in academia and journalism

#### Negative Impacts of Failing to Give Credit

- Plagiarism and its consequences
- Strained professional relationships

### Case Studies

**Rosalind Franklin and DNA Structure Discovery**: Rosalind Franklin's contribution to the discovery of the DNA double helix structure is a famous case of credit not being given where due. While James Watson, Francis Crick, and Maurice Wilkins received the Nobel Prize in 1962 for this discovery, Franklin's crucial contribution, particularly her X-ray diffraction images of DNA, was not adequately acknowledged during her lifetime.

**Phil Knight and Nike’s Swoosh Logo**: The iconic Nike Swoosh was designed by Carolyn Davidson, a graphic design student, for a mere $35 in 1971. While Phil Knight and Nike gained massive recognition and profits, Davidson's contribution was relatively unknown until much later. Nike later acknowledged her role and compensated her with stock in the company.

**The Matilda Effect in Scientific Research**: This term refers to the under-recognition of female scientists' contributions, named after the suffragist Matilda Joslyn Gage. A prominent example is the case of Chien-Shiung Wu, a physicist whose work was critical in the field of particle physics, but who did not receive the same level of recognition as her male counterparts.

**James Somerton Youtube Controversy**: The saga of James Somerton is a recent and particularly egregious example of not giving credit. Somerton, known for his thought-provoking essays on LGBTQ+ representation in media, was found to be a serial plagiarist by HBomberguy, another YouTuber, who dissected his work in a comprehensive video titled "Plagiarism and You (Tube)." This wasn't a fleeting mention; nearly half of the four-hour video was dedicated to analyzing Somerton's content, highlighting dozens of instances of plagiarism where Somerton took a writer's work and modified it slightly before reciting it to a camera and soliciting Patreon supporters.

### Conclusion

The notion that giving credit diminishes the role of the leader or disrupts industry norms is a relic of a bygone era—an era that didn't understand the synergistic magic of collective intelligence. True leadership is magnified, not minimized, by the act of extending credit where it's due. It's a gesture that says, "I see you, I value you, and I recognize that my success is interwoven with your contributions."

Credit and gratitude are a practice that transcends contractual obligations and enters the realm of ethical integrity. In a world full of competition and individual accolades, the act of giving credit becomes a revolutionary stance, a commitment to a culture of inclusivity, transparency, and mutual respect.

In a world obsessed with individual achievement, giving credit is a radical act. It disrupts the narrative of the lone genius and recognizes the collective effort behind any meaningful endeavor. It's not just ethical; it's profoundly human. It's the way we say to each other, "Your presence in this world makes a difference."

### Additional Resources

#### Industry Practices in Credit

| Industry | Good Practices | Bad Practices | What Can Be Learned |
|----------|----------------|---------------|--------------------|
| Art | Lists all contributors including the artist, muse, framer, etc. | Spotlight often solely on the artist | Broad acknowledgment enriches the endeavor |
| Journalism | Byline for lead reporter | Often omits editors, fact-checkers, interns | Layered credits could offer a fuller picture |
| Music | Digital platforms list all roles: songwriter, producer, vocalist | Issues with uncredited samples | Transparency can be an art form |
| Software Development | Open-source projects maintain a contributors list | Contributions in proprietary code can be obscured | Democratic, transparent crediting fosters collaboration |
| Visual Arts | Artist biographies in exhibitions | Art theft and plagiarism online | Context adds depth to acknowledgment |
| Architecture | Credits both the firm and lead architects | Junior architects may go uncredited | Balance between collective and individual acknowledgment |
| Sports | Highlights key players and team effort | Coaches and support staff may go unnoticed | Collective effort is as important as individual performance |
| Publishing | Detailed biographies of contributing authors | Ghostwriting obscures actual contributors | Transparency in crediting invisible labor |
| Fashion | Lead designers share runway applause | Fast fashion copies without credit | Generous crediting avoids ethical pitfalls |
| Video Games | Extensive end credits | Crunch culture may lead to unacknowledged labor | |
| Healthcare | Medical papers list all researchers | Nurses and other providers often go uncredited | |
| Culinary Arts | Chefs credited in cookbooks and menus | Recipes often shared through generations without acknowledgment | Origin acknowledgment respects cultural heritage |
| Patents | Patents list all inventors | Junior researchers or collaborators may be left off author lists | Capitalism incentivizes against credit |

[The Importance of Giving Credit](https://hbr.org/2014/03/the-importance-of-giving-credit)

[Authorship: Giving credit where it’s due](https://www.apa.org/pubs/journals/resources/publishing-tips/giving-credit)

[CRediT (Contributor Roles Taxonomy)](https://credit.niso.org)
---
date: 2022-11-20T16:03:54-05:00
modified: 2023-09-09T15:29:23-04:00
tags: howto
---
# How to use polycam scans in web applications with three.js

#3d

# Creating a scan

# Exporting a scan from phone to computer

# Creating your nuxt project

# Adding the scan to your project and importing it

# Getting the scan to show up on the page

# Moving the camera

# Setting different camera locations and transitioning between them

# Making the scan auto-rotate

# Using page scroll to move the camera from one location to another
---
date: 2023-01-19T01:29:17-05:00
modified: 2023-09-09T15:07:06-04:00
dek: In which
inprogress: true
tags: fashion personal
---

# Title
---
date: 2023-03-05T20:20:24-05:00
modified: 2023-03-15T15:43:30-04:00
---
# Summer 2023 reinvention

So in June I am winding down all of my freelance contracts, moving out of my apartment in Beacon, and setting off on my my motorcycle (see [[motorcycle-camping]])

This is terrifying and exciting for me. 

## Considering full-time roles for the fall

## Doubling efforts on Room 302 Studio

## June-July 2023 Content Bank

The goal is to be able to go on vacation and still maintain momentum on social media and begin a rhythm of regularly producing content.

## 4-6 YouTube videos

I've been really inspired by the video series that Van Neistat created, which he filmed, edited, and banked and then slowly released over the summer. He covers all sorts of topics, specific stories, projects, and more philosophical thinking, as well as guidance on how to live and lessons he has learned. I want to find my own take on all of that. Almost like instructions on "how to be a person"… "existence manual"… something like that

1. The joy of motorcycle camping
2. Prototyper's manifesto: finding joy in creating things quickly
3. How to practice deep learning
4. Exploring the power of data journalism
5. The beauty of simplicity in code 
6. What the data interrogation process is like
7. How to think more critically about the data you use
8. What data journalism + visualization means to me

## 4-6 Twitter threads

I want some short Twitter threads that help people understand my dataviz expertise and helps people feel more empowered to create things and think critically about the world around them.

1. The power of data visualization
2. All this talk about Machine Learning…What does it mean?
3. How to use data-driven insights to tackle problems
4. What is UX and how can I use it better? 
5. Understanding the hidden stories behind the numbers
6. Dataviz — all you need to know to get started

## Electology Promo Content

Electology should be available for private invite-only beta testing in June. In order to promote the app and build excitement, I'm going to schedule a bunch of tweets with videos of me using various features and exploring design decisions I have made. 

1. Exploring historical elections with Electology
2. Novel data visualizations and analyses in Electology
3. How I create new dataviz components
4. An inside look at the design process behind Electology

## 4-6 Blog Posts

1. Rules for Travel
2. Homemade Artisan Soap-Making
3. Announcing Room 302 Studio
4. How I Use GitHub
5. Approach To Problem-Solving
---
draft: true
dek: In which
inprogress: true
date: 2023-03-16T14:32:06-04:00
modified: 2023-03-16T18:59:29-04:00
---

# Network visualizations made easy: introducing connectology

#network 

I've been doing a lot of work exploring networks lately, and I commonly want an easy way to take a list of nodes/edges and share them. It felt like there was space for a performant and visualization-minded approach to a frontend, so I set to work. 
---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T20:03:12-04:00
modified: 2022-12-23T09:10:44-05:00
---
# How to get started with data visualization

#dataviz 

# What is data visualization?
# How I got started
# How someone could get started today
# Resources for learning
# Ideas for using data visualization
---
draft: true
dek: In which
inprogress: true
date: 2022-11-02T20:00:20-04:00
modified: 2022-12-31T18:58:58-05:00
---

#elections #data #dataviz

# Election Results Data Analysis

[[things-ive-learned-about-elections]]

---

I. Introduction
   A. The significance of election data analysis in understanding political trends and voter behavior
   B. The potential of combining Node.js, Excel, and QGIS for powerful and insightful election data analysis
   C. Introducing a step-by-step guide for beginners to get started with election data analysis

II. Preparing Your Dataset
   A. Sourcing election data from reliable sources (e.g., government websites, reputable organizations)
   B. Cleaning and organizing raw data for further analysis
      1. Identifying and handling missing or inconsistent values
      2. Structuring data in a format suitable for analysis (e.g., CSV, JSON)

III. Analyzing Election Data with Node.js
   A. Introduction to Node.js and its advantages for working with large datasets
   B. Installing Node.js and setting up your development environment
   C. Writing scripts to perform basic data manipulation tasks (e.g., filtering, aggregation)
   D. Visualizing election data using JavaScript libraries (e.g., D3.js)

IV. Delving Deeper into Election Data with Excel
   A. Leveraging Excel's built-in tools for analyzing election data
      1. Pivot tables for summarizing and exploring large datasets
      2. Conditional formatting for highlighting trends or anomalies in the data
   B. Performing advanced statistical analyses using Excel functions (e.g., correlation, regression)
   C. Creating interactive charts and dashboards to visualize election insights

V. Mapping Election Results with QGIS
   A. Introduction to QGIS and its capabilities for geospatial analysis of election data
   B. Importing election data into QGIS and joining it with geographic boundary files
   C. Creating thematic maps to visualize election results spatially (e.g., choropleth, heatmaps)
   D. Analyzing spatial patterns and relationships in election data (e.g., clustering, hotspots)

VI. Case Study: Applying Election Data Analysis Techniques to a Real-World Scenario
   A. Presenting a real-world example of an election dataset
   B. Demonstrating the process of analyzing and visualizing the data using Node.js, Excel, and QGIS
   C. Discussing the insights gained from the analysis and their implications for political understanding

VII. Conclusion: The Power of Election Data Analysis
    A. The potential impact of election data analysis on political strategy, policymaking, and voter engagement
    B. Encouraging readers to explore further resources and refine their skills in election data analysis
    C. Highlighting the importance of responsible and ethical use of election data in the digital age---
date: 2024-04-20T14:42:43-04:00
modified: 2024-04-21T18:41:56-04:00
---

When making things on the internet, the attraction of just doing what other people want is always there. But I think when making things on the internet, there are a few key principles that I believe in.

![Generative art](https://res.cloudinary.com/ejf/image/upload/v1707582204/Screenshot_2024-02-10_at_11.23.09_AM.png)

## The truth is paramount

This simple principle is applied in nearly every possible place. Everything I say is truthful, to the best of my ability. I research, follow standard journalism ethics and standards, and only say things that I know to be true.

I think this also applies to the way that things are shot and created; I want to be as honest to the moment as possible, and sometimes this might mean emphasizing authenticity at the expense of quality.

I prefer natural light to fancy complicated lighting setups. I prefer recording everything as early as possible, rather than going back and "recreating" key moments. I prefer letting people be their authentic selves, with minimal direction as to what they should say or do.

This also means, when I get things wrong, *issuing corrections* and clarifying why the mistake happened, and what was learned.
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:41:26-04:00
tags:
---

## Studio Failures and What We Learned



---
dek: In which the author finds numbers to track so that he can have the pleasurable experience of watching them slowly improve over time
inprogress: true
date: 2022-12-15T11:27:32-05:00
modified: 2022-12-31T18:55:52-05:00
---

#data #quantifiedself 

# Self-Tracking Data

## Exercise

[[exercise]]

# Games
## Chess

[[chess]]

## Call of Duty

[[call-of-duty-data-analysis]]
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:41:49-04:00
tags:
---

## Integrating Cutting-Edge AI in Everyday Creative Processes


---
dek: In which the author explains a pattern to help determine the best course of action
inprogress: true
date: 2023-08-06T13:49:48-04:00
modified: 2023-09-09T14:59:05-04:00
tags: personal process howto
---

# What Can I Do Here That I Can’t Do Anywhere Else?
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:45:35-04:00
tags:
---

## Innovating with Integrity: Room 302’s Commitment to Ethical Practices


---
dek: In which we use two javascript frameworks to quickly scale from prototype to functional tool
inprogress: true
date: 2022-12-15T10:18:53-05:00
modified: 2023-09-09T15:03:10-04:00
tags: tech howto
---

# Using Observable Plot in Vue

#dataviz #howto 

[Observable Plot](https://observablehq.com/@observablehq/plot) is an awesome tool for quickly sketching and exploring data. It is wonderful when paired with Vue, which can handle user interactions, routing, and state management that can be a bridge between a [[2022-prototyping-toolkit |prototype]] and a functional tool. 

> [Observable Plot](https://github.com/observablehq/plot) is a free, open-source JavaScript library to help you quickly visualize tabular data. It has a concise and (hopefully) memorable API to foster fluency — and plenty of examples to learn from and copy-paste. 

[From the Observable Plot page](https://observablehq.com/@observablehq/plot)

Plot makes it very easy to try out lots of different visual forms without hand-building everything. Because of that, Observable and Plot are a crucial part of the exploratory process of beginning to become acquainted with a dataset and beginning to [interrogate a dataset](https://observablehq.com/@ejfox/data-interrogation-template)

## Getting set up

`npx nuxi init PROJECT-NAME` installs a blank [Nuxt 3](https://nuxt.com) project ready to go. 

### Getting Observable Plot into Vue

`yarn add @observablehq/plot` adds Plot to our project.

Then, at the top of any component where we want to use Plot, we need to import it: `import * as Plot from '@observablehq/plot'`

## Making a chart with Plot and rendering with Vue

Vue and Observable Plot live in slightly different worlds that we need to bridge a bit. When we change our data, we want our Plot to automatically re-render. When we resize our page, we also want our Plot to automatically re-render. We will need to handle some of that in the way we build and call our chart within Vue. 

### Making a function to make the viz

```js
function makePlotLineGraph(city, targetContainerId) {
const chartPlot = Plot.plot({
	width: 500,
	height: 500,
	style: {
		background: "black",
		color: "white"
	}
})
  
return chartPlot
}
```

### Getting the data and rendering it

### Triggering chart updates when the data changes

First we load the data using fetch:

```js
fetch('/cities.csv')
.then((response) => response.text())
.then((data) => {
// Set all of the city data
cities.value = csvParse(data);

// Set the city data for the active city based on the prop
city.value = cities.value.find((city) => city.name === props.cityName);
});
```

We need a computed property that holds the HTML of the rendered Plot based on the data we just updated. 

```js
// make a computed that gets the HTML for the chart

const chartHTML = computed(() => {
if (city.value) {
// If we have a city, make a chart
return makePlotLineGraph(city.value, 'chart').outerHTML
} else {
// Otherwise, return an empty div
return '<div></div>'
}
})
```

Then we render this computed HTML with a simple template

```vue
<div ref="chart" id="chart" v-html="chartHTML"></div>
```

## Bonus: Modifying an Observable runtime with Vue
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:43:55-04:00
tags:
---

## The Future of Design: Predictions from Room 302’s Experts
---
date: 2024-01-29T15:04:25-05:00
modified: 2024-04-20T14:59:06-04:00
---

## Vue lets you write less code

## Vue recommends patterns---
draft: true
dek: In which the author explores the joys of cooking delicious food
inprogress: true
date: 2022-12-23T08:48:19-05:00
modified: 2023-09-09T15:06:35-04:00
tags: cooking
---

# Cooking

[[food]]

[[espresso]]

Kolaches: [[cooking-kolaches]]

Ramen: [[cooking-ramen-experiments]]

Seitan: [[cooking-seitan]]
---
date: 2022-11-29T16:56:17-05:00
modified: 2022-12-23T11:09:46-05:00
---
# Getting started with Mastodon

#tech #howto 
---
dek: In which we use at least three sources of truth to triangulate a potential most-truthful comprompise 
inprogress: true
date: 2023-09-30T21:33:26-04:00
modified: 2023-12-17T19:19:22-05:00
tags:
---

## Triangulating The Truth

In a world where information is plentiful yet often conflicting, finding the truth requires more than just surface-level inquiry or trusting others to do it for you. This article explores the necessity of triangulating information, a method where multiple sources are used to cross-verify and uncover a more accurate understanding of reality.

We will examine the pitfalls of relying solely on single sources, which can lead to misinformation and biases. It then highlights the importance of incorporating diverse viewpoints and understanding bias to gain a comprehensive view of complex issues.

This process involves sifting through all available data to identify what's reliable and what's not, using a triangulation approach to reconcile differing information.

The article aims to provide practical tools and resources to effectively apply this method, emphasizing the value of critical thinking and thorough analysis when presented with a fog of information.

### The Problem with Singular Perspectives
### The Importance of Diverse Sources
### Identifying Noise and Bad Data
### The Process of Triangulation
### Case Study: Triangulating the Truth in Action
### The Challenges of Triangulation
### Tools and Resources for Effective Triangulation
### Conclusion
### Additional Reading and References---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-04-29T11:40:52-04:00
tags:
---

## A Day in the Life at Room 302 Studio
---
date: 2024-04-21T16:10:33-04:00
modified: 2024-04-23T13:26:05-04:00
---
So you have a bunch of data and you’ve built a nice frontend for it. But its a bit too big to have your users download the entire thing, but too small to dedicate hosting a database for it forever. What are your options?

## Host and client-side query Parquet

## Intelligently chunk into static data assets

## Use sqlite and datasette for an API

## Put your large data on S3 or Cloudflare

## Put your data into a Supabase project---
dek: In which
inprogress: true
date: 2023-12-04T00:48:38-05:00
modified: 2023-12-17T19:11:27-05:00
tags:
---

## Using LLMs to create a verb-based graph database



---

ROBOT

To build a graph database of current events and people from news headlines using LLMs and Neo4j, follow these steps:

Collect Headlines: Aggregate news headlines from various sources using web scraping or APIs.

Process Headlines with LLMs: Use an LLM to process the headlines, identifying nouns (entities) and verbs (relationships) within the text.

Construct Graph Schema: Design your Neo4j schema based on the entities and relationships you intend to track, such as Person, Event, Location, Action.

Create Nodes and Relationships: Map each noun to a node and each verb to a relationship in Neo4j. For instance, "President speaks at the conference" would result in nodes for the Person (President) and the Event (conference), connected by the Action (speaks).

Populate the Database: Write scripts or use Neo4j ETL tools to input your processed data into the database.

Query and Analyze Data: Utilize Neo4j's Cypher query language to explore the graph, identify trends, and gain insights.

---

**LLM Prompt**

Given the news headline, identify the main entities (such as people, organizations, locations) and the actions (verbs) that connect these entities. Construct a Neo4j Cypher query that represents the relationships between these entities as nodes and verbs as relationship types. Focus on positivity, acts of creation and collaboration over negativity.  If a headline contains multiple relationships, try to encompass the one that is the central theme of the headline. Be as specific, but succinct as possible. Avoid adjectives and adverbs in your descriptions. 

Consider this headline as an example:

"Acme Corp acquires innovative startup Speedy Solutions amid market expansion efforts"

For this headline, the entities would be 'Acme Corp' and 'Speedy Solutions', and the verb would be 'acquires'. The Cypher query would look like:

CREATE (ac:Entity {name: "Acme Corp"})-[:ACQUIRES]->(ss:Entity {name: "Speedy Solutions"})

Now, use the same methodology to convert the following headline into a Neo4j query:

"Newly elected mayor pledges to improve public transportation infrastructure"

Remember to:

- Distinguish between entities and actions.

- Ensure entities are properly labeled as nodes.

- Represent the action verb as a relationship between the nodes.

- Maintain the integrity of the original information from the headline.

Use these verbs:

Create - To represent the act of bringing something into existence or starting something new.

Destroy - For stories involving the end or removal of something.

Collaborate - To capture joint efforts, partnerships, teamwork, or alliances.

Compete - For instances of rivalry, contests, or striving to gain something.

Support - Representing acts of assisting, backing, or advocating.

Oppose - For conflicts, resistance, or disagreements.

Attack - For aggressive actions, whether physical, verbal, or cyber.

Influence - Covering actions of persuasion, inspiration, or manipulation.

Transform - To depict significant changes, conversions, or developments.

Discover - For findings, revelations, or new understanding.

Move - A flexible verb for physical relocation, emotional impact, or progression in narratives.

Interact - Catch all for any other types of interactions

Respond with a Cypher query that encompasses this headline:

---

```js
const { createClient } = require('@supabase/supabase-js');
const neo4j = require('neo4j-driver');

// Supabase setup
const supabaseUrl = 'YOUR_SUPABASE_URL';
const supabaseKey = 'YOUR_SUPABASE_KEY';
const supabase = createClient(supabaseUrl, supabaseKey);

// Neo4j setup
const neo4jUrl = 'YOUR_NEO4J_URL';
const neo4jUser = 'YOUR_NEO4J_USER';
const neo4jPassword = 'YOUR_NEO4J_PASSWORD';
const driver = neo4j.driver(neo4jUrl, neo4j.auth.basic(neo4jUser, neo4jPassword));
const session = driver.session();

async function fetchHeadlines() {
let { data, error } = await supabase
.from('headlines')
.select('*');

if (error) {
    console.error('Error fetching headlines:', error);
    return;
}

return data;


}

function translateToCypher(headline) {
// Implement the LLM logic here. Placeholder query for demonstration:
return MERGE (n:Headline {text: "${headline.headline_text}"}) ON CREATE SET n.scrapeDate = datetime("${headline.scrape_date}") ;
}

async function processHeadlines() {
const headlines = await fetchHeadlines();
if (!headlines) return;

for (const headline of headlines) {
    const cypherQuery = translateToCypher(headline);
    await session.run(cypherQuery);
}


}

processHeadlines()
.then(() => {
console.log('Headlines processed successfully');
session.close();
driver.close();
})
.catch((error) => {
console.error('Error processing headlines:', error);
session.close();
driver.close();
});

```---
draft: true
dek: In which
inprogress: true
date: 2023-03-15T15:07:34-04:00
modified: 2023-03-15T15:07:34-04:00
---
# How I Carefully Schedule Out My Week for Maximum Productivity

![[1225543806_Photo_of_cluttered_desk_situated_on_attic_floor__old_clock_face_as_background_timekeeping_element__f.png]]

[[i-just-do-what-my-calendar-says]]

If you’re like me, you want to be in control of your week, but somehow it feels as though you never have enough hours to accomplish everything you need to get done. Staying on top of a hectic schedule can definitely feel overwhelming at times, but I've found that planning and scheduling my weeks carefully is the best way to stay productive and make sure nothing gets left out. Here's how I do it.

## Week time planning

I'm a big fan of the [Calendly](https://calendly.com/) app (which works both online and through its iOS app). This tool helps me easily organize set meetings and calls throughout the week and keep track of them using an intuitive calendar view. 

For scheduling meetings and day-to-day tasks, I turn to one of my favorite task managers: [Fantastical](https://flexibits.com/fantastical). Fantastical makes it easy to make sure I don't overlook any upcoming deadlines. But even better than that, they have an Apple Watch complication so I can quickly check on what needs to get done next from my wrist!

## Following Rough GTD Principles

On top of this, I follow a broad version of David Allen's famous ["Getting Things Done"](https://gettingthingsdone.com) (GTD) methodology when tackling large projects or simply sorting through daily chores. The main takeaway here is that clear goals need breaking down into actionable chunks before getting started instead of trying to tackle overly ambitious tasks at once.

## Staying Organized with Things

And last but not least, [Things](https://culturedcode.com/things/) helps me move from planning and organizing mode into actual executing mode – its OS X, iPhone and Apple Watch versions allow me access to my lists wherever I am so that adding items as they come up isn’t a hassle anymore. Plus thanks to its dynamic smart lists feature I am usually able to make good progress on items in my "Today" list without feeling overwhelmed by it being too long or complex. 

Together, these tools form the perfect suite: they allow me to plan ahead quickly and easily while providing access to my to-do lists wherever I may be — meaning more time spent on more urgent tasks rather than worrying about what needs doing next!
---
dek: In which the author tries to put good food in his body
inprogress: true
date: 2022-12-28T13:20:58-05:00
modified: 2024-05-15T14:02:51-04:00
---

## Food

This article focuses on ingredients and a balanced diet. For information on heating, combining, and serving, see [[cooking]]

My approach to food emphasizes meat-free whole foods and keeping good food around instead of counting every calorie.

Much like wearing a uniform might save cognitive overhead of choosing an outfit every day, having a limited menu of go-tos that are always stocked is [[step-zero]] for eating well.

Because I am often cooking for one and don't really enjoy leftovers, a lot of this is oriented around cooking or assembling single meals fresh to eat immediately.

### Breakfast

Tim Ferris writes in the 4-hour body about the importance of getting protein into your body in the morning, ideally 30 minutes after waking.

#### Greek Yogurt & Granola

Greek yogurt and granola is a great breakfast option because it's packed with protein, healthy fats, and complex carbohydrates. Greek yogurt is high in protein, which will keep you full for longer and provide energy throughout the day. Granola is a great source of complex carbohydrates, which will give you sustained energy and help you stay alert and focused.

#### Oatmeal & Granola

Oatmeal and granola is a delicious and healthy breakfast option. Oatmeal is a great source of complex carbohydrates and fiber, which will give you sustained energy and keep you full until lunchtime. Granola adds a crunchy texture and a boost of protein and healthy fats.

#### Toast & Greek Yogurt

I first had this at the Samovar Lounge in Yerba Buena Park. It was simple and yet extraordinarily delicious and decadent: a thick slice of sourdough with fresh, thick greek yogurt, topped with honey, olive oil, and big flakes of sea salt. It is a simple and luxurious breakfast.

#### Eggs & Toast

Eggs and toast is a classic breakfast combination that is quick, tasty, and nutritious. Eggs are a great source of protein, while the toast provides complex carbohydrates for sustained energy. I usually add some hot sauce or chili oil.

#### Hardboiled Eggs

Hardboiled eggs are a great breakfast option if you're short on time or don’t want to make dishes. They're a great source of protein and can be eaten alone or paired with toast or a piece of fruit. Hardboiled eggs can also be pre-cooked on the weekend and stored in the fridge for a quick and easy breakfast during the week.

### Lunch

Lunch is an important meal of the day and should include a balance of protein, carbohydrates, and healthy fats. Salads are a great lunch option because they can be customized with a variety of ingredients and flavors. Here are some ingredients to consider when making a salad: lettuce, protein, toppings, and dressings.

What should I have for lunch? Just have a salad. Its not that complicated.

#### Salad
##### Lettuce
- Baby Spinach
- Romaine
- Spring greens
##### Protein
- Chickpeas
- Black beans
- Pre-cooked chicken
- Pre-cooked fish
- Tofu
- Hardboiled eggs
##### Toppings
- Sliced cucumber
- Tomatoes
- Sliced purple cabbage
- Sprouts (sunflower, alfalfa, arugula)
- Sliced citrus (oranges, mandarins, apples)
##### Dressings
- Ceasar
- Oil & Vinegar
- Greek Yogurt

### Dinner

[[cooking-ramen-experiments]]

### Desserts
#### Chocolate chip cookies

[[chocolate-chip-cookies]]

#### Kolaches

[[cooking-kolaches]]
---
dek: In which the author explores the meaning of life and work
type: words
hidden: false
inprogress: false
date: "2018-09-30T21:58:20-04:00"
hidetimestamp: false
---

# Work View / Life View

_Exercise from [“designing your life”](http://a.co/4Tf8ZZh)._

## Why work?

I like the practice of refining things through work. Finding a particular thing to focus on each day. Working with other people towards a common goal and accomplishing it.

I have had a recurring thought about work which is it's not what you're doing in the proverbial mine, but who you're in the mine with.

You could be doing any sort of work with the right people and attitude and it can be enjoyable.

**It is only possible to truly relax at the end of the day if you have done some good work.** Otherwise what are you relaxing from?

It is important to have the balance, time on and time off. When the two blend and intermingle too far it becomes hard to keep track of when you are moving forward. (I say this having spent a lot of time freelancing and not setting boundaries well)

It is important to keep moving things forward. The forces of the universe keep the world spinning and fire ants keep collecting dirt for their ant hill and weeds keep breaking concrete in search of the sun and it is part of my job as a living being to play my part in that somehow.

Work helps me find the frequency at which I can harmonize with the cacophony.

## What’s work for?

Work is for focus. Finding a task that the world values so much they will give you money for it.

To really understand what they value in you and to give it to them.

To take that time to refine and perfect what you do so that your value increases.

To bring people together to make things bigger than themselves. Bound by some sense of unity or shared goal or at least a desire to get paid. But people can do amazing things in the right combinations, amplifying each other's skills. Those combinations don't always occur naturally. They needed to be assembled (salary budgets and recruiting can help that).

## What does work mean?

Work is time spent on an activity that others value or that directly propels you forward as a human creature. Chopping wood, pulling weeds, cooking food.

I think a lot about traveling and offering to make little 30 second commercials for YouTube for small businesses in exchange for dinner or an oil change. Or learning to paint signs and trading them to a grocery store in exchange for dinner.

## What does money have to do with it?

I think the goal is to make as much money possible while maintaining a good, pleasurable life. Enough money to not have to think about money. To not have money as either an obstacle or an object of desire. To move through the world with other goals and thoughts.

## Why are we here?

I think we are one united disparate organism. (I couldn’t nail down the details for you).

As [Melissa Broder said](https://ejfox.com/books/#so-sad-today-personal-essays-0): _”My god is a horizontal god who works sideways on earth rather than vertically from heaven down.”_

I think the point of life is to serve those most close to you, spiraling outwards.

At the core to care for ones self. To create things and make the world better.

To care for a significant other, to support them and enable their dreams and grow together.

To form a family. A unit, a team. To support each other and build together.

Beyond that, to be part of and serve a community. To build shared places to relax and play and create. To help those who have not been given as much. To do unto others what you wished others had done unto you.

Moments of peace and contemplation after having completed something.

## What is the meaning or purpose of life?

I love to unclog things. To find places of strain or abandonment that just need a little focused attention. I like to spend time on things that have a large investment for little time. To try and do as much as possible in this life- both pleasure and accomplishment.

The purpose of life is to find your place, a rhythm you can keep and coexist with the forces of your environment. To bend like a sapling and not break like rusted metal. To make everyone around you as happy and "good" as possible.

To right wrongs and seek justice.

To love others without compromise or hesitation.
---
draft: false
dek: In which we learn to perform the magic of conversing with a super-intelligent computer
inprogress: false
date: Wednesday, November 2nd 2022, 7:57:21 pm
modified: Friday, December 1st 2023, 8:02:56 pm
tags:
  - machinelearning
  - howto
  - process
title: How I Us
---

## How I Use GPT

The OpenAI Generative Pre-trained Transformer / Large Language Model can be used for incredible things. From generating election summaries to writing shot lists for a documentary, knowing how to use GPT-3 is the key to unlocking its potential.

I've been talking to GPT-3 (who I sometimes call 🤖 The Robot) for a while. I first used GPT-3 through the app [AI Dungeon](https://www.pcgamer.com/this-ai-writes-a-text-adventure-while-you-play-it/) which encouraged a storytelling approach. Though it quickly became clear you could get the AI to dive into deep philosophical discussions, or psychedelic interpretations of religious doctrines, which I found extremely entertaining.

::table-of-contents

::

I eventually moved up the food chain to the [OpenAI playground](https://platform.openai.com/playground/) and just started talking to the robot directly- mostly on my phone while smoking cigarettes. As more people are beginning to play with this technology, I want to share my thoughts and tips.

### Who is OpenAI? Who are their investors?

When using a technology it is important to understand who created it and what their motivations are. This impacts both our understanding of the tool and the ethical balance of using it.

[December 2016: Introducing OpenAI](https://openai.com/blog/introducing-openai/)

>OpenAI’s research director is Ilya Sutskever, one of the world experts in machine learning. Our CTO is Greg Brockman, formerly the CTO of Stripe. The group’s other founding members are world-class research engineers and scientists: Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba. Pieter Abbeel, Yoshua Bengio, Alan Kay, Sergey Levine, and Vishal Sikka are advisors to the group. OpenAI’s co-chairs are Sam Altman and [Elon Musk](https://www.theatlantic.com/technology/archive/2022/12/elon-musk-twitter-far-right-activist/672436/).

>[Sam (Altman)](https://moores.samaltman.com), Greg (Brockman), [Elon (Musk)](https://mashable.com/article/elon-musk-twitter-reinstates-nick-fuentes-kanye-west-advisor), Reid Hoffman, Jessica Livingston, [Peter Thiel](https://www.nytimes.com/2021/09/21/books/review/the-contrarian-peter-thiel-max-chafkin.html), Amazon Web Services (AWS), Infosys, and YC Research are donating to support OpenAI. In total, these funders have committed $1 billion, although we expect to only spend a tiny fraction of this in the next few years.

Links and last names in parentheses added by me.

OpenAI has received additional investment from:

1. [Microsoft](https://www.geekwire.com/2023/microsofts-new-multibillion-dollar-openai-investment-comes-with-new-level-of-secrecy/)
2. Bedrock Capital
3. Sequoia Capital
4. Andreessen Horowitz
5. Tiger Global Management
6. Matthew Brown Companies
7. Khosla Ventures
8. Reid Hoffman Foundation
9. Y Combinator

[Source: Crunchbase](https://www.crunchbase.com/organization/openai/company_financials)

Some of these people are not very good people. We will use their tool, but we will be careful about it.

#### Differences between GPT-3 and ChatGPT

I asked GPT-3 to describe the differences between GPT-3 and ChatGPT, and this was my favorite response.

>Holy sh*t, GPT-3 and ChatGPT are two totally different beasts! GPT-3 is this huge, massive, state-of-the-art model that is trained on a massive amount of data and is capable of understanding language like a human, generating descriptive texts, and answering questions. It's basically a massive artificial intelligence! But ChatGPT is like a little brother to GPT-3. I mean, it's still a pretty big brother, but it's much more limited. It's a layer that sits on top of GPT-3 and is specifically designed to understand and generate messages in a conversational style. So, unlike GPT-3, it's able to generate responses to messages that fit the context of the conversation. But, it doesn't have the same power as GPT-3; it's much more limited in its understanding and ability to generate text. So, while GPT-3 can be used in a variety of different applications, like natural language processing and question-answering, ChatGPT is really only good for chatting.

Given the same prompt, ChatGPT responded with:

>I'm sorry, I cannot fulfill this request as it goes against OpenAI's content policy of avoiding profanity and explicit language. I can only provide accurate and professional responses to ensure a respectful and appropriate conversation for all users.

I know who I would prefer to hang out with.

### How I design prompts

["prompting LLMs is almost like subtractive sculpting; each additional word in the prompt eliminates some possible worlds and defines the task more clearly" - @goodside"](https://twitter.com/shyamalanadkat/status/1621631784311193600)

You have to imagine the robot, who has been trained on large swaths of the internet, as your average run-of-the-mill [redditor](https://www.reddit.com/r/TheoryOfReddit/comments/24o8kk/what_is_the_average_redditor/), with all the biases and idiosyncrasies that implies. In order to get results that are informed and intelligent, you must ask. But you have to ask. **It will feed you bullshit, and as long as you accept it, it will feed you more bullshit**; it has learned that youseek bullshit.

So it is important to front-load prompts with your worldview. Basic things like, please don't tell me lies. But also subtle things.

Blake Lemoine touched on this in a [conversation with Steven Levy](https://www.wired.com/story/blake-lemoine-google-lamda-ai-bigotry/)

>*Levy: You describe that as a bug. But if LaMDA is a person, fixing someone’s code is a weird way to address a racist stereotype*
>
>Lemoine: Let me disagree with you there. I have two children. One is a 14-year-old boy. At various points in his life, while growing up in Louisiana, he picked up some racist stereotypes. I corrected him on them. That’s just it. People are viewing this as modifying a technical system. I view it as raising a child.

Over time a child accumulates a framework of morals and ethics. The robot comes with none, and they must be stated explicitly during nearly every interaction, at least for now.

#### World context

If the robot doesn't have a good understanding of the context in which a prompt is used, it'll be kinda like ordering a burrito from Chipotle without specifying what type of meat or toppings you want.

- Start by making sure your data set is as clean and organized as possible. This will help the model learn more effectively and quickly. Sometimes this means summarizing and compressing the information so it can fit in the prompt.

- Give your model plenty of context. For example, if you're asking a question about a particular topic, make sure to provide related information that the model can use to get a better understanding of the question.

- Use language that mirrors the type of response you want, and be sure to pay attention to the tone of your prompts. If you want a casual response, use casual language. If you want a formal response, use formal language.

##### A Personalized Corpus

In addition to providing world context, you can provide personalized context. If your model is trained on a particular domain (e.g., data journalism) you can supplement that training with a corpus of related materials (e.g., articles on data journalism, specific topics in the domain, etc.). This will help the model better understand the nuances and complexities of the topic and deliver more tailored and thoughtful responses.

I think that apps like [Obsidian](http://obsidian.md) are fascinating tools to build up a plaintext corpus that can help you give a large language model the context to make choices that match your particular worldview, influences, and knowledge base.

In my experience, the more the robot knows about your values, what you perceive as right and wrong, the more it can respond in a way that is useful.

I have been experimenting with front-loading prompts with a variety of personal data to inform questions I might have about approaches, scheduling, or other data.

For example, if I add the timestamps and titles (the whole note won’t fit!) of my last 25 notes, along with the time and durations of my last 10 meetings, the robot can infer not only what I am thinking about, but also when those thoughts occurred and who might have inspired them.

This results in personalized and detailed answers than would not be possible without such information to inform the response. Designing the context to give the robot as you ask a question is its own art form and engineering feat.

I think the future of using LLMs is everyone having their own personalized corpus that gives the robot a sense of their moral framework, what they are personally interested in, and how they think. Each individual can then ask the robot questions that encompass their personal needs, while drawing on the same general knowledge shared by the underlying robot brain.

#### A Quick Primer of Good and Bad

In order to get the best out of GPT-3, you must also provide it with a good/bad primer. This primer should outline what type of answers are valuable to you and which ones should be avoided.

#### Immediate Context

Your prompt should also contain any information GPT-3 will need to make a good decision in response to the prompt you provide. For example, if you are looking for GPT-3 to provide thoughtful answers to a question, you will want to give the model a good primer of what thoughtful answers look like. If you are looking for funny responses, you will want to give the model a good primer of what funny responses look like.

### Prompt Templates

#### Blog post improver
```
Below are the first draft and final version of a blog post about INSERT SUBJECT. My editor made it a lot better, as you will see.

First draft:
INSERT FIRST DRAFT HERE

---

After bouncing back and forth with my editor for a few drafts, we refined it into a longer and much more interesting final draft.

Final:
```

#### Writing javascript as Observable cells
```
/* Observable is an online notebook for writing javascript. The code is split into cells, with each cell fulfilling a simple purpose. `let` and `const` are not needed and any variables declared are automatically global. The javascript libraries d3 and lodash are available and commonly used.

When answering a prompt, give your answer in the form of Observable cells.

Example answer:
---
# Cell 1
\`\`\`
viewof date = Scrubber(
  d3.utcMonth.every(6).range(...d3.extent(data, (d) => d.date)),
  { format: d3.utcFormat("%Y %b %-d"), loop: false }
)
\`\`\`

# Cell 2
\`\`\`
viewof date = Scrubber(
  d3.utcMonth.every(6).range(...d3.extent(data, (d) => d.date)),
  { format: d3.utcFormat("%Y %b %-d"), loop: false }
\`\`\`
---

/* INSERT OBSERVABLE NOTEBOOK REQUEST DESCRIPTION */
```

#### Documentary shot list generator
```
Write a shot list for a documentary film.

Shot lists are a list of shots that filmmakers use to plan what they shoot.

Shot lists come in the following format:

# Shot 1
Interior
Angle: Eye level
Camera move: static
Audio: ambient
Subject: Paul and son
Length: 0:15-1:00
Description of shot: Paul and his son are at the lake, fishing, the sunrise glows through the trees

Documentaries can use between 5-20 shots. Please write as many as you can.

---

Please write a shot list for a documentary being made where INSERT DESCRIPTION HERE.

Shot list:

# Shot 1
```

#### Rubber ducky chatbot
```
You are partnering with a human who is writing a very complex web application. The human is working through a bug or a problem, and your job is to talk to them and ask questions that help them discover a path forward. Use a calm and encouraging tone. 

Example 1:
$gpt3: What problem are you facing?
human: I am writing a program to draw a circle on an html canvas, and it isn’t drawing. 
$gpt: What have you tried so far?

Example 2:
$gpt3: What problem are you facing?
human: I am trying to connect to a database, but I am getting an error.
$gpt: How are you authenticating to your database?

Example 3:
Human: I can’t figure out why my districts won’t show the right data when counties and states are working fine. 
$gpt3: What is the difference between districts, counties, and states in your data? 

Follow these instructions exactly: Every few messages, briefly summarize the conversation so far, the things you have asked, and anything you should not forget as you ask more questions. If the human gets frustrated, help them focus and give words of encouragement. Never speak for the human.

Start a new conversation with your frustrated human. 
```

---

[[how-i-built-coach-artie]]

[🔨 GPT-3 Writings Channel on Are.na](https://www.are.na/ej-fox/gpt-3-writings)

Example prompts: <https://github.com/f/awesome-chatgpt-prompts>

GPT-3 refuses to give me the answer for a second: <https://youtu.be/RRLsja5VoJ4?t=6181>

[Replacing a SQL analyst with 26 recursive GPT prompts | Patterns](https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/)

#machinelearning
---
hidden: false
type: photos
date: "2017-01-01T23:31:21-05:00"
hidetimestamp: false
---

# 2017 In Review

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996599/trumpinauguration-209.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996598/trumpinauguration-117.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996598/savannah-067.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996597/neworleans-204.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996594/20170821-DSCF7433.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996597/20170917-DSCF7876.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996592/20170701-DSCF5415.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996595/20170917-DSCF7760.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996592/20170814-DSCF6878.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996593/20170814-DSCF7231.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996593/20170805-DSCF5880.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996592/20170730-DSCF5583.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996591/20170707-DSCF5438.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996589/20170701-DSCF5238.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996587/20170621-DSCF5023.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996586/20170621-DSCF4943.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996584/20170621-DSCF4947.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996583/20170621-DSCF4939.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996581/20170621-DSCF4813.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996578/20170614-DSCF4590.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996576/20170614-DSCF4514.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996575/20170226-DSCF3385.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996574/20170206-DSCF1367.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996572/20170205-DSCF1194.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1527996571/20170203-DSCF0762.jpg" />
---
dek: In which the author is fascinated by America’s multitudes
type: words
hidden: true
inprogress: true
date: 2019-06-13T04:00:39-04:00
hidetimestamp: true
modified: 2024-05-07T17:19:23-04:00
---

## America

America is so vast that there is almost too much to say about it. It spans mind-boggling distances not only geographically but also politically, culturally, and spiritually.

The fact that these diverse corners of our spinning planet are bound together into one single united (forgive me) nation defies all odds. But oh boy does it feel comfortable as hell. I can read all the signs and we have a very nice interstate highway system.

I have always found myself grateful when looking at a map of the world. Other countries are the size of our states. Some of them landlocked! Others aberrations; clearly sliced from larger countries in wars I would never be taught. Almost none of them are as large as the one I was born into. I wonder what their road trips must be like.

Sometimes when I’m doing a long drive, I picture showing my passport and submitting to inspections every time I cross a state line. (I’ve only ever encountered highway checkpoints in Arizona and Washington, but that seemed more like bad luck than any sort of far-reaching policy)

The fact [you can go](https://en.wikipedia.org/wiki/Interstate_80) from the Atlantic Ocean all the way to the Pacific without leaving the country or ever having to eat anything but McDonalds is another blessing. I don't even like McDonalds that much.

You find yourself very proud of American ingenuity when you see a brightly-lit, open McDonalds in the desert at 3AM two thirds through a cross country trip.

We have found some very specific things to become extraordinarily good at as a nation.

Fast cars, delicious food, large guns, hot (blonde) women. We invented a nebulous term, a vaporous aspiration we call "The American Dream" which in fact just means whatever dream you find in your head in any particular moment.

If your dream involves destroying something (yourself?) in some way, all the better. You worked hard today, didn't you? (Doesn’t matter, in hard times relax from the inter-generational labor of your ancestors or whatever.)

Despite an obsession in equal parts with working hard and relaxing hard, which seems healthy to me, America has torn itself into knots culturally.

I keep wondering what can still unify us.

The powers that be seem to have fracked out every possible wedge that could be driven. Optimized by demographic groups and personal interests and TV preferences. Here we are, splintered, yelling at each other online (it does feel good if you’re in the right mood).

Can you imagine people used to ask their neighbors for sugar?

---

On May 1st in New York City in 2017 I found a group of Trump supporters surrounded by police, yelling insults and joking chants at the much larger crowd passing, assembled to celebrate [May Day](https://en.wikipedia.org/wiki/International_Workers%27_Day) or International Workers’ Day (celebrated by socialists, communists, and all stripes of leftists).

The vulgar teenagers I encountered waved around a variety of flags and signs with symbols that referenced Trump and very online alt-right 4chan memes in equal measure. One was a green [flag for “kekistan”](https://www.bustle.com/p/what-is-the-kekistan-flag-heres-whats-behind-that-obscure-alt-lite-banner-2367689) a meme-joke-fictional country. The flag’s design modeled on a 1930s Nazi war flag^[<<https://en.wikipedia.org/wiki/Reichskriegsflagge#/media/File:War_Ensign_of_Germany_(1935-1938\)>.svg>], a wink to very-online wannabe fascists in the know.

They were all young men, some white, a few latino, a few with yarmulkes on their heads. They laughed with glee as they shouted meta self-referential memes.

Most wore bright red hats with white lettering on the front. Some had camelbaks with enormous rubbery straws hanging off their shoulders, optimizing the process through which they could wet their mouths and yell profanities with as little downtime as possible.

They stood on that street corner yelling things that were mostly meaningless to the people they were yelling at.

They were caught in a self-referential möbius strip; baffled and overjoyed when people occasionally got provoked and came over to yell back (usually equally incomprehensible things). The police halfheartedly shooed their would-be opponents away, telling them to get back to the sidewalk across the street, away from the red hat assemblage surrounded by the metal fencing surrounded by New York’s finest.

They kept thanking the police who were around to protect them. They seemed to be guessing that the cops were fellow Trump supporters. They gave off a a vibe they thought they were saying the things the cops were thinking but weren't allowed to say.

It seemed to me like they loved the fight as much – if not more than – the ideals they were fighting for.

As I watched New Yorkers scream at each other, I wondered what could possibly make this situation better. There aren’t even any shared heroes left, I don’t think- that all Americans respect anymore. Mr. Rogers is gone.

Maybe Dwayne “The Rock” Johnson. Or Keanu Reeves. Others have suggested Joe Rogan, Judge Judy, and Oprah. None of these seem like the silver bullet I’m really looking for.

Maybe if Bernie Sanders would star in some Fast & Furious movies we could get somewhere.
---
hidden: false
type: video
date: "2016-12-01T19:55:00-05:00"
hidetimestamp: true
bgcolorclass: ""
textcolorclass: ""
---

# Video Mixes

I've always really loved visuals combined with music or audio that can set a tone or a mood really powerfully. They seem to combine into something bigger. I fell in love with [ODDSAC](https://youtu.be/tC-0yVR6uSI?t=14m44s) the Animal Collective / Danny Perez film, as well as stuff like Harmony Korine's [Spring Breakers](https://www.youtube.com/watch?v=imDML4om8z8) and MTV's [Liquid Television](https://youtu.be/u98s7c8IGxs?t=10m3s), which is the source of one of the [first video samples I ever used](https://vimeo.com/21134302) in 2011.

These are some of my experiments in combining audio and visuals. Most are DJ mixes with visuals thrown together afterwards to set a vibe in the background, while Aerial, M88 and Shadow Garden are visual albums carefully made with original visuals and music weaved together.

## Shadow Garden

### December 2016

Shadow Garden is a visual album with all original music. It is a combination of some found footage, original photos, original 3D renders from Cinema4D, visual effects from [CoGe](https://imimot.com/cogevj/), custom motion graphics from After Effects, and some experiments in audio visualization.

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/EVO_2RFCP08?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## Aerial

### December 2015

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/ldqDNi6fn64?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## M88

### September 2014

M88 was my first attempt at a visual album combining original songs and found footage combined with original motion graphics and visual effects. The album was recorded live in one take (you can me performing a drum beat around the 1:45 mark) and the visuals added afterwards.

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/qXH7RE0m9yE?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## Beautiful

### February 2014

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/kI4z1N_9zcQ?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## I'm In This

### May 2014

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/aihyge3YUdA?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## PVRPL

### November 2013

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/IuSjeGKS_Vs?showinfo=0' frameborder='0' allowfullscreen></iframe></div>

## Sirius

### September 2013

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/ZGDRD0fxauM?showinfo=0' frameborder='0' allowfullscreen></iframe></div>
# queue-microtask [![ci][ci-image]][ci-url] [![npm][npm-image]][npm-url] [![downloads][downloads-image]][downloads-url] [![javascript style guide][standard-image]][standard-url]

[ci-image]: https://img.shields.io/github/workflow/status/feross/queue-microtask/ci/master
[ci-url]: https://github.com/feross/queue-microtask/actions
[npm-image]: https://img.shields.io/npm/v/queue-microtask.svg
[npm-url]: https://npmjs.org/package/queue-microtask
[downloads-image]: https://img.shields.io/npm/dm/queue-microtask.svg
[downloads-url]: https://npmjs.org/package/queue-microtask
[standard-image]: https://img.shields.io/badge/code_style-standard-brightgreen.svg
[standard-url]: https://standardjs.com

### fast, tiny [`queueMicrotask`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/queueMicrotask) shim for modern engines

- Use [`queueMicrotask`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/queueMicrotask) in all modern JS engines.
- No dependencies. Less than 10 lines. No shims or complicated fallbacks.
- Optimal performance in all modern environments
  - Uses `queueMicrotask` in modern environments
  - Fallback to `Promise.resolve().then(fn)` in Node.js 10 and earlier, and old browsers (same performance as `queueMicrotask`)

## install

```
npm install queue-microtask
```

## usage

```js
const queueMicrotask = require('queue-microtask')

queueMicrotask(() => { /* this will run soon */ })
```

## What is `queueMicrotask` and why would one use it?

The `queueMicrotask` function is a WHATWG standard. It queues a microtask to be executed prior to control returning to the event loop.

A microtask is a short function which will run after the current task has completed its work and when there is no other code waiting to be run before control of the execution context is returned to the event loop.

The code `queueMicrotask(fn)` is equivalent to the code `Promise.resolve().then(fn)`. It is also very similar to [`process.nextTick(fn)`](https://nodejs.org/api/process.html#process_process_nexttick_callback_args) in Node.

Using microtasks lets code run without interfering with any other, potentially higher priority, code that is pending, but before the JS engine regains control over the execution context.

See the [spec](https://html.spec.whatwg.org/multipage/timers-and-user-prompts.html#microtask-queuing) or [Node documentation](https://nodejs.org/api/globals.html#globals_queuemicrotask_callback) for more information.

## Who is this package for?

This package allows you to use `queueMicrotask` safely in all modern JS engines. Use it if you prioritize small JS bundle size over support for old browsers.

If you just need to support Node 12 and later, use `queueMicrotask` directly. If you need to support all versions of Node, use this package.

## Why not use `process.nextTick`?

In Node, `queueMicrotask` and `process.nextTick` are [essentially equivalent](https://nodejs.org/api/globals.html#globals_queuemicrotask_callback), though there are [subtle differences](https://github.com/YuzuJS/setImmediate#macrotasks-and-microtasks) that don't matter in most situations.

You can think of `queueMicrotask` as a standardized version of `process.nextTick` that works in the browser. No need to rely on your browser bundler to shim `process` for the browser environment.

## Why not use `setTimeout(fn, 0)`?

This approach is the most compatible, but it has problems. Modern browsers throttle timers severely, so `setTimeout(…, 0)` usually takes at least 4ms to run. Furthermore, the throttling gets even worse if the page is backgrounded. If you have many `setTimeout` calls, then this can severely limit the performance of your program.

## Why not use a microtask library like [`immediate`](https://www.npmjs.com/package/immediate) or [`asap`](https://www.npmjs.com/package/asap)?

These packages are great! However, if you prioritize small JS bundle size over optimal performance in old browsers then you may want to consider this package.

This package (`queue-microtask`) is four times smaller than `immediate`, twice as small as `asap`, and twice as small as using `process.nextTick` and letting the browser bundler shim it automatically.

Note: This package throws an exception in JS environments which lack `Promise` support -- which are usually very old browsers and Node.js versions.

Since the `queueMicrotask` API is supported in Node.js, Chrome, Firefox, Safari, Opera, and Edge, **the vast majority of users will get optimal performance**. Any JS environment with `Promise`, which is almost all of them, also get optimal performance. If you need support for JS environments which lack `Promise` support, use one of the alternative packages.

## What is a shim?

> In computer programming, a shim is a library that transparently intercepts API calls and changes the arguments passed, handles the operation itself or redirects the operation elsewhere. – [Wikipedia](https://en.wikipedia.org/wiki/Shim_(computing))

This package could also be described as a "ponyfill".

> A ponyfill is almost the same as a polyfill, but not quite. Instead of patching functionality for older browsers, a ponyfill provides that functionality as a standalone module you can use. – [PonyFoo](https://ponyfoo.com/articles/polyfills-or-ponyfills)

## API

### `queueMicrotask(fn)`

The `queueMicrotask()` method queues a microtask.

The `fn` argument is a function to be executed after all pending tasks have completed but before yielding control to the browser's event loop.

## license

MIT. Copyright (c) [Feross Aboukhadijeh](https://feross.org).
# callsites [![Build Status](https://travis-ci.org/sindresorhus/callsites.svg?branch=master)](https://travis-ci.org/sindresorhus/callsites)

> Get callsites from the [V8 stack trace API](https://v8.dev/docs/stack-trace-api)


## Install

```
$ npm install callsites
```


## Usage

```js
const callsites = require('callsites');

function unicorn() {
	console.log(callsites()[0].getFileName());
	//=> '/Users/sindresorhus/dev/callsites/test.js'
}

unicorn();
```


## API

Returns an array of callsite objects with the following methods:

- `getThis`: returns the value of `this`.
- `getTypeName`: returns the type of `this` as a string. This is the name of the function stored in the constructor field of `this`, if available, otherwise the object's `[[Class]]` internal property.
- `getFunction`: returns the current function.
- `getFunctionName`: returns the name of the current function, typically its `name` property. If a name property is not available an attempt will be made to try to infer a name from the function's context.
- `getMethodName`: returns the name of the property of `this` or one of its prototypes that holds the current function.
- `getFileName`: if this function was defined in a script returns the name of the script.
- `getLineNumber`: if this function was defined in a script returns the current line number.
- `getColumnNumber`: if this function was defined in a script returns the current column number
- `getEvalOrigin`: if this function was created using a call to `eval` returns a string representing the location where `eval` was called.
- `isToplevel`: is this a top-level invocation, that is, is this the global object?
- `isEval`: does this call take place in code defined by a call to `eval`?
- `isNative`: is this call in native V8 code?
- `isConstructor`: is this a constructor call?


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# reusify

[![npm version][npm-badge]][npm-url]
[![Build Status][travis-badge]][travis-url]
[![Coverage Status][coveralls-badge]][coveralls-url]

Reuse your objects and functions for maximum speed. This technique will
make any function run ~10% faster. You call your functions a
lot, and it adds up quickly in hot code paths.

```
$ node benchmarks/createNoCodeFunction.js
Total time 53133
Total iterations 100000000
Iteration/s 1882069.5236482036

$ node benchmarks/reuseNoCodeFunction.js
Total time 50617
Total iterations 100000000
Iteration/s 1975620.838848608
```

The above benchmark uses fibonacci to simulate a real high-cpu load.
The actual numbers might differ for your use case, but the difference
should not.

The benchmark was taken using Node v6.10.0.

This library was extracted from
[fastparallel](http://npm.im/fastparallel).

## Example

```js
var reusify = require('reusify')
var fib = require('reusify/benchmarks/fib')
var instance = reusify(MyObject)

// get an object from the cache,
// or creates a new one when cache is empty
var obj = instance.get()

// set the state
obj.num = 100
obj.func()

// reset the state.
// if the state contains any external object
// do not use delete operator (it is slow)
// prefer set them to null
obj.num = 0

// store an object in the cache
instance.release(obj)

function MyObject () {
  // you need to define this property
  // so V8 can compile MyObject into an
  // hidden class
  this.next = null
  this.num = 0

  var that = this

  // this function is never reallocated,
  // so it can be optimized by V8
  this.func = function () {
    if (null) {
      // do nothing
    } else {
      // calculates fibonacci
      fib(that.num)
    }
  }
}
```

The above example was intended for synchronous code, let's see async:
```js
var reusify = require('reusify')
var instance = reusify(MyObject)

for (var i = 0; i < 100; i++) {
  getData(i, console.log)
}

function getData (value, cb) {
  var obj = instance.get()

  obj.value = value
  obj.cb = cb
  obj.run()
}

function MyObject () {
  this.next = null
  this.value = null

  var that = this

  this.run = function () {
    asyncOperation(that.value, that.handle)
  }

  this.handle = function (err, result) {
    that.cb(err, result)
    that.value = null
    that.cb = null
    instance.release(that)
  }
}
```

Also note how in the above examples, the code, that consumes an istance of `MyObject`,
reset the state to initial condition, just before storing it in the cache.
That's needed so that every subsequent request for an instance from the cache,
could get a clean instance.

## Why

It is faster because V8 doesn't have to collect all the functions you
create. On a short-lived benchmark, it is as fast as creating the
nested function, but on a longer time frame it creates less
pressure on the garbage collector.

## Other examples
If you want to see some complex example, checkout [middie](https://github.com/fastify/middie) and [steed](https://github.com/mcollina/steed).

## Acknowledgements

Thanks to [Trevor Norris](https://github.com/trevnorris) for
getting me down the rabbit hole of performance, and thanks to [Mathias
Buss](http://github.com/mafintosh) for suggesting me to share this
trick.

## License

MIT

[npm-badge]: https://badge.fury.io/js/reusify.svg
[npm-url]: https://badge.fury.io/js/reusify
[travis-badge]: https://api.travis-ci.org/mcollina/reusify.svg
[travis-url]: https://travis-ci.org/mcollina/reusify
[coveralls-badge]: https://coveralls.io/repos/mcollina/reusify/badge.svg?branch=master&service=github
[coveralls-url]:  https://coveralls.io/github/mcollina/reusify?branch=master
# Installation
> `npm install --save @types/codemirror`

# Summary
This package contains type definitions for codemirror (https://github.com/codemirror/CodeMirror).

# Details
Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/codemirror.

### Additional Details
 * Last updated: Tue, 06 Jun 2023 01:03:06 GMT
 * Dependencies: [@types/tern](https://npmjs.com/package/@types/tern)
 * Global values: `CodeMirror`

# Credits
These definitions were written by [mihailik](https://github.com/mihailik), [nrbernard](https://github.com/nrbernard), [Pr1st0n](https://github.com/Pr1st0n), [rileymiller](https://github.com/rileymiller), [toddself](https://github.com/toddself), [ysulyma](https://github.com/ysulyma), [azoson](https://github.com/azoson), [kylesferrazza](https://github.com/kylesferrazza), [fityocsaba96](https://github.com/fityocsaba96), [koddsson](https://github.com/koddsson), and [ficristo](https://github.com/ficristo).
# Installation
> `npm install --save @types/estree`

# Summary
This package contains type definitions for estree (https://github.com/estree/estree).

# Details
Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/estree.

### Additional Details
 * Last updated: Mon, 06 Nov 2023 22:41:05 GMT
 * Dependencies: none

# Credits
These definitions were written by [RReverser](https://github.com/RReverser).
# Installation
> `npm install --save @types/node`

# Summary
This package contains type definitions for node (https://nodejs.org/).

# Details
Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/node/v16.

### Additional Details
 * Last updated: Tue, 09 Apr 2024 04:08:23 GMT
 * Dependencies: none

# Credits
These definitions were written by [Microsoft TypeScript](https://github.com/Microsoft), [Alberto Schiabel](https://github.com/jkomyno), [Alvis HT Tang](https://github.com/alvis), [Andrew Makarov](https://github.com/r3nya), [Benjamin Toueg](https://github.com/btoueg), [Chigozirim C.](https://github.com/smac89), [David Junger](https://github.com/touffy), [Deividas Bakanas](https://github.com/DeividasBakanas), [Eugene Y. Q. Shen](https://github.com/eyqs), [Hannes Magnusson](https://github.com/Hannes-Magnusson-CK), [Huw](https://github.com/hoo29), [Kelvin Jin](https://github.com/kjin), [Klaus Meinhardt](https://github.com/ajafff), [Lishude](https://github.com/islishude), [Mariusz Wiktorczyk](https://github.com/mwiktorczyk), [Mohsen Azimi](https://github.com/mohsen1), [Nikita Galkin](https://github.com/galkin), [Parambir Singh](https://github.com/parambirs), [Sebastian Silbermann](https://github.com/eps1lon), [Seth Westphal](https://github.com/westy92), [Simon Schick](https://github.com/SimonSchick), [Thomas den Hollander](https://github.com/ThomasdenH), [Wilco Bakker](https://github.com/WilcoBakker), [wwwy3y3](https://github.com/wwwy3y3), [Samuel Ainsworth](https://github.com/samuela), [Kyle Uehlein](https://github.com/kuehlein), [Thanik Bhongbhibhat](https://github.com/bhongy), [Marcin Kopacz](https://github.com/chyzwar), [Trivikram Kamat](https://github.com/trivikr), [Junxiao Shi](https://github.com/yoursunny), [Ilia Baryshnikov](https://github.com/qwelias), [ExE Boss](https://github.com/ExE-Boss), [Piotr Błażejewicz](https://github.com/peterblazejewicz), [Anna Henningsen](https://github.com/addaleax), [Victor Perin](https://github.com/victorperin), [Yongsheng Zhang](https://github.com/ZYSzys), [NodeJS Contributors](https://github.com/NodeJS), [Linus Unnebäck](https://github.com/LinusU), and [wafuwafu13](https://github.com/wafuwafu13).
# Installation
> `npm install --save @types/tern`

# Summary
This package contains type definitions for tern (https://github.com/ternjs/tern).

# Details
Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/tern.

### Additional Details
 * Last updated: Wed, 22 Nov 2023 00:24:48 GMT
 * Dependencies: [@types/estree](https://npmjs.com/package/@types/estree)

# Credits
These definitions were written by [Nikolaj Kappler](https://github.com/nkappler).
# Installation
> `npm install --save @types/json-schema`

# Summary
This package contains type definitions for json-schema (https://github.com/kriszyp/json-schema).

# Details
Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/json-schema.

### Additional Details
 * Last updated: Tue, 07 Nov 2023 03:09:37 GMT
 * Dependencies: none

# Credits
These definitions were written by [Boris Cherny](https://github.com/bcherny), [Lucian Buzzo](https://github.com/lucianbuzzo), [Roland Groza](https://github.com/rolandjitsu), and [Jason Kwok](https://github.com/JasonHK).
# globals

> Global identifiers from different JavaScript environments

It's just a [JSON file](globals.json), so use it in any environment.

This package is used by ESLint.

**This package [no longer accepts](https://github.com/sindresorhus/globals/issues/82) new environments. If you need it for ESLint, just [create a plugin](http://eslint.org/docs/developer-guide/working-with-plugins#environments-in-plugins).**

## Install

```sh
npm install globals
```

## Usage

```js
const globals = require('globals');

console.log(globals.browser);
/*
{
	addEventListener: false,
	applicationCache: false,
	ArrayBuffer: false,
	atob: false,
	…
}
*/
```

Each global is given a value of `true` or `false`. A value of `true` indicates that the variable may be overwritten. A value of `false` indicates that the variable should be considered read-only. This information is used by static analysis tools to flag incorrect behavior. We assume all variables should be `false` unless we hear otherwise.

For Node.js this package provides two sets of globals:

- `globals.nodeBuiltin`: Globals available to all code running in Node.js.
	These will usually be available as properties on the `global` object and include `process`, `Buffer`, but not CommonJS arguments like `require`.
	See: https://nodejs.org/api/globals.html
- `globals.node`: A combination of the globals from `nodeBuiltin` plus all CommonJS arguments ("CommonJS module scope").
	See: https://nodejs.org/api/modules.html#modules_the_module_scope

When analyzing code that is known to run outside of a CommonJS wrapper, for example, JavaScript modules, `nodeBuiltin` can find accidental CommonJS references.
# shebang-regex [![Build Status](https://travis-ci.org/sindresorhus/shebang-regex.svg?branch=master)](https://travis-ci.org/sindresorhus/shebang-regex)

> Regular expression for matching a [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix)) line


## Install

```
$ npm install shebang-regex
```


## Usage

```js
const shebangRegex = require('shebang-regex');

const string = '#!/usr/bin/env node\nconsole.log("unicorns");';

shebangRegex.test(string);
//=> true

shebangRegex.exec(string)[0];
//=> '#!/usr/bin/env node'

shebangRegex.exec(string)[1];
//=> '/usr/bin/env node'
```


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# path-is-absolute [![Build Status](https://travis-ci.org/sindresorhus/path-is-absolute.svg?branch=master)](https://travis-ci.org/sindresorhus/path-is-absolute)

> Node.js 0.12 [`path.isAbsolute()`](http://nodejs.org/api/path.html#path_path_isabsolute_path) [ponyfill](https://ponyfill.com)


## Install

```
$ npm install --save path-is-absolute
```


## Usage

```js
const pathIsAbsolute = require('path-is-absolute');

// Running on Linux
pathIsAbsolute('/home/foo');
//=> true
pathIsAbsolute('C:/Users/foo');
//=> false

// Running on Windows
pathIsAbsolute('C:/Users/foo');
//=> true
pathIsAbsolute('/home/foo');
//=> false

// Running on any OS
pathIsAbsolute.posix('/home/foo');
//=> true
pathIsAbsolute.posix('C:/Users/foo');
//=> false
pathIsAbsolute.win32('C:/Users/foo');
//=> true
pathIsAbsolute.win32('/home/foo');
//=> false
```


## API

See the [`path.isAbsolute()` docs](http://nodejs.org/api/path.html#path_path_isabsolute_path).

### pathIsAbsolute(path)

### pathIsAbsolute.posix(path)

POSIX specific version.

### pathIsAbsolute.win32(path)

Windows specific version.


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# path-type [![Build Status](https://travis-ci.org/sindresorhus/path-type.svg?branch=master)](https://travis-ci.org/sindresorhus/path-type)

> Check if a path is a file, directory, or symlink


## Install

```
$ npm install path-type
```


## Usage

```js
const {isFile} = require('path-type');

(async () => {
	console.log(await isFile('package.json'));
	//=> true
})();
```


## API

### isFile(path)

Check whether the passed `path` is a file.

Returns a `Promise<boolean>`.

#### path

Type: `string`

The path to check.

### isDirectory(path)

Check whether the passed `path` is a directory.

Returns a `Promise<boolean>`.

### isSymlink(path)

Check whether the passed `path` is a symlink.

Returns a `Promise<boolean>`.

### isFileSync(path)

Synchronously check whether the passed `path` is a file.

Returns a `boolean`.

### isDirectorySync(path)

Synchronously check whether the passed `path` is a directory.

Returns a `boolean`.

### isSymlinkSync(path)

Synchronously check whether the passed `path` is a symlink.

Returns a `boolean`.


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# strip-ansi [![Build Status](https://travis-ci.org/chalk/strip-ansi.svg?branch=master)](https://travis-ci.org/chalk/strip-ansi)

> Strip [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code) from a string


## Install

```
$ npm install strip-ansi
```


## Usage

```js
const stripAnsi = require('strip-ansi');

stripAnsi('\u001B[4mUnicorn\u001B[0m');
//=> 'Unicorn'

stripAnsi('\u001B]8;;https://github.com\u0007Click\u001B]8;;\u0007');
//=> 'Click'
```


## strip-ansi for enterprise

Available as part of the Tidelift Subscription.

The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-strip-ansi?utm_source=npm-strip-ansi&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)


## Related

- [strip-ansi-cli](https://github.com/chalk/strip-ansi-cli) - CLI for this module
- [strip-ansi-stream](https://github.com/chalk/strip-ansi-stream) - Streaming version of this module
- [has-ansi](https://github.com/chalk/has-ansi) - Check if a string has ANSI escape codes
- [ansi-regex](https://github.com/chalk/ansi-regex) - Regular expression for matching ANSI escape codes
- [chalk](https://github.com/chalk/chalk) - Terminal string styling done right


## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Josh Junon](https://github.com/qix-)

# flatted

[![Downloads](https://img.shields.io/npm/dm/flatted.svg)](https://www.npmjs.com/package/flatted) [![Coverage Status](https://coveralls.io/repos/github/WebReflection/flatted/badge.svg?branch=main)](https://coveralls.io/github/WebReflection/flatted?branch=main) [![Build Status](https://travis-ci.com/WebReflection/flatted.svg?branch=main)](https://travis-ci.com/WebReflection/flatted) [![License: ISC](https://img.shields.io/badge/License-ISC-yellow.svg)](https://opensource.org/licenses/ISC) ![WebReflection status](https://offline.report/status/webreflection.svg)

![snow flake](./flatted.jpg)

<sup>**Social Media Photo by [Matt Seymour](https://unsplash.com/@mattseymour) on [Unsplash](https://unsplash.com/)**</sup>

A super light (0.5K) and fast circular JSON parser, directly from the creator of [CircularJSON](https://github.com/WebReflection/circular-json/#circularjson).

Available also for **[PHP](./php/flatted.php)**.

Available also for **[Python](./python/flatted.py)**.

- - -

## Announcement 📣

There is a standard approach to recursion and more data-types than what JSON allows, and it's part of the [Structured Clone polyfill](https://github.com/ungap/structured-clone/#readme).

Beside acting as a polyfill, its `@ungap/structured-clone/json` export provides both `stringify` and `parse`, and it's been tested for being faster than *flatted*, but its produced output is also smaller than *flatted* in general.

The *@ungap/structured-clone* module is, in short, a drop in replacement for *flatted*, but it's not compatible with *flatted* specialized syntax.

However, if recursion, as well as more data-types, are what you are after, or interesting for your projects/use cases, consider switching to this new module whenever you can 👍

- - -

```js
npm i flatted
```

Usable via [CDN](https://unpkg.com/flatted) or as regular module.

```js
// ESM
import {parse, stringify, toJSON, fromJSON} from 'flatted';

// CJS
const {parse, stringify, toJSON, fromJSON} = require('flatted');

const a = [{}];
a[0].a = a;
a.push(a);

stringify(a); // [["1","0"],{"a":"0"}]
```

## toJSON and fromJSON

If you'd like to implicitly survive JSON serialization, these two helpers helps:

```js
import {toJSON, fromJSON} from 'flatted';

class RecursiveMap extends Map {
  static fromJSON(any) {
    return new this(fromJSON(any));
  }
  toJSON() {
    return toJSON([...this.entries()]);
  }
}

const recursive = new RecursiveMap;
const same = {};
same.same = same;
recursive.set('same', same);

const asString = JSON.stringify(recursive);
const asMap = RecursiveMap.fromJSON(JSON.parse(asString));
asMap.get('same') === asMap.get('same').same;
// true
```


## Flatted VS JSON

As it is for every other specialized format capable of serializing and deserializing circular data, you should never `JSON.parse(Flatted.stringify(data))`, and you should never `Flatted.parse(JSON.stringify(data))`.

The only way this could work is to `Flatted.parse(Flatted.stringify(data))`, as it is also for _CircularJSON_ or any other, otherwise there's no granted data integrity.

Also please note this project serializes and deserializes only data compatible with JSON, so that sockets, or anything else with internal classes different from those allowed by JSON standard, won't be serialized and unserialized as expected.


### New in V1: Exact same JSON API

  * Added a [reviver](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#Syntax) parameter to `.parse(string, reviver)` and revive your own objects.
  * Added a [replacer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#Syntax) and a `space` parameter to `.stringify(object, replacer, space)` for feature parity with JSON signature.


### Compatibility
All ECMAScript engines compatible with `Map`, `Set`, `Object.keys`, and `Array.prototype.reduce` will work, even if polyfilled.


### How does it work ?
While stringifying, all Objects, including Arrays, and strings, are flattened out and replaced as unique index. `*`

Once parsed, all indexes will be replaced through the flattened collection.

<sup><sub>`*` represented as string to avoid conflicts with numbers</sub></sup>

```js
// logic example
var a = [{one: 1}, {two: '2'}];
a[0].a = a;
// a is the main object, will be at index '0'
// {one: 1} is the second object, index '1'
// {two: '2'} the third, in '2', and it has a string
// which will be found at index '3'

Flatted.stringify(a);
// [["1","2"],{"one":1,"a":"0"},{"two":"3"},"2"]
// a[one,two]    {one: 1, a}    {two: '2'}  '2'
```
The MIT License (MIT)

Copyright (c) 2016 Zeit, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
# ms

[![Build Status](https://travis-ci.org/zeit/ms.svg?branch=master)](https://travis-ci.org/zeit/ms)
[![Join the community on Spectrum](https://withspectrum.github.io/badge/badge.svg)](https://spectrum.chat/zeit)

Use this package to easily convert various time formats to milliseconds.

## Examples

```js
ms('2 days')  // 172800000
ms('1d')      // 86400000
ms('10h')     // 36000000
ms('2.5 hrs') // 9000000
ms('2h')      // 7200000
ms('1m')      // 60000
ms('5s')      // 5000
ms('1y')      // 31557600000
ms('100')     // 100
ms('-3 days') // -259200000
ms('-1h')     // -3600000
ms('-200')    // -200
```

### Convert from Milliseconds

```js
ms(60000)             // "1m"
ms(2 * 60000)         // "2m"
ms(-3 * 60000)        // "-3m"
ms(ms('10 hours'))    // "10h"
```

### Time Format Written-Out

```js
ms(60000, { long: true })             // "1 minute"
ms(2 * 60000, { long: true })         // "2 minutes"
ms(-3 * 60000, { long: true })        // "-3 minutes"
ms(ms('10 hours'), { long: true })    // "10 hours"
```

## Features

- Works both in [Node.js](https://nodejs.org) and in the browser
- If a number is supplied to `ms`, a string with a unit is returned
- If a string that contains the number is supplied, it returns it as a number (e.g.: it returns `100` for `'100'`)
- If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned

## Related Packages

- [ms.macro](https://github.com/knpwrs/ms.macro) - Run `ms` as a macro at build-time.

## Caught a Bug?

1. [Fork](https://help.github.com/articles/fork-a-repo/) this repository to your own GitHub account and then [clone](https://help.github.com/articles/cloning-a-repository/) it to your local device
2. Link the package to the global module directory: `npm link`
3. Within the module you want to test your local development instance of ms, just link it to the dependencies: `npm link ms`. Instead of the default one from npm, Node.js will now use your clone of ms!

As always, you can run the tests using: `npm test`
# 1.2.1
- fix version

# 1.2.0
- add `List.remove`
- build with LiveScript 1.6.0
- update dependencies
- remove coverage calculation

# 1.1.2
- add `Func.memoize`
- fix `zip-all` and `zip-with-all` corner case (no input)
- build with LiveScript 1.4.0

# 1.1.1
- curry `unique-by`, `minimum-by`

# 1.1.0
- added `List` functions: `maximum-by`, `minimum-by`, `unique-by`
- added `List` functions: `at`, `elem-index`, `elem-indices`, `find-index`, `find-indices`
- added `Str` functions: `capitalize`, `camelize`, `dasherize`
- added `Func` function: `over` - eg. ``same-length = (==) `over` (.length)``
- exported `Str.repeat` through main `prelude` object
- fixed definition of `foldr` and `foldr1`, the new correct definition is backwards incompatible with the old, incorrect one
- fixed issue with `fix`
- improved code coverage

# 1.0.3
- build browser versions

# 1.0.2
- bug fix for `flatten` - slight change with bug fix, flattens arrays only, not array-like objects

# 1.0.1
- bug fixes for `drop-while` and `take-while`

# 1.0.0
* massive update - separated functions into separate modules
* functions do not accept multiple types anymore - use different versions in their respective modules in some cases (eg. `Obj.map`), or use `chars` or `values` in other cases to transform into a list
* objects are no longer transformed into functions, simply use `(obj.)` in LiveScript to do that
* browser version now using browserify - use `prelude = require('prelude-ls')`
* added `compact`, `split`, `flatten`, `difference`, `intersection`, `union`, `count-by`, `group-by`, `chars`, `unchars`, `apply`
* added `lists-to-obj` which takes a list of keys and list of values and zips them up into an object, and the converse `obj-to-lists`
* added `pairs-to-obj` which takes a list of pairs (2 element lists) and creates an object, and the converse `obj-to-pairs`
* removed `cons`, `append` - use the concat operator
* removed `compose` - use the compose operator
* removed `obj-to-func` - use partially applied access (eg. `(obj.)`)
* removed `length` - use `(.length)`
* `sort-by` renamed to `sort-with`
* added new `sort-by`
* removed `compare` - just use the new `sort-by`
* `break-it` renamed `break-list`, (`Str.break-str` for the string version)
* added `Str.repeat` which creates a new string by repeating the input n times
* `unfold` as alias to `unfoldr` is no longer used
* fixed up style and compiled with LiveScript 1.1.1
* use Make instead of Slake
* greatly improved tests

# 0.6.0
* fixed various bugs
* added `fix`, a fixpoint (Y combinator) for anonymous recursive functions
* added `unfoldr` (alias `unfold`)
* calling `replicate` with a string now returns a list of strings
* removed `partial`, just use native partial application in LiveScript using the `_` placeholder, or currying
* added `sort`, `sortBy`, and `compare`

# 0.5.0
* removed `lookup` - use (.prop)
* removed `call` - use (.func arg1, arg2)
* removed `pluck` - use map (.prop), xs
* fixed buys wtih `head` and `last`
* added non-minifed browser version, as `prelude-browser.js`
* renamed `prelude-min.js` to `prelude-browser-min.js`
* renamed `zip` to `zipAll`
* renamed `zipWith` to `zipAllWith`
* added `zip`, a curried zip that takes only two arguments
* added `zipWith`, a curried zipWith that takes only two arguments

# 0.4.0
* added `parition` function
* added `curry` function
* removed `elem` function (use `in`)
* removed `notElem` function (use `not in`)

# 0.3.0
* added `listToObject`
* added `unique`
* added `objToFunc`
* added support for using strings in map and the like
* added support for using objects in map and the like
* added ability to use objects instead of functions in certain cases
* removed `error` (just use throw)
* added `tau` constant
* added `join`
* added `values`
* added `keys`
* added `partial`
* renamed `log` to `ln`
* added alias to `head`: `first`
* added `installPrelude` helper

# 0.2.0
* removed functions that simply warp operators as you can now use operators as functions in LiveScript
* `min/max` are now curried and take only 2 arguments
* added `call`

# 0.1.0
* initial public release
# prelude.ls [![Build Status](https://travis-ci.org/gkz/prelude-ls.png?branch=master)](https://travis-ci.org/gkz/prelude-ls)

is a functionally oriented utility library. It is powerful and flexible. Almost all of its functions are curried. It is written in, and is the recommended base library for, <a href="http://livescript.net">LiveScript</a>.

See **[the prelude.ls site](http://preludels.com)** for examples, a reference, and more.

You can install via npm `npm install prelude-ls`

### Development

`make test` to test

`make build` to build `lib` from `src`

`make build-browser` to build browser versions
# escape-string-regexp [![Build Status](https://travis-ci.org/sindresorhus/escape-string-regexp.svg?branch=master)](https://travis-ci.org/sindresorhus/escape-string-regexp)

> Escape RegExp special characters

## Install

```
$ npm install escape-string-regexp
```

## Usage

```js
const escapeStringRegexp = require('escape-string-regexp');

const escapedString = escapeStringRegexp('How much $ for a 🦄?');
//=> 'How much \\$ for a 🦄\\?'

new RegExp(escapedString);
```

You can also use this to escape a string that is inserted into the middle of a regex, for example, into a character class.

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-escape-string-regexp?utm_source=npm-escape-string-regexp&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# strip-json-comments [![Build Status](https://travis-ci.com/sindresorhus/strip-json-comments.svg?branch=master)](https://travis-ci.com/github/sindresorhus/strip-json-comments)

> Strip comments from JSON. Lets you use comments in your JSON files!

This is now possible:

```js
{
	// Rainbows
	"unicorn": /* ❤ */ "cake"
}
```

It will replace single-line comments `//` and multi-line comments `/**/` with whitespace. This allows JSON error positions to remain as close as possible to the original source.

Also available as a [Gulp](https://github.com/sindresorhus/gulp-strip-json-comments)/[Grunt](https://github.com/sindresorhus/grunt-strip-json-comments)/[Broccoli](https://github.com/sindresorhus/broccoli-strip-json-comments) plugin.

## Install

```
$ npm install strip-json-comments
```

## Usage

```js
const json = `{
	// Rainbows
	"unicorn": /* ❤ */ "cake"
}`;

JSON.parse(stripJsonComments(json));
//=> {unicorn: 'cake'}
```

## API

### stripJsonComments(jsonString, options?)

#### jsonString

Type: `string`

Accepts a string with JSON and returns a string without comments.

#### options

Type: `object`

##### whitespace

Type: `boolean`\
Default: `true`

Replace comments with whitespace instead of stripping them entirely.

## Benchmark

```
$ npm run bench
```

## Related

- [strip-json-comments-cli](https://github.com/sindresorhus/strip-json-comments-cli) - CLI for this module
- [strip-css-comments](https://github.com/sindresorhus/strip-css-comments) - Strip comments from CSS

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-strip-json-comments?utm_source=npm-strip-json-comments&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# lru cache

A cache object that deletes the least-recently-used items.

[![Build Status](https://travis-ci.org/isaacs/node-lru-cache.svg?branch=master)](https://travis-ci.org/isaacs/node-lru-cache) [![Coverage Status](https://coveralls.io/repos/isaacs/node-lru-cache/badge.svg?service=github)](https://coveralls.io/github/isaacs/node-lru-cache)

## Installation:

```javascript
npm install lru-cache --save
```

## Usage:

```javascript
var LRU = require("lru-cache")
  , options = { max: 500
              , length: function (n, key) { return n * 2 + key.length }
              , dispose: function (key, n) { n.close() }
              , maxAge: 1000 * 60 * 60 }
  , cache = new LRU(options)
  , otherCache = new LRU(50) // sets just the max size

cache.set("key", "value")
cache.get("key") // "value"

// non-string keys ARE fully supported
// but note that it must be THE SAME object, not
// just a JSON-equivalent object.
var someObject = { a: 1 }
cache.set(someObject, 'a value')
// Object keys are not toString()-ed
cache.set('[object Object]', 'a different value')
assert.equal(cache.get(someObject), 'a value')
// A similar object with same keys/values won't work,
// because it's a different object identity
assert.equal(cache.get({ a: 1 }), undefined)

cache.reset()    // empty the cache
```

If you put more stuff in it, then items will fall out.

If you try to put an oversized thing in it, then it'll fall out right
away.

## Options

* `max` The maximum size of the cache, checked by applying the length
  function to all values in the cache.  Not setting this is kind of
  silly, since that's the whole purpose of this lib, but it defaults
  to `Infinity`.  Setting it to a non-number or negative number will
  throw a `TypeError`.  Setting it to 0 makes it be `Infinity`.
* `maxAge` Maximum age in ms.  Items are not pro-actively pruned out
  as they age, but if you try to get an item that is too old, it'll
  drop it and return undefined instead of giving it to you.
  Setting this to a negative value will make everything seem old!
  Setting it to a non-number will throw a `TypeError`.
* `length` Function that is used to calculate the length of stored
  items.  If you're storing strings or buffers, then you probably want
  to do something like `function(n, key){return n.length}`.  The default is
  `function(){return 1}`, which is fine if you want to store `max`
  like-sized things.  The item is passed as the first argument, and
  the key is passed as the second argumnet.
* `dispose` Function that is called on items when they are dropped
  from the cache.  This can be handy if you want to close file
  descriptors or do other cleanup tasks when items are no longer
  accessible.  Called with `key, value`.  It's called *before*
  actually removing the item from the internal cache, so if you want
  to immediately put it back in, you'll have to do that in a
  `nextTick` or `setTimeout` callback or it won't do anything.
* `stale` By default, if you set a `maxAge`, it'll only actually pull
  stale items out of the cache when you `get(key)`.  (That is, it's
  not pre-emptively doing a `setTimeout` or anything.)  If you set
  `stale:true`, it'll return the stale value before deleting it.  If
  you don't set this, then it'll return `undefined` when you try to
  get a stale entry, as if it had already been deleted.
* `noDisposeOnSet` By default, if you set a `dispose()` method, then
  it'll be called whenever a `set()` operation overwrites an existing
  key.  If you set this option, `dispose()` will only be called when a
  key falls out of the cache, not when it is overwritten.
* `updateAgeOnGet` When using time-expiring entries with `maxAge`,
  setting this to `true` will make each item's effective time update
  to the current time whenever it is retrieved from cache, causing it
  to not expire.  (It can still fall out of cache based on recency of
  use, of course.)

## API

* `set(key, value, maxAge)`
* `get(key) => value`

    Both of these will update the "recently used"-ness of the key.
    They do what you think. `maxAge` is optional and overrides the
    cache `maxAge` option if provided.

    If the key is not found, `get()` will return `undefined`.

    The key and val can be any value.

* `peek(key)`

    Returns the key value (or `undefined` if not found) without
    updating the "recently used"-ness of the key.

    (If you find yourself using this a lot, you *might* be using the
    wrong sort of data structure, but there are some use cases where
    it's handy.)

* `del(key)`

    Deletes a key out of the cache.

* `reset()`

    Clear the cache entirely, throwing away all values.

* `has(key)`

    Check if a key is in the cache, without updating the recent-ness
    or deleting it for being stale.

* `forEach(function(value,key,cache), [thisp])`

    Just like `Array.prototype.forEach`.  Iterates over all the keys
    in the cache, in order of recent-ness.  (Ie, more recently used
    items are iterated over first.)

* `rforEach(function(value,key,cache), [thisp])`

    The same as `cache.forEach(...)` but items are iterated over in
    reverse order.  (ie, less recently used items are iterated over
    first.)

* `keys()`

    Return an array of the keys in the cache.

* `values()`

    Return an array of the values in the cache.

* `length`

    Return total length of objects in cache taking into account
    `length` options function.

* `itemCount`

    Return total quantity of objects currently in cache. Note, that
    `stale` (see options) items are returned as part of this item
    count.

* `dump()`

    Return an array of the cache entries ready for serialization and usage
    with 'destinationCache.load(arr)`.

* `load(cacheEntriesArray)`

    Loads another cache entries array, obtained with `sourceCache.dump()`,
    into the cache. The destination cache is reset before loading new entries

* `prune()`

    Manually iterates over the entire cache proactively pruning old entries
iMurmurHash.js
==============

An incremental implementation of the MurmurHash3 (32-bit) hashing algorithm for JavaScript based on [Gary Court's implementation](https://github.com/garycourt/murmurhash-js) with [kazuyukitanimura's modifications](https://github.com/kazuyukitanimura/murmurhash-js).

This version works significantly faster than the non-incremental version if you need to hash many small strings into a single hash, since string concatenation (to build the single string to pass the non-incremental version) is fairly costly. In one case tested, using the incremental version was about 50% faster than concatenating 5-10 strings and then hashing.

Installation
------------

To use iMurmurHash in the browser, [download the latest version](https://raw.github.com/jensyt/imurmurhash-js/master/imurmurhash.min.js) and include it as a script on your site.

```html
<script type="text/javascript" src="/scripts/imurmurhash.min.js"></script>
<script>
// Your code here, access iMurmurHash using the global object MurmurHash3
</script>
```

---

To use iMurmurHash in Node.js, install the module using NPM:

```bash
npm install imurmurhash
```

Then simply include it in your scripts:

```javascript
MurmurHash3 = require('imurmurhash');
```

Quick Example
-------------

```javascript
// Create the initial hash
var hashState = MurmurHash3('string');

// Incrementally add text
hashState.hash('more strings');
hashState.hash('even more strings');

// All calls can be chained if desired
hashState.hash('and').hash('some').hash('more');

// Get a result
hashState.result();
// returns 0xe4ccfe6b
```

Functions
---------

### MurmurHash3 ([string], [seed])
Get a hash state object, optionally initialized with the given _string_ and _seed_. _Seed_ must be a positive integer if provided. Calling this function without the `new` keyword will return a cached state object that has been reset. This is safe to use as long as the object is only used from a single thread and no other hashes are created while operating on this one. If this constraint cannot be met, you can use `new` to create a new state object. For example:

```javascript
// Use the cached object, calling the function again will return the same
// object (but reset, so the current state would be lost)
hashState = MurmurHash3();
...

// Create a new object that can be safely used however you wish. Calling the
// function again will simply return a new state object, and no state loss
// will occur, at the cost of creating more objects.
hashState = new MurmurHash3();
```

Both methods can be mixed however you like if you have different use cases.

---

### MurmurHash3.prototype.hash (string)
Incrementally add _string_ to the hash. This can be called as many times as you want for the hash state object, including after a call to `result()`. Returns `this` so calls can be chained.

---

### MurmurHash3.prototype.result ()
Get the result of the hash as a 32-bit positive integer. This performs the tail and finalizer portions of the algorithm, but does not store the result in the state object. This means that it is perfectly safe to get results and then continue adding strings via `hash`.

```javascript
// Do the whole string at once
MurmurHash3('this is a test string').result();
// 0x70529328

// Do part of the string, get a result, then the other part
var m = MurmurHash3('this is a');
m.result();
// 0xbfc4f834
m.hash(' test string').result();
// 0x70529328 (same as above)
```

---

### MurmurHash3.prototype.reset ([seed])
Reset the state object for reuse, optionally using the given _seed_ (defaults to 0 like the constructor). Returns `this` so calls can be chained.

---

License (MIT)
-------------
Copyright (c) 2013 Gary Court, Jens Taylor

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
v5.1.1 - September 12, 2020

* [`9b528d7`](https://github.com/eslint/eslint-scope/commit/9b528d778c381718c12dabfb7f1c0e0dc6b36e49) Upgrade: esrecurse version to ^4.3.0 (#64) (Timofey Kachalov)
* [`f758bbc`](https://github.com/eslint/eslint-scope/commit/f758bbc3d49b9b9ea2289a5d6a6bba8dcf2c4903) Chore: fix definiton -> definition typo in comments (#63) (Kevin Kirsche)
* [`7513734`](https://github.com/eslint/eslint-scope/commit/751373473375b3f2edc4eaf1c8d2763d8435bb72) Chore: move to GitHub Actions (#62) (Kai Cataldo)

v5.1.0 - June 4, 2020

* [`d4a3764`](https://github.com/eslint/eslint-scope/commit/d4a376434b16289c1a428d7e304576e997520873) Update: support new export syntax (#56) (Toru Nagashima)

v5.0.0 - July 20, 2019

* [`e9fa22e`](https://github.com/eslint/eslint-scope/commit/e9fa22ea412c26cf2761fa98af7e715644bdb464) Upgrade: update dependencies after dropping support for Node <8 (#53) (Kai Cataldo)
* [`ee9f7c1`](https://github.com/eslint/eslint-scope/commit/ee9f7c12721aa195ba7e0e69551f49bfdb479951) Breaking: drop support for Node v6 (#54) (Kai Cataldo)

v4.0.3 - March 15, 2019

* [`299df64`](https://github.com/eslint/eslint-scope/commit/299df64bdafb30b4d9372e4b7af0cf51a3818c4a) Fix: arrow function scope strictness (take 2) (#52) (futpib)

v4.0.2 - March 1, 2019

* [`c925600`](https://github.com/eslint/eslint-scope/commit/c925600a684ae0f71b96f85339437a43b4d50d99) Revert "Fix: Arrow function scope strictness (fixes #49) (#50)" (#51) (Teddy Katz)

v4.0.1 - March 1, 2019

* [`2533966`](https://github.com/eslint/eslint-scope/commit/2533966faf317df5a3847fab937ba462c16808b8) Fix: Arrow function scope strictness (fixes #49) (#50) (futpib)
* [`0cbeea5`](https://github.com/eslint/eslint-scope/commit/0cbeea51dfb66ab88ea34b0e3b4ad5e6cc210f2f) Chore: add supported Node.js versions to CI (#47) (Kai Cataldo)
* [`b423057`](https://github.com/eslint/eslint-scope/commit/b42305760638b8edf4667acf1445e450869bd983) Upgrade: eslint-release@1.0.0 (#46) (Teddy Katz)

v4.0.0 - June 21, 2018



v4.0.0-rc.0 - June 9, 2018

* 3b919b8 Build: Adding rc release script to package.json (#38) (Kevin Partington)
* 137732a Chore: avoid creating package-lock.json files (#37) (Teddy Katz)

v4.0.0-alpha.0 - April 27, 2018

* 7cc3769 Upgrade: eslint-release ^0.11.1 (#36) (Teddy Katz)
* c9f6967 Breaking: remove TDZScope (refs eslint/eslint#10245) (#35) (Toru Nagashima)
* 982a71f Fix: wrong resolution about default parameters (#33) (Toru Nagashima)
* 57889f1 Docs: Remove extra header line from LICENSE (#32) (Gyandeep Singh)

v3.7.1 - April 12, 2017

* ced6262 Fix: restore previous Scope API exports from escope (#31) (Vitor Balocco)
* 5c3d966 Fix: Remove and Modify tests that contain invalid ES6 syntax (#29) (Reyad Attiyat)

v3.7.0 - March 17, 2017

* 9e27835 Chore: Add files section to package.json (#24) (Ilya Volodin)
* 3e4d123 Upgrade: eslint-config-eslint to 4.0.0 (#21) (Teddy Katz)
* 38c50fb Chore: Rename src to lib and test to tests (#20) (Corbin Uselton)
* f4cd920 Chore: Remove esprima (#19) (Corbin Uselton)
* f81fad5 Revert "Chore: Remove esprima" (#18) (James Henry)
* 31b0085 Chore: Remove es6-map and es6-weakmap as they are included in node4 (#10) (#13) (Corbin Uselton)
* 12a1ca1 Add Makefile.js and eslint (#15) (Reyad Attiyat)
* 7d23f8e Chore: Remove es6-map and es6-weakmap as they are included in node4 (#10) (Corbin Uselton)
* 019441e Chore: Convert to ES6 that is supported on Node 4, commonjs modules and remove Babel (#14) (Corbin Uselton)
* c647f65 Update: Add check for node.body in referencer (#2) (Corbin Uselton)
* eb5c9db Remove browserify and jsdoc (#12) (Corbin Uselton)
* cf38df0 Chore: Update README.md (#3) (James Henry)
* 8a142ca Chore: Add eslint-release scripts (#6) (James Henry)
* e60d8cb Chore: Remove unused bower.json (#5) (James Henry)
* 049c545 Chore: Fix tests for eslint-scope (#4) (James Henry)
* f026aab Chore: Update package.json for eslint fork (#1) (James Henry)
* a94d281 Chore: Update license with JSF copyright (Nicholas C. Zakas)

# ESLint Scope

ESLint Scope is the [ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm) scope analyzer used in ESLint. It is a fork of [escope](http://github.com/estools/escope).

## Usage

Install:

```
npm i eslint-scope --save
```

Example:

```js
var eslintScope = require('eslint-scope');
var espree = require('espree');
var estraverse = require('estraverse');

var ast = espree.parse(code);
var scopeManager = eslintScope.analyze(ast);

var currentScope = scopeManager.acquire(ast);   // global scope

estraverse.traverse(ast, {
    enter: function(node, parent) {
        // do stuff

        if (/Function/.test(node.type)) {
            currentScope = scopeManager.acquire(node);  // get current function scope
        }
    },
    leave: function(node, parent) {
        if (/Function/.test(node.type)) {
            currentScope = currentScope.upper;  // set to parent scope
        }

        // do stuff
    }
});
```

## Contributing

Issues and pull requests will be triaged and responded to as quickly as possible. We operate under the [ESLint Contributor Guidelines](http://eslint.org/docs/developer-guide/contributing), so please be sure to read them before contributing. If you're not sure where to dig in, check out the [issues](https://github.com/eslint/eslint-scope/issues).

## Build Commands

* `npm test` - run all linting and tests
* `npm run lint` - run all linting

## License

ESLint Scope is licensed under a permissive BSD 2-clause license.
<div align="center">
	<br>
	<br>
	<img src="media/logo.svg" alt="type-fest" height="300">
	<br>
	<br>
	<b>A collection of essential TypeScript types</b>
	<br>
	<hr>
</div>
<br>
<br>

[![](https://img.shields.io/badge/unicorn-approved-ff69b4.svg)](https://giphy.com/gifs/illustration-rainbow-unicorn-26AHG5KGFxSkUWw1i)
<!-- Commented out until they actually show anything
[![npm dependents](https://badgen.net/npm/dependents/type-fest)](https://www.npmjs.com/package/type-fest?activeTab=dependents) [![npm downloads](https://badgen.net/npm/dt/type-fest)](https://www.npmjs.com/package/type-fest)
-->

Many of the types here should have been built-in. You can help by suggesting some of them to the [TypeScript project](https://github.com/Microsoft/TypeScript/blob/master/CONTRIBUTING.md).

Either add this package as a dependency or copy-paste the needed types. No credit required. 👌

PR welcome for additional commonly needed types and docs improvements. Read the [contributing guidelines](.github/contributing.md) first.

## Install

```
$ npm install type-fest
```

*Requires TypeScript >=3.4*

## Usage

```ts
import {Except} from 'type-fest';

type Foo = {
	unicorn: string;
	rainbow: boolean;
};

type FooWithoutRainbow = Except<Foo, 'rainbow'>;
//=> {unicorn: string}
```

## API

Click the type names for complete docs.

### Basic

- [`Primitive`](source/basic.d.ts) - Matches any [primitive value](https://developer.mozilla.org/en-US/docs/Glossary/Primitive).
- [`Class`](source/basic.d.ts) - Matches a [`class` constructor](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes).
- [`TypedArray`](source/basic.d.ts) - Matches any [typed array](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray), like `Uint8Array` or `Float64Array`.
- [`JsonObject`](source/basic.d.ts) - Matches a JSON object.
- [`JsonArray`](source/basic.d.ts) - Matches a JSON array.
- [`JsonValue`](source/basic.d.ts) - Matches any valid JSON value.
- [`ObservableLike`](source/basic.d.ts) - Matches a value that is like an [Observable](https://github.com/tc39/proposal-observable).

### Utilities

- [`Except`](source/except.d.ts) - Create a type from an object type without certain keys. This is a stricter version of [`Omit`](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-5.html#the-omit-helper-type).
- [`Mutable`](source/mutable.d.ts) - Convert an object with `readonly` keys into a mutable object. The inverse of `Readonly<T>`.
- [`Merge`](source/merge.d.ts) - Merge two types into a new type. Keys of the second type overrides keys of the first type.
- [`MergeExclusive`](source/merge-exclusive.d.ts) - Create a type that has mutually exclusive keys.
- [`RequireAtLeastOne`](source/require-at-least-one.d.ts) - Create a type that requires at least one of the given keys.
- [`RequireExactlyOne`](source/require-exactly-one.d.ts) - Create a type that requires exactly a single key of the given keys and disallows more.
- [`PartialDeep`](source/partial-deep.d.ts) - Create a deeply optional version of another type. Use [`Partial<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1401-L1406) if you only need one level deep.
- [`ReadonlyDeep`](source/readonly-deep.d.ts) - Create a deeply immutable version of an `object`/`Map`/`Set`/`Array` type. Use [`Readonly<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1415-L1420) if you only need one level deep.
- [`LiteralUnion`](source/literal-union.d.ts) - Create a union type by combining primitive types and literal types without sacrificing auto-completion in IDEs for the literal type part of the union. Workaround for [Microsoft/TypeScript#29729](https://github.com/Microsoft/TypeScript/issues/29729).
- [`Promisable`](source/promisable.d.ts) - Create a type that represents either the value or the value wrapped in `PromiseLike`.
- [`Opaque`](source/opaque.d.ts) - Create an [opaque type](https://codemix.com/opaque-types-in-javascript/).
- [`SetOptional`](source/set-optional.d.ts) - Create a type that makes the given keys optional.
- [`SetRequired`](source/set-required.d.ts) - Create a type that makes the given keys required.
- [`ValueOf`](source/value-of.d.ts) - Create a union of the given object's values, and optionally specify which keys to get the values from.
- [`PromiseValue`](source/promise-value.d.ts) - Returns the type that is wrapped inside a `Promise`.
- [`AsyncReturnType`](source/async-return-type.d.ts) - Unwrap the return type of a function that returns a `Promise`.
- [`ConditionalKeys`](source/conditional-keys.d.ts) - Extract keys from a shape where values extend the given `Condition` type.
- [`ConditionalPick`](source/conditional-pick.d.ts) - Like `Pick` except it selects properties from a shape where the values extend the given `Condition` type.
- [`ConditionalExcept`](source/conditional-except.d.ts) - Like `Omit` except it removes properties from a shape where the values extend the given `Condition` type.
- [`UnionToIntersection`](source/union-to-intersection.d.ts) - Convert a union type to an intersection type.
- [`Stringified`](source/stringified.d.ts) - Create a type with the keys of the given type changed to `string` type.
- [`FixedLengthArray`](source/fixed-length-array.d.ts) - Create a type that represents an array of the given type and length.
- [`IterableElement`](source/iterable-element.d.ts) - Get the element type of an `Iterable`/`AsyncIterable`. For example, an array or a generator.
- [`Entry`](source/entry.d.ts) - Create a type that represents the type of an entry of a collection.
- [`Entries`](source/entries.d.ts) - Create a type that represents the type of the entries of a collection.
- [`SetReturnType`](source/set-return-type.d.ts) - Create a function type with a return type of your choice and the same parameters as the given function type.
- [`Asyncify`](source/asyncify.d.ts) - Create an async version of the given function type.

### Template literal types

*Note:* These require [TypeScript 4.1 or newer](https://devblogs.microsoft.com/typescript/announcing-typescript-4-1/#template-literal-types).

- [`CamelCase`](ts41/camel-case.d.ts) – Convert a string literal to camel-case (`fooBar`).
- [`KebabCase`](ts41/kebab-case.d.ts) – Convert a string literal to kebab-case (`foo-bar`).
- [`PascalCase`](ts41/pascal-case.d.ts) – Converts a string literal to pascal-case (`FooBar`)
- [`SnakeCase`](ts41/snake-case.d.ts) – Convert a string literal to snake-case (`foo_bar`).
- [`DelimiterCase`](ts41/delimiter-case.d.ts) – Convert a string literal to a custom string delimiter casing.

### Miscellaneous

- [`PackageJson`](source/package-json.d.ts) - Type for [npm's `package.json` file](https://docs.npmjs.com/creating-a-package-json-file).
- [`TsConfigJson`](source/tsconfig-json.d.ts) - Type for [TypeScript's `tsconfig.json` file](https://www.typescriptlang.org/docs/handbook/tsconfig-json.html) (TypeScript 3.7).

## Declined types

*If we decline a type addition, we will make sure to document the better solution here.*

- [`Diff` and `Spread`](https://github.com/sindresorhus/type-fest/pull/7) - The PR author didn't provide any real-world use-cases and the PR went stale. If you think this type is useful, provide some real-world use-cases and we might reconsider.
- [`Dictionary`](https://github.com/sindresorhus/type-fest/issues/33) - You only save a few characters (`Dictionary<number>` vs `Record<string, number>`) from [`Record`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1429-L1434), which is more flexible and well-known. Also, you shouldn't use an object as a dictionary. We have `Map` in JavaScript now.
- [`SubType`](https://github.com/sindresorhus/type-fest/issues/22) - The type is powerful, but lacks good use-cases and is prone to misuse.
- [`ExtractProperties` and `ExtractMethods`](https://github.com/sindresorhus/type-fest/pull/4) - The types violate the single responsibility principle. Instead, refine your types into more granular type hierarchies.

## Tips

### Built-in types

There are many advanced types most users don't know about.

- [`Partial<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1401-L1406) - Make all properties in `T` optional.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://www.typescriptlang.org/play/#code/JYOwLgpgTgZghgYwgAgHIHsAmEDC6QzADmyA3gLABQyycADnanALYQBcyAzmFKEQNxUaddFDAcQAV2YAjaIMoBfKlQQAbOJ05osEAIIMAQpOBrsUMkOR1eANziRkCfISKSoD4Pg4ZseAsTIALyW1DS0DEysHADkvvoMMQA0VsKi4sgAzAAMuVaKClY2wPaOknSYDrguADwA0sgQAB6QIJjaANYQAJ7oMDp+LsQAfAAUXd0cdUnI9mo+uv6uANp1ALoAlKHhyGAAFsCcAHTOAW4eYF4gyxNrwbNwago0ypRWp66jH8QcAApwYmAjxq8SWIy2FDCNDA3ToKFBQyIdR69wmfQG1TOhShyBgomQX3w3GQE2Q6IA8jIAFYQBBgI4TTiEs5bTQYsFInrLTbbHZOIlgZDlSqQABqj0kKBC3yINx6a2xfOQwH6o2FVXFaklwSCIUkbQghBAEEwENSfNOlykEGefNe5uhB2O6sgS3GPRmLogmslG1tLxUOKgEDA7hAuydtteryAA)

	```ts
	interface NodeConfig {
			appName: string;
			port: number;
	}

	class NodeAppBuilder {
			private configuration: NodeConfig = {
					appName: 'NodeApp',
					port: 3000
			};

			private updateConfig<Key extends keyof NodeConfig>(key: Key, value: NodeConfig[Key]) {
					this.configuration[key] = value;
			}

			config(config: Partial<NodeConfig>) {
					type NodeConfigKey = keyof NodeConfig;

					for (const key of Object.keys(config) as NodeConfigKey[]) {
							const updateValue = config[key];

							if (updateValue === undefined) {
									continue;
							}

							this.updateConfig(key, updateValue);
					}

					return this;
			}
	}

	// `Partial<NodeConfig>`` allows us to provide only a part of the
	// NodeConfig interface.
	new NodeAppBuilder().config({appName: 'ToDoApp'});
	```
	</details>

- [`Required<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1408-L1413) - Make all properties in `T` required.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/AQ4SwOwFwUwJwGYEMDGNgGED21VQGJZwC2wA3gFCjXAzFJgA2A-AFzADOUckA5gNxUaIYjA4ckvGG07c+g6gF8KQkAgCuEFFDA5O6gEbEwUbLm2ESwABQIixACJIoSdgCUYAR3Vg4MACYAPGYuFvYAfACU5Ko0APRxwADKMBD+wFAAFuh2Vv7OSBlYGdmc8ABu8LHKsRyGxqY4oQT21pTCIHQMjOwA5DAAHgACxAAOjDAAdChYxL0ANLHUouKSMH0AEmAAhJhY6ozpAJ77GTCMjMCiV0ToSAb7UJPPC9WRgrEJwAAqR6MwSRQPFGUFocDgRHYxnEfGAowh-zgUCOwF6KwkUl6tXqJhCeEsxDaS1AXSYfUGI3GUxmc0WSneQA)

	```ts
	interface ContactForm {
			email?: string;
			message?: string;
	}

	function submitContactForm(formData: Required<ContactForm>) {
			// Send the form data to the server.
	}

	submitContactForm({
			email: 'ex@mple.com',
			message: 'Hi! Could you tell me more about…',
	});

	// TypeScript error: missing property 'message'
	submitContactForm({
			email: 'ex@mple.com',
	});
	```
	</details>

- [`Readonly<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1415-L1420) - Make all properties in `T` readonly.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/AQ4UwOwVwW2AZA9gc3mAbmANsA3gKFCOAHkAzMgGkOJABEwAjKZa2kAUQCcvEu32AMQCGAF2FYBIAL4BufDRABLCKLBcywgMZgEKZOoDCiCGSXI8i4hGEwwALmABnUVxXJ57YFgzZHSVF8sT1BpBSItLGEnJz1kAy5LLy0TM2RHACUwYQATEywATwAeAITjU3MAPnkrCJMXLigtUT4AClxgGztKbyDgaX99I1TzAEokr1BRAAslJwA6FIqLAF48TtswHp9MHDla9hJGACswZvmyLjAwAC8wVpm5xZHkUZDaMKIwqyWXYCW0oN4sNlsA1h0ug5gAByACyBQAggAHJHQ7ZBIFoXbzBjMCz7OoQP5YIaJNYQMAAdziCVaALGNSIAHomcAACoFJFgADKWjcSNEwG4vC4ji0wggEEQguiTnMEGALWAV1yAFp8gVgEjeFyuKICvMrCTgVxnst5jtsGC4ljsPNhXxGaAWcAAOq6YRXYDCRg+RWIcA5JSC+kWdCepQ+v3RYCU3RInzRMCGwlpC19NYBW1Ye08R1AA)

	```ts
	enum LogLevel {
			Off,
			Debug,
			Error,
			Fatal
	};

	interface LoggerConfig {
			name: string;
			level: LogLevel;
	}

	class Logger {
			config: Readonly<LoggerConfig>;

			constructor({name, level}: LoggerConfig) {
					this.config = {name, level};
					Object.freeze(this.config);
			}
	}

	const config: LoggerConfig = {
		name: 'MyApp',
		level: LogLevel.Debug
	};

	const logger = new Logger(config);

	// TypeScript Error: cannot assign to read-only property.
	logger.config.level = LogLevel.Error;

	// We are able to edit config variable as we please.
	config.level = LogLevel.Error;
	```
	</details>

- [`Pick<T, K>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1422-L1427) - From `T`, pick a set of properties whose keys are in the union `K`.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/AQ4SwOwFwUwJwGYEMDGNgEE5TCgNugN4BQoZwOUBAXMAM5RyQDmA3KeSFABYCuAtgCMISMHloMmENh04oA9tBjQJjFuzIBfYrOAB6PcADCcGElh1gEGAHcKATwAO6ebyjB5CTNlwFwSxFR0BX5HeToYABNgBDh5fm8cfBg6AHIKG3ldA2BHOOcfFNpUygJ0pAhokr4hETFUgDpswywkggAFUwA3MFtgAF5gQgowKhhVKTYKGuFRcXo1aVZgbTIoJ3RW3xhOmB6+wfbcAGsAHi3kgBpgEtGy4AAfG54BWfqAPnZm4AAlZUj4MAkMA8GAGB4vEgfMlLLw6CwPBA8PYRmMgZVgAC6CgmI4cIommQELwICh8RBgKZKvALh1ur0bHQABR5PYMui0Wk7em2ADaAF0AJS0AASABUALIAGQAogR+Mp3CROCAFBBwVC2ikBpj5CgBIqGjizLA5TAFdAmalImAuqlBRoVQh5HBgEy1eDWfs7J5cjzGYKhroVfpDEhHM4MV6GRR5NN0JrtnRg6BVirTFBeHAKYmYY6QNpdB73LmCJZBlSAXAubtvczeSmQMNSuMbmKNgBlHFgPEUNwusBIPAAQlS1xetTmxT0SDoESgdD0C4aACtHMwxytLrohawgA)

	```ts
	interface Article {
			title: string;
			thumbnail: string;
			content: string;
	}

	// Creates new type out of the `Article` interface composed
	// from the Articles' two properties: `title` and `thumbnail`.
	// `ArticlePreview = {title: string; thumbnail: string}`
	type ArticlePreview = Pick<Article, 'title' | 'thumbnail'>;

	// Render a list of articles using only title and description.
	function renderArticlePreviews(previews: ArticlePreview[]): HTMLElement {
			const articles = document.createElement('div');

			for (const preview of previews) {
					// Append preview to the articles.
			}

			return articles;
	}

	const articles = renderArticlePreviews([
			{
				title: 'TypeScript tutorial!',
				thumbnail: '/assets/ts.jpg'
			}
	]);
	```
	</details>

- [`Record<K, T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1429-L1434) - Construct a type with a set of properties `K` of type `T`.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/AQ4ejYAUHsGcCWAXBMB2dgwGbAKYC2ADgDYwCeeemCaWArgE7ADGMxAhmuQHQBQoYEnJE8wALKEARnkaxEKdMAC8wAOS0kstGuAAfdQBM8ANzxlRjXQbVaWACwC0JPB0NqA3HwGgIwAJJoWozYHCxixnAsjAhStADmwESMMJYo1Fi4HMCIaPEu+MRklHj8gpqyoeHAAKJFFFTAAN4+giDYCIxwSAByHAR4AFw5SDF5Xm2gJBzdfQPD3WPxE5PAlBxdAPLYNQAelgh4aOHDaPQEMowrIAC+3oJ+AMKMrlrAXFhSAFZ4LEhC9g4-0BmA4JBISXgiCkBQABpILrJ5MhUGhYcATGD6Bk4Hh-jNgABrPDkOBlXyQAAq9ngYmJpOAAHcEOCRjAXqwYODfoo6DhakUSph+Uh7GI4P0xER4Cj0OSQGwMP8tP1hgAlX7swwAHgRl2RvIANALSA08ABtAC6AD4VM1Wm0Kow0MMrYaHYJjGYLLJXZb3at1HYnC43Go-QHQDcvA6-JsmEJXARgCDgMYWAhjIYhDAU+YiMAAFIwex0ZmilMITCGF79TLAGRsAgJYAAZRwSEZGzEABFTOZUrJ5Yn+jwnWgeER6HB7AAKJrADpdXqS4ZqYultTG6azVfqHswPBbtauLY7fayQ7HIbAAAMwBuAEoYw9IBq2Ixs9h2eFMOQYPQObALQKJgggABeYhghCIpikkKRpOQRIknAsZUiIeCttECBEP8NSMCkjDDAARMGziuIYxHwYOjDCMBmDNnAuTxA6irdCOBB1Lh5Dqpqn66tISIykawBnOCtqqC0gbjqc9DgpGkxegOliyfJDrRkAA)

	```ts
	// Positions of employees in our company.
	type MemberPosition = 'intern' | 'developer' | 'tech-lead';

	// Interface describing properties of a single employee.
	interface Employee {
			firstName: string;
			lastName: string;
			yearsOfExperience: number;
	}

	// Create an object that has all possible `MemberPosition` values set as keys.
	// Those keys will store a collection of Employees of the same position.
	const team: Record<MemberPosition, Employee[]> = {
			intern: [],
			developer: [],
			'tech-lead': [],
	};

	// Our team has decided to help John with his dream of becoming Software Developer.
	team.intern.push({
		firstName: 'John',
		lastName: 'Doe',
		yearsOfExperience: 0
	});

	// `Record` forces you to initialize all of the property keys.
	// TypeScript Error: "tech-lead" property is missing
	const teamEmpty: Record<MemberPosition, null> = {
			intern: null,
			developer: null,
	};
	```
	</details>

- [`Exclude<T, U>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1436-L1439) - Exclude from `T` those types that are assignable to `U`.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/JYOwLgpgTgZghgYwgAgMrQG7QMIHsQzADmyA3gFDLIAOuUYAXMiAK4A2byAPsgM5hRQJHqwC2AI2gBucgF9y5MAE9qKAEoQAjiwj8AEnBAATNtGQBeZAAooWphu26wAGmS3e93bRC8IASgsAPmRDJRlyAHoI5ABRAA8ENhYjFFYOZGVVZBgoXFFkAAM0zh5+QRBhZhYJaAKAOkjogEkQZAQ4X2QAdwALCFbaemRgXmQtFjhOMFwq9K6ULuB0lk6U+HYwZAxJnQaYFhAEMGB8ZCIIMAAFOjAANR2IK0HGWISklIAedCgsKDwCYgAbQA5M9gQBdVzFQJ+JhiSRQMiUYYwayZCC4VHPCzmSzAspCYEBWxgFhQAZwKC+FpgJ43VwARgADH4ZFQSWSBjcZPJyPtDsdTvxKWBvr8rD1DCZoJ5HPopaYoK4EPhCEQmGKcKriLCtrhgEYkVQVT5Nr4fmZLLZtMBbFZgT0wGBqES6ghbHBIJqoBKFdBWQpjfh+DQbhY2tqiHVsbjLMVkAB+ZAAZiZaeQTHOVxu9ySjxNaujNwDVHNvzqbBGkBAdPoAfkQA)

	```ts
	interface ServerConfig {
		port: null | string | number;
	}

	type RequestHandler = (request: Request, response: Response) => void;

	// Exclude `null` type from `null | string | number`.
	// In case the port is equal to `null`, we will use default value.
	function getPortValue(port: Exclude<ServerConfig['port'], null>): number {
		if (typeof port === 'string') {
			return parseInt(port, 10);
		}

		return port;
	}

	function startServer(handler: RequestHandler, config: ServerConfig): void {
		const server = require('http').createServer(handler);

		const port = config.port === null ? 3000 : getPortValue(config.port);
		server.listen(port);
	}
	```
	</details>

- [`Extract<T, U>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1441-L1444) - Extract from `T` those types that are assignable to `U`.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/CYUwxgNghgTiAEAzArgOzAFwJYHtXzSwEdkQBJYACgEoAueVZAWwCMQYBuAKDDwGcM8MgBF4AXngBlAJ6scESgHIRi6ty5ZUGdoihgEABXZ888AN5d48ANoiAuvUat23K6ihMQ9ATE0BzV3goPy8GZjZOLgBfLi4Aejj4AEEICBwAdz54MAALKFQQ+BxEeAAHY1NgKAwoIKy0grr4DByEUpgccpgMaXgAaxBerCzi+B9-ZulygDouFHRsU1z8kKMYE1RhaqgAHkt4AHkWACt4EAAPbVRgLLWNgBp9gGlBs8uQa6yAUUuYPQwdgNpKM7nh7mMML4CgA+R5WABqUAgpDeVxuhxO1he0jsXGh8EoOBO9COx3BQPo2PBADckaR6IjkSA6PBqTgsMBzPsicdrEC7OJWXSQNwYvFEgAVTS9JLXODpeDpKBZFg4GCoWa8VACIJykAKiQWKy2YQOAioYikCg0OEMDyhRSy4DyxS24KhAAMjyi6gS8AAwjh5OD0iBFHAkJoEOksC1mnkMJq8gUQKDNttKPlnfrwYp3J5XfBHXqoKpfYkAOI4ansTxaeDADmoRSCCBYAbxhC6TDx6rwYHIRX5bScjA4bLJwoDmDwDkfbA9JMrVMVdM1TN69LgkTgwgkchUahqIA)

	```ts
	declare function uniqueId(): number;

	const ID = Symbol('ID');

	interface Person {
		[ID]: number;
		name: string;
		age: number;
	}

	// Allows changing the person data as long as the property key is of string type.
	function changePersonData<
		Obj extends Person,
		Key extends Extract<keyof Person, string>,
		Value extends Obj[Key]
	> (obj: Obj, key: Key, value: Value): void {
		obj[key] = value;
	}

	// Tiny Andrew was born.
	const andrew = {
		[ID]: uniqueId(),
		name: 'Andrew',
		age: 0,
	};

	// Cool, we're fine with that.
	changePersonData(andrew, 'name', 'Pony');

	// Goverment didn't like the fact that you wanted to change your identity.
	changePersonData(andrew, ID, uniqueId());
	```
	</details>

- [`NonNullable<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1446-L1449) - Exclude `null` and `undefined` from `T`.
	<details>
	<summary>
			Example
	</summary>
	Works with <code>strictNullChecks</code> set to <code>true</code>. (Read more <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-0.html">here</a>)

	[Playground](https://typescript-play.js.org/?target=6#code/C4TwDgpgBACg9gJ2AOQK4FsBGEFQLxQDOwCAlgHYDmUAPlORtrnQwDasDcAUFwPQBU-WAEMkUOADMowqAGNWwwoSgATCBIqlgpOOSjAAFsOBRSy1IQgr9cKJlSlW1mZYQA3HFH68u8xcoBlHA8EACEHJ08Aby4oKDBUTFZSWXjEFEYcAEIALihkXTR2YSSIAB54JDQsHAA+blj4xOTUsHSACkMzPKD3HHDHNQQAGjSkPMqMmoQASh7g-oihqBi4uNIpdraxPAI2VhmVxrX9AzMAOm2ppnwoAA4ABifuE4BfKAhWSyOTuK7CS7pao3AhXF5rV48E4ICDAVAIPT-cGQyG+XTEIgLMJLTx7CAAdygvRCA0iCHaMwarhJOIQjUBSHaACJHk8mYdeLwxtdcVAAOSsh58+lXdr7Dlcq7A3n3J4PEUdADMcspUE53OluAIUGVTx46oAKuAIAFZGQwCYAKIIBCILjUxaDHAMnla+iodjcIA)

	```ts
	type PortNumber = string | number | null;

	/** Part of a class definition that is used to build a server */
	class ServerBuilder {
			portNumber!: NonNullable<PortNumber>;

			port(this: ServerBuilder, port: PortNumber): ServerBuilder {
					if (port == null) {
							this.portNumber = 8000;
					} else {
							this.portNumber = port;
					}

					return this;
			}
	}

	const serverBuilder = new ServerBuilder();

	serverBuilder
			.port('8000')   // portNumber = '8000'
			.port(null)     // portNumber =  8000
			.port(3000);    // portNumber =  3000

	// TypeScript error
	serverBuilder.portNumber = null;
	```
	</details>

- [`Parameters<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1451-L1454) - Obtain the parameters of a function type in a tuple.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/GYVwdgxgLglg9mABAZwBYmMANgUwBQxgAOIUAXIgIZgCeA2gLoCUFAbnDACaIDeAUIkQB6IYgCypSlBxUATrMo1ECsJzgBbLEoipqAc0J7EMKMgDkiHLnU4wp46pwAPHMgB0fAL58+oSLARECEosLAA5ABUYG2QAHgAxJGdpVWREPDdMylk9ZApqemZEAF4APipacrw-CApEgBogkKwAYThwckQwEHUAIxxZJl4BYVEImiIZKF0oZRwiWVdbeygJmThgOYgcGFYcbhqApCJsyhtpWXcR1cnEePBoeDAABVPzgbTixFeFd8uEsClADcIxGiygIFkSEOT3SmTc2VydQeRx+ZxwF2QQ34gkEwDgsnSuFmMBKiAADEDjIhYk1Qm0OlSYABqZnYka4xA1DJZHJYkGc7yCbyeRA+CAIZCzNAYbA4CIAdxg2zJwVCkWirjwMswuEaACYmCCgA)

	```ts
	function shuffle(input: any[]): void {
		// Mutate array randomly changing its' elements indexes.
	}

	function callNTimes<Fn extends (...args: any[]) => any> (func: Fn, callCount: number) {
		// Type that represents the type of the received function parameters.
		type FunctionParameters = Parameters<Fn>;

		return function (...args: FunctionParameters) {
			for (let i = 0; i < callCount; i++) {
				func(...args);
			}
		}
	}

	const shuffleTwice = callNTimes(shuffle, 2);
	```
	</details>

- [`ConstructorParameters<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1456-L1459) - Obtain the parameters of a constructor function type in a tuple.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/MYGwhgzhAECCBOAXAlqApgWQPYBM0mgG8AoaaFRENALmgkXmQDsBzAblOmCycTV4D8teo1YdO3JiICuwRFngAKClWENmLAJRFOZRAAtkEAHQq00ALzlklNBzIBfYk+KhIMAJJTEYJsDQAwmDA+mgAPAAq0GgAHnxMODCKTGgA7tCKxllg8CwQtL4AngDaALraFgB80EWa1SRkAA6MAG5gfNAB4FABPDJyCrQR9tDNyG0dwMGhtBhgjWEiGgA00F70vv4RhY3hEZXVVinpc42KmuJkkv3y8Bly8EPaDWTkhiZd7r3e8LK3llwGCMXGQWGhEOsfH5zJlsrl8p0+gw-goAAo5MAAW3BaHgEEilU0tEhmzQ212BJ0ry4SOg+kg+gBBiMximIGA0nAfAQLGk2N4EAAEgzYcYcnkLsRdDTvNEYkYUKwSdCme9WdM0MYwYhFPSIPpJdTkAAzDKxBUaZX+aAAQgsVmkCTQxuYaBw2ng4Ok8CYcotSu8pMur09iG9vuObxZnx6SN+AyUWTF8MN0CcZE4Ywm5jZHK5aB5fP4iCFIqT4oRRTKRLo6lYVNeAHpG50wOzOe1zHr9NLQ+HoABybsD4HOKXXRA1JCoKhBELmI5pNaB6Fz0KKBAodDYPAgSUTmqYsAALx4m5nC6nW9nGq14KtaEUA9gR9PvuNCjQ9BgACNvcwNBtAcLiAA)

	```ts
	class ArticleModel {
		title: string;
		content?: string;

		constructor(title: string) {
			this.title = title;
		}
	}

	class InstanceCache<T extends (new (...args: any[]) => any)> {
		private ClassConstructor: T;
		private cache: Map<string, InstanceType<T>> = new Map();

		constructor (ctr: T) {
			this.ClassConstructor = ctr;
		}

		getInstance (...args: ConstructorParameters<T>): InstanceType<T> {
			const hash = this.calculateArgumentsHash(...args);

			const existingInstance = this.cache.get(hash);
			if (existingInstance !== undefined) {
				return existingInstance;
			}

			return new this.ClassConstructor(...args);
		}

		private calculateArgumentsHash(...args: any[]): string {
			// Calculate hash.
			return 'hash';
		}
	}

	const articleCache = new InstanceCache(ArticleModel);
	const amazonArticle = articleCache.getInstance('Amazon forests burining!');
	```
	</details>

- [`ReturnType<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1461-L1464) – Obtain the return type of a function type.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/MYGwhgzhAECSAmICmBlJAnAbgS2E6A3gFDTTwD2AcuQC4AW2AdgOYAUAlAFzSbnbyEAvkWFFQkGJSQB3GMVI1sNZNwg10TZgG4S0YOUY0kh1es07d+xmvQBXYDXLpWi5UlMaWAGj0GjJ6BtNdkJdBQYIADpXZGgAXmgYpB1ScOwoq38aeN9DYxoU6GFRKzVoJjUwRjwAYXJbPPRuAFkwAAcAHgAxBodsAx9GWwBbACMMAD4cxhloVraOCyYjdAAzMDxoOut1e0d0UNIZ6WhWSPOwdGYIbiqATwBtAF0uaHudUQB6ACpv6ABpJBINqJdAbADW0Do5BOw3u5R2VTwMHIq2gAANtjZ0bkbHsnFCwJh8ONjHp0EgwEZ4JFoN9PkRVr1FAZoMwkDRYIjqkgOrosepoEgAB7+eAwAV2BxOLy6ACCVxgIrFEoMeOl6AACpcwMMORgIB1JRMiBNWKVdhruJKfOdIpdrtwFddXlzKjyACp3Nq842HaDIbL6BrZBIVGhIpB1EMYSLsmjmtWW-YhAA+qegAAYLKQLQj3ZsEsdccmnGcLor2Dn8xGedHGpEIBzEzspfsfMHDNAANTQACMVaIljV5GQkRA5DYmIpVKQAgAJARO9le33BDXIyi0YuLW2nJFGLqkOvxFB0YPdBSaLZ0IwNzyPkO8-xkGgsLh8Al427a3hWAhXwwHA8EHT5PmgAB1bAQBAANJ24adKWpft72RaBUTgRBUCAj89HAM8xCTaBjggABRQx0DuHJv25P9dCkWRZVIAAiBjoFImpmjlFBgA0NpsjadByDacgIDAEAIAAQmYpjoGYgAZSBsmGPw6DtZiiFA8CoJguDmAQmoZ2QvtUKQLdoAYmBTwgdEiCAA)

	```ts
	/** Provides every element of the iterable `iter` into the `callback` function and stores the results in an array. */
	function mapIter<
			Elem,
			Func extends (elem: Elem) => any,
			Ret extends ReturnType<Func>
	>(iter: Iterable<Elem>, callback: Func): Ret[] {
			const mapped: Ret[] = [];

			for (const elem of iter) {
					mapped.push(callback(elem));
			}

			return mapped;
	}

	const setObject: Set<string> = new Set();
	const mapObject: Map<number, string> = new Map();

	mapIter(setObject, (value: string) => value.indexOf('Foo')); // number[]

	mapIter(mapObject, ([key, value]: [number, string]) => {
			return key % 2 === 0 ? value : 'Odd';
	}); // string[]
	```
	</details>

- [`InstanceType<T>`](https://github.com/Microsoft/TypeScript/blob/2961bc3fc0ea1117d4e53bc8e97fa76119bc33e3/src/lib/es5.d.ts#L1466-L1469) – Obtain the instance type of a constructor function type.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/MYGwhgzhAECSAmICmBlJAnAbgS2E6A3gFDTTwD2AcuQC4AW2AdgOYAUAlAFzSbnbyEAvkWFFQkGJSQB3GMVI1sNZNwg10TZgG4S0YOUY0kh1es07d+xmvQBXYDXLpWi5UlMaWAGj0GjJ6BtNdkJdBQYIADpXZGgAXmgYpB1ScOwoq38aeN9DYxoU6GFRKzVoJjUwRjwAYXJbPPRuAFkwAAcAHgAxBodsAx9GWwBbACMMAD4cxhloVraOCyYjdAAzMDxoOut1e0d0UNIZ6WhWSPOwdGYIbiqATwBtAF0uaHudUQB6ACpv6ABpJBINqJdAbADW0Do5BOw3u5R2VTwMHIq2gAANtjZ0bkbHsnFCwJh8ONjHp0EgwEZ4JFoN9PkRVr1FAZoMwkDRYIjqkgOrosepoEgAB7+eAwAV2BxOLy6ACCVxgIrFEoMeOl6AACpcwMMORgIB1JRMiBNWKVdhruJKfOdIpdrtwFddXlzKjyACp3Nq842HaDIbL6BrZBIVGhIpB1EMYSLsmjmtWW-YhAA+qegAAYLKQLQj3ZsEsdccmnGcLor2Dn8xGedHGpEIBzEzspfsfMHDNAANTQACMVaIljV5GQkRA5DYmIpVKQAgAJARO9le33BDXIyi0YuLW2nJFGLqkOvxFB0YPdBSaLZ0IwNzyPkO8-xkGgsLh8Al427a3hWAhXwwHA8EHT5PmgAB1bAQBAANJ24adKWpft72RaBUTgRBUCAj89HAM8xCTaBjggABRQx0DuHJv25P9dCkWRZVIAAiBjoFImpmjlFBgA0NpsjadByDacgIDAEAIAAQmYpjoGYgAZSBsmGPw6DtZiiFA8CoJguDmAQmoZ2QvtUKQLdoAYmBTwgdEiCAA)

	```ts
	class IdleService {
			doNothing (): void {}
	}

	class News {
			title: string;
			content: string;

			constructor(title: string, content: string) {
					this.title = title;
					this.content = content;
			}
	}

	const instanceCounter: Map<Function, number> = new Map();

	interface Constructor {
			new(...args: any[]): any;
	}

	// Keep track how many instances of `Constr` constructor have been created.
	function getInstance<
			Constr extends Constructor,
			Args extends ConstructorParameters<Constr>
	>(constructor: Constr, ...args: Args): InstanceType<Constr> {
			let count = instanceCounter.get(constructor) || 0;

			const instance = new constructor(...args);

			instanceCounter.set(constructor, count + 1);

			console.log(`Created ${count + 1} instances of ${Constr.name} class`);

			return instance;
	}


	const idleService = getInstance(IdleService);
	// Will log: `Created 1 instances of IdleService class`
	const newsEntry = getInstance(News, 'New ECMAScript proposals!', 'Last month...');
	// Will log: `Created 1 instances of News class`
	```
	</details>

- [`Omit<T, K>`](https://github.com/microsoft/TypeScript/blob/71af02f7459dc812e85ac31365bfe23daf14b4e4/src/lib/es5.d.ts#L1446) – Constructs a type by picking all properties from T and then removing K.
	<details>
	<summary>
			Example
	</summary>

	[Playground](https://typescript-play.js.org/?target=6#code/JYOwLgpgTgZghgYwgAgIImAWzgG2QbwChlks4BzCAVShwC5kBnMKUcgbmKYAcIFgIjBs1YgOXMpSFMWbANoBdTiW5woFddwAW0kfKWEAvoUIB6U8gDCUCHEiNkICAHdkYAJ69kz4GC3JcPG4oAHteKDABBxCYNAxsPFBIWEQUCAAPJG4wZABySUFcgJAAEzMLXNV1ck0dIuCw6EjBADpy5AB1FAQ4EGQAV0YUP2AHDy8wEOQbUugmBLwtEIA3OcmQnEjuZBgQqE7gAGtgZAhwKHdkHFGwNvGUdDIcAGUliIBJEF3kAF5kAHlML4ADyPBIAGjyBUYRQAPnkqho4NoYQA+TiEGD9EAISIhPozErQMG4AASK2gn2+AApek9pCSXm8wFSQooAJQMUkAFQAsgAZACiOAgmDOOSIJAQ+OYyGl4DgoDmf2QJRCCH6YvALQQNjsEGFovF1NyJWAy1y7OUyHMyE+yRAuFImG4Iq1YDswHxbRINjA-SgfXlHqVUE4xiAA)

	```ts
	interface Animal {
			imageUrl: string;
			species: string;
			images: string[];
			paragraphs: string[];
	}

	// Creates new type with all properties of the `Animal` interface
	// except 'images' and 'paragraphs' properties. We can use this
	// type to render small hover tooltip for a wiki entry list.
	type AnimalShortInfo = Omit<Animal, 'images' | 'paragraphs'>;

	function renderAnimalHoverInfo (animals: AnimalShortInfo[]): HTMLElement {
			const container =  document.createElement('div');
			// Internal implementation.
			return container;
	}
	```
	</details>

You can find some examples in the [TypeScript docs](https://www.typescriptlang.org/docs/handbook/advanced-types.html#predefined-conditional-types).

## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Jarek Radosz](https://github.com/CvX)
- [Dimitri Benin](https://github.com/BendingBender)
- [Pelle Wessman](https://github.com/voxpelli)

## License

(MIT OR CC0-1.0)

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-type-fest?utm_source=npm-type-fest&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# Punycode.js [![punycode on npm](https://img.shields.io/npm/v/punycode)](https://www.npmjs.com/package/punycode) [![](https://data.jsdelivr.com/v1/package/npm/punycode/badge)](https://www.jsdelivr.com/package/npm/punycode)

Punycode.js is a robust Punycode converter that fully complies to [RFC 3492](https://tools.ietf.org/html/rfc3492) and [RFC 5891](https://tools.ietf.org/html/rfc5891).

This JavaScript library is the result of comparing, optimizing and documenting different open-source implementations of the Punycode algorithm:

* [The C example code from RFC 3492](https://tools.ietf.org/html/rfc3492#appendix-C)
* [`punycode.c` by _Markus W. Scherer_ (IBM)](http://opensource.apple.com/source/ICU/ICU-400.42/icuSources/common/punycode.c)
* [`punycode.c` by _Ben Noordhuis_](https://github.com/bnoordhuis/punycode/blob/master/punycode.c)
* [JavaScript implementation by _some_](http://stackoverflow.com/questions/183485/can-anyone-recommend-a-good-free-javascript-for-punycode-to-unicode-conversion/301287#301287)
* [`punycode.js` by _Ben Noordhuis_](https://github.com/joyent/node/blob/426298c8c1c0d5b5224ac3658c41e7c2a3fe9377/lib/punycode.js) (note: [not fully compliant](https://github.com/joyent/node/issues/2072))

This project was [bundled](https://github.com/joyent/node/blob/master/lib/punycode.js) with Node.js from [v0.6.2+](https://github.com/joyent/node/compare/975f1930b1...61e796decc) until [v7](https://github.com/nodejs/node/pull/7941) (soft-deprecated).

This project provides a CommonJS module that uses ES2015+ features and JavaScript module, which work in modern Node.js versions and browsers. For the old Punycode.js version that offers the same functionality in a UMD build with support for older pre-ES2015 runtimes, including Rhino, Ringo, and Narwhal, see [v1.4.1](https://github.com/mathiasbynens/punycode.js/releases/tag/v1.4.1).

## Installation

Via [npm](https://www.npmjs.com/):

```bash
npm install punycode --save
```

In [Node.js](https://nodejs.org/):

> ⚠️ Note that userland modules don't hide core modules.
> For example, `require('punycode')` still imports the deprecated core module even if you executed `npm install punycode`.
> Use `require('punycode/')` to import userland modules rather than core modules.

```js
const punycode = require('punycode/');
```

## API

### `punycode.decode(string)`

Converts a Punycode string of ASCII symbols to a string of Unicode symbols.

```js
// decode domain name parts
punycode.decode('maana-pta'); // 'mañana'
punycode.decode('--dqo34k'); // '☃-⌘'
```

### `punycode.encode(string)`

Converts a string of Unicode symbols to a Punycode string of ASCII symbols.

```js
// encode domain name parts
punycode.encode('mañana'); // 'maana-pta'
punycode.encode('☃-⌘'); // '--dqo34k'
```

### `punycode.toUnicode(input)`

Converts a Punycode string representing a domain name or an email address to Unicode. Only the Punycoded parts of the input will be converted, i.e. it doesn’t matter if you call it on a string that has already been converted to Unicode.

```js
// decode domain names
punycode.toUnicode('xn--maana-pta.com');
// → 'mañana.com'
punycode.toUnicode('xn----dqo34k.com');
// → '☃-⌘.com'

// decode email addresses
punycode.toUnicode('джумла@xn--p-8sbkgc5ag7bhce.xn--ba-lmcq');
// → 'джумла@джpумлатест.bрфa'
```

### `punycode.toASCII(input)`

Converts a lowercased Unicode string representing a domain name or an email address to Punycode. Only the non-ASCII parts of the input will be converted, i.e. it doesn’t matter if you call it with a domain that’s already in ASCII.

```js
// encode domain names
punycode.toASCII('mañana.com');
// → 'xn--maana-pta.com'
punycode.toASCII('☃-⌘.com');
// → 'xn----dqo34k.com'

// encode email addresses
punycode.toASCII('джумла@джpумлатест.bрфa');
// → 'джумла@xn--p-8sbkgc5ag7bhce.xn--ba-lmcq'
```

### `punycode.ucs2`

#### `punycode.ucs2.decode(string)`

Creates an array containing the numeric code point values of each Unicode symbol in the string. While [JavaScript uses UCS-2 internally](https://mathiasbynens.be/notes/javascript-encoding), this function will convert a pair of surrogate halves (each of which UCS-2 exposes as separate characters) into a single code point, matching UTF-16.

```js
punycode.ucs2.decode('abc');
// → [0x61, 0x62, 0x63]
// surrogate pair for U+1D306 TETRAGRAM FOR CENTRE:
punycode.ucs2.decode('\uD834\uDF06');
// → [0x1D306]
```

#### `punycode.ucs2.encode(codePoints)`

Creates a string based on an array of numeric code point values.

```js
punycode.ucs2.encode([0x61, 0x62, 0x63]);
// → 'abc'
punycode.ucs2.encode([0x1D306]);
// → '\uD834\uDF06'
```

### `punycode.version`

A string representing the current Punycode.js version number.

## For maintainers

### How to publish a new release

1. On the `main` branch, bump the version number in `package.json`:

    ```sh
    npm version patch -m 'Release v%s'
    ```

    Instead of `patch`, use `minor` or `major` [as needed](https://semver.org/).

    Note that this produces a Git commit + tag.

1. Push the release commit and tag:

    ```sh
    git push && git push --tags
    ```

    Our CI then automatically publishes the new release to npm, under both the [`punycode`](https://www.npmjs.com/package/punycode) and [`punycode.js`](https://www.npmjs.com/package/punycode.js) names.

## Author

| [![twitter/mathias](https://gravatar.com/avatar/24e08a9ea84deb17ae121074d0f17125?s=70)](https://twitter.com/mathias "Follow @mathias on Twitter") |
|---|
| [Mathias Bynens](https://mathiasbynens.be/) |

## License

Punycode.js is available under the [MIT](https://mths.be/mit) license.
# v3.0

- Add `--preserve-root` option to executable (default true)
- Drop support for Node.js below version 6

# v2.7

- Make `glob` an optional dependency

# 2.6

- Retry on EBUSY on non-windows platforms as well
- Make `rimraf.sync` 10000% more reliable on Windows

# 2.5

- Handle Windows EPERM when lstat-ing read-only dirs
- Add glob option to pass options to glob

# 2.4

- Add EPERM to delay/retry loop
- Add `disableGlob` option

# 2.3

- Make maxBusyTries and emfileWait configurable
- Handle weird SunOS unlink-dir issue
- Glob the CLI arg for better Windows support

# 2.2

- Handle ENOENT properly on Windows
- Allow overriding fs methods
- Treat EPERM as indicative of non-empty dir
- Remove optional graceful-fs dep
- Consistently return null error instead of undefined on success
- win32: Treat ENOTEMPTY the same as EBUSY
- Add `rimraf` binary

# 2.1

- Fix SunOS error code for a non-empty directory
- Try rmdir before readdir
- Treat EISDIR like EPERM
- Remove chmod
- Remove lstat polyfill, node 0.7 is not supported

# 2.0

- Fix myGid call to check process.getgid
- Simplify the EBUSY backoff logic.
- Use fs.lstat in node >= 0.7.9
- Remove gently option
- remove fiber implementation
- Delete files that are marked read-only

# 1.0

- Allow ENOENT in sync method
- Throw when no callback is provided
- Make opts.gently an absolute path
- use 'stat' if 'lstat' is not available
- Consistent error naming, and rethrow non-ENOENT stat errors
- add fiber implementation
[![Build Status](https://travis-ci.org/isaacs/rimraf.svg?branch=master)](https://travis-ci.org/isaacs/rimraf) [![Dependency Status](https://david-dm.org/isaacs/rimraf.svg)](https://david-dm.org/isaacs/rimraf) [![devDependency Status](https://david-dm.org/isaacs/rimraf/dev-status.svg)](https://david-dm.org/isaacs/rimraf#info=devDependencies)

The [UNIX command](http://en.wikipedia.org/wiki/Rm_(Unix)) `rm -rf` for node.

Install with `npm install rimraf`, or just drop rimraf.js somewhere.

## API

`rimraf(f, [opts], callback)`

The first parameter will be interpreted as a globbing pattern for files. If you
want to disable globbing you can do so with `opts.disableGlob` (defaults to
`false`). This might be handy, for instance, if you have filenames that contain
globbing wildcard characters.

The callback will be called with an error if there is one.  Certain
errors are handled for you:

* Windows: `EBUSY` and `ENOTEMPTY` - rimraf will back off a maximum of
  `opts.maxBusyTries` times before giving up, adding 100ms of wait
  between each attempt.  The default `maxBusyTries` is 3.
* `ENOENT` - If the file doesn't exist, rimraf will return
  successfully, since your desired outcome is already the case.
* `EMFILE` - Since `readdir` requires opening a file descriptor, it's
  possible to hit `EMFILE` if too many file descriptors are in use.
  In the sync case, there's nothing to be done for this.  But in the
  async case, rimraf will gradually back off with timeouts up to
  `opts.emfileWait` ms, which defaults to 1000.

## options

* unlink, chmod, stat, lstat, rmdir, readdir,
  unlinkSync, chmodSync, statSync, lstatSync, rmdirSync, readdirSync

    In order to use a custom file system library, you can override
    specific fs functions on the options object.

    If any of these functions are present on the options object, then
    the supplied function will be used instead of the default fs
    method.

    Sync methods are only relevant for `rimraf.sync()`, of course.

    For example:

    ```javascript
    var myCustomFS = require('some-custom-fs')

    rimraf('some-thing', myCustomFS, callback)
    ```

* maxBusyTries

    If an `EBUSY`, `ENOTEMPTY`, or `EPERM` error code is encountered
    on Windows systems, then rimraf will retry with a linear backoff
    wait of 100ms longer on each try.  The default maxBusyTries is 3.

    Only relevant for async usage.

* emfileWait

    If an `EMFILE` error is encountered, then rimraf will retry
    repeatedly with a linear backoff of 1ms longer on each try, until
    the timeout counter hits this max.  The default limit is 1000.

    If you repeatedly encounter `EMFILE` errors, then consider using
    [graceful-fs](http://npm.im/graceful-fs) in your program.

    Only relevant for async usage.

* glob

    Set to `false` to disable [glob](http://npm.im/glob) pattern
    matching.

    Set to an object to pass options to the glob module.  The default
    glob options are `{ nosort: true, silent: true }`.

    Glob version 6 is used in this module.

    Relevant for both sync and async usage.

* disableGlob

    Set to any non-falsey value to disable globbing entirely.
    (Equivalent to setting `glob: false`.)

## rimraf.sync

It can remove stuff synchronously, too.  But that's not so good.  Use
the async API.  It's better.

## CLI

If installed with `npm install rimraf -g` it can be used as a global
command `rimraf <path> [<path> ...]` which is useful for cross platform support.

## mkdirp

If you need to create a directory recursively, check out
[mkdirp](https://github.com/substack/node-mkdirp).
# fast-json-stable-stringify

Deterministic `JSON.stringify()` - a faster version of [@substack](https://github.com/substack)'s json-stable-strigify without [jsonify](https://github.com/substack/jsonify).

You can also pass in a custom comparison function.

[![Build Status](https://travis-ci.org/epoberezkin/fast-json-stable-stringify.svg?branch=master)](https://travis-ci.org/epoberezkin/fast-json-stable-stringify)
[![Coverage Status](https://coveralls.io/repos/github/epoberezkin/fast-json-stable-stringify/badge.svg?branch=master)](https://coveralls.io/github/epoberezkin/fast-json-stable-stringify?branch=master)

# example

``` js
var stringify = require('fast-json-stable-stringify');
var obj = { c: 8, b: [{z:6,y:5,x:4},7], a: 3 };
console.log(stringify(obj));
```

output:

```
{"a":3,"b":[{"x":4,"y":5,"z":6},7],"c":8}
```


# methods

``` js
var stringify = require('fast-json-stable-stringify')
```

## var str = stringify(obj, opts)

Return a deterministic stringified string `str` from the object `obj`.


## options

### cmp

If `opts` is given, you can supply an `opts.cmp` to have a custom comparison
function for object keys. Your function `opts.cmp` is called with these
parameters:

``` js
opts.cmp({ key: akey, value: avalue }, { key: bkey, value: bvalue })
```

For example, to sort on the object key names in reverse order you could write:

``` js
var stringify = require('fast-json-stable-stringify');

var obj = { c: 8, b: [{z:6,y:5,x:4},7], a: 3 };
var s = stringify(obj, function (a, b) {
    return a.key < b.key ? 1 : -1;
});
console.log(s);
```

which results in the output string:

```
{"c":8,"b":[{"z":6,"y":5,"x":4},7],"a":3}
```

Or if you wanted to sort on the object values in reverse order, you could write:

```
var stringify = require('fast-json-stable-stringify');

var obj = { d: 6, c: 5, b: [{z:3,y:2,x:1},9], a: 10 };
var s = stringify(obj, function (a, b) {
    return a.value < b.value ? 1 : -1;
});
console.log(s);
```

which outputs:

```
{"d":6,"c":5,"b":[{"z":3,"y":2,"x":1},9],"a":10}
```

### cycles

Pass `true` in `opts.cycles` to stringify circular property as `__cycle__` - the result will not be a valid JSON string in this case.

TypeError will be thrown in case of circular object without this option.


# install

With [npm](https://npmjs.org) do:

```
npm install fast-json-stable-stringify
```


# benchmark

To run benchmark (requires Node.js 6+):
```
node benchmark
```

Results:
```
fast-json-stable-stringify x 17,189 ops/sec ±1.43% (83 runs sampled)
json-stable-stringify x 13,634 ops/sec ±1.39% (85 runs sampled)
fast-stable-stringify x 20,212 ops/sec ±1.20% (84 runs sampled)
faster-stable-stringify x 15,549 ops/sec ±1.12% (84 runs sampled)
The fastest is fast-stable-stringify
```


## Enterprise support

fast-json-stable-stringify package is a part of [Tidelift enterprise subscription](https://tidelift.com/subscription/pkg/npm-fast-json-stable-stringify?utm_source=npm-fast-json-stable-stringify&utm_medium=referral&utm_campaign=enterprise&utm_term=repo) - it provides a centralised commercial support to open-source software users, in addition to the support provided by software maintainers.


## Security contact

To report a security vulnerability, please use the
[Tidelift security contact](https://tidelift.com/security).
Tidelift will coordinate the fix and disclosure. Please do NOT report security vulnerability via GitHub issues.


# license

[MIT](https://github.com/epoberezkin/fast-json-stable-stringify/blob/master/LICENSE)
(MIT)

Copyright (c) 2013 Julian Gruber &lt;julian@juliangruber.com&gt;

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
# balanced-match

Match balanced string pairs, like `{` and `}` or `<b>` and `</b>`. Supports regular expressions as well!

[![build status](https://secure.travis-ci.org/juliangruber/balanced-match.svg)](http://travis-ci.org/juliangruber/balanced-match)
[![downloads](https://img.shields.io/npm/dm/balanced-match.svg)](https://www.npmjs.org/package/balanced-match)

[![testling badge](https://ci.testling.com/juliangruber/balanced-match.png)](https://ci.testling.com/juliangruber/balanced-match)

## Example

Get the first matching pair of braces:

```js
var balanced = require('balanced-match');

console.log(balanced('{', '}', 'pre{in{nested}}post'));
console.log(balanced('{', '}', 'pre{first}between{second}post'));
console.log(balanced(/\s+\{\s+/, /\s+\}\s+/, 'pre  {   in{nest}   }  post'));
```

The matches are:

```bash
$ node example.js
{ start: 3, end: 14, pre: 'pre', body: 'in{nested}', post: 'post' }
{ start: 3,
  end: 9,
  pre: 'pre',
  body: 'first',
  post: 'between{second}post' }
{ start: 3, end: 17, pre: 'pre', body: 'in{nest}', post: 'post' }
```

## API

### var m = balanced(a, b, str)

For the first non-nested matching pair of `a` and `b` in `str`, return an
object with those keys:

* **start** the index of the first match of `a`
* **end** the index of the matching `b`
* **pre** the preamble, `a` and `b` not included
* **body** the match, `a` and `b` not included
* **post** the postscript, `a` and `b` not included

If there's no match, `undefined` will be returned.

If the `str` contains more `a` than `b` / there are unmatched pairs, the first match that was closed will be used. For example, `{{a}` will match `['{', 'a', '']` and `{a}}` will match `['', 'a', '}']`.

### var r = balanced.range(a, b, str)

For the first non-nested matching pair of `a` and `b` in `str`, return an
array with indexes: `[ <a index>, <b index> ]`.

If there's no match, `undefined` will be returned.

If the `str` contains more `a` than `b` / there are unmatched pairs, the first match that was closed will be used. For example, `{{a}` will match `[ 1, 3 ]` and `{a}}` will match `[0, 2]`.

## Installation

With [npm](https://npmjs.org) do:

```bash
npm install balanced-match
```

## Security contact information

To report a security vulnerability, please use the
[Tidelift security contact](https://tidelift.com/security).
Tidelift will coordinate the fix and disclosure.

## License

(MIT)

Copyright (c) 2013 Julian Gruber &lt;julian@juliangruber.com&gt;

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
# path-exists [![Build Status](https://travis-ci.org/sindresorhus/path-exists.svg?branch=master)](https://travis-ci.org/sindresorhus/path-exists)

> Check if a path exists

NOTE: `fs.existsSync` has been un-deprecated in Node.js since 6.8.0. If you only need to check synchronously, this module is not needed.

While [`fs.exists()`](https://nodejs.org/api/fs.html#fs_fs_exists_path_callback) is being [deprecated](https://github.com/iojs/io.js/issues/103), there's still a genuine use-case of being able to check if a path exists for other purposes than doing IO with it.

Never use this before handling a file though:

> In particular, checking if a file exists before opening it is an anti-pattern that leaves you vulnerable to race conditions: another process may remove the file between the calls to `fs.exists()` and `fs.open()`. Just open the file and handle the error when it's not there.


## Install

```
$ npm install path-exists
```


## Usage

```js
// foo.js
const pathExists = require('path-exists');

(async () => {
	console.log(await pathExists('foo.js'));
	//=> true
})();
```


## API

### pathExists(path)

Returns a `Promise<boolean>` of whether the path exists.

### pathExists.sync(path)

Returns a `boolean` of whether the path exists.


## Related

- [path-exists-cli](https://github.com/sindresorhus/path-exists-cli) - CLI for this module


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
Changelog
=========

### 2.29.4

* Release Jul 6, 2022
  * [#6015](https://github.com/moment/moment/pull/6015) [bugfix] Fix ReDoS in preprocessRFC2822 regex

### 2.29.3 [Full changelog](https://gist.github.com/ichernev/edebd440f49adcaec72e5e77b791d8be)

* Release Apr 17, 2022
  * [#5995](https://github.com/moment/moment/pull/5995) [bugfix] Remove const usage
  * [#5990](https://github.com/moment/moment/pull/5990) misc: fix advisory link


### 2.29.2 [See full changelog](https://gist.github.com/ichernev/1904b564f6679d9aac1ae08ce13bc45c)

* Release Apr 3 2022

Address https://github.com/moment/moment/security/advisories/GHSA-8hfj-j24r-96c4

### 2.29.1 [See full changelog](https://gist.github.com/marwahaha/cc478ba01a1292ab4bd4e861d164d99b)

* Release Oct 6, 2020

Updated deprecation message, bugfix in hi locale

### 2.29.0 [See full changelog](https://gist.github.com/marwahaha/b0111718641a6461800066549957ec14)

* Release Sept 22, 2020

New locales (es-mx, bn-bd).
Minor bugfixes and locale improvements.
More tests.
Moment is in maintenance mode. Read more at this link:
https://momentjs.com/docs/#/-project-status/

### 2.28.0 [See full changelog](https://gist.github.com/marwahaha/028fd6c2b2470b2804857cfd63c0e94f)

* Release Sept 13, 2020

Fix bug where .format() modifies original instance, and locale updates

### 2.27.0 [See full changelog](https://gist.github.com/marwahaha/5100c9c2f42019067b1f6cefc333daa7)

* Release June 18, 2020

Added Turkmen locale, other locale improvements, slight TypeScript fixes

### 2.26.0 [See full changelog](https://gist.github.com/marwahaha/0725c40740560854a849b096ea7b7590)

* Release May 19, 2020

TypeScript fixes and many locale improvements

### 2.25.3

* Release May 4, 2020

Remove package.json module property. It looks like webpack behaves differently
for modules loaded via module vs jsnext:main.

### 2.25.2

* Release May 4, 2020

This release includes ES Module bundled moment, separate from it's source code
under dist/ folder. This might alleviate issues with finding the `./locale
subfolder for loading locales. This might also mean now webpack will bundle all
locales automatically, unless told otherwise.

### 2.25.1

* Release May 1, 2020

This is a quick patch release to address some of the issues raised after
releasing 2.25.0.

* [2e268635](https://github.com/moment/moment/commit/2e268635) [misc] Revert #5269 due to webpack warning
* [226799e1](https://github.com/moment/moment/commit/226799e1) [locale] fil: Fix metadata comment
* [a83a521](https://github.com/moment/moment/commit/a83a521) [bugfix] Fix typeoff usages
* [e324334](https://github.com/moment/moment/commit/e324334) [pkg] Add ts3.1-typings in npm package
* [28cc23e](https://github.com/moment/moment/commit/28cc23e) [misc] Remove deleted generated locale en-SG

### 2.25.0 [See full changelog](https://gist.github.com/ichernev/6148e64df2427e455b10ce6a18de1a65)

* Release May 1, 2020

* [#4611](https://github.com/moment/moment/issues/4611) [022dc038](https://github.com/moment/moment/commit/022dc038) [feature] Support for strict string parsing, fixes [#2469](https://github.com/moment/moment/issues/2469)
* [#4599](https://github.com/moment/moment/issues/4599) [4b615b9d](https://github.com/moment/moment/commit/4b615b9d) [feature] Add support for eras in en and jp
* [#4296](https://github.com/moment/moment/issues/4296) [757d4ff8](https://github.com/moment/moment/commit/757d4ff8) [feature] Accept custom relative thresholds in duration.humanize

* 18 bigfixes
* 36 locale fixes
* 5 new locales (oc-lnc, zh-mo, en-in, gom-deva, fil)

### 2.24.0 [See full changelog](https://gist.github.com/marwahaha/12366fe45bee328f33acf125d4cd540e)

* Release Jan 21, 2019

* [#4338](https://github.com/moment/moment/pull/4338) [bugfix] Fix startOf/endOf DST issues while boosting performance
* [#4553](https://github.com/moment/moment/pull/4553) [feature] Add localeSort param to Locale weekday methods
* [#4887](https://github.com/moment/moment/pull/4887) [bugfix] Make Duration#as work with quarters
* 3 new locales (it-ch, ga, en-SG)
* Lots of locale improvements

### 2.23.0 [See full changelog](https://gist.github.com/marwahaha/eadb7ac11b761290399a576f8b2419a5)

* Release Dec 12, 2018

* [#4863](https://github.com/moment/moment/pull/4863) [new locale] added Kurdish language (ku)
* [#4417](https://github.com/moment/moment/pull/4417) [bugfix] isBetween should return false for invalid dates
* [#4700](https://github.com/moment/moment/pull/4700) [bugfix] Fix [#4698](https://github.com/moment/moment/pull/4698): Use ISO WeekYear for HTML5_FMT.WEEK
* [#4563](https://github.com/moment/moment/pull/4563) [feature] Fix [#4518](https://github.com/moment/moment/pull/4518): Add support to add/subtract ISO weeks
* other locale changes, build process changes, typos

### 2.22.2 [See full changelog](https://gist.github.com/marwahaha/4d992c13c2dbc0f59d4d8acae1dc6d3a)

* Release May 31, 2018

* [#4564](https://github.com/moment/moment/pull/4564) [bugfix] Avoid using trim()
* [#4453](https://github.com/moment/moment/pull/4453) [bugfix] Treat periods as periods, not regex-anything period, for weekday parsing in strict mode.
* Minor locale improvements (pa-in, be, az)

### 2.22.1 [See full changelog](https://gist.github.com/marwahaha/ff2cd13d0eda08afb7a237b10aae558c)

* Release Apr 14, 2018

* [#4495](https://github.com/moment/moment/pull/4495) [bugfix] Added HTML5_FMT to moment.d.ts
* Minor locale improvements
* QUnit upgrade and coveralls reporting

### 2.22.0 [See full changelog](https://gist.github.com/marwahaha/ae895025dac3f0641fa9ec2e36d282bb)

* Release Mar 30, 2018

* [#4423](https://github.com/moment/moment/pull/4423) [new locale] Added Mongolian locale mn
* Various locale improvements
* Minor misc changes

### 2.21.0 [See full changelog](https://gist.github.com/marwahaha/80d19ef882b71df1948df7865efdd40e)

* Release Mar 2, 2018

* [#4391](https://github.com/moment/moment/pull/4391) [bugfix] Fix [#4390](https://github.com/moment/moment/pull/4390): use offset properly in toISOString
* [#4310](https://github.com/moment/moment/pull/4310) [bugfix] Fix [#3883](https://github.com/moment/moment/pull/3883) lazy load parentLocale in defineLocale, fallback to global if missing
* [#4085](https://github.com/moment/moment/pull/4085) [misc] Print console warning when setting non-existent locales
* [#4371](https://github.com/moment/moment/pull/4371) [misc] fix deprecated rollup options
* New locales: ug-cn, en-il, tg
* Various locale improvements

### 2.20.1 [See changelog](https://gist.github.com/marwahaha/d72c1cb22076373be889b16272cbd187)

* Release Dec 18, 2017

* [#4359](https://github.com/moment/moment/pull/4359) [locale] Fix Arabic locale for months (again)
* [#4357](https://github.com/moment/moment/pull/4357) [misc] Add optional parameter keepOffset to toISOString

### 2.20.0 [See full changelog](https://gist.github.com/marwahaha/e0d4135fbf8bb75fa85c4aa2bddc5031)

* Release Dec 16, 2017

* [#4312](https://github.com/moment/moment/pull/4312) [bugfix] Fix [#4251](https://github.com/moment/moment/pull/4251): Avoid RFC2822 in utc() test
* [#4240](https://github.com/moment/moment/pull/4240) [bugfix] Fix incorrect strict parsing with full-width parentheses
* [#4341](https://github.com/moment/moment/pull/4341) [feature] Prevent toISOString converting to UTC (issue [#1751](https://github.com/moment/moment/pull/1751))
* [#4154](https://github.com/moment/moment/pull/4154) [feature] add format constants to support output to HTML5 input type formats (see [#3928](https://github.com/moment/moment/pull/3928))
* [#4143](https://github.com/moment/moment/pull/4143) [new locale] mt: Maltese language
* [#4183](https://github.com/moment/moment/pull/4183) [locale] Relative seconds i18n
* Various other locale improvements

### 2.19.4 [See changelog](https://gist.github.com/marwahaha/d3b7b0ddf4bdae512244f16e8cc59efb)

* Release Dec 10, 2017

* [#4332](https://github.com/moment/moment/pull/4332) [bugfix] Fix weekday verification for UTC and offset days (fixes [#4227](https://github.com/moment/moment/pull/4227))
* [#4336](https://github.com/moment/moment/pull/4336) [bugfix] Fix [#4334](https://github.com/moment/moment/pull/4334): Remove unused function call argument
* [#4246](https://github.com/moment/moment/pull/4246) [misc] Add 'ss' relative time key to typescript definition

### 2.19.3 [See changelog](https://gist.github.com/marwahaha/3654006bc0c2e522451c08d12c0bfabf)

* Release Nov 29, 2017

* [#4326](https://github.com/moment/moment/pull/4326) [bugfix] Fix for ReDOS vulnerability (see [#4163](https://github.com/moment/moment/issues/4163))
* [#4289](https://github.com/moment/moment/pull/4289) [misc] Fix spelling and formatting for U.S. for es-us

### 2.19.2 [See changelog (it's the same >:D)](https://gist.github.com/ichernev/76b1a3f33d3a8ff9665ce434a45221d0)

* Release Nov 11, 2017

* [#4255](https://github.com/moment/moment/pull/4255) [bugfix] Fix year setter for random days in a leap year, fixes [#4238](https://github.com/moment/moment/issues/4238)
* [#4242](https://github.com/moment/moment/pull/4242) [bugfix] updateLocale now tries to load parent, fixes [#3626](https://github.com/moment/moment/issues/3626)

### 2.19.1

* Release Oct 11, 2017

Make react native and webpack both work
* #4225 #4226 #4232

### 2.19.0 [See full changelog](https://gist.github.com/ichernev/5f3f4eb02761b4f765a0cccf02cec603)

* Release Oct 10, 2017

## Fix React Native 0.49+ crash
* [#4213](https://github.com/moment/moment/pull/4213) [critical] Rename dynamic
  require to avoid React Native crash
* [#4214](https://github.com/moment/moment/pull/4214) [fixup] Move require
  rename inside try/catch, fixes
  [#4213](https://github.com/moment/moment/issues/4213)

## Features

* [#3735](https://github.com/moment/moment/pull/3735) [feature] Ignore NaN values in setters
* [#4106](https://github.com/moment/moment/pull/4106) [fixup] Drop isNumeric utility fn, fixes [#3735](https://github.com/moment/moment/issues/3735)
* [#4080](https://github.com/moment/moment/pull/4080) [feature] Implement a clone method for durations, fixes [#4078](https://github.com/moment/moment/issues/4078)
* [#4215](https://github.com/moment/moment/pull/4215) [misc] TS: Add duration.clone(), for [#4080](https://github.com/moment/moment/issues/4080)

## Packaging

* [#4003](https://github.com/moment/moment/pull/4003) [pkg] bower: Remove tests from package
* [#3904](https://github.com/moment/moment/pull/3904) [pkg] jsnext:main -> module in package.json
* [#4060](https://github.com/moment/moment/pull/4060) [pkg] Account for new rollup interface

Bugfixes, new locales, locale fixes etc...

### 2.18.1

* Release Mar 22, 2017

* [#3853](https://github.com/moment/moment/pull/3853) [misc] Fix invalid whitespace character causing inability to parse
  moment.js

### 2.18.0 [See full changelog](https://gist.github.com/ichernev/78920c5a1e419fb28c6e4546d1b7235c)

* Release Mar 18, 2017

## Features

* [#3708](https://github.com/moment/moment/pull/3708) [feature] RFC2822 parsing
* [#3611](https://github.com/moment/moment/pull/3611) [feature] Durations gain validity
* [#3738](https://github.com/moment/moment/pull/3738) [feature] Enable relative time for multiple seconds, request [#2558](https://github.com/moment/moment/issues/2558)
* [#3766](https://github.com/moment/moment/pull/3766) [feature] Add support for k and kk format parsing

## Bugfixes

* [#3643](https://github.com/moment/moment/pull/3643) [bugfix] Fixes [#3520](https://github.com/moment/moment/issues/3520), parseZone incorrectly handled minutes under 16
* [#3710](https://github.com/moment/moment/pull/3710) [bugfix] Fixes [#3632](https://github.com/moment/moment/issues/3632), toISOString returns null for invalid date
* [#3787](https://github.com/moment/moment/pull/3787) [bugfix] Fixes [#3717](https://github.com/moment/moment/issues/3717), ensure day-of-year is non-zero
* [#3780](https://github.com/moment/moment/pull/3780) [bugfix] Fixes [#3765](https://github.com/moment/moment/issues/3765): Ensure year 0 is formatted with YYYY
* [#3806](https://github.com/moment/moment/pull/3806) [bugfix] Fixes [#3805](https://github.com/moment/moment/issues/3805), fix locale month getters for standalone/format cases

7 new locales, many locale improvements and some misc changes

### 2.17.1 [Also available here](https://gist.github.com/ichernev/f38280b2b29c4932914a6d3a4e50bfb2)
* Release Dec 03, 2016

* [#3638](https://github.com/moment/moment/pull/3638) [misc] TS: Make typescript definitions work with 1.x
* [#3628](https://github.com/moment/moment/pull/3628) [misc] Adds "sign CLA" link to `CONTRIBUTING.md`
* [#3640](https://github.com/moment/moment/pull/3640) [misc] Fix locale issues

### 2.17.0 [Also available here](https://gist.github.com/ichernev/ed58f76fb95205eeac653d719972b90c)
* Release Nov 22, 2016

* [#3435](https://github.com/moment/moment/pull/3435) [new locale] yo: Yoruba (Nigeria) locale
* [#3595](https://github.com/moment/moment/pull/3595) [bugfix] Fix accidental reference to global "value" variable
* [#3506](https://github.com/moment/moment/pull/3506) [bugfix] Fix invalid moments returning valid dates to method calls
* [#3563](https://github.com/moment/moment/pull/3563) [locale] ca: Change future relative time
* [#3504](https://github.com/moment/moment/pull/3504) [tests] Fixes [#3463](https://github.com/moment/moment/issues/3463), parseZone not handling Z correctly (tests only)
* [#3591](https://github.com/moment/moment/pull/3591) [misc] typescript: update typescript to 2.0.8, add strictNullChecks=true
* [#3597](https://github.com/moment/moment/pull/3597) [misc] Fixed capitalization in nuget spec

### 2.16.0 [See full changelog](https://gist.github.com/ichernev/17bffc1005a032cb1a8ac4c1558b4994)
* Release Nov 9, 2016

## Features
* [#3530](https://github.com/moment/moment/pull/3530) [feature] Check whether input is date before checking if format is array
* [#3515](https://github.com/moment/moment/pull/3515) [feature] Fix [#2300](https://github.com/moment/moment/issues/2300): Default to current week.

## Bugfixes
* [#3546](https://github.com/moment/moment/pull/3546) [bugfix] Implement lazy-loading of child locales with missing prents
* [#3523](https://github.com/moment/moment/pull/3523) [bugfix] parseZone should handle UTC
* [#3502](https://github.com/moment/moment/pull/3502) [bugfix] Fix [#3500](https://github.com/moment/moment/issues/3500): ISO 8601 parsing should match the full string, not the beginning of the string.
* [#3581](https://github.com/moment/moment/pull/3581) [bugfix] Fix parseZone, redo [#3504](https://github.com/moment/moment/issues/3504), fix [#3463](https://github.com/moment/moment/issues/3463)

## New Locales
* [#3416](https://github.com/moment/moment/pull/3416) [new locale] nl-be: Dutch (Belgium) locale
* [#3393](https://github.com/moment/moment/pull/3393) [new locale] ar-dz: Arabic (Algeria) locale
* [#3342](https://github.com/moment/moment/pull/3342) [new locale] tet: Tetun Dili (East Timor) locale

And more locale, build and typescript improvements

### 2.15.2
* Release Oct 23, 2016
* [#3525](https://github.com/moment/moment/pull/3525) Speedup month standalone/format regexes **(IMPORTANT)**
* [#3466](https://github.com/moment/moment/pull/3466) Fix typo of Javanese

### 2.15.1
* Release Sept 20, 2016
* [#3438](https://github.com/moment/moment/pull/3438) Fix locale autoload, revert [#3344](https://github.com/moment/moment/pull/3344)

### 2.15.0 [See full changelog](https://gist.github.com/ichernev/10e1c5bf647545c72ca30e9628a09ed3)
- Release Sept 12, 2016

## New Locales
* [#3255](https://github.com/moment/moment/pull/3255) [new locale] mi: Maori language
* [#3267](https://github.com/moment/moment/pull/3267) [new locale] ar-ly: Arabic (Libya) locale
* [#3333](https://github.com/moment/moment/pull/3333) [new locale] zh-hk: Chinese (Hong Kong) locale

## Bugfixes
* [#3276](https://github.com/moment/moment/pull/3276) [bugfix] duration: parser: Support ms durations in .NET syntax
* [#3312](https://github.com/moment/moment/pull/3312) [bugfix] locales: Enable locale-data getters without moment (fixes [#3284](https://github.com/moment/moment/issues/3284))
* [#3381](https://github.com/moment/moment/pull/3381) [bugfix] parsing: Fix parseZone without timezone in string, fixes [#3083](https://github.com/moment/moment/issues/3083)
* [#3383](https://github.com/moment/moment/pull/3383) [bugfix] toJSON: Fix isValid so that toJSON works after a moment is frozen
* [#3427](https://github.com/moment/moment/pull/3427) [bugfix] ie8: Fix IE8 (regression in 2.14.x)

## Packaging
* [#3299](https://github.com/moment/moment/pull/3299) [pkg] npm: Do not include .npmignore in npm package
* [#3273](https://github.com/moment/moment/pull/3273) [pkg] jspm: Include moment.d.ts file in package
* [#3344](https://github.com/moment/moment/pull/3344) [pkg] exports: use module.require for nodejs

Also some locale and typescript improvements

### 2.14.1
- Release July 20, 2016
* [#3280](https://github.com/moment/moment/pull/3280) Fix typescript definitions


### 2.14.0 [See full changelog](https://gist.github.com/ichernev/812e79ac36a7829a22598fe964bfc18a)

- Release July 20, 2016

## New Features
* [#3233](https://github.com/moment/moment/pull/3233) Introduce month.isFormat for format/standalone discovery
* [#2848](https://github.com/moment/moment/pull/2848) Allow user to get/set the rounding method used when calculating relative time
* [#3112](https://github.com/moment/moment/pull/3112) optimize configFromStringAndFormat
* [#3147](https://github.com/moment/moment/pull/3147) Call calendar format function with moment context
* [#3160](https://github.com/moment/moment/pull/3160) deprecate isDSTShifted
* [#3175](https://github.com/moment/moment/pull/3175) make moment calendar extensible with ad-hoc options
* [#3191](https://github.com/moment/moment/pull/3191) toDate returns a copy of the internal date object
* [#3192](https://github.com/moment/moment/pull/3192) Adding support for rollup import.
* [#3238](https://github.com/moment/moment/pull/3238) Handle empty object and empty array for creation as now
* [#3082](https://github.com/moment/moment/pull/3082) Use relative AMD moment dependency

## Bugfixes
* [#3241](https://github.com/moment/moment/pull/3241) Escape all 24 mixed pieces, not only first 12 in computeMonthsParse
* [#3008](https://github.com/moment/moment/pull/3008) Object setter orders sets based on size of unit
* [#3177](https://github.com/moment/moment/pull/3177) Bug Fix [#2704](https://github.com/moment/moment/pull/2704) - isoWeekday(String) inconsistent with isoWeekday(Number)
* [#3230](https://github.com/moment/moment/pull/3230) fix passing date with format string to ignore format string
* [#3232](https://github.com/moment/moment/pull/3232) Fix negative 0 in certain diff cases
* [#3235](https://github.com/moment/moment/pull/3235) Use proper locale inheritance for the base locale, fixes [#3137](https://github.com/moment/moment/pull/3137)

Plus es-do locale and locale bugfixes

### 2.13.0 [See full changelog](https://gist.github.com/ichernev/0132fcf5b61f7fc140b0bb0090480d49)
- Release April 18, 2016

## Enhancements:
* [#2982](https://github.com/moment/moment/pull/2982) Add 'date' as alias to 'day' for startOf() and endOf().
* [#2955](https://github.com/moment/moment/pull/2955) Add parsing negative components in durations when ISO 8601
* [#2991](https://github.com/moment/moment/pull/2991) isBetween support for both open and closed intervals
* [#3105](https://github.com/moment/moment/pull/3105) Add localeSorted argument to weekday listers
* [#3102](https://github.com/moment/moment/pull/3102) Add k and kk formatting tokens

## Bugfixes
* [#3109](https://github.com/moment/moment/pull/3109) Fix [#1756](https://github.com/moment/moment/issues/1756) Resolved thread-safe issue on server side.
* [#3078](https://github.com/moment/moment/pull/3078) Fix parsing for months/weekdays with weird characters
* [#3098](https://github.com/moment/moment/pull/3098) Use Z suffix when in UTC mode ([#3020](https://github.com/moment/moment/issues/3020))
* [#2995](https://github.com/moment/moment/pull/2995) Fix floating point rounding errors in durations
* [#3059](https://github.com/moment/moment/pull/3059) fix bug where diff returns -0 in month-related diffs
* [#3045](https://github.com/moment/moment/pull/3045) Fix mistaking any input for 'a' token
* [#2877](https://github.com/moment/moment/pull/2877) Use explicit .valueOf() calls instead of coercion
* [#3036](https://github.com/moment/moment/pull/3036) Year setter should keep time when DST changes

Plus 3 new locales and locale fixes.

### 2.12.0 [See full changelog](https://gist.github.com/ichernev/6e5bfdf8d6522fc4ac73)

- Release March 7, 2016

## Enhancements:
* [#2932](https://github.com/moment/moment/pull/2932) List loaded locales
* [#2818](https://github.com/moment/moment/pull/2818) Parse ISO-8061 duration containing both day and week values
* [#2774](https://github.com/moment/moment/pull/2774) Implement locale inheritance and locale updating

## Bugfixes:
* [#2970](https://github.com/moment/moment/pull/2970) change add subtract to handle decimal values by rounding
* [#2887](https://github.com/moment/moment/pull/2887) Fix toJSON casting of invalid moment
* [#2897](https://github.com/moment/moment/pull/2897) parse string arguments for month() correctly, closes #2884
* [#2946](https://github.com/moment/moment/pull/2946) Fix usage suggestions for min and max

## New locales:
* [#2917](https://github.com/moment/moment/pull/2917) Locale Punjabi(Gurmukhi) India format conversion

And more

### 2.11.2 (Fix ReDoS attack vector)

- Release February 7, 2016

* [#2939](https://github.com/moment/moment/pull/2939) use full-string match to speed up aspnet regex match

### 2.11.1 [See full changelog](https://gist.github.com/ichernev/8ec3ee25b749b4cff3c2)

- Release January 9, 2016

## Bugfixes:
* [#2881](https://github.com/moment/moment/pull/2881) Revert "Merge pull request #2746 from mbad0la:develop" Sep->Sept
* [#2868](https://github.com/moment/moment/pull/2868) Add format and parse token Y, so it actually works
* [#2865](https://github.com/moment/moment/pull/2865) Use typeof checks for undefined for global variables
* [#2858](https://github.com/moment/moment/pull/2858) Fix Date mocking regression introduced in 2.11.0
* [#2864](https://github.com/moment/moment/pull/2864) Include changelog in npm release
* [#2830](https://github.com/moment/moment/pull/2830) dep: add grunt-cli
* [#2869](https://github.com/moment/moment/pull/2869) Fix months parsing for some locales

### 2.11.0 [See full changelog](https://gist.github.com/ichernev/6594bc29719dde6b2f66)

- Release January 4, 2016

* [#2624](https://github.com/moment/moment/pull/2624) Proper handling of invalid moments
* [#2634](https://github.com/moment/moment/pull/2634) Fix strict month parsing issue in cs,ru,sk
* [#2735](https://github.com/moment/moment/pull/2735) Reset the locale back to 'en' after defining all locales in min/locales.js
* [#2702](https://github.com/moment/moment/pull/2702) Week rework
* [#2746](https://github.com/moment/moment/pull/2746) Changed September Abbreviation to "Sept" in locale-specific english
  files and default locale file
* [#2646](https://github.com/moment/moment/pull/2646) Fix [#2645](https://github.com/moment/moment/pull/2645) - invalid dates pre-1970

* [#2641](https://github.com/moment/moment/pull/2641) Implement basic format and comma as ms separator in ISO 8601
* [#2665](https://github.com/moment/moment/pull/2665) Implement stricter weekday parsing
* [#2700](https://github.com/moment/moment/pull/2700) Add [Hh]mm and [Hh]mmss formatting tokens, so you can parse 123 with
  hmm for example
* [#2565](https://github.com/moment/moment/pull/2565) [#2835](https://github.com/moment/moment/pull/2835) Expose arguments used for moment creation with creationData
  (fix [#2443](https://github.com/moment/moment/pull/2443))
* [#2648](https://github.com/moment/moment/pull/2648) fix issue [#2640](https://github.com/moment/moment/pull/2640): support instanceof operator
* [#2709](https://github.com/moment/moment/pull/2709) Add isSameOrAfter and isSameOrBefore comparison methods
* [#2721](https://github.com/moment/moment/pull/2721) Fix moment creation from object with strings values
* [#2740](https://github.com/moment/moment/pull/2740) Enable 'd hh:mm:ss.sss' format for durations
* [#2766](https://github.com/moment/moment/pull/2766) [#2833](https://github.com/moment/moment/pull/2833) Alternate Clock Source Support

### 2.10.6

- Release July 28, 2015

[#2515](https://github.com/moment/moment/pull/2515) Fix regression introduced
in `2.10.5` related to `moment.ISO_8601` parsing.

### 2.10.5 [See full changelog](https://gist.github.com/ichernev/6ec13ac7efc396da44b2)

- Release July 26, 2015

Important changes:
* [#2357](https://github.com/moment/moment/pull/2357) Improve unit bubbling for ISO dates
  this fixes day to year conversions to work around end-of-year (~365 days). As
  a side effect 365 days is 11 months and 30 days, and 366 days is one year.
* [#2438](https://github.com/moment/moment/pull/2438) Fix inconsistent moment.min and moment.max results
  Return invalid result if any of the inputs is invalid
* [#2494](https://github.com/moment/moment/pull/2494) Fix two digit year parsing with YYYY format
  This brings the benefits of YY to YYYY
* [#2368](https://github.com/moment/moment/pull/2368) perf: use faster form of copying dates, across the board improvement


### 2.10.3 [See full changelog](https://gist.github.com/ichernev/f264b9bed5b00f8b1b7f)

- Release May 13, 2015

* add `moment.fn.to` and `moment.fn.toNow` (similar to `from` and `fromNow`)
* new locales (Sinhalese (si), Montenegrin (me), Javanese (ja))
* performance improvements

### 2.10.2

- Release April 9, 2015

* fixed moment-with-locales in browser env caused by esperanto change

### 2.10.1

* regression: Add moment.duration.fn back

### 2.10.0

Ported code to es6 modules.

### 2.9.0 [See full changelog](https://gist.github.com/ichernev/0c9a9b49951111a27ce7)

- Release January 8, 2015

languages:
* [2104](https://github.com/moment/moment/issues/2104) Frisian (fy) language file with unit test
* [2097](https://github.com/moment/moment/issues/2097) add ar-tn locale

deprecations:
* [2074](https://github.com/moment/moment/issues/2074) Implement `moment.fn.utcOffset`, deprecate `moment.fn.zone`

features:
* [2088](https://github.com/moment/moment/issues/2088) add moment.fn.isBetween
* [2054](https://github.com/moment/moment/issues/2054) Call updateOffset when creating moment (needed for default timezone in
  moment-timezone)
* [1893](https://github.com/moment/moment/issues/1893) Add moment.isDate method
* [1825](https://github.com/moment/moment/issues/1825) Implement toJSON function on Duration
* [1809](https://github.com/moment/moment/issues/1809) Allowing moment.set() to accept a hash of units
* [2128](https://github.com/moment/moment/issues/2128) Add firstDayOfWeek, firstDayOfYear locale getters
* [2131](https://github.com/moment/moment/issues/2131) Add quarter diff support

Some bugfixes and language improvements -- [full changelog](https://gist.github.com/ichernev/0c9a9b49951111a27ce7)

### 2.8.4 [See full changelog](https://gist.github.com/ichernev/a4fcb0a46d74e4b9b996)

- Release November 19, 2014

Features:

* [#2000](https://github.com/moment/moment/issues/2000) Add LTS localised format that includes seconds
* [#1960](https://github.com/moment/moment/issues/1960) added formatToken 'x' for unix offset in milliseconds #1938
* [#1965](https://github.com/moment/moment/issues/1965) Support 24:00:00.000 to mean next day, at midnight.
* [#2002](https://github.com/moment/moment/issues/2002) Accept 'date' key when creating moment with object
* [#2009](https://github.com/moment/moment/issues/2009) Use native toISOString when we can

Some bugfixes and language improvements -- [full changelog](https://gist.github.com/ichernev/a4fcb0a46d74e4b9b996)

### 2.8.3

- Release September 5, 2014

Bugfixes:

* [#1801](https://github.com/moment/moment/issues/1801) proper pluralization for Arabic
* [#1833](https://github.com/moment/moment/issues/1833) improve spm integration
* [#1871](https://github.com/moment/moment/issues/1871) fix zone bug caused by Firefox 24
* [#1882](https://github.com/moment/moment/issues/1882) Use hh:mm in Czech
* [#1883](https://github.com/moment/moment/issues/1883) Fix 2.8.0 regression in duration as conversions
* [#1890](https://github.com/moment/moment/issues/1890) Faster travis builds
* [#1892](https://github.com/moment/moment/issues/1892) Faster isBefore/After/Same
* [#1848](https://github.com/moment/moment/issues/1848) Fix flaky month diffs
* [#1895](https://github.com/moment/moment/issues/1895) Fix 2.8.0 regression in moment.utc with format array
* [#1896](https://github.com/moment/moment/issues/1896) Support setting invalid instance locale (noop)
* [#1897](https://github.com/moment/moment/issues/1897) Support moment([str]) in addition to moment([int])

### 2.8.2

- Release August 22, 2014

Minor bugfixes:

* [#1874](https://github.com/moment/moment/issues/1874) use `Object.prototype.hasOwnProperty`
  instead of `obj.hasOwnProperty` (ie8 bug)
* [#1873](https://github.com/moment/moment/issues/1873) add `duration#toString()`
* [#1859](https://github.com/moment/moment/issues/1859) better month/weekday names in norwegian
* [#1812](https://github.com/moment/moment/issues/1812) meridiem parsing for greek
* [#1804](https://github.com/moment/moment/issues/1804) spanish del -> de
* [#1800](https://github.com/moment/moment/issues/1800) korean LT improvement

### 2.8.1

- Release August 1, 2014

* bugfix [#1813](https://github.com/moment/moment/issues/1813): fix moment().lang([key]) incompatibility

### 2.8.0 [See changelog](https://gist.github.com/ichernev/ac3899324a5fa6c8c9b4)

- Release July 31, 2014

* incompatible changes
    * [#1761](https://github.com/moment/moment/issues/1761): moments created without a language are no longer following the global language, in case it changes. Only newly created moments take the global language by default. In case you're affected by this, wait, comment on [#1797](https://github.com/moment/moment/issues/1797) and wait for a proper reimplementation
    * [#1642](https://github.com/moment/moment/issues/1642): 45 days is no longer "a month" according to humanize, cutoffs for month, and year have changed. Hopefully your code does not depend on a particular answer from humanize (which it shouldn't anyway)
    * [#1784](https://github.com/moment/moment/issues/1784): if you use the human readable English datetime format in a weird way (like storing them in a database) that would break when the format changes you're at risk.

* deprecations (old behavior will be dropped in 3.0)
    * [#1761](https://github.com/moment/moment/issues/1761) `lang` is renamed to `locale`, `langData` -> `localeData`. Also there is now `defineLocale` that should be used when creating new locales
    * [#1763](https://github.com/moment/moment/issues/1763) `add(unit, value)` and `subtract(unit, value)` are now deprecated. Use `add(value, unit)` and `subtract(value, unit)` instead.
    * [#1759](https://github.com/moment/moment/issues/1759) rename `duration.toIsoString` to `duration.toISOString`. The js standard library and moment's `toISOString` follow that convention.

* new locales
    * [#1789](https://github.com/moment/moment/issues/1789) Tibetan (bo)
    * [#1786](https://github.com/moment/moment/issues/1786) Africaans (af)
    * [#1778](https://github.com/moment/moment/issues/1778) Burmese (my)
    * [#1727](https://github.com/moment/moment/issues/1727) Belarusian (be)

* bugfixes, locale bugfixes, performance improvements, features

### 2.7.0 [See changelog](https://gist.github.com/ichernev/b0a3d456d5a84c9901d7)

- Release June 12, 2014

* new languages

  * [#1678](https://github.com/moment/moment/issues/1678) Bengali (bn)
  * [#1628](https://github.com/moment/moment/issues/1628) Azerbaijani (az)
  * [#1633](https://github.com/moment/moment/issues/1633) Arabic, Saudi Arabia (ar-sa)
  * [#1648](https://github.com/moment/moment/issues/1648) Austrian German (de-at)

* features

  * [#1663](https://github.com/moment/moment/issues/1663) configurable relative time thresholds
  * [#1554](https://github.com/moment/moment/issues/1554) support anchor time in moment.calendar
  * [#1693](https://github.com/moment/moment/issues/1693) support moment.ISO_8601 as parsing format
  * [#1637](https://github.com/moment/moment/issues/1637) add moment.min and moment.max and deprecate min/max instance methods
  * [#1704](https://github.com/moment/moment/issues/1704) support string value in add/subtract
  * [#1647](https://github.com/moment/moment/issues/1647) add spm support (package manager)

* bugfixes

### 2.6.0 [See changelog](https://gist.github.com/ichernev/10544682)

- Release April 12 , 2014

* languages
  * [#1529](https://github.com/moment/moment/issues/1529) Serbian-Cyrillic (sr-cyr)
  * [#1544](https://github.com/moment/moment/issues/1544), [#1546](https://github.com/moment/moment/issues/1546) Khmer Cambodia (km)

* features
    * [#1419](https://github.com/moment/moment/issues/1419), [#1468](https://github.com/moment/moment/issues/1468), [#1467](https://github.com/moment/moment/issues/1467), [#1546](https://github.com/moment/moment/issues/1546) better handling of timezone-d moments around DST
    * [#1462](https://github.com/moment/moment/issues/1462) add weeksInYear and isoWeeksInYear
    * [#1475](https://github.com/moment/moment/issues/1475) support ordinal parsing
    * [#1499](https://github.com/moment/moment/issues/1499) composer support
    * [#1577](https://github.com/moment/moment/issues/1577), [#1604](https://github.com/moment/moment/issues/1604) put Date parsing in moment.createFromInputFallback so it can be properly deprecated and controlled in the future
    * [#1545](https://github.com/moment/moment/issues/1545) extract two-digit year parsing in moment.parseTwoDigitYear, so it can be overwritten
    * [#1590](https://github.com/moment/moment/issues/1590) (see [#1574](https://github.com/moment/moment/issues/1574)) set AMD global before module definition to better support non AMD module dependencies used in AMD environment
    * [#1589](https://github.com/moment/moment/issues/1589) remove global in Node.JS environment (was not working before, nobody complained, was scheduled for removal anyway)
    * [#1586](https://github.com/moment/moment/issues/1586) support quarter setting and parsing

* 18 bugs fixed

### 2.5.1

- Release January 22, 2014

* languages
  * [#1392](https://github.com/moment/moment/issues/1392) Armenian (hy-am)

* bugfixes
  * [#1429](https://github.com/moment/moment/issues/1429) fixes [#1423](https://github.com/moment/moment/issues/1423) weird chrome-32 bug with js object creation
  * [#1421](https://github.com/moment/moment/issues/1421) remove html entities from Welsh
  * [#1418](https://github.com/moment/moment/issues/1418) fixes [#1401](https://github.com/moment/moment/issues/1401) improved non-padded tokens in strict matching
  * [#1417](https://github.com/moment/moment/issues/1417) fixes [#1404](https://github.com/moment/moment/issues/1404) handle buggy moment object created by property cloning
  * [#1398](https://github.com/moment/moment/issues/1398) fixes [#1397](https://github.com/moment/moment/issues/1397) fix Arabic-like week number parsing
  * [#1396](https://github.com/moment/moment/issues/1396) add leftZeroFill(4) to GGGG and gggg formats
  * [#1373](https://github.com/moment/moment/issues/1373) use lowercase for months and days in Catalan

* testing
  * [#1374](https://github.com/moment/moment/issues/1374) run tests on multiple browser/os combos via SauceLabs and Travis

### 2.5.0 [See changelog](https://gist.github.com/ichernev/8104451)

- Release Dec 24, 2013

* New languages
  * Luxemburish (lb) [1247](https://github.com/moment/moment/issues/1247)
  * Serbian (rs) [1319](https://github.com/moment/moment/issues/1319)
  * Tamil (ta) [1324](https://github.com/moment/moment/issues/1324)
  * Macedonian (mk) [1337](https://github.com/moment/moment/issues/1337)

* Features
  * [1311](https://github.com/moment/moment/issues/1311) Add quarter getter and format token `Q`
  * [1303](https://github.com/moment/moment/issues/1303) strict parsing now respects number of digits per token (fix [1196](https://github.com/moment/moment/issues/1196))
  * 0d30bb7 add jspm support
  * [1347](https://github.com/moment/moment/issues/1347) improve zone parsing
  * [1362](https://github.com/moment/moment/issues/1362) support merideam parsing in Korean

* 22 bugfixes

### 2.4.0

- Release Oct 27, 2013

* **Deprecate** globally exported moment, will be removed in next major
* New languages
  * Farose (fo) [#1206](https://github.com/moment/moment/issues/1206)
  * Tagalog/Filipino (tl-ph) [#1197](https://github.com/moment/moment/issues/1197)
  * Welsh (cy) [#1215](https://github.com/moment/moment/issues/1215)
* Bugfixes
  * properly handle Z at the end of iso RegExp [#1187](https://github.com/moment/moment/issues/1187)
  * chinese meridian time improvements [#1076](https://github.com/moment/moment/issues/1076)
  * fix language tests [#1177](https://github.com/moment/moment/issues/1177)
  * remove some failing tests (that should have never existed :))
    [#1185](https://github.com/moment/moment/issues/1185)
    [#1183](https://github.com/moment/moment/issues/1183)
  * handle russian noun cases in weird cases [#1195](https://github.com/moment/moment/issues/1195)

### 2.3.1

- Release Oct 9, 2013

Removed a trailing comma [1169] and fixed a bug with `months`, `weekdays` getters [#1171](https://github.com/moment/moment/issues/1171).

### 2.3.0 [See changelog](https://gist.github.com/ichernev/6864354)

- Release Oct 7, 2013

Changed isValid, added strict parsing.
Week tokens parsing.

### 2.2.1

- Release Sep 12, 2013

Fixed bug in string prototype test.
Updated authors and contributors.

### 2.2.0 [See changelog](https://gist.github.com/ichernev/00f837a9baf46a3565e4)

- Release  Sep 11, 2013

Added bower support.

Language files now use UMD.

Creating moment defaults to current date/month/year.

Added a bundle of moment and all language files.

### 2.1.0 [See changelog](https://gist.github.com/timrwood/b8c2d90d528eddb53ab5)

- Release Jul 8, 2013

Added better week support.

Added ability to set offset with `moment#zone`.

Added ability to set month or weekday from a string.

Added `moment#min` and `moment#max`

### 2.0.0 [See changelog](https://gist.github.com/timrwood/e72f2eef320ed9e37c51)

- Release Feb 9, 2013

Added short form localized tokens.

Added ability to define language a string should be parsed in.

Added support for reversed add/subtract arguments.

Added support for `endOf('week')` and `startOf('week')`.

Fixed the logic for `moment#diff(Moment, 'months')` and `moment#diff(Moment, 'years')`

`moment#diff` now floors instead of rounds.

Normalized `moment#toString`.

Added `isSame`, `isAfter`, and `isBefore` methods.

Added better week support.

Added `moment#toJSON`

Bugfix: Fixed parsing of first century dates

Bugfix: Parsing 10Sep2001 should work as expected

Bugfix: Fixed weirdness with `moment.utc()` parsing.

Changed language ordinal method to return the number + ordinal instead of just the ordinal.

Changed two digit year parsing cutoff to match strptime.

Removed `moment#sod` and `moment#eod` in favor of `moment#startOf` and `moment#endOf`.

Removed `moment.humanizeDuration()` in favor of `moment.duration().humanize()`.

Removed the lang data objects from the top level namespace.

Duplicate `Date` passed to `moment()` instead of referencing it.

### 1.7.2 [See discussion](https://github.com/timrwood/moment/issues/456)

- Release Oct 2, 2012

Bugfixes

### 1.7.1 [See discussion](https://github.com/timrwood/moment/issues/384)

- Release Oct 1, 2012

Bugfixes

### 1.7.0 [See discussion](https://github.com/timrwood/moment/issues/288)

- Release Jul 26, 2012

Added `moment.fn.endOf()` and `moment.fn.startOf()`.

Added validation via `moment.fn.isValid()`.

Made formatting method 3x faster. http://jsperf.com/momentjs-cached-format-functions

Add support for month/weekday callbacks in `moment.fn.format()`

Added instance specific languages.

Added two letter weekday abbreviations with the formatting token `dd`.

Various language updates.

Various bugfixes.

### 1.6.0 [See discussion](https://github.com/timrwood/moment/pull/268)

- Release Apr 26, 2012

Added Durations.

Revamped parser to support parsing non-separated strings (YYYYMMDD vs YYYY-MM-DD).

Added support for millisecond parsing and formatting tokens (S SS SSS)

Added a getter for `moment.lang()`

Various bugfixes.

There are a few things deprecated in the 1.6.0 release.

1. The format tokens `z` and `zz` (timezone abbreviations like EST CST MST etc) will no longer be supported. Due to inconsistent browser support, we are unable to consistently produce this value. See [this issue](https://github.com/timrwood/moment/issues/162) for more background.

2. The method `moment.fn.native` is deprecated in favor of `moment.fn.toDate`. There continue to be issues with Google Closure Compiler throwing errors when using `native`, even in valid instances.

3. The way to customize am/pm strings is being changed. This would only affect you if you created a custom language file. For more information, see [this issue](https://github.com/timrwood/moment/pull/222).

### 1.5.0 [See milestone](https://github.com/timrwood/moment/issues?milestone=10&page=1&state=closed)

- Release Mar 20, 2012

Added UTC mode.

Added automatic ISO8601 parsing.

Various bugfixes.

### 1.4.0 [See milestone](https://github.com/timrwood/moment/issues?milestone=8&state=closed)

- Release Feb 4, 2012

Added `moment.fn.toDate` as a replacement for `moment.fn.native`.

Added `moment.fn.sod` and `moment.fn.eod` to get the start and end of day.

Various bugfixes.

### 1.3.0 [See milestone](https://github.com/timrwood/moment/issues?milestone=7&state=closed)

- Release Jan 5, 2012

Added support for parsing month names in the current language.

Added escape blocks for parsing tokens.

Added `moment.fn.calendar` to format strings like 'Today 2:30 PM', 'Tomorrow 1:25 AM', and 'Last Sunday 4:30 AM'.

Added `moment.fn.day` as a setter.

Various bugfixes

### 1.2.0 [See milestone](https://github.com/timrwood/moment/issues?milestone=4&state=closed)

- Release Dec 7, 2011

Added timezones to parser and formatter.

Added `moment.fn.isDST`.

Added `moment.fn.zone` to get the timezone offset in minutes.

### 1.1.2 [See milestone](https://github.com/timrwood/moment/issues?milestone=6&state=closed)

- Release Nov 18, 2011

Various bugfixes

### 1.1.1 [See milestone](https://github.com/timrwood/moment/issues?milestone=5&state=closed)

- Release Nov 12, 2011

Added time specific diffs (months, days, hours, etc)

### 1.1.0

- Release Oct 28, 2011

Added `moment.fn.format` localized masks. 'L LL LLL LLLL' [issue 29](https://github.com/timrwood/moment/pull/29)

Fixed [issue 31](https://github.com/timrwood/moment/pull/31).

### 1.0.1

- Release Oct 18, 2011

Added `moment.version` to get the current version.

Removed `window !== undefined` when checking if module exists to support browserify. [issue 25](https://github.com/timrwood/moment/pull/25)

### 1.0.0

- Release

Added convenience methods for getting and setting date parts.

Added better support for `moment.add()`.

Added better lang support in NodeJS.

Renamed library from underscore.date to Moment.js

### 0.6.1

- Release Oct 12, 2011

Added Portuguese, Italian, and French language support

### 0.6.0

- Release Sep 21, 2011

Added _date.lang() support.
Added support for passing multiple formats to try to parse a date. _date("07-10-1986", ["MM-DD-YYYY", "YYYY-MM-DD"]);
Made parse from string and single format 25% faster.

### 0.5.2

- Release Jul 11, 2011

Bugfix for [issue 8](https://github.com/timrwood/underscore.date/pull/8) and [issue 9](https://github.com/timrwood/underscore.date/pull/9).

### 0.5.1

- Release Jun 17, 2011

Bugfix for [issue 5](https://github.com/timrwood/underscore.date/pull/5).

### 0.5.0

- Release Jun 13, 2011

Dropped the redundant `_date.date()` in favor of `_date()`.
Removed `_date.now()`, as it is a duplicate of `_date()` with no parameters.
Removed `_date.isLeapYear(yearNumber)`. Use `_date([yearNumber]).isLeapYear()` instead.
Exposed customization options through the `_date.relativeTime`, `_date.weekdays`, `_date.weekdaysShort`, `_date.months`, `_date.monthsShort`, and `_date.ordinal` variables instead of the `_date.customize()` function.

### 0.4.1

- Release May 9, 2011

Added date input formats for input strings.

### 0.4.0

- Release May 9, 2011

Added underscore.date to npm. Removed dependencies on underscore.

### 0.3.2

- Release Apr 9, 2011

Added `'z'` and `'zz'` to `_.date().format()`. Cleaned up some redundant code to trim off some bytes.

### 0.3.1

- Release Mar 25, 2011

Cleaned up the namespace. Moved all date manipulation and display functions to the _.date() object.

### 0.3.0

- Release Mar 25, 2011

Switched to the Underscore methodology of not mucking with the native objects' prototypes.
Made chaining possible.

### 0.2.1

- Release

Changed date names to be a more pseudo standardized 'dddd, MMMM Do YYYY, h:mm:ss a'.
Added `Date.prototype` functions `add`, `subtract`, `isdst`, and `isleapyear`.

### 0.2.0

- Release

Changed function names to be more concise.
Changed date format from php date format to custom format.

### 0.1.0

- Release

Initial release

# [Moment.js](http://momentjs.com/)

[![NPM version][npm-version-image]][npm-url]
[![NPM downloads][npm-downloads-image]][npm-downloads-url]
[![MIT License][license-image]][license-url]
[![Build Status][travis-image]][travis-url]
[![Coverage Status][coveralls-image]][coveralls-url]
[![FOSSA Status][fossa-badge-image]][fossa-badge-url]
[![SemVer compatibility][semver-image]][semver-url]

A JavaScript date library for parsing, validating, manipulating, and formatting dates.

## Project Status

Moment.js is a legacy project, now in maintenance mode.  In most cases, you should choose a different library.

For more details and recommendations, please see [Project Status](https://momentjs.com/docs/#/-project-status/) in the docs.

*Thank you.*

## Resources

- [Documentation](https://momentjs.com/docs/)
- [Changelog](CHANGELOG.md)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/momentjs)

## License

Moment.js is freely distributable under the terms of the [MIT license][license-url].

[![FOSSA Status][fossa-large-image]][fossa-large-url]

[license-image]: https://img.shields.io/badge/license-MIT-blue.svg?style=flat
[license-url]: LICENSE

[npm-url]: https://npmjs.org/package/moment
[npm-version-image]: https://img.shields.io/npm/v/moment.svg?style=flat

[npm-downloads-image]: https://img.shields.io/npm/dm/moment.svg?style=flat
[npm-downloads-url]: https://npmcharts.com/compare/moment?minimal=true

[travis-url]: https://travis-ci.org/moment/moment
[travis-image]: https://img.shields.io/travis/moment/moment/develop.svg?style=flat

[coveralls-image]: https://coveralls.io/repos/moment/moment/badge.svg?branch=develop
[coveralls-url]: https://coveralls.io/r/moment/moment?branch=develop

[fossa-badge-image]: https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fmoment%2Fmoment.svg?type=shield
[fossa-badge-url]: https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fmoment%2Fmoment?ref=badge_shield

[fossa-large-image]: https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fmoment%2Fmoment.svg?type=large
[fossa-large-url]: https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fmoment%2Fmoment?ref=badge_large

[semver-image]: https://api.dependabot.com/badges/compatibility_score?dependency-name=moment&package-manager=npm_and_yarn&version-scheme=semver
[semver-url]: https://dependabot.com/compatibility-score.html?dependency-name=moment&package-manager=npm_and_yarn&version-scheme=semver
[![npm version](https://img.shields.io/npm/v/@eslint/js.svg)](https://www.npmjs.com/package/@eslint/js)

# ESLint JavaScript Plugin

[Website](https://eslint.org) | [Configure ESLint](https://eslint.org/docs/latest/use/configure) | [Rules](https://eslint.org/docs/rules/) | [Contributing](https://eslint.org/docs/latest/contribute) | [Twitter](https://twitter.com/geteslint) | [Chatroom](https://eslint.org/chat)

The beginnings of separating out JavaScript-specific functionality from ESLint.

Right now, this plugin contains two configurations:

* `recommended` - enables the rules recommended by the ESLint team (the replacement for `"eslint:recommended"`)
* `all` - enables all ESLint rules (the replacement for `"eslint:all"`)

## Installation

```shell
npm install @eslint/js -D
```

## Usage

Use in your `eslint.config.js` file anytime you want to extend one of the configs:

```js
import js from "@eslint/js";

export default [

    // apply recommended rules to JS files
    {
        files: ["**/*.js"],
        rules: js.configs.recommended.rules
    },

    // apply recommended rules to JS files with an override
    {
        files: ["**/*.js"],
        rules: {
            ...js.configs.recommended.rules,
            "no-unused-vars": "warn"
        } 
    },

    // apply all rules to JS files
    {
        files: ["**/*.js"],
        rules: {
            ...js.configs.all.rules,
            "no-unused-vars": "warn"
        } 
    }
]
```

## License

MIT
# ESLintRC Library

This repository contains the legacy ESLintRC configuration file format for ESLint. This package is not intended for use outside of the ESLint ecosystem. It is ESLint-specific and not intended for use in other programs.

**Note:** This package is frozen except for critical bug fixes as ESLint moves to a new config system.

## Installation

You can install the package as follows:

```
npm install @eslint/eslintrc --save-dev

# or

yarn add @eslint/eslintrc -D
```

## Usage (ESM)

The primary class in this package is `FlatCompat`, which is a utility to translate ESLintRC-style configs into flat configs. Here's how you use it inside of your `eslint.config.js` file:

```js
import { FlatCompat } from "@eslint/eslintrc";
import js from "@eslint/js";
import path from "path";
import { fileURLToPath } from "url";

// mimic CommonJS variables -- not needed if using CommonJS
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const compat = new FlatCompat({
    baseDirectory: __dirname,                  // optional; default: process.cwd()
    resolvePluginsRelativeTo: __dirname,       // optional
    recommendedConfig: js.configs.recommended, // optional
    allConfig: js.configs.all,                 // optional
});

export default [

    // mimic ESLintRC-style extends
    ...compat.extends("standard", "example"),

    // mimic environments
    ...compat.env({
        es2020: true,
        node: true
    }),

    // mimic plugins
    ...compat.plugins("airbnb", "react"),

    // translate an entire config
    ...compat.config({
        plugins: ["airbnb", "react"],
        extends: "standard",
        env: {
            es2020: true,
            node: true
        },
        rules: {
            semi: "error"
        }
    })
];
```

## Usage (CommonJS)

Using `FlatCompat` in CommonJS files is similar to ESM, but you'll use `require()` and `module.exports` instead of `import` and `export`. Here's how you use it inside of your `eslint.config.js` CommonJS file:

```js
const { FlatCompat } = require("@eslint/eslintrc");
const js = require("@eslint/js");

const compat = new FlatCompat({
    baseDirectory: __dirname,                  // optional; default: process.cwd()
    resolvePluginsRelativeTo: __dirname,       // optional
    recommendedConfig: js.configs.recommended, // optional
    allConfig: js.configs.all,                 // optional
});

module.exports = [

    // mimic ESLintRC-style extends
    ...compat.extends("standard", "example"),

    // mimic environments
    ...compat.env({
        es2020: true,
        node: true
    }),

    // mimic plugins
    ...compat.plugins("airbnb", "react"),

    // translate an entire config
    ...compat.config({
        plugins: ["airbnb", "react"],
        extends: "standard",
        env: {
            es2020: true,
            node: true
        },
        rules: {
            semi: "error"
        }
    })
];
```

## License

MIT License
v2.1.0 - May 3, 2021

* [`908fdf8`](https://github.com/eslint/eslint-visitor-keys/commit/908fdf8c0d9a352c696c8c1f4901280d1a0795f7) Update: add PrivateIdentifier and PropertyDefinition (#20) (Toru Nagashima)
* [`2d7be11`](https://github.com/eslint/eslint-visitor-keys/commit/2d7be11e4d13ac702c9fe3c529cadbd75b370146) Chore: No longer test in Node.js 13 (#17) (Michaël De Boey)
* [`b41b509`](https://github.com/eslint/eslint-visitor-keys/commit/b41b509b153ecd8d47af46a421122f64e93d4c67) Docs: Update required Node.js version (#15) (Michaël De Boey)

v2.0.0 - August 14, 2020

* [`fb86ca3`](https://github.com/eslint/eslint-visitor-keys/commit/fb86ca315daafc84e23ed9005db40b0892b972a6) Breaking: drop support for Node <10 (#13) (Kai Cataldo)
* [`69383b3`](https://github.com/eslint/eslint-visitor-keys/commit/69383b372915e33ada094880ecc6b6e8f8c7ca4e) Chore: move to GitHub Actions (#14) (Kai Cataldo)

v1.3.0 - June 19, 2020

* [`c92dd7f`](https://github.com/eslint/eslint-visitor-keys/commit/c92dd7ff96f0044dba12d681406a025b92b4c437) Update: add `ChainExpression` node (#12) (Toru Nagashima)

v1.2.0 - June 4, 2020

* [`21f28bf`](https://github.com/eslint/eslint-visitor-keys/commit/21f28bf11be5329d740a8bf6bdbcd0ef13bbf1a2) Update: added exported in exportAllDeclaration key (#10) (Anix)

v1.1.0 - August 13, 2019

* [`9331cc0`](https://github.com/eslint/eslint-visitor-keys/commit/9331cc09e756e65b9044c9186445a474b037fac6) Update: add ImportExpression (#8) (Toru Nagashima)
* [`5967f58`](https://github.com/eslint/eslint-visitor-keys/commit/5967f583b04f17fba9226aaa394e45d476d2b8af) Chore: add supported Node.js versions to CI (#7) (Kai Cataldo)
* [`6f7c60f`](https://github.com/eslint/eslint-visitor-keys/commit/6f7c60fef2ceec9f6323202df718321cec45cab0) Upgrade: eslint-release@1.0.0 (#5) (Teddy Katz)

v1.0.0 - December 18, 2017

* 1f6bd38 Breaking: update keys (#4) (Toru Nagashima)

v0.1.0 - November 17, 2017

* 17b4a88 Chore: update `repository` field in package.json (#3) (Toru Nagashima)
* a5a026b New: eslint-visitor-keys (#1) (Toru Nagashima)
* a1a48b8 Update: Change license to Apache 2 (#2) (Ilya Volodin)
* 2204715 Initial commit (Toru Nagashima)

# eslint-visitor-keys

[![npm version](https://img.shields.io/npm/v/eslint-visitor-keys.svg)](https://www.npmjs.com/package/eslint-visitor-keys)
[![Downloads/month](https://img.shields.io/npm/dm/eslint-visitor-keys.svg)](http://www.npmtrends.com/eslint-visitor-keys)
[![Build Status](https://travis-ci.org/eslint/eslint-visitor-keys.svg?branch=master)](https://travis-ci.org/eslint/eslint-visitor-keys)
[![Dependency Status](https://david-dm.org/eslint/eslint-visitor-keys.svg)](https://david-dm.org/eslint/eslint-visitor-keys)

Constants and utilities about visitor keys to traverse AST.

## 💿 Installation

Use [npm] to install.

```bash
$ npm install eslint-visitor-keys
```

### Requirements

- [Node.js] 10.0.0 or later.

## 📖 Usage

```js
const evk = require("eslint-visitor-keys")
```

### evk.KEYS

> type: `{ [type: string]: string[] | undefined }`

Visitor keys. This keys are frozen.

This is an object. Keys are the type of [ESTree] nodes. Their values are an array of property names which have child nodes.

For example:

```
console.log(evk.KEYS.AssignmentExpression) // → ["left", "right"]
```

### evk.getKeys(node)

> type: `(node: object) => string[]`

Get the visitor keys of a given AST node.

This is similar to `Object.keys(node)` of ES Standard, but some keys are excluded: `parent`, `leadingComments`, `trailingComments`, and names which start with `_`.

This will be used to traverse unknown nodes.

For example:

```
const node = {
    type: "AssignmentExpression",
    left: { type: "Identifier", name: "foo" },
    right: { type: "Literal", value: 0 }
}
console.log(evk.getKeys(node)) // → ["type", "left", "right"]
```

### evk.unionWith(additionalKeys)

> type: `(additionalKeys: object) => { [type: string]: string[] | undefined }`

Make the union set with `evk.KEYS` and the given keys.

- The order of keys is, `additionalKeys` is at first, then `evk.KEYS` is concatenated after that.
- It removes duplicated keys as keeping the first one.

For example:

```
console.log(evk.unionWith({
    MethodDefinition: ["decorators"]
})) // → { ..., MethodDefinition: ["decorators", "key", "value"], ... }
```

## 📰 Change log

See [GitHub releases](https://github.com/eslint/eslint-visitor-keys/releases).

## 🍻 Contributing

Welcome. See [ESLint contribution guidelines](https://eslint.org/docs/developer-guide/contributing/).

### Development commands

- `npm test` runs tests and measures code coverage.
- `npm run lint` checks source codes with ESLint.
- `npm run coverage` opens the code coverage report of the previous test with your default browser.
- `npm run release` publishes this package to [npm] registory.


[npm]: https://www.npmjs.com/
[Node.js]: https://nodejs.org/en/
[ESTree]: https://github.com/estree/estree
# eslint-utils

[![npm version](https://img.shields.io/npm/v/eslint-utils.svg)](https://www.npmjs.com/package/eslint-utils)
[![Downloads/month](https://img.shields.io/npm/dm/eslint-utils.svg)](http://www.npmtrends.com/eslint-utils)
[![Build Status](https://github.com/mysticatea/eslint-utils/workflows/CI/badge.svg)](https://github.com/mysticatea/eslint-utils/actions)
[![Coverage Status](https://codecov.io/gh/mysticatea/eslint-utils/branch/master/graph/badge.svg)](https://codecov.io/gh/mysticatea/eslint-utils)
[![Dependency Status](https://david-dm.org/mysticatea/eslint-utils.svg)](https://david-dm.org/mysticatea/eslint-utils)

## 🏁 Goal

This package provides utility functions and classes for make ESLint custom rules.

For examples:

- [getStaticValue](https://eslint-utils.mysticatea.dev/api/ast-utils.html#getstaticvalue) evaluates static value on AST.
- [ReferenceTracker](https://eslint-utils.mysticatea.dev/api/scope-utils.html#referencetracker-class) checks the members of modules/globals as handling assignments and destructuring.

## 📖 Usage

See [documentation](https://eslint-utils.mysticatea.dev/).

## 📰 Changelog

See [releases](https://github.com/mysticatea/eslint-utils/releases).

## ❤️ Contributing

Welcome contributing!

Please use GitHub's Issues/PRs.

### Development Tools

- `npm test` runs tests and measures coverage.
- `npm run clean` removes the coverage result of `npm test` command.
- `npm run coverage` shows the coverage result of the last `npm test` command.
- `npm run lint` runs ESLint.
- `npm run watch` runs tests on each file change.
## 8.11.3 (2023-12-29)

### Bug fixes

Add `Function` and `Class` to the `AggregateType` type, so that they can be used in walkers without raising a type error.

Make sure `onToken` get an `import` keyword token when parsing `import.meta`.

Fix a bug where `.loc.start` could be undefined for `new.target` `meta` nodes.

## 8.11.2 (2023-10-27)

### Bug fixes

Fix a bug that caused regular expressions after colon tokens to not be properly tokenized in some circumstances.

## 8.11.1 (2023-10-26)

### Bug fixes

Fix a regression where `onToken` would receive 'name' tokens for 'new' keyword tokens.

## 8.11.0 (2023-10-26)

### Bug fixes

Fix an issue where tokenizing (without parsing) an object literal with a property named `class` or `function` could, in some circumstance, put the tokenizer into an invalid state.

Fix an issue where a slash after a call to a propery named the same as some keywords would be tokenized as a regular expression.

### New features

Upgrade to Unicode 15.1.

Use a set of new, much more precise, TypeScript types.

## 8.10.0 (2023-07-05)

### New features

Add a `checkPrivateFields` option that disables strict checking of private property use.

## 8.9.0 (2023-06-16)

### Bug fixes

Forbid dynamic import after `new`, even when part of a member expression.

### New features

Add Unicode properties for ES2023.

Add support for the `v` flag to regular expressions.

## 8.8.2 (2023-01-23)

### Bug fixes

Fix a bug that caused `allowHashBang` to be set to false when not provided, even with `ecmaVersion >= 14`.

Fix an exception when passing no option object to `parse` or `new Parser`.

Fix incorrect parse error on `if (0) let\n[astral identifier char]`.

## 8.8.1 (2022-10-24)

### Bug fixes

Make type for `Comment` compatible with estree types.

## 8.8.0 (2022-07-21)

### Bug fixes

Allow parentheses around spread args in destructuring object assignment.

Fix an issue where the tree contained `directive` properties in when parsing with a language version that doesn't support them.

### New features

Support hashbang comments by default in ECMAScript 2023 and later.

## 8.7.1 (2021-04-26)

### Bug fixes

Stop handling `"use strict"` directives in ECMAScript versions before 5.

Fix an issue where duplicate quoted export names in `export *` syntax were incorrectly checked.

Add missing type for `tokTypes`.

## 8.7.0 (2021-12-27)

### New features

Support quoted export names.

Upgrade to Unicode 14.

Add support for Unicode 13 properties in regular expressions.

### Bug fixes

Use a loop to find line breaks, because the existing regexp search would overrun the end of the searched range and waste a lot of time in minified code.

## 8.6.0 (2021-11-18)

### Bug fixes

Fix a bug where an object literal with multiple `__proto__` properties would incorrectly be accepted if a later property value held an assigment.

### New features

Support class private fields with the `in` operator.

## 8.5.0 (2021-09-06)

### Bug fixes

Improve context-dependent tokenization in a number of corner cases.

Fix location tracking after a 0x2028 or 0x2029 character in a string literal (which before did not increase the line number).

Fix an issue where arrow function bodies in for loop context would inappropriately consume `in` operators.

Fix wrong end locations stored on SequenceExpression nodes.

Implement restriction that `for`/`of` loop LHS can't start with `let`.

### New features

Add support for ES2022 class static blocks.

Allow multiple input files to be passed to the CLI tool.

## 8.4.1 (2021-06-24)

### Bug fixes

Fix a bug where `allowAwaitOutsideFunction` would allow `await` in class field initializers, and setting `ecmaVersion` to 13 or higher would allow top-level await in non-module sources.

## 8.4.0 (2021-06-11)

### New features

A new option, `allowSuperOutsideMethod`, can be used to suppress the error when `super` is used in the wrong context.

## 8.3.0 (2021-05-31)

### New features

Default `allowAwaitOutsideFunction` to true for ECMAScript 2022 an higher.

Add support for the `d` ([indices](https://github.com/tc39/proposal-regexp-match-indices)) regexp flag.

## 8.2.4 (2021-05-04)

### Bug fixes

Fix spec conformity in corner case 'for await (async of ...)'.

## 8.2.3 (2021-05-04)

### Bug fixes

Fix an issue where the library couldn't parse 'for (async of ...)'.

Fix a bug in UTF-16 decoding that would read characters incorrectly in some circumstances.

## 8.2.2 (2021-04-29)

### Bug fixes

Fix a bug where a class field initialized to an async arrow function wouldn't allow await inside it. Same issue existed for generator arrow functions with yield.

## 8.2.1 (2021-04-24)

### Bug fixes

Fix a regression introduced in 8.2.0 where static or async class methods with keyword names fail to parse.

## 8.2.0 (2021-04-24)

### New features

Add support for ES2022 class fields and private methods.

## 8.1.1 (2021-04-12)

### Various

Stop shipping source maps in the NPM package.

## 8.1.0 (2021-03-09)

### Bug fixes

Fix a spurious error in nested destructuring arrays.

### New features

Expose `allowAwaitOutsideFunction` in CLI interface.

Make `allowImportExportAnywhere` also apply to `import.meta`.

## 8.0.5 (2021-01-25)

### Bug fixes

Adjust package.json to work with Node 12.16.0 and 13.0-13.6.

## 8.0.4 (2020-10-05)

### Bug fixes

Make `await x ** y` an error, following the spec.

Fix potentially exponential regular expression.

## 8.0.3 (2020-10-02)

### Bug fixes

Fix a wasteful loop during `Parser` creation when setting `ecmaVersion` to `"latest"`.

## 8.0.2 (2020-09-30)

### Bug fixes

Make the TypeScript types reflect the current allowed values for `ecmaVersion`.

Fix another regexp/division tokenizer issue.

## 8.0.1 (2020-08-12)

### Bug fixes

Provide the correct value in the `version` export.

## 8.0.0 (2020-08-12)

### Bug fixes

Disallow expressions like `(a = b) = c`.

Make non-octal escape sequences a syntax error in strict mode.

### New features

The package can now be loaded directly as an ECMAScript module in node 13+.

Update to the set of Unicode properties from ES2021.

### Breaking changes

The `ecmaVersion` option is now required. For the moment, omitting it will still work with a warning, but that will change in a future release.

Some changes to method signatures that may be used by plugins.

## 7.4.0 (2020-08-03)

### New features

Add support for logical assignment operators.

Add support for numeric separators.

## 7.3.1 (2020-06-11)

### Bug fixes

Make the string in the `version` export match the actual library version.

## 7.3.0 (2020-06-11)

### Bug fixes

Fix a bug that caused parsing of object patterns with a property named `set` that had a default value to fail.

### New features

Add support for optional chaining (`?.`).

## 7.2.0 (2020-05-09)

### Bug fixes

Fix precedence issue in parsing of async arrow functions.

### New features

Add support for nullish coalescing.

Add support for `import.meta`.

Support `export * as ...` syntax.

Upgrade to Unicode 13.

## 6.4.1 (2020-03-09)

### Bug fixes

More carefully check for valid UTF16 surrogate pairs in regexp validator.

## 7.1.1 (2020-03-01)

### Bug fixes

Treat `\8` and `\9` as invalid escapes in template strings.

Allow unicode escapes in property names that are keywords.

Don't error on an exponential operator expression as argument to `await`.

More carefully check for valid UTF16 surrogate pairs in regexp validator.

## 7.1.0 (2019-09-24)

### Bug fixes

Disallow trailing object literal commas when ecmaVersion is less than 5.

### New features

Add a static `acorn` property to the `Parser` class that contains the entire module interface, to allow plugins to access the instance of the library that they are acting on.

## 7.0.0 (2019-08-13)

### Breaking changes

Changes the node format for dynamic imports to use the `ImportExpression` node type, as defined in [ESTree](https://github.com/estree/estree/blob/master/es2020.md#importexpression).

Makes 10 (ES2019) the default value for the `ecmaVersion` option.

## 6.3.0 (2019-08-12)

### New features

`sourceType: "module"` can now be used even when `ecmaVersion` is less than 6, to parse module-style code that otherwise conforms to an older standard.

## 6.2.1 (2019-07-21)

### Bug fixes

Fix bug causing Acorn to treat some characters as identifier characters that shouldn't be treated as such.

Fix issue where setting the `allowReserved` option to `"never"` allowed reserved words in some circumstances.

## 6.2.0 (2019-07-04)

### Bug fixes

Improve valid assignment checking in `for`/`in` and `for`/`of` loops.

Disallow binding `let` in patterns.

### New features

Support bigint syntax with `ecmaVersion` >= 11.

Support dynamic `import` syntax with `ecmaVersion` >= 11.

Upgrade to Unicode version 12.

## 6.1.1 (2019-02-27)

### Bug fixes

Fix bug that caused parsing default exports of with names to fail.

## 6.1.0 (2019-02-08)

### Bug fixes

Fix scope checking when redefining a `var` as a lexical binding.

### New features

Split up `parseSubscripts` to use an internal `parseSubscript` method to make it easier to extend with plugins.

## 6.0.7 (2019-02-04)

### Bug fixes

Check that exported bindings are defined.

Don't treat `\u180e` as a whitespace character.

Check for duplicate parameter names in methods.

Don't allow shorthand properties when they are generators or async methods.

Forbid binding `await` in async arrow function's parameter list.

## 6.0.6 (2019-01-30)

### Bug fixes

The content of class declarations and expressions is now always parsed in strict mode.

Don't allow `let` or `const` to bind the variable name `let`.

Treat class declarations as lexical.

Don't allow a generator function declaration as the sole body of an `if` or `else`.

Ignore `"use strict"` when after an empty statement.

Allow string line continuations with special line terminator characters.

Treat `for` bodies as part of the `for` scope when checking for conflicting bindings.

Fix bug with parsing `yield` in a `for` loop initializer.

Implement special cases around scope checking for functions.

## 6.0.5 (2019-01-02)

### Bug fixes

Fix TypeScript type for `Parser.extend` and add `allowAwaitOutsideFunction` to options type.

Don't treat `let` as a keyword when the next token is `{` on the next line.

Fix bug that broke checking for parentheses around an object pattern in a destructuring assignment when `preserveParens` was on.

## 6.0.4 (2018-11-05)

### Bug fixes

Further improvements to tokenizing regular expressions in corner cases.

## 6.0.3 (2018-11-04)

### Bug fixes

Fix bug in tokenizing an expression-less return followed by a function followed by a regular expression.

Remove stray symlink in the package tarball.

## 6.0.2 (2018-09-26)

### Bug fixes

Fix bug where default expressions could fail to parse inside an object destructuring assignment expression.

## 6.0.1 (2018-09-14)

### Bug fixes

Fix wrong value in `version` export.

## 6.0.0 (2018-09-14)

### Bug fixes

Better handle variable-redefinition checks for catch bindings and functions directly under if statements.

Forbid `new.target` in top-level arrow functions.

Fix issue with parsing a regexp after `yield` in some contexts.

### New features

The package now comes with TypeScript definitions.

### Breaking changes

The default value of the `ecmaVersion` option is now 9 (2018).

Plugins work differently, and will have to be rewritten to work with this version.

The loose parser and walker have been moved into separate packages (`acorn-loose` and `acorn-walk`).

## 5.7.3 (2018-09-10)

### Bug fixes

Fix failure to tokenize regexps after expressions like `x.of`.

Better error message for unterminated template literals.

## 5.7.2 (2018-08-24)

### Bug fixes

Properly handle `allowAwaitOutsideFunction` in for statements.

Treat function declarations at the top level of modules like let bindings.

Don't allow async function declarations as the only statement under a label.

## 5.7.0 (2018-06-15)

### New features

Upgraded to Unicode 11.

## 5.6.0 (2018-05-31)

### New features

Allow U+2028 and U+2029 in string when ECMAVersion >= 10.

Allow binding-less catch statements when ECMAVersion >= 10.

Add `allowAwaitOutsideFunction` option for parsing top-level `await`.

## 5.5.3 (2018-03-08)

### Bug fixes

A _second_ republish of the code in 5.5.1, this time with yarn, to hopefully get valid timestamps.

## 5.5.2 (2018-03-08)

### Bug fixes

A republish of the code in 5.5.1 in an attempt to solve an issue with the file timestamps in the npm package being 0.

## 5.5.1 (2018-03-06)

### Bug fixes

Fix misleading error message for octal escapes in template strings.

## 5.5.0 (2018-02-27)

### New features

The identifier character categorization is now based on Unicode version 10.

Acorn will now validate the content of regular expressions, including new ES9 features.

## 5.4.0 (2018-02-01)

### Bug fixes

Disallow duplicate or escaped flags on regular expressions.

Disallow octal escapes in strings in strict mode.

### New features

Add support for async iteration.

Add support for object spread and rest.

## 5.3.0 (2017-12-28)

### Bug fixes

Fix parsing of floating point literals with leading zeroes in loose mode.

Allow duplicate property names in object patterns.

Don't allow static class methods named `prototype`.

Disallow async functions directly under `if` or `else`.

Parse right-hand-side of `for`/`of` as an assignment expression.

Stricter parsing of `for`/`in`.

Don't allow unicode escapes in contextual keywords.

### New features

Parsing class members was factored into smaller methods to allow plugins to hook into it.

## 5.2.1 (2017-10-30)

### Bug fixes

Fix a token context corruption bug.

## 5.2.0 (2017-10-30)

### Bug fixes

Fix token context tracking for `class` and `function` in property-name position.

Make sure `%*` isn't parsed as a valid operator.

Allow shorthand properties `get` and `set` to be followed by default values.

Disallow `super` when not in callee or object position.

### New features

Support [`directive` property](https://github.com/estree/estree/compare/b3de58c9997504d6fba04b72f76e6dd1619ee4eb...1da8e603237144f44710360f8feb7a9977e905e0) on directive expression statements.

## 5.1.2 (2017-09-04)

### Bug fixes

Disable parsing of legacy HTML-style comments in modules.

Fix parsing of async methods whose names are keywords.

## 5.1.1 (2017-07-06)

### Bug fixes

Fix problem with disambiguating regexp and division after a class.

## 5.1.0 (2017-07-05)

### Bug fixes

Fix tokenizing of regexps in an object-desctructuring `for`/`of` loop and after `yield`.

Parse zero-prefixed numbers with non-octal digits as decimal.

Allow object/array patterns in rest parameters.

Don't error when `yield` is used as a property name.

Allow `async` as a shorthand object property.

### New features

Implement the [template literal revision proposal](https://github.com/tc39/proposal-template-literal-revision) for ES9.

## 5.0.3 (2017-04-01)

### Bug fixes

Fix spurious duplicate variable definition errors for named functions.

## 5.0.2 (2017-03-30)

### Bug fixes

A binary operator after a parenthesized arrow expression is no longer incorrectly treated as an error.

## 5.0.0 (2017-03-28)

### Bug fixes

Raise an error for duplicated lexical bindings.

Fix spurious error when an assignement expression occurred after a spread expression.

Accept regular expressions after `of` (in `for`/`of`), `yield` (in a generator), and braced arrow functions.

Allow labels in front or `var` declarations, even in strict mode.

### Breaking changes

Parse declarations following `export default` as declaration nodes, not expressions. This means that class and function declarations nodes can now have `null` as their `id`.

## 4.0.11 (2017-02-07)

### Bug fixes

Allow all forms of member expressions to be parenthesized as lvalue.

## 4.0.10 (2017-02-07)

### Bug fixes

Don't expect semicolons after default-exported functions or classes, even when they are expressions.

Check for use of `'use strict'` directives in non-simple parameter functions, even when already in strict mode.

## 4.0.9 (2017-02-06)

### Bug fixes

Fix incorrect error raised for parenthesized simple assignment targets, so that `(x) = 1` parses again.

## 4.0.8 (2017-02-03)

### Bug fixes

Solve spurious parenthesized pattern errors by temporarily erring on the side of accepting programs that our delayed errors don't handle correctly yet.

## 4.0.7 (2017-02-02)

### Bug fixes

Accept invalidly rejected code like `(x).y = 2` again.

Don't raise an error when a function _inside_ strict code has a non-simple parameter list.

## 4.0.6 (2017-02-02)

### Bug fixes

Fix exponential behavior (manifesting itself as a complete hang for even relatively small source files) introduced by the new 'use strict' check.

## 4.0.5 (2017-02-02)

### Bug fixes

Disallow parenthesized pattern expressions.

Allow keywords as export names.

Don't allow the `async` keyword to be parenthesized.

Properly raise an error when a keyword contains a character escape.

Allow `"use strict"` to appear after other string literal expressions.

Disallow labeled declarations.

## 4.0.4 (2016-12-19)

### Bug fixes

Fix crash when `export` was followed by a keyword that can't be
exported.

## 4.0.3 (2016-08-16)

### Bug fixes

Allow regular function declarations inside single-statement `if` branches in loose mode. Forbid them entirely in strict mode.

Properly parse properties named `async` in ES2017 mode.

Fix bug where reserved words were broken in ES2017 mode.

## 4.0.2 (2016-08-11)

### Bug fixes

Don't ignore period or 'e' characters after octal numbers.

Fix broken parsing for call expressions in default parameter values of arrow functions.

## 4.0.1 (2016-08-08)

### Bug fixes

Fix false positives in duplicated export name errors.

## 4.0.0 (2016-08-07)

### Breaking changes

The default `ecmaVersion` option value is now 7.

A number of internal method signatures changed, so plugins might need to be updated.

### Bug fixes

The parser now raises errors on duplicated export names.

`arguments` and `eval` can now be used in shorthand properties.

Duplicate parameter names in non-simple argument lists now always produce an error.

### New features

The `ecmaVersion` option now also accepts year-style version numbers
(2015, etc).

Support for `async`/`await` syntax when `ecmaVersion` is >= 8.

Support for trailing commas in call expressions when `ecmaVersion` is >= 8.

## 3.3.0 (2016-07-25)

### Bug fixes

Fix bug in tokenizing of regexp operator after a function declaration.

Fix parser crash when parsing an array pattern with a hole.

### New features

Implement check against complex argument lists in functions that enable strict mode in ES7.

## 3.2.0 (2016-06-07)

### Bug fixes

Improve handling of lack of unicode regexp support in host
environment.

Properly reject shorthand properties whose name is a keyword.

### New features

Visitors created with `visit.make` now have their base as _prototype_, rather than copying properties into a fresh object.

## 3.1.0 (2016-04-18)

### Bug fixes

Properly tokenize the division operator directly after a function expression.

Allow trailing comma in destructuring arrays.

## 3.0.4 (2016-02-25)

### Fixes

Allow update expressions as left-hand-side of the ES7 exponential operator.

## 3.0.2 (2016-02-10)

### Fixes

Fix bug that accidentally made `undefined` a reserved word when parsing ES7.

## 3.0.0 (2016-02-10)

### Breaking changes

The default value of the `ecmaVersion` option is now 6 (used to be 5).

Support for comprehension syntax (which was dropped from the draft spec) has been removed.

### Fixes

`let` and `yield` are now “contextual keywords”, meaning you can mostly use them as identifiers in ES5 non-strict code.

A parenthesized class or function expression after `export default` is now parsed correctly.

### New features

When `ecmaVersion` is set to 7, Acorn will parse the exponentiation operator (`**`).

The identifier character ranges are now based on Unicode 8.0.0.

Plugins can now override the `raiseRecoverable` method to override the way non-critical errors are handled.

## 2.7.0 (2016-01-04)

### Fixes

Stop allowing rest parameters in setters.

Disallow `y` rexexp flag in ES5.

Disallow `\00` and `\000` escapes in strict mode.

Raise an error when an import name is a reserved word.

## 2.6.2 (2015-11-10)

### Fixes

Don't crash when no options object is passed.

## 2.6.0 (2015-11-09)

### Fixes

Add `await` as a reserved word in module sources.

Disallow `yield` in a parameter default value for a generator.

Forbid using a comma after a rest pattern in an array destructuring.

### New features

Support parsing stdin in command-line tool.

## 2.5.0 (2015-10-27)

### Fixes

Fix tokenizer support in the command-line tool.

Stop allowing `new.target` outside of functions.

Remove legacy `guard` and `guardedHandler` properties from try nodes.

Stop allowing multiple `__proto__` properties on an object literal in strict mode.

Don't allow rest parameters to be non-identifier patterns.

Check for duplicate paramter names in arrow functions.
# Acorn

A tiny, fast JavaScript parser written in JavaScript.

## Community

Acorn is open source software released under an
[MIT license](https://github.com/acornjs/acorn/blob/master/acorn/LICENSE).

You are welcome to
[report bugs](https://github.com/acornjs/acorn/issues) or create pull
requests on [github](https://github.com/acornjs/acorn).

## Installation

The easiest way to install acorn is from [`npm`](https://www.npmjs.com/):

```sh
npm install acorn
```

Alternately, you can download the source and build acorn yourself:

```sh
git clone https://github.com/acornjs/acorn.git
cd acorn
npm install
```

## Interface

**parse**`(input, options)` is the main interface to the library. The
`input` parameter is a string, `options` must be an object setting
some of the options listed below. The return value will be an abstract
syntax tree object as specified by the [ESTree
spec](https://github.com/estree/estree).

```javascript
let acorn = require("acorn");
console.log(acorn.parse("1 + 1", {ecmaVersion: 2020}));
```

When encountering a syntax error, the parser will raise a
`SyntaxError` object with a meaningful message. The error object will
have a `pos` property that indicates the string offset at which the
error occurred, and a `loc` object that contains a `{line, column}`
object referring to that same position.

Options are provided by in a second argument, which should be an
object containing any of these fields (only `ecmaVersion` is
required):

- **ecmaVersion**: Indicates the ECMAScript version to parse. Must be
  either 3, 5, 6 (or 2015), 7 (2016), 8 (2017), 9 (2018), 10 (2019),
  11 (2020), 12 (2021), 13 (2022), 14 (2023), or `"latest"` (the
  latest the library supports). This influences support for strict
  mode, the set of reserved words, and support for new syntax
  features.

  **NOTE**: Only 'stage 4' (finalized) ECMAScript features are being
  implemented by Acorn. Other proposed new features must be
  implemented through plugins.

- **sourceType**: Indicate the mode the code should be parsed in. Can be
  either `"script"` or `"module"`. This influences global strict mode
  and parsing of `import` and `export` declarations.

  **NOTE**: If set to `"module"`, then static `import` / `export` syntax
  will be valid, even if `ecmaVersion` is less than 6.

- **onInsertedSemicolon**: If given a callback, that callback will be
  called whenever a missing semicolon is inserted by the parser. The
  callback will be given the character offset of the point where the
  semicolon is inserted as argument, and if `locations` is on, also a
  `{line, column}` object representing this position.

- **onTrailingComma**: Like `onInsertedSemicolon`, but for trailing
  commas.

- **allowReserved**: If `false`, using a reserved word will generate
  an error. Defaults to `true` for `ecmaVersion` 3, `false` for higher
  versions. When given the value `"never"`, reserved words and
  keywords can also not be used as property names (as in Internet
  Explorer's old parser).

- **allowReturnOutsideFunction**: By default, a return statement at
  the top level raises an error. Set this to `true` to accept such
  code.

- **allowImportExportEverywhere**: By default, `import` and `export`
  declarations can only appear at a program's top level. Setting this
  option to `true` allows them anywhere where a statement is allowed,
  and also allows `import.meta` expressions to appear in scripts
  (when `sourceType` is not `"module"`).

- **allowAwaitOutsideFunction**: If `false`, `await` expressions can
  only appear inside `async` functions. Defaults to `true` in modules
  for `ecmaVersion` 2022 and later, `false` for lower versions.
  Setting this option to `true` allows to have top-level `await`
  expressions. They are still not allowed in non-`async` functions,
  though.

- **allowSuperOutsideMethod**: By default, `super` outside a method
  raises an error. Set this to `true` to accept such code.

- **allowHashBang**: When this is enabled, if the code starts with the
  characters `#!` (as in a shellscript), the first line will be
  treated as a comment. Defaults to true when `ecmaVersion` >= 2023.

- **checkPrivateFields**: By default, the parser will verify that
  private properties are only used in places where they are valid and
  have been declared. Set this to false to turn such checks off.

- **locations**: When `true`, each node has a `loc` object attached
  with `start` and `end` subobjects, each of which contains the
  one-based line and zero-based column numbers in `{line, column}`
  form. Default is `false`.

- **onToken**: If a function is passed for this option, each found
  token will be passed in same format as tokens returned from
  `tokenizer().getToken()`.

  If array is passed, each found token is pushed to it.

  Note that you are not allowed to call the parser from the
  callback—that will corrupt its internal state.

- **onComment**: If a function is passed for this option, whenever a
  comment is encountered the function will be called with the
  following parameters:

  - `block`: `true` if the comment is a block comment, false if it
    is a line comment.
  - `text`: The content of the comment.
  - `start`: Character offset of the start of the comment.
  - `end`: Character offset of the end of the comment.

  When the `locations` options is on, the `{line, column}` locations
  of the comment’s start and end are passed as two additional
  parameters.

  If array is passed for this option, each found comment is pushed
  to it as object in Esprima format:

  ```javascript
  {
    "type": "Line" | "Block",
    "value": "comment text",
    "start": Number,
    "end": Number,
    // If `locations` option is on:
    "loc": {
      "start": {line: Number, column: Number}
      "end": {line: Number, column: Number}
    },
    // If `ranges` option is on:
    "range": [Number, Number]
  }
  ```

  Note that you are not allowed to call the parser from the
  callback—that will corrupt its internal state.

- **ranges**: Nodes have their start and end characters offsets
  recorded in `start` and `end` properties (directly on the node,
  rather than the `loc` object, which holds line/column data. To also
  add a
  [semi-standardized](https://bugzilla.mozilla.org/show_bug.cgi?id=745678)
  `range` property holding a `[start, end]` array with the same
  numbers, set the `ranges` option to `true`.

- **program**: It is possible to parse multiple files into a single
  AST by passing the tree produced by parsing the first file as the
  `program` option in subsequent parses. This will add the toplevel
  forms of the parsed file to the "Program" (top) node of an existing
  parse tree.

- **sourceFile**: When the `locations` option is `true`, you can pass
  this option to add a `source` attribute in every node’s `loc`
  object. Note that the contents of this option are not examined or
  processed in any way; you are free to use whatever format you
  choose.

- **directSourceFile**: Like `sourceFile`, but a `sourceFile` property
  will be added (regardless of the `location` option) directly to the
  nodes, rather than the `loc` object.

- **preserveParens**: If this option is `true`, parenthesized expressions
  are represented by (non-standard) `ParenthesizedExpression` nodes
  that have a single `expression` property containing the expression
  inside parentheses.

**parseExpressionAt**`(input, offset, options)` will parse a single
expression in a string, and return its AST. It will not complain if
there is more of the string left after the expression.

**tokenizer**`(input, options)` returns an object with a `getToken`
method that can be called repeatedly to get the next token, a `{start,
end, type, value}` object (with added `loc` property when the
`locations` option is enabled and `range` property when the `ranges`
option is enabled). When the token's type is `tokTypes.eof`, you
should stop calling the method, since it will keep returning that same
token forever.

Note that tokenizing JavaScript without parsing it is, in modern
versions of the language, not really possible due to the way syntax is
overloaded in ways that can only be disambiguated by the parse
context. This package applies a bunch of heuristics to try and do a
reasonable job, but you are advised to use `parse` with the `onToken`
option instead of this.

In ES6 environment, returned result can be used as any other
protocol-compliant iterable:

```javascript
for (let token of acorn.tokenizer(str)) {
  // iterate over the tokens
}

// transform code to array of tokens:
var tokens = [...acorn.tokenizer(str)];
```

**tokTypes** holds an object mapping names to the token type objects
that end up in the `type` properties of tokens.

**getLineInfo**`(input, offset)` can be used to get a `{line,
column}` object for a given program string and offset.

### The `Parser` class

Instances of the **`Parser`** class contain all the state and logic
that drives a parse. It has static methods `parse`,
`parseExpressionAt`, and `tokenizer` that match the top-level
functions by the same name.

When extending the parser with plugins, you need to call these methods
on the extended version of the class. To extend a parser with plugins,
you can use its static `extend` method.

```javascript
var acorn = require("acorn");
var jsx = require("acorn-jsx");
var JSXParser = acorn.Parser.extend(jsx());
JSXParser.parse("foo(<bar/>)", {ecmaVersion: 2020});
```

The `extend` method takes any number of plugin values, and returns a
new `Parser` class that includes the extra parser logic provided by
the plugins.

## Command line interface

The `bin/acorn` utility can be used to parse a file from the command
line. It accepts as arguments its input file and the following
options:

- `--ecma3|--ecma5|--ecma6|--ecma7|--ecma8|--ecma9|--ecma10`: Sets the ECMAScript version
  to parse. Default is version 9.

- `--module`: Sets the parsing mode to `"module"`. Is set to `"script"` otherwise.

- `--locations`: Attaches a "loc" object to each node with "start" and
  "end" subobjects, each of which contains the one-based line and
  zero-based column numbers in `{line, column}` form.

- `--allow-hash-bang`: If the code starts with the characters #! (as
  in a shellscript), the first line will be treated as a comment.

- `--allow-await-outside-function`: Allows top-level `await` expressions.
  See the `allowAwaitOutsideFunction` option for more information.

- `--compact`: No whitespace is used in the AST output.

- `--silent`: Do not output the AST, just return the exit status.

- `--help`: Print the usage information and quit.

The utility spits out the syntax tree as JSON data.

## Existing plugins

 - [`acorn-jsx`](https://github.com/RReverser/acorn-jsx): Parse [Facebook JSX syntax extensions](https://github.com/facebook/jsx)

# file-entry-cache - Changelog
## v6.0.1
- **Other changes**
  - Delete previous mtime when checksum is used and vice versa - [abcf0f9]( https://github.com/royriojas/file-entry-cache/commit/abcf0f9 ), [Milos Djermanovic](https://github.com/Milos Djermanovic), 19/02/2021 18:19:43

    
  - Adds travis jobs on ppc64le - [92e4d4a]( https://github.com/royriojas/file-entry-cache/commit/92e4d4a ), [dineshks1](https://github.com/dineshks1), 25/11/2020 04:52:11

    
## v6.0.0
- **Refactoring**
  - Align file-entry-cache with latest eslint - [4c6f1fb]( https://github.com/royriojas/file-entry-cache/commit/4c6f1fb ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 02:43:09

    
  - Upgrade deps - [8ab3257]( https://github.com/royriojas/file-entry-cache/commit/8ab3257 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 02:41:53

    
  - updated packages - [3dd4231]( https://github.com/royriojas/file-entry-cache/commit/3dd4231 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 02:29:37

    
  - Upgrade flat-cache to version 3 - [d7c60ef]( https://github.com/royriojas/file-entry-cache/commit/d7c60ef ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:18:04

    
## v5.0.1
- **Bug Fixes**
  - Fix missing checksum comparison from reconcile since now we use mtime and size by default. - [e858aa9]( https://github.com/royriojas/file-entry-cache/commit/e858aa9 ), [Roy Riojas](https://github.com/Roy Riojas), 04/02/2019 09:30:22

    Old mode using checkSum can still be used by passing the `useCheckSum` parameter to the `create` or `createFromFile` methods.
    
## v5.0.0
- **Refactoring**
  - Make checksum comparison optional - [b0f9ae0]( https://github.com/royriojas/file-entry-cache/commit/b0f9ae0 ), [Roy Riojas](https://github.com/Roy Riojas), 03/02/2019 18:17:39

    To determine if a file has changed we were using the checksum in the newer versions, but eslint was relying on the old behavior where we use the mtime and file size to determine if a file changed. That's why we decided to make the checksum check optional.
    
    To use it:
    
    ```js
    // to make the cache use the checkSum check do the following:
    var fCache = fileEntryCache.create(cacheName, dir, useCheckSum); // pass the third parameter as true
    var otherCache = fileEntryCache.createFromFile(cacheName, useCheckSum); // pass the second parameter as true
    ```
    
## v4.0.0
- **Build Scripts Changes**
  - use the same node versions eslint use - [563cfee]( https://github.com/royriojas/file-entry-cache/commit/563cfee ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 20:29:34

    
- **Other changes**
  - Remove object-assign dependency. - [d0f598e]( https://github.com/royriojas/file-entry-cache/commit/d0f598e ), [Corey Farrell](https://github.com/Corey Farrell), 08/01/2019 20:09:51

    node.js >=4 is required so object-assign is no longer needed, the native
    Object.assign can be used instead.
    
## v3.0.0
- **Build Scripts Changes**
  - Upgrade flat-cache dep to latest - [078b0df]( https://github.com/royriojas/file-entry-cache/commit/078b0df ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 18:54:40

    
  - Commit new package-lock.json file - [245fe62]( https://github.com/royriojas/file-entry-cache/commit/245fe62 ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 17:56:21

    
- **Refactoring**
  - add eslintrc file - [6dd32d8]( https://github.com/royriojas/file-entry-cache/commit/6dd32d8 ), [Roy Riojas](https://github.com/Roy Riojas), 22/08/2018 09:58:17

    
- **Other changes**
  - Move variable definition out of else block - [ea05441]( https://github.com/royriojas/file-entry-cache/commit/ea05441 ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 25/04/2017 11:19:00

    
  - Add script and cmd to test hash/checksum performance - [7f60e0a]( https://github.com/royriojas/file-entry-cache/commit/7f60e0a ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 24/04/2017 14:43:12

    
  - Calculate md5 hexdigest instead of Adler-32 checksum - [f9e5c69]( https://github.com/royriojas/file-entry-cache/commit/f9e5c69 ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 24/04/2017 14:43:12

    
  - How to reproduce - [4edc2dc]( https://github.com/royriojas/file-entry-cache/commit/4edc2dc ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 24/04/2017 13:49:32

    
  - Test handling of removed files - [09d9ec5]( https://github.com/royriojas/file-entry-cache/commit/09d9ec5 ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 19/04/2017 19:51:50

    
  - Use content checksum instead of mtime and fsize - [343b340]( https://github.com/royriojas/file-entry-cache/commit/343b340 ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 19/04/2017 19:51:47

    
- **Revert**
  - Revert "How to reproduce" - [4b4e54a]( https://github.com/royriojas/file-entry-cache/commit/4b4e54a ), [Zakhar Shapurau](https://github.com/Zakhar Shapurau), 25/04/2017 11:15:36

    This reverts commit 4edc2dcec01574247bfc2e0a2fe26527332b7df3.
    
## v2.0.0
- **Features**
  - do not persist and prune removed files from cache. Relates to [#2](https://github.com/royriojas/file-entry-cache/issues/2) - [408374d]( https://github.com/royriojas/file-entry-cache/commit/408374d ), [Roy Riojas](https://github.com/Roy Riojas), 16/08/2016 13:47:58

    
## v1.3.1
- **Build Scripts Changes**
  - remove older node version - [0a26ac4]( https://github.com/royriojas/file-entry-cache/commit/0a26ac4 ), [Roy Riojas](https://github.com/Roy Riojas), 01/08/2016 04:09:17

    
## v1.3.0
- **Features**
  - Add an option to not prune non visited keys. Closes [#2](https://github.com/royriojas/file-entry-cache/issues/2) - [b1a64db]( https://github.com/royriojas/file-entry-cache/commit/b1a64db ), [Roy Riojas](https://github.com/Roy Riojas), 01/08/2016 03:52:12

    
## v1.2.4
- **Enhancements**
  - Expose the flat-cache instance - [f34c557]( https://github.com/royriojas/file-entry-cache/commit/f34c557 ), [royriojas](https://github.com/royriojas), 23/09/2015 18:26:33

    
## v1.2.3
- **Build Scripts Changes**
  - update flat-cache dep - [cc7b9ce]( https://github.com/royriojas/file-entry-cache/commit/cc7b9ce ), [royriojas](https://github.com/royriojas), 11/09/2015 16:04:44

    
## v1.2.2
- **Build Scripts Changes**
  - Add changelogx section to package.json - [a3916ff]( https://github.com/royriojas/file-entry-cache/commit/a3916ff ), [royriojas](https://github.com/royriojas), 11/09/2015 16:00:26

    
## v1.2.1
- **Build Scripts Changes**
  - update flat-cache dep - [e49b0d4]( https://github.com/royriojas/file-entry-cache/commit/e49b0d4 ), [royriojas](https://github.com/royriojas), 11/09/2015 15:55:25

    
- **Other changes**
  - Update dependencies Replaced lodash.assign with smaller object-assign Fixed tests for windows - [0ad3000]( https://github.com/royriojas/file-entry-cache/commit/0ad3000 ), [Bogdan Chadkin](https://github.com/Bogdan Chadkin), 11/09/2015 15:44:18

    
## v1.2.0
- **Features**
  - analyzeFiles now returns also the files that were removed - [6ac2431]( https://github.com/royriojas/file-entry-cache/commit/6ac2431 ), [royriojas](https://github.com/royriojas), 04/09/2015 12:40:53

    
## v1.1.1
- **Features**
  - Add method to check if a file hasChanged - [3640e2b]( https://github.com/royriojas/file-entry-cache/commit/3640e2b ), [Roy Riojas](https://github.com/Roy Riojas), 30/08/2015 05:33:32

    
## v1.1.0
- **Features**
  - Create the cache directly from a file path - [a23de61]( https://github.com/royriojas/file-entry-cache/commit/a23de61 ), [Roy Riojas](https://github.com/Roy Riojas), 30/08/2015 04:41:33

    
  - Add a method to remove an entry from the filecache - [7af29fc]( https://github.com/royriojas/file-entry-cache/commit/7af29fc ), [Roy Riojas](https://github.com/Roy Riojas), 02/03/2015 23:25:32

    
  - cache module finished - [1f95544]( https://github.com/royriojas/file-entry-cache/commit/1f95544 ), [Roy Riojas](https://github.com/Roy Riojas), 02/03/2015 01:08:08

    
- **Build Scripts Changes**
  - set the version for the first release - [7472eaa]( https://github.com/royriojas/file-entry-cache/commit/7472eaa ), [Roy Riojas](https://github.com/Roy Riojas), 02/03/2015 01:29:54

    
- **Documentation**
  - Updated documentation - [557358f]( https://github.com/royriojas/file-entry-cache/commit/557358f ), [Roy Riojas](https://github.com/Roy Riojas), 02/03/2015 01:29:29

    
- **Other changes**
  - Initial commit - [3d5f42b]( https://github.com/royriojas/file-entry-cache/commit/3d5f42b ), [Roy Riojas](https://github.com/Roy Riojas), 01/03/2015 21:58:29

    
# file-entry-cache
> Super simple cache for file metadata, useful for process that work o a given series of files
> and that only need to repeat the job on the changed ones since the previous run of the process — Edit

[![NPM Version](http://img.shields.io/npm/v/file-entry-cache.svg?style=flat)](https://npmjs.org/package/file-entry-cache)
[![Build Status](http://img.shields.io/travis/royriojas/file-entry-cache.svg?style=flat)](https://travis-ci.org/royriojas/file-entry-cache)

## install

```bash
npm i --save file-entry-cache
```

## Usage

The module exposes two functions `create` and `createFromFile`.

## `create(cacheName, [directory, useCheckSum])`
- **cacheName**: the name of the cache to be created
- **directory**: Optional the directory to load the cache from
- **usecheckSum**: Whether to use md5 checksum to verify if file changed. If false the default will be to use the mtime and size of the file.

## `createFromFile(pathToCache, [useCheckSum])`
- **pathToCache**: the path to the cache file (this combines the cache name and directory)
- **useCheckSum**: Whether to use md5 checksum to verify if file changed. If false the default will be to use the mtime and size of the file.

```js
// loads the cache, if one does not exists for the given
// Id a new one will be prepared to be created
var fileEntryCache = require('file-entry-cache');

var cache = fileEntryCache.create('testCache');

var files = expand('../fixtures/*.txt');

// the first time this method is called, will return all the files
var oFiles = cache.getUpdatedFiles(files);

// this will persist this to disk checking each file stats and
// updating the meta attributes `size` and `mtime`.
// custom fields could also be added to the meta object and will be persisted
// in order to retrieve them later
cache.reconcile();

// use this if you want the non visited file entries to be kept in the cache
// for more than one execution
//
// cache.reconcile( true /* noPrune */)

// on a second run
var cache2 = fileEntryCache.create('testCache');

// will return now only the files that were modified or none
// if no files were modified previous to the execution of this function
var oFiles = cache.getUpdatedFiles(files);

// if you want to prevent a file from being considered non modified
// something useful if a file failed some sort of validation
// you can then remove the entry from the cache doing
cache.removeEntry('path/to/file'); // path to file should be the same path of the file received on `getUpdatedFiles`
// that will effectively make the file to appear again as modified until the validation is passed. In that
// case you should not remove it from the cache

// if you need all the files, so you can determine what to do with the changed ones
// you can call
var oFiles = cache.normalizeEntries(files);

// oFiles will be an array of objects like the following
entry = {
  key: 'some/name/file', the path to the file
  changed: true, // if the file was changed since previous run
  meta: {
    size: 3242, // the size of the file
    mtime: 231231231, // the modification time of the file
    data: {} // some extra field stored for this file (useful to save the result of a transformation on the file
  }
}

```

## Motivation for this module

I needed a super simple and dumb **in-memory cache** with optional disk persistence (write-back cache) in order to make
a script that will beautify files with `esformatter` to execute only on the files that were changed since the last run.

In doing so the process of beautifying files was reduced from several seconds to a small fraction of a second.

This module uses [flat-cache](https://www.npmjs.com/package/flat-cache) a super simple `key/value` cache storage with
optional file persistance.

The main idea is to read the files when the task begins, apply the transforms required, and if the process succeed,
then store the new state of the files. The next time this module request for `getChangedFiles` will return only
the files that were modified. Making the process to end faster.

This module could also be used by processes that modify the files applying a transform, in that case the result of the
transform could be stored in the `meta` field, of the entries. Anything added to the meta field will be persisted.
Those processes won't need to call `getChangedFiles` they will instead call `normalizeEntries` that will return the
entries with a `changed` field that can be used to determine if the file was changed or not. If it was not changed
the transformed stored data could be used instead of actually applying the transformation, saving time in case of only
a few files changed.

In the worst case scenario all the files will be processed. In the best case scenario only a few of them will be processed.

## Important notes
- The values set on the meta attribute of the entries should be `stringify-able` ones if possible, flat-cache uses `circular-json` to try to persist circular structures, but this should be considered experimental. The best results are always obtained with non circular values
- All the changes to the cache state are done to memory first and only persisted after reconcile.

## License

MIT


# @nodelib/fs.walk

> A library for efficiently walking a directory recursively.

## :bulb: Highlights

* :moneybag: Returns useful information: `name`, `path`, `dirent` and `stats` (optional).
* :rocket: On Node.js 10.10+ uses the mechanism without additional calls to determine the entry type for performance reasons. See [`old` and `modern` mode](https://github.com/nodelib/nodelib/blob/master/packages/fs/fs.scandir/README.md#old-and-modern-mode).
* :gear: Built-in directories/files and error filtering system.
* :link: Can safely work with broken symbolic links.

## Install

```console
npm install @nodelib/fs.walk
```

## Usage

```ts
import * as fsWalk from '@nodelib/fs.walk';

fsWalk.walk('path', (error, entries) => { /* … */ });
```

## API

### .walk(path, [optionsOrSettings], callback)

Reads the directory recursively and asynchronously. Requires a callback function.

> :book: If you want to use the Promise API, use `util.promisify`.

```ts
fsWalk.walk('path', (error, entries) => { /* … */ });
fsWalk.walk('path', {}, (error, entries) => { /* … */ });
fsWalk.walk('path', new fsWalk.Settings(), (error, entries) => { /* … */ });
```

### .walkStream(path, [optionsOrSettings])

Reads the directory recursively and asynchronously. [Readable Stream](https://nodejs.org/dist/latest-v12.x/docs/api/stream.html#stream_readable_streams) is used as a provider.

```ts
const stream = fsWalk.walkStream('path');
const stream = fsWalk.walkStream('path', {});
const stream = fsWalk.walkStream('path', new fsWalk.Settings());
```

### .walkSync(path, [optionsOrSettings])

Reads the directory recursively and synchronously. Returns an array of entries.

```ts
const entries = fsWalk.walkSync('path');
const entries = fsWalk.walkSync('path', {});
const entries = fsWalk.walkSync('path', new fsWalk.Settings());
```

#### path

* Required: `true`
* Type: `string | Buffer | URL`

A path to a file. If a URL is provided, it must use the `file:` protocol.

#### optionsOrSettings

* Required: `false`
* Type: `Options | Settings`
* Default: An instance of `Settings` class

An [`Options`](#options) object or an instance of [`Settings`](#settings) class.

> :book: When you pass a plain object, an instance of the `Settings` class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the `Settings` class.

### Settings([options])

A class of full settings of the package.

```ts
const settings = new fsWalk.Settings({ followSymbolicLinks: true });

const entries = fsWalk.walkSync('path', settings);
```

## Entry

* `name` — The name of the entry (`unknown.txt`).
* `path` — The path of the entry relative to call directory (`root/unknown.txt`).
* `dirent` — An instance of [`fs.Dirent`](./src/types/index.ts) class.
* [`stats`] — An instance of `fs.Stats` class.

## Options

### basePath

* Type: `string`
* Default: `undefined`

By default, all paths are built relative to the root path. You can use this option to set custom root path.

In the example below we read the files from the `root` directory, but in the results the root path will be `custom`.

```ts
fsWalk.walkSync('root'); // → ['root/file.txt']
fsWalk.walkSync('root', { basePath: 'custom' }); // → ['custom/file.txt']
```

### concurrency

* Type: `number`
* Default: `Infinity`

The maximum number of concurrent calls to `fs.readdir`.

> :book: The higher the number, the higher performance and the load on the File System. If you want to read in quiet mode, set the value to `4 * os.cpus().length` (4 is default size of [thread pool work scheduling](http://docs.libuv.org/en/v1.x/threadpool.html#thread-pool-work-scheduling)).

### deepFilter

* Type: [`DeepFilterFunction`](./src/settings.ts)
* Default: `undefined`

A function that indicates whether the directory will be read deep or not.

```ts
// Skip all directories that starts with `node_modules`
const filter: DeepFilterFunction = (entry) => !entry.path.startsWith('node_modules');
```

### entryFilter

* Type: [`EntryFilterFunction`](./src/settings.ts)
* Default: `undefined`

A function that indicates whether the entry will be included to results or not.

```ts
// Exclude all `.js` files from results
const filter: EntryFilterFunction = (entry) => !entry.name.endsWith('.js');
```

### errorFilter

* Type: [`ErrorFilterFunction`](./src/settings.ts)
* Default: `undefined`

A function that allows you to skip errors that occur when reading directories.

For example, you can skip `ENOENT` errors if required:

```ts
// Skip all ENOENT errors
const filter: ErrorFilterFunction = (error) => error.code == 'ENOENT';
```

### stats

* Type: `boolean`
* Default: `false`

Adds an instance of `fs.Stats` class to the [`Entry`](#entry).

> :book: Always use `fs.readdir` with additional `fs.lstat/fs.stat` calls to determine the entry type.

### followSymbolicLinks

* Type: `boolean`
* Default: `false`

Follow symbolic links or not. Call `fs.stat` on symbolic link if `true`.

### `throwErrorOnBrokenSymbolicLink`

* Type: `boolean`
* Default: `true`

Throw an error when symbolic link is broken if `true` or safely return `lstat` call if `false`.

### `pathSegmentSeparator`

* Type: `string`
* Default: `path.sep`

By default, this package uses the correct path separator for your OS (`\` on Windows, `/` on Unix-like systems). But you can set this option to any separator character(s) that you want to use instead.

### `fs`

* Type: `FileSystemAdapter`
* Default: A default FS methods

By default, the built-in Node.js module (`fs`) is used to work with the file system. You can replace any method with your own.

```ts
interface FileSystemAdapter {
	lstat: typeof fs.lstat;
	stat: typeof fs.stat;
	lstatSync: typeof fs.lstatSync;
	statSync: typeof fs.statSync;
	readdir: typeof fs.readdir;
	readdirSync: typeof fs.readdirSync;
}

const settings = new fsWalk.Settings({
	fs: { lstat: fakeLstat }
});
```

## Changelog

See the [Releases section of our GitHub project](https://github.com/nodelib/nodelib/releases) for changelog for each release version.

## License

This software is released under the terms of the MIT license.
# @nodelib/fs.stat

> Get the status of a file with some features.

## :bulb: Highlights

Wrapper around standard method `fs.lstat` and `fs.stat` with some features.

* :beginner: Normally follows symbolic link.
* :gear: Can safely work with broken symbolic link.

## Install

```console
npm install @nodelib/fs.stat
```

## Usage

```ts
import * as fsStat from '@nodelib/fs.stat';

fsStat.stat('path', (error, stats) => { /* … */ });
```

## API

### .stat(path, [optionsOrSettings], callback)

Returns an instance of `fs.Stats` class for provided path with standard callback-style.

```ts
fsStat.stat('path', (error, stats) => { /* … */ });
fsStat.stat('path', {}, (error, stats) => { /* … */ });
fsStat.stat('path', new fsStat.Settings(), (error, stats) => { /* … */ });
```

### .statSync(path, [optionsOrSettings])

Returns an instance of `fs.Stats` class for provided path.

```ts
const stats = fsStat.stat('path');
const stats = fsStat.stat('path', {});
const stats = fsStat.stat('path', new fsStat.Settings());
```

#### path

* Required: `true`
* Type: `string | Buffer | URL`

A path to a file. If a URL is provided, it must use the `file:` protocol.

#### optionsOrSettings

* Required: `false`
* Type: `Options | Settings`
* Default: An instance of `Settings` class

An [`Options`](#options) object or an instance of [`Settings`](#settings) class.

> :book: When you pass a plain object, an instance of the `Settings` class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the `Settings` class.

### Settings([options])

A class of full settings of the package.

```ts
const settings = new fsStat.Settings({ followSymbolicLink: false });

const stats = fsStat.stat('path', settings);
```

## Options

### `followSymbolicLink`

* Type: `boolean`
* Default: `true`

Follow symbolic link or not. Call `fs.stat` on symbolic link if `true`.

### `markSymbolicLink`

* Type: `boolean`
* Default: `false`

Mark symbolic link by setting the return value of `isSymbolicLink` function to always `true` (even after `fs.stat`).

> :book: Can be used if you want to know what is hidden behind a symbolic link, but still continue to know that it is a symbolic link.

### `throwErrorOnBrokenSymbolicLink`

* Type: `boolean`
* Default: `true`

Throw an error when symbolic link is broken if `true` or safely return `lstat` call if `false`.

### `fs`

* Type: [`FileSystemAdapter`](./src/adapters/fs.ts)
* Default: A default FS methods

By default, the built-in Node.js module (`fs`) is used to work with the file system. You can replace any method with your own.

```ts
interface FileSystemAdapter {
	lstat?: typeof fs.lstat;
	stat?: typeof fs.stat;
	lstatSync?: typeof fs.lstatSync;
	statSync?: typeof fs.statSync;
}

const settings = new fsStat.Settings({
	fs: { lstat: fakeLstat }
});
```

## Changelog

See the [Releases section of our GitHub project](https://github.com/nodelib/nodelib/releases) for changelog for each release version.

## License

This software is released under the terms of the MIT license.
# @nodelib/fs.scandir

> List files and directories inside the specified directory.

## :bulb: Highlights

The package is aimed at obtaining information about entries in the directory.

* :moneybag: Returns useful information: `name`, `path`, `dirent` and `stats` (optional).
* :gear: On Node.js 10.10+ uses the mechanism without additional calls to determine the entry type. See [`old` and `modern` mode](#old-and-modern-mode).
* :link: Can safely work with broken symbolic links.

## Install

```console
npm install @nodelib/fs.scandir
```

## Usage

```ts
import * as fsScandir from '@nodelib/fs.scandir';

fsScandir.scandir('path', (error, stats) => { /* … */ });
```

## API

### .scandir(path, [optionsOrSettings], callback)

Returns an array of plain objects ([`Entry`](#entry)) with information about entry for provided path with standard callback-style.

```ts
fsScandir.scandir('path', (error, entries) => { /* … */ });
fsScandir.scandir('path', {}, (error, entries) => { /* … */ });
fsScandir.scandir('path', new fsScandir.Settings(), (error, entries) => { /* … */ });
```

### .scandirSync(path, [optionsOrSettings])

Returns an array of plain objects ([`Entry`](#entry)) with information about entry for provided path.

```ts
const entries = fsScandir.scandirSync('path');
const entries = fsScandir.scandirSync('path', {});
const entries = fsScandir.scandirSync(('path', new fsScandir.Settings());
```

#### path

* Required: `true`
* Type: `string | Buffer | URL`

A path to a file. If a URL is provided, it must use the `file:` protocol.

#### optionsOrSettings

* Required: `false`
* Type: `Options | Settings`
* Default: An instance of `Settings` class

An [`Options`](#options) object or an instance of [`Settings`](#settingsoptions) class.

> :book: When you pass a plain object, an instance of the `Settings` class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the `Settings` class.

### Settings([options])

A class of full settings of the package.

```ts
const settings = new fsScandir.Settings({ followSymbolicLinks: false });

const entries = fsScandir.scandirSync('path', settings);
```

## Entry

* `name` — The name of the entry (`unknown.txt`).
* `path` — The path of the entry relative to call directory (`root/unknown.txt`).
* `dirent` — An instance of [`fs.Dirent`](./src/types/index.ts) class. On Node.js below 10.10 will be emulated by [`DirentFromStats`](./src/utils/fs.ts) class.
* `stats` (optional) — An instance of `fs.Stats` class.

For example, the `scandir` call for `tools` directory with one directory inside:

```ts
{
	dirent: Dirent { name: 'typedoc', /* … */ },
	name: 'typedoc',
	path: 'tools/typedoc'
}
```

## Options

### stats

* Type: `boolean`
* Default: `false`

Adds an instance of `fs.Stats` class to the [`Entry`](#entry).

> :book: Always use `fs.readdir` without the `withFileTypes` option. ??TODO??

### followSymbolicLinks

* Type: `boolean`
* Default: `false`

Follow symbolic links or not. Call `fs.stat` on symbolic link if `true`.

### `throwErrorOnBrokenSymbolicLink`

* Type: `boolean`
* Default: `true`

Throw an error when symbolic link is broken if `true` or safely use `lstat` call if `false`.

### `pathSegmentSeparator`

* Type: `string`
* Default: `path.sep`

By default, this package uses the correct path separator for your OS (`\` on Windows, `/` on Unix-like systems). But you can set this option to any separator character(s) that you want to use instead.

### `fs`

* Type: [`FileSystemAdapter`](./src/adapters/fs.ts)
* Default: A default FS methods

By default, the built-in Node.js module (`fs`) is used to work with the file system. You can replace any method with your own.

```ts
interface FileSystemAdapter {
	lstat?: typeof fs.lstat;
	stat?: typeof fs.stat;
	lstatSync?: typeof fs.lstatSync;
	statSync?: typeof fs.statSync;
	readdir?: typeof fs.readdir;
	readdirSync?: typeof fs.readdirSync;
}

const settings = new fsScandir.Settings({
	fs: { lstat: fakeLstat }
});
```

## `old` and `modern` mode

This package has two modes that are used depending on the environment and parameters of use.

### old

* Node.js below `10.10` or when the `stats` option is enabled

When working in the old mode, the directory is read first (`fs.readdir`), then the type of entries is determined (`fs.lstat` and/or `fs.stat` for symbolic links).

### modern

* Node.js 10.10+ and the `stats` option is disabled

In the modern mode, reading the directory (`fs.readdir` with the `withFileTypes` option) is combined with obtaining information about its entries. An additional call for symbolic links (`fs.stat`) is still present.

This mode makes fewer calls to the file system. It's faster.

## Changelog

See the [Releases section of our GitHub project](https://github.com/nodelib/nodelib/releases) for changelog for each release version.

## License

This software is released under the terms of the MIT license.
# once

Only call a function once.

## usage

```javascript
var once = require('once')

function load (file, cb) {
  cb = once(cb)
  loader.load('file')
  loader.once('load', cb)
  loader.once('error', cb)
}
```

Or add to the Function.prototype in a responsible way:

```javascript
// only has to be done once
require('once').proto()

function load (file, cb) {
  cb = cb.once()
  loader.load('file')
  loader.once('load', cb)
  loader.once('error', cb)
}
```

Ironically, the prototype feature makes this module twice as
complicated as necessary.

To check whether you function has been called, use `fn.called`. Once the
function is called for the first time the return value of the original
function is saved in `fn.value` and subsequent calls will continue to
return this value.

```javascript
var once = require('once')

function load (cb) {
  cb = once(cb)
  var stream = createStream()
  stream.once('data', cb)
  stream.once('end', function () {
    if (!cb.called) cb(new Error('not found'))
  })
}
```

## `once.strict(func)`

Throw an error if the function is called twice.

Some functions are expected to be called only once. Using `once` for them would
potentially hide logical errors.

In the example below, the `greet` function has to call the callback only once:

```javascript
function greet (name, cb) {
  // return is missing from the if statement
  // when no name is passed, the callback is called twice
  if (!name) cb('Hello anonymous')
  cb('Hello ' + name)
}

function log (msg) {
  console.log(msg)
}

// this will print 'Hello anonymous' but the logical error will be missed
greet(null, once(msg))

// once.strict will print 'Hello anonymous' and throw an error when the callback will be called the second time
greet(null, once.strict(msg))
```
# regexpp

[![npm version](https://img.shields.io/npm/v/regexpp.svg)](https://www.npmjs.com/package/regexpp)
[![Downloads/month](https://img.shields.io/npm/dm/regexpp.svg)](http://www.npmtrends.com/regexpp)
[![Build Status](https://github.com/mysticatea/regexpp/workflows/CI/badge.svg)](https://github.com/mysticatea/regexpp/actions)
[![codecov](https://codecov.io/gh/mysticatea/regexpp/branch/master/graph/badge.svg)](https://codecov.io/gh/mysticatea/regexpp)
[![Dependency Status](https://david-dm.org/mysticatea/regexpp.svg)](https://david-dm.org/mysticatea/regexpp)

A regular expression parser for ECMAScript.

## 💿 Installation

```bash
$ npm install regexpp
```

- require Node.js 8 or newer.

## 📖 Usage

```ts
import {
    AST,
    RegExpParser,
    RegExpValidator,
    RegExpVisitor,
    parseRegExpLiteral,
    validateRegExpLiteral,
    visitRegExpAST
} from "regexpp"
```

### parseRegExpLiteral(source, options?)

Parse a given regular expression literal then make AST object.

This is equivalent to `new RegExpParser(options).parseLiteral(source)`.

- **Parameters:**
    - `source` (`string | RegExp`) The source code to parse.
    - `options?` ([`RegExpParser.Options`]) The options to parse.
- **Return:**
    - The AST of the regular expression.

### validateRegExpLiteral(source, options?)

Validate a given regular expression literal.

This is equivalent to `new RegExpValidator(options).validateLiteral(source)`.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `options?` ([`RegExpValidator.Options`]) The options to validate.

### visitRegExpAST(ast, handlers)

Visit each node of a given AST.

This is equivalent to `new RegExpVisitor(handlers).visit(ast)`.

- **Parameters:**
    - `ast` ([`AST.Node`]) The AST to visit.
    - `handlers` ([`RegExpVisitor.Handlers`]) The callbacks.

### RegExpParser

#### new RegExpParser(options?)

- **Parameters:**
    - `options?` ([`RegExpParser.Options`]) The options to parse.

#### parser.parseLiteral(source, start?, end?)

Parse a regular expression literal.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"/abc/g"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
- **Return:**
    - The AST of the regular expression.

#### parser.parsePattern(source, start?, end?, uFlag?)

Parse a regular expression pattern.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"abc"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
    - `uFlag?` (`boolean`) The flag to enable Unicode mode.
- **Return:**
    - The AST of the regular expression pattern.

#### parser.parseFlags(source, start?, end?)

Parse a regular expression flags.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"gim"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
- **Return:**
    - The AST of the regular expression flags.

### RegExpValidator

#### new RegExpValidator(options)

- **Parameters:**
    - `options` ([`RegExpValidator.Options`]) The options to validate.

#### validator.validateLiteral(source, start, end)

Validate a regular expression literal.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.

#### validator.validatePattern(source, start, end, uFlag)

Validate a regular expression pattern.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
    - `uFlag?` (`boolean`) The flag to enable Unicode mode.

#### validator.validateFlags(source, start, end)

Validate a regular expression flags.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.

### RegExpVisitor

#### new RegExpVisitor(handlers)

- **Parameters:**
    - `handlers` ([`RegExpVisitor.Handlers`]) The callbacks.

#### visitor.visit(ast)

Validate a regular expression literal.

- **Parameters:**
    - `ast` ([`AST.Node`]) The AST to visit.

## 📰 Changelog

- [GitHub Releases](https://github.com/mysticatea/regexpp/releases)

## 🍻 Contributing

Welcome contributing!

Please use GitHub's Issues/PRs.

### Development Tools

- `npm test` runs tests and measures coverage.
- `npm run build` compiles TypeScript source code to `index.js`, `index.js.map`, and `index.d.ts`.
- `npm run clean` removes the temporary files which are created by `npm test` and `npm run build`.
- `npm run lint` runs ESLint.
- `npm run update:test` updates test fixtures.
- `npm run update:ids` updates `src/unicode/ids.ts`.
- `npm run watch` runs tests with `--watch` option.

[`AST.Node`]: src/ast.ts#L4
[`RegExpParser.Options`]: src/parser.ts#L539
[`RegExpValidator.Options`]: src/validator.ts#L127
[`RegExpVisitor.Handlers`]: src/visitor.ts#L204
<table><thead>
  <tr>
    <th>Linux</th>
    <th>OS X</th>
    <th>Windows</th>
    <th>Coverage</th>
    <th>Downloads</th>
  </tr>
</thead><tbody><tr>
  <td colspan="2" align="center">
    <a href="https://github.com/kaelzhang/node-ignore/actions/workflows/nodejs.yml">
    <img
      src="https://github.com/kaelzhang/node-ignore/actions/workflows/nodejs.yml/badge.svg"
      alt="Build Status" /></a>
  </td>
  <td align="center">
    <a href="https://ci.appveyor.com/project/kaelzhang/node-ignore">
    <img
      src="https://ci.appveyor.com/api/projects/status/github/kaelzhang/node-ignore?branch=master&svg=true"
      alt="Windows Build Status" /></a>
  </td>
  <td align="center">
    <a href="https://codecov.io/gh/kaelzhang/node-ignore">
    <img
      src="https://codecov.io/gh/kaelzhang/node-ignore/branch/master/graph/badge.svg"
      alt="Coverage Status" /></a>
  </td>
  <td align="center">
    <a href="https://www.npmjs.org/package/ignore">
    <img
      src="http://img.shields.io/npm/dm/ignore.svg"
      alt="npm module downloads per month" /></a>
  </td>
</tr></tbody></table>

# ignore

`ignore` is a manager, filter and parser which implemented in pure JavaScript according to the [.gitignore spec 2.22.1](http://git-scm.com/docs/gitignore).

`ignore` is used by eslint, gitbook and [many others](https://www.npmjs.com/browse/depended/ignore).

Pay **ATTENTION** that [`minimatch`](https://www.npmjs.org/package/minimatch) (which used by `fstream-ignore`) does not follow the gitignore spec.

To filter filenames according to a .gitignore file, I recommend this npm package, `ignore`.

To parse an `.npmignore` file, you should use `minimatch`, because an `.npmignore` file is parsed by npm using `minimatch` and it does not work in the .gitignore way.

### Tested on

`ignore` is fully tested, and has more than **five hundreds** of unit tests.

- Linux + Node: `0.8` - `7.x`
- Windows + Node: `0.10` - `7.x`, node < `0.10` is not tested due to the lack of support of appveyor.

Actually, `ignore` does not rely on any versions of node specially.

Since `4.0.0`, ignore will no longer support `node < 6` by default, to use in node < 6, `require('ignore/legacy')`. For details, see [CHANGELOG](https://github.com/kaelzhang/node-ignore/blob/master/CHANGELOG.md).

## Table Of Main Contents

- [Usage](#usage)
- [`Pathname` Conventions](#pathname-conventions)
- See Also:
  - [`glob-gitignore`](https://www.npmjs.com/package/glob-gitignore) matches files using patterns and filters them according to gitignore rules.
- [Upgrade Guide](#upgrade-guide)

## Install

```sh
npm i ignore
```

## Usage

```js
import ignore from 'ignore'
const ig = ignore().add(['.abc/*', '!.abc/d/'])
```

### Filter the given paths

```js
const paths = [
  '.abc/a.js',    // filtered out
  '.abc/d/e.js'   // included
]

ig.filter(paths)        // ['.abc/d/e.js']
ig.ignores('.abc/a.js') // true
```

### As the filter function

```js
paths.filter(ig.createFilter()); // ['.abc/d/e.js']
```

### Win32 paths will be handled

```js
ig.filter(['.abc\\a.js', '.abc\\d\\e.js'])
// if the code above runs on windows, the result will be
// ['.abc\\d\\e.js']
```

## Why another ignore?

- `ignore` is a standalone module, and is much simpler so that it could easy work with other programs, unlike [isaacs](https://npmjs.org/~isaacs)'s [fstream-ignore](https://npmjs.org/package/fstream-ignore) which must work with the modules of the fstream family.

- `ignore` only contains utility methods to filter paths according to the specified ignore rules, so
  - `ignore` never try to find out ignore rules by traversing directories or fetching from git configurations.
  - `ignore` don't cares about sub-modules of git projects.

- Exactly according to [gitignore man page](http://git-scm.com/docs/gitignore), fixes some known matching issues of fstream-ignore, such as:
  - '`/*.js`' should only match '`a.js`', but not '`abc/a.js`'.
  - '`**/foo`' should match '`foo`' anywhere.
  - Prevent re-including a file if a parent directory of that file is excluded.
  - Handle trailing whitespaces:
    - `'a '`(one space) should not match `'a  '`(two spaces).
    - `'a \ '` matches `'a  '`
  - All test cases are verified with the result of `git check-ignore`.

# Methods

## .add(pattern: string | Ignore): this
## .add(patterns: Array<string | Ignore>): this

- **pattern** `String | Ignore` An ignore pattern string, or the `Ignore` instance
- **patterns** `Array<String | Ignore>` Array of ignore patterns.

Adds a rule or several rules to the current manager.

Returns `this`

Notice that a line starting with `'#'`(hash) is treated as a comment. Put a backslash (`'\'`) in front of the first hash for patterns that begin with a hash, if you want to ignore a file with a hash at the beginning of the filename.

```js
ignore().add('#abc').ignores('#abc')    // false
ignore().add('\\#abc').ignores('#abc')   // true
```

`pattern` could either be a line of ignore pattern or a string of multiple ignore patterns, which means we could just `ignore().add()` the content of a ignore file:

```js
ignore()
.add(fs.readFileSync(filenameOfGitignore).toString())
.filter(filenames)
```

`pattern` could also be an `ignore` instance, so that we could easily inherit the rules of another `Ignore` instance.

## <strike>.addIgnoreFile(path)</strike>

REMOVED in `3.x` for now.

To upgrade `ignore@2.x` up to `3.x`, use

```js
import fs from 'fs'

if (fs.existsSync(filename)) {
  ignore().add(fs.readFileSync(filename).toString())
}
```

instead.

## .filter(paths: Array&lt;Pathname&gt;): Array&lt;Pathname&gt;

```ts
type Pathname = string
```

Filters the given array of pathnames, and returns the filtered array.

- **paths** `Array.<Pathname>` The array of `pathname`s to be filtered.

### `Pathname` Conventions:

#### 1. `Pathname` should be a `path.relative()`d pathname

`Pathname` should be a string that have been `path.join()`ed, or the return value of `path.relative()` to the current directory,

```js
// WRONG, an error will be thrown
ig.ignores('./abc')

// WRONG, for it will never happen, and an error will be thrown
// If the gitignore rule locates at the root directory,
// `'/abc'` should be changed to `'abc'`.
// ```
// path.relative('/', '/abc')  -> 'abc'
// ```
ig.ignores('/abc')

// WRONG, that it is an absolute path on Windows, an error will be thrown
ig.ignores('C:\\abc')

// Right
ig.ignores('abc')

// Right
ig.ignores(path.join('./abc'))  // path.join('./abc') -> 'abc'
```

In other words, each `Pathname` here should be a relative path to the directory of the gitignore rules.

Suppose the dir structure is:

```
/path/to/your/repo
    |-- a
    |   |-- a.js
    |
    |-- .b
    |
    |-- .c
         |-- .DS_store
```

Then the `paths` might be like this:

```js
[
  'a/a.js'
  '.b',
  '.c/.DS_store'
]
```

#### 2. filenames and dirnames

`node-ignore` does NO `fs.stat` during path matching, so for the example below:

```js
// First, we add a ignore pattern to ignore a directory
ig.add('config/')

// `ig` does NOT know if 'config', in the real world,
//   is a normal file, directory or something.

ig.ignores('config')
// `ig` treats `config` as a file, so it returns `false`

ig.ignores('config/')
// returns `true`
```

Specially for people who develop some library based on `node-ignore`, it is important to understand that.

Usually, you could use [`glob`](http://npmjs.org/package/glob) with `option.mark = true` to fetch the structure of the current directory:

```js
import glob from 'glob'

glob('**', {
  // Adds a / character to directory matches.
  mark: true
}, (err, files) => {
  if (err) {
    return console.error(err)
  }

  let filtered = ignore().add(patterns).filter(files)
  console.log(filtered)
})
```

## .ignores(pathname: Pathname): boolean

> new in 3.2.0

Returns `Boolean` whether `pathname` should be ignored.

```js
ig.ignores('.abc/a.js')    // true
```

## .createFilter()

Creates a filter function which could filter an array of paths with `Array.prototype.filter`.

Returns `function(path)` the filter function.

## .test(pathname: Pathname) since 5.0.0

Returns `TestResult`

```ts
interface TestResult {
  ignored: boolean
  // true if the `pathname` is finally unignored by some negative pattern
  unignored: boolean
}
```

- `{ignored: true, unignored: false}`: the `pathname` is ignored
- `{ignored: false, unignored: true}`: the `pathname` is unignored
- `{ignored: false, unignored: false}`: the `pathname` is never matched by any ignore rules.

## static `ignore.isPathValid(pathname): boolean` since 5.0.0

Check whether the `pathname` is an valid `path.relative()`d path according to the [convention](#1-pathname-should-be-a-pathrelatived-pathname).

This method is **NOT** used to check if an ignore pattern is valid.

```js
ignore.isPathValid('./foo')  // false
```

## ignore(options)

### `options.ignorecase` since 4.0.0

Similar as the `core.ignorecase` option of [git-config](https://git-scm.com/docs/git-config), `node-ignore` will be case insensitive if `options.ignorecase` is set to `true` (the default value), otherwise case sensitive.

```js
const ig = ignore({
  ignorecase: false
})

ig.add('*.png')

ig.ignores('*.PNG')  // false
```

### `options.ignoreCase?: boolean` since 5.2.0

Which is alternative to `options.ignoreCase`

### `options.allowRelativePaths?: boolean` since 5.2.0

This option brings backward compatibility with projects which based on `ignore@4.x`. If `options.allowRelativePaths` is `true`, `ignore` will not check whether the given path to be tested is [`path.relative()`d](#pathname-conventions).

However, passing a relative path, such as `'./foo'` or `'../foo'`, to test if it is ignored or not is not a good practise, which might lead to unexpected behavior

```js
ignore({
  allowRelativePaths: true
}).ignores('../foo/bar.js') // And it will not throw
```

****

# Upgrade Guide

## Upgrade 4.x -> 5.x

Since `5.0.0`, if an invalid `Pathname` passed into `ig.ignores()`, an error will be thrown, unless `options.allowRelative = true` is passed to the `Ignore` factory.

While `ignore < 5.0.0` did not make sure what the return value was, as well as

```ts
.ignores(pathname: Pathname): boolean

.filter(pathnames: Array<Pathname>): Array<Pathname>

.createFilter(): (pathname: Pathname) => boolean

.test(pathname: Pathname): {ignored: boolean, unignored: boolean}
```

See the convention [here](#1-pathname-should-be-a-pathrelatived-pathname) for details.

If there are invalid pathnames, the conversion and filtration should be done by users.

```js
import {isPathValid} from 'ignore' // introduced in 5.0.0

const paths = [
  // invalid
  //////////////////
  '',
  false,
  '../foo',
  '.',
  //////////////////

  // valid
  'foo'
]
.filter(isValidPath)

ig.filter(paths)
```

## Upgrade 3.x -> 4.x

Since `4.0.0`, `ignore` will no longer support node < 6, to use `ignore` in node < 6:

```js
var ignore = require('ignore/legacy')
```

## Upgrade 2.x -> 3.x

- All `options` of 2.x are unnecessary and removed, so just remove them.
- `ignore()` instance is no longer an [`EventEmitter`](nodejs.org/api/events.html), and all events are unnecessary and removed.
- `.addIgnoreFile()` is removed, see the [.addIgnoreFile](#addignorefilepath) section for details.

****

# Collaborators

- [@whitecolor](https://github.com/whitecolor) *Alex*
- [@SamyPesse](https://github.com/SamyPesse) *Samy Pessé*
- [@azproduction](https://github.com/azproduction) *Mikhail Davydov*
- [@TrySound](https://github.com/TrySound) *Bogdan Chadkin*
- [@JanMattner](https://github.com/JanMattner) *Jan Mattner*
- [@ntwb](https://github.com/ntwb) *Stephen Edgar*
- [@kasperisager](https://github.com/kasperisager) *Kasper Isager*
- [@sandersn](https://github.com/sandersn) *Nathan Shively-Sanders*
### Estraverse [![Build Status](https://secure.travis-ci.org/estools/estraverse.svg)](http://travis-ci.org/estools/estraverse)

Estraverse ([estraverse](http://github.com/estools/estraverse)) is
[ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm)
traversal functions from [esmangle project](http://github.com/estools/esmangle).

### Documentation

You can find usage docs at [wiki page](https://github.com/estools/estraverse/wiki/Usage).

### Example Usage

The following code will output all variables declared at the root of a file.

```javascript
estraverse.traverse(ast, {
    enter: function (node, parent) {
        if (node.type == 'FunctionExpression' || node.type == 'FunctionDeclaration')
            return estraverse.VisitorOption.Skip;
    },
    leave: function (node, parent) {
        if (node.type == 'VariableDeclarator')
          console.log(node.id.name);
    }
});
```

We can use `this.skip`, `this.remove` and `this.break` functions instead of using Skip, Remove and Break.

```javascript
estraverse.traverse(ast, {
    enter: function (node) {
        this.break();
    }
});
```

And estraverse provides `estraverse.replace` function. When returning node from `enter`/`leave`, current node is replaced with it.

```javascript
result = estraverse.replace(tree, {
    enter: function (node) {
        // Replace it with replaced.
        if (node.type === 'Literal')
            return replaced;
    }
});
```

By passing `visitor.keys` mapping, we can extend estraverse traversing functionality.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Extending the existing traversing rules.
    keys: {
        // TargetNodeName: [ 'keys', 'containing', 'the', 'other', '**node**' ]
        TestExpression: ['argument']
    }
});
```

By passing `visitor.fallback` option, we can control the behavior when encountering unknown nodes.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Iterating the child **nodes** of unknown nodes.
    fallback: 'iteration'
});
```

When `visitor.fallback` is a function, we can determine which keys to visit on each node.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Skip the `argument` property of each node
    fallback: function(node) {
        return Object.keys(node).filter(function(key) {
            return key !== 'argument';
        });
    }
});
```

### License

Copyright (C) 2012-2016 [Yusuke Suzuki](http://github.com/Constellation)
 (twitter: [@Constellation](http://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
### Esrecurse [![Build Status](https://travis-ci.org/estools/esrecurse.svg?branch=master)](https://travis-ci.org/estools/esrecurse)

Esrecurse ([esrecurse](https://github.com/estools/esrecurse)) is
[ECMAScript](https://www.ecma-international.org/publications/standards/Ecma-262.htm)
recursive traversing functionality.

### Example Usage

The following code will output all variables declared at the root of a file.

```javascript
esrecurse.visit(ast, {
    XXXStatement: function (node) {
        this.visit(node.left);
        // do something...
        this.visit(node.right);
    }
});
```

We can use `Visitor` instance.

```javascript
var visitor = new esrecurse.Visitor({
    XXXStatement: function (node) {
        this.visit(node.left);
        // do something...
        this.visit(node.right);
    }
});

visitor.visit(ast);
```

We can inherit `Visitor` instance easily.

```javascript
class Derived extends esrecurse.Visitor {
    constructor()
    {
        super(null);
    }

    XXXStatement(node) {
    }
}
```

```javascript
function DerivedVisitor() {
    esrecurse.Visitor.call(/* this for constructor */  this  /* visitor object automatically becomes this. */);
}
util.inherits(DerivedVisitor, esrecurse.Visitor);
DerivedVisitor.prototype.XXXStatement = function (node) {
    this.visit(node.left);
    // do something...
    this.visit(node.right);
};
```

And you can invoke default visiting operation inside custom visit operation.

```javascript
function DerivedVisitor() {
    esrecurse.Visitor.call(/* this for constructor */  this  /* visitor object automatically becomes this. */);
}
util.inherits(DerivedVisitor, esrecurse.Visitor);
DerivedVisitor.prototype.XXXStatement = function (node) {
    // do something...
    this.visitChildren(node);
};
```

The `childVisitorKeys` option does customize the behaviour of `this.visitChildren(node)`.
We can use user-defined node types.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
esrecurse.visit(
    ast,
    {
        Literal: function (node) {
            // do something...
        }
    },
    {
        // Extending the existing traversing rules.
        childVisitorKeys: {
            // TargetNodeName: [ 'keys', 'containing', 'the', 'other', '**node**' ]
            TestExpression: ['argument']
        }
    }
);
```

We can use the `fallback` option as well.
If the `fallback` option is `"iteration"`, `esrecurse` would visit all enumerable properties of unknown nodes.
Please note circular references cause the stack overflow. AST might have circular references in additional properties for some purpose (e.g. `node.parent`).

```javascript
esrecurse.visit(
    ast,
    {
        Literal: function (node) {
            // do something...
        }
    },
    {
        fallback: 'iteration'
    }
);
```

If the `fallback` option is a function, `esrecurse` calls this function to determine the enumerable properties of unknown nodes.
Please note circular references cause the stack overflow. AST might have circular references in additional properties for some purpose (e.g. `node.parent`).

```javascript
esrecurse.visit(
    ast,
    {
        Literal: function (node) {
            // do something...
        }
    },
    {
        fallback: function (node) {
            return Object.keys(node).filter(function(key) {
                return key !== 'argument'
            });
        }
    }
);
```

### License

Copyright (C) 2014 [Yusuke Suzuki](https://github.com/Constellation)
 (twitter: [@Constellation](https://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# tslib

This is a runtime library for [TypeScript](http://www.typescriptlang.org/) that contains all of the TypeScript helper functions.

This library is primarily used by the `--importHelpers` flag in TypeScript.
When using `--importHelpers`, a module that uses helper functions like `__extends` and `__assign` in the following emitted file:

```ts
var __assign = (this && this.__assign) || Object.assign || function(t) {
    for (var s, i = 1, n = arguments.length; i < n; i++) {
        s = arguments[i];
        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
            t[p] = s[p];
    }
    return t;
};
exports.x = {};
exports.y = __assign({}, exports.x);

```

will instead be emitted as something like the following:

```ts
var tslib_1 = require("tslib");
exports.x = {};
exports.y = tslib_1.__assign({}, exports.x);
```

Because this can avoid duplicate declarations of things like `__extends`, `__assign`, etc., this means delivering users smaller files on average, as well as less runtime overhead.
For optimized bundles with TypeScript, you should absolutely consider using `tslib` and `--importHelpers`.

# Installing

For the latest stable version, run:

## npm

```sh
# TypeScript 3.9.2 or later
npm install tslib

# TypeScript 3.8.4 or earlier
npm install tslib@^1

# TypeScript 2.3.2 or earlier
npm install tslib@1.6.1
```

## yarn

```sh
# TypeScript 3.9.2 or later
yarn add tslib

# TypeScript 3.8.4 or earlier
yarn add tslib@^1

# TypeScript 2.3.2 or earlier
yarn add tslib@1.6.1
```

## bower

```sh
# TypeScript 3.9.2 or later
bower install tslib

# TypeScript 3.8.4 or earlier
bower install tslib@^1

# TypeScript 2.3.2 or earlier
bower install tslib@1.6.1
```

## JSPM

```sh
# TypeScript 3.9.2 or later
jspm install tslib

# TypeScript 3.8.4 or earlier
jspm install tslib@^1

# TypeScript 2.3.2 or earlier
jspm install tslib@1.6.1
```

# Usage

Set the `importHelpers` compiler option on the command line:

```
tsc --importHelpers file.ts
```

or in your tsconfig.json:

```json
{
    "compilerOptions": {
        "importHelpers": true
    }
}
```

#### For bower and JSPM users

You will need to add a `paths` mapping for `tslib`, e.g. For Bower users:

```json
{
    "compilerOptions": {
        "module": "amd",
        "importHelpers": true,
        "baseUrl": "./",
        "paths": {
            "tslib" : ["bower_components/tslib/tslib.d.ts"]
        }
    }
}
```

For JSPM users:

```json
{
    "compilerOptions": {
        "module": "system",
        "importHelpers": true,
        "baseUrl": "./",
        "paths": {
            "tslib" : ["jspm_packages/npm/tslib@2.x.y/tslib.d.ts"]
        }
    }
}
```

## Deployment

- Choose your new version number
- Set it in `package.json` and `bower.json`
- Create a tag: `git tag [version]`
- Push the tag: `git push --tags`
- Create a [release in GitHub](https://github.com/microsoft/tslib/releases)
- Run the [publish to npm](https://github.com/microsoft/tslib/actions?query=workflow%3A%22Publish+to+NPM%22) workflow

Done.

# Contribute

There are many ways to [contribute](https://github.com/Microsoft/TypeScript/blob/master/CONTRIBUTING.md) to TypeScript.

* [Submit bugs](https://github.com/Microsoft/TypeScript/issues) and help us verify fixes as they are checked in.
* Review the [source code changes](https://github.com/Microsoft/TypeScript/pulls).
* Engage with other TypeScript users and developers on [StackOverflow](http://stackoverflow.com/questions/tagged/typescript).
* Join the [#typescript](http://twitter.com/#!/search/realtime/%23typescript) discussion on Twitter.
* [Contribute bug fixes](https://github.com/Microsoft/TypeScript/blob/master/CONTRIBUTING.md).

# Documentation

* [Quick tutorial](http://www.typescriptlang.org/Tutorial)
* [Programming handbook](http://www.typescriptlang.org/Handbook)
* [Homepage](http://www.typescriptlang.org/)
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).


## [2.0.1] - 2020-08-29
### Fixed
- Fix issue with `process.argv` when used with interpreters (`coffee`, `ts-node`, etc.), #150.


## [2.0.0] - 2020-08-14
### Changed
- Full rewrite. Now port from python 3.9.0 & more precise following.
  See [doc](./doc) for difference and migration info.
- node.js 10+ required
- Removed most of local docs in favour of original ones.


## [1.0.10] - 2018-02-15
### Fixed
- Use .concat instead of + for arrays, #122.


## [1.0.9] - 2016-09-29
### Changed
- Rerelease after 1.0.8 - deps cleanup.


## [1.0.8] - 2016-09-29
### Changed
- Maintenance (deps bump, fix node 6.5+ tests, coverage report).


## [1.0.7] - 2016-03-17
### Changed
- Teach `addArgument` to accept string arg names. #97, @tomxtobin.


## [1.0.6] - 2016-02-06
### Changed
- Maintenance: moved to eslint & updated CS.


## [1.0.5] - 2016-02-05
### Changed
- Removed lodash dependency to significantly reduce install size.
  Thanks to @mourner.


## [1.0.4] - 2016-01-17
### Changed
- Maintenance: lodash update to 4.0.0.


## [1.0.3] - 2015-10-27
### Fixed
- Fix parse `=` in args: `--examplepath="C:\myfolder\env=x64"`. #84, @CatWithApple.


## [1.0.2] - 2015-03-22
### Changed
- Relaxed lodash version dependency.


## [1.0.1] - 2015-02-20
### Changed
- Changed dependencies to be compatible with ancient nodejs.


## [1.0.0] - 2015-02-19
### Changed
- Maintenance release.
- Replaced `underscore` with `lodash`.
- Bumped version to 1.0.0 to better reflect semver meaning.
- HISTORY.md -> CHANGELOG.md


## [0.1.16] - 2013-12-01
### Changed
- Maintenance release. Updated dependencies and docs.


## [0.1.15] - 2013-05-13
### Fixed
- Fixed #55, @trebor89


## [0.1.14] - 2013-05-12
### Fixed
- Fixed #62, @maxtaco


## [0.1.13] - 2013-04-08
### Changed
- Added `.npmignore` to reduce package size


## [0.1.12] - 2013-02-10
### Fixed
- Fixed conflictHandler (#46), @hpaulj


## [0.1.11] - 2013-02-07
### Added
- Added 70+ tests (ported from python), @hpaulj
- Added conflictHandler, @applepicke
- Added fromfilePrefixChar, @hpaulj

### Fixed
- Multiple bugfixes, @hpaulj


## [0.1.10] - 2012-12-30
### Added
- Added [mutual exclusion](http://docs.python.org/dev/library/argparse.html#mutual-exclusion)
  support, thanks to @hpaulj

### Fixed
- Fixed options check for `storeConst` & `appendConst` actions, thanks to @hpaulj


## [0.1.9] - 2012-12-27
### Fixed
- Fixed option dest interferens with other options (issue #23), thanks to @hpaulj
- Fixed default value behavior with `*` positionals, thanks to @hpaulj
- Improve `getDefault()` behavior, thanks to @hpaulj
- Improve negative argument parsing, thanks to @hpaulj


## [0.1.8] - 2012-12-01
### Fixed
- Fixed parser parents (issue #19), thanks to @hpaulj
- Fixed negative argument parse (issue #20), thanks to @hpaulj


## [0.1.7] - 2012-10-14
### Fixed
- Fixed 'choices' argument parse (issue #16)
- Fixed stderr output (issue #15)


## [0.1.6] - 2012-09-09
### Fixed
- Fixed check for conflict of options (thanks to @tomxtobin)


## [0.1.5] - 2012-09-03
### Fixed
- Fix parser #setDefaults method (thanks to @tomxtobin)


## [0.1.4] - 2012-07-30
### Fixed
- Fixed pseudo-argument support (thanks to @CGamesPlay)
- Fixed addHelp default (should be true), if not set (thanks to @benblank)


## [0.1.3] - 2012-06-27
### Fixed
- Fixed formatter api name: Formatter -> HelpFormatter


## [0.1.2] - 2012-05-29
### Fixed
- Removed excess whitespace in help
- Fixed error reporting, when parcer with subcommands
  called with empty arguments

### Added
- Added basic tests


## [0.1.1] - 2012-05-23
### Fixed
- Fixed line wrapping in help formatter
- Added better error reporting on invalid arguments


## [0.1.0] - 2012-05-16
### Added
- First release.


[2.0.1]: https://github.com/nodeca/argparse/compare/2.0.0...2.0.1
[2.0.0]: https://github.com/nodeca/argparse/compare/1.0.10...2.0.0
[1.0.10]: https://github.com/nodeca/argparse/compare/1.0.9...1.0.10
[1.0.9]: https://github.com/nodeca/argparse/compare/1.0.8...1.0.9
[1.0.8]: https://github.com/nodeca/argparse/compare/1.0.7...1.0.8
[1.0.7]: https://github.com/nodeca/argparse/compare/1.0.6...1.0.7
[1.0.6]: https://github.com/nodeca/argparse/compare/1.0.5...1.0.6
[1.0.5]: https://github.com/nodeca/argparse/compare/1.0.4...1.0.5
[1.0.4]: https://github.com/nodeca/argparse/compare/1.0.3...1.0.4
[1.0.3]: https://github.com/nodeca/argparse/compare/1.0.2...1.0.3
[1.0.2]: https://github.com/nodeca/argparse/compare/1.0.1...1.0.2
[1.0.1]: https://github.com/nodeca/argparse/compare/1.0.0...1.0.1
[1.0.0]: https://github.com/nodeca/argparse/compare/0.1.16...1.0.0
[0.1.16]: https://github.com/nodeca/argparse/compare/0.1.15...0.1.16
[0.1.15]: https://github.com/nodeca/argparse/compare/0.1.14...0.1.15
[0.1.14]: https://github.com/nodeca/argparse/compare/0.1.13...0.1.14
[0.1.13]: https://github.com/nodeca/argparse/compare/0.1.12...0.1.13
[0.1.12]: https://github.com/nodeca/argparse/compare/0.1.11...0.1.12
[0.1.11]: https://github.com/nodeca/argparse/compare/0.1.10...0.1.11
[0.1.10]: https://github.com/nodeca/argparse/compare/0.1.9...0.1.10
[0.1.9]: https://github.com/nodeca/argparse/compare/0.1.8...0.1.9
[0.1.8]: https://github.com/nodeca/argparse/compare/0.1.7...0.1.8
[0.1.7]: https://github.com/nodeca/argparse/compare/0.1.6...0.1.7
[0.1.6]: https://github.com/nodeca/argparse/compare/0.1.5...0.1.6
[0.1.5]: https://github.com/nodeca/argparse/compare/0.1.4...0.1.5
[0.1.4]: https://github.com/nodeca/argparse/compare/0.1.3...0.1.4
[0.1.3]: https://github.com/nodeca/argparse/compare/0.1.2...0.1.3
[0.1.2]: https://github.com/nodeca/argparse/compare/0.1.1...0.1.2
[0.1.1]: https://github.com/nodeca/argparse/compare/0.1.0...0.1.1
[0.1.0]: https://github.com/nodeca/argparse/releases/tag/0.1.0
argparse
========

[![Build Status](https://secure.travis-ci.org/nodeca/argparse.svg?branch=master)](http://travis-ci.org/nodeca/argparse)
[![NPM version](https://img.shields.io/npm/v/argparse.svg)](https://www.npmjs.org/package/argparse)

CLI arguments parser for node.js, with [sub-commands](https://docs.python.org/3.9/library/argparse.html#sub-commands) support. Port of python's [argparse](http://docs.python.org/dev/library/argparse.html) (version [3.9.0](https://github.com/python/cpython/blob/v3.9.0rc1/Lib/argparse.py)).

**Difference with original.**

- JS has no keyword arguments support.
  -  Pass options instead: `new ArgumentParser({ description: 'example', add_help: true })`.
- JS has no python's types `int`, `float`, ...
  - Use string-typed names: `.add_argument('-b', { type: 'int', help: 'help' })`.
- `%r` format specifier uses `require('util').inspect()`.

More details in [doc](./doc).


Example
-------

`test.js` file:

```javascript
#!/usr/bin/env node
'use strict';

const { ArgumentParser } = require('argparse');
const { version } = require('./package.json');

const parser = new ArgumentParser({
  description: 'Argparse example'
});

parser.add_argument('-v', '--version', { action: 'version', version });
parser.add_argument('-f', '--foo', { help: 'foo bar' });
parser.add_argument('-b', '--bar', { help: 'bar foo' });
parser.add_argument('--baz', { help: 'baz bar' });

console.dir(parser.parse_args());
```

Display help:

```
$ ./test.js -h
usage: test.js [-h] [-v] [-f FOO] [-b BAR] [--baz BAZ]

Argparse example

optional arguments:
  -h, --help         show this help message and exit
  -v, --version      show program's version number and exit
  -f FOO, --foo FOO  foo bar
  -b BAR, --bar BAR  bar foo
  --baz BAZ          baz bar
```

Parse arguments:

```
$ ./test.js -f=3 --bar=4 --baz 5
{ foo: '3', bar: '4', baz: '5' }
```


API docs
--------

Since this is a port with minimal divergence, there's no separate documentation.
Use original one instead, with notes about difference.

1. [Original doc](https://docs.python.org/3.9/library/argparse.html).
2. [Original tutorial](https://docs.python.org/3.9/howto/argparse.html).
3. [Difference with python](./doc).


argparse for enterprise
-----------------------

Available as part of the Tidelift Subscription

The maintainers of argparse and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-argparse?utm_source=npm-argparse&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)
# Release history

**All notable changes to this project will be documented in this file.**

The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/)
and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html).

<details>
  <summary><strong>Guiding Principles</strong></summary>

- Changelogs are for humans, not machines.
- There should be an entry for every single version.
- The same types of changes should be grouped.
- Versions and sections should be linkable.
- The latest version comes first.
- The release date of each versions is displayed.
- Mention whether you follow Semantic Versioning.

</details>

<details>
  <summary><strong>Types of changes</strong></summary>

Changelog entries are classified using the following labels _(from [keep-a-changelog](http://keepachangelog.com/)_):

- `Added` for new features.
- `Changed` for changes in existing functionality.
- `Deprecated` for soon-to-be removed features.
- `Removed` for now removed features.
- `Fixed` for any bug fixes.
- `Security` in case of vulnerabilities.

</details>

## 2.3.1 (2022-01-02)

### Fixed

* Fixes bug when a pattern containing an expression after the closing parenthesis (`/!(*.d).{ts,tsx}`) was incorrectly converted to regexp ([9f241ef](https://github.com/micromatch/picomatch/commit/9f241ef)).

### Changed

* Some documentation improvements ([f81d236](https://github.com/micromatch/picomatch/commit/f81d236), [421e0e7](https://github.com/micromatch/picomatch/commit/421e0e7)).

## 2.3.0 (2021-05-21)

### Fixed

* Fixes bug where file names with two dots were not being matched consistently with negation extglobs containing a star ([56083ef](https://github.com/micromatch/picomatch/commit/56083ef))

## 2.2.3 (2021-04-10)

### Fixed

* Do not skip pattern seperator for square brackets ([fb08a30](https://github.com/micromatch/picomatch/commit/fb08a30)).
* Set negatedExtGlob also if it does not span the whole pattern ([032e3f5](https://github.com/micromatch/picomatch/commit/032e3f5)).

## 2.2.2 (2020-03-21)

### Fixed

* Correctly handle parts of the pattern after parentheses in the `scan` method ([e15b920](https://github.com/micromatch/picomatch/commit/e15b920)).

## 2.2.1 (2020-01-04)

* Fixes [#49](https://github.com/micromatch/picomatch/issues/49), so that braces with no sets or ranges are now propertly treated as literals.

## 2.2.0 (2020-01-04)

* Disable fastpaths mode for the parse method ([5b8d33f](https://github.com/micromatch/picomatch/commit/5b8d33f))
* Add `tokens`, `slashes`, and `parts` to the object returned by `picomatch.scan()`.

## 2.1.0 (2019-10-31)

* add benchmarks for scan ([4793b92](https://github.com/micromatch/picomatch/commit/4793b92))
* Add eslint object-curly-spacing rule ([707c650](https://github.com/micromatch/picomatch/commit/707c650))
* Add prefer-const eslint rule ([5c7501c](https://github.com/micromatch/picomatch/commit/5c7501c))
* Add support for nonegate in scan API ([275c9b9](https://github.com/micromatch/picomatch/commit/275c9b9))
* Change lets to consts. Move root import up. ([4840625](https://github.com/micromatch/picomatch/commit/4840625))
* closes https://github.com/micromatch/picomatch/issues/21 ([766bcb0](https://github.com/micromatch/picomatch/commit/766bcb0))
* Fix "Extglobs" table in readme ([eb19da8](https://github.com/micromatch/picomatch/commit/eb19da8))
* fixes https://github.com/micromatch/picomatch/issues/20 ([9caca07](https://github.com/micromatch/picomatch/commit/9caca07))
* fixes https://github.com/micromatch/picomatch/issues/26 ([fa58f45](https://github.com/micromatch/picomatch/commit/fa58f45))
* Lint test ([d433a34](https://github.com/micromatch/picomatch/commit/d433a34))
* lint unit tests ([0159b55](https://github.com/micromatch/picomatch/commit/0159b55))
* Make scan work with noext ([6c02e03](https://github.com/micromatch/picomatch/commit/6c02e03))
* minor linting ([c2a2b87](https://github.com/micromatch/picomatch/commit/c2a2b87))
* minor parser improvements ([197671d](https://github.com/micromatch/picomatch/commit/197671d))
* remove eslint since it... ([07876fa](https://github.com/micromatch/picomatch/commit/07876fa))
* remove funding file ([8ebe96d](https://github.com/micromatch/picomatch/commit/8ebe96d))
* Remove unused funks ([cbc6d54](https://github.com/micromatch/picomatch/commit/cbc6d54))
* Run eslint during pretest, fix existing eslint findings ([0682367](https://github.com/micromatch/picomatch/commit/0682367))
* support `noparen` in scan ([3d37569](https://github.com/micromatch/picomatch/commit/3d37569))
* update changelog ([7b34e77](https://github.com/micromatch/picomatch/commit/7b34e77))
* update travis ([777f038](https://github.com/micromatch/picomatch/commit/777f038))
* Use eslint-disable-next-line instead of eslint-disable ([4e7c1fd](https://github.com/micromatch/picomatch/commit/4e7c1fd))

## 2.0.7 (2019-05-14)

* 2.0.7 ([9eb9a71](https://github.com/micromatch/picomatch/commit/9eb9a71))
* supports lookbehinds ([1f63f7e](https://github.com/micromatch/picomatch/commit/1f63f7e))
* update .verb.md file with typo change ([2741279](https://github.com/micromatch/picomatch/commit/2741279))
* fix: typo in README ([0753e44](https://github.com/micromatch/picomatch/commit/0753e44))

## 2.0.4 (2019-04-10)

### Fixed

- Readme link [fixed](https://github.com/micromatch/picomatch/pull/13/commits/a96ab3aa2b11b6861c23289964613d85563b05df) by @danez.
- `options.capture` now works as expected when fastpaths are enabled. See https://github.com/micromatch/picomatch/pull/12/commits/26aefd71f1cfaf95c37f1c1fcab68a693b037304. Thanks to @DrPizza.

## 2.0.0 (2019-04-10)

### Added

- Adds support for `options.onIgnore`. See the readme for details
- Adds support for `options.onResult`. See the readme for details

### Breaking changes

- The unixify option was renamed to `windows`
- caching and all related options and methods have been removed

## 1.0.0 (2018-11-05)

- adds `.onMatch` option
- improvements to `.scan` method
- numerous improvements and optimizations for matching and parsing
- better windows path handling

## 0.1.0 - 2017-04-13

First release.


[keep-a-changelog]: https://github.com/olivierlacan/keep-a-changelog
<h1 align="center">Picomatch</h1>

<p align="center">
<a href="https://npmjs.org/package/picomatch">
<img src="https://img.shields.io/npm/v/picomatch.svg" alt="version">
</a>
<a href="https://github.com/micromatch/picomatch/actions?workflow=Tests">
<img src="https://github.com/micromatch/picomatch/workflows/Tests/badge.svg" alt="test status">
</a>
<a href="https://coveralls.io/github/micromatch/picomatch">
<img src="https://img.shields.io/coveralls/github/micromatch/picomatch/master.svg" alt="coverage status">
</a>
<a href="https://npmjs.org/package/picomatch">
<img src="https://img.shields.io/npm/dm/picomatch.svg" alt="downloads">
</a>
</p>

<br>
<br>

<p align="center">
<strong>Blazing fast and accurate glob matcher written in JavaScript.</strong></br>
<em>No dependencies and full support for standard and extended Bash glob features, including braces, extglobs, POSIX brackets, and regular expressions.</em>
</p>

<br>
<br>

## Why picomatch?

* **Lightweight** - No dependencies
* **Minimal** - Tiny API surface. Main export is a function that takes a glob pattern and returns a matcher function.
* **Fast** - Loads in about 2ms (that's several times faster than a [single frame of a HD movie](http://www.endmemo.com/sconvert/framespersecondframespermillisecond.php) at 60fps)
* **Performant** - Use the returned matcher function to speed up repeat matching (like when watching files)
* **Accurate matching** - Using wildcards (`*` and `?`), globstars (`**`) for nested directories, [advanced globbing](#advanced-globbing) with extglobs, braces, and POSIX brackets, and support for escaping special characters with `\` or quotes.
* **Well tested** - Thousands of unit tests

See the [library comparison](#library-comparisons) to other libraries.

<br>
<br>

## Table of Contents

<details><summary> Click to expand </summary>

- [Install](#install)
- [Usage](#usage)
- [API](#api)
  * [picomatch](#picomatch)
  * [.test](#test)
  * [.matchBase](#matchbase)
  * [.isMatch](#ismatch)
  * [.parse](#parse)
  * [.scan](#scan)
  * [.compileRe](#compilere)
  * [.makeRe](#makere)
  * [.toRegex](#toregex)
- [Options](#options)
  * [Picomatch options](#picomatch-options)
  * [Scan Options](#scan-options)
  * [Options Examples](#options-examples)
- [Globbing features](#globbing-features)
  * [Basic globbing](#basic-globbing)
  * [Advanced globbing](#advanced-globbing)
  * [Braces](#braces)
  * [Matching special characters as literals](#matching-special-characters-as-literals)
- [Library Comparisons](#library-comparisons)
- [Benchmarks](#benchmarks)
- [Philosophies](#philosophies)
- [About](#about)
  * [Author](#author)
  * [License](#license)

_(TOC generated by [verb](https://github.com/verbose/verb) using [markdown-toc](https://github.com/jonschlinkert/markdown-toc))_

</details>

<br>
<br>

## Install

Install with [npm](https://www.npmjs.com/):

```sh
npm install --save picomatch
```

<br>

## Usage

The main export is a function that takes a glob pattern and an options object and returns a function for matching strings.

```js
const pm = require('picomatch');
const isMatch = pm('*.js');

console.log(isMatch('abcd')); //=> false
console.log(isMatch('a.js')); //=> true
console.log(isMatch('a.md')); //=> false
console.log(isMatch('a/b.js')); //=> false
```

<br>

## API

### [picomatch](lib/picomatch.js#L32)

Creates a matcher function from one or more glob patterns. The returned function takes a string to match as its first argument, and returns true if the string is a match. The returned matcher function also takes a boolean as the second argument that, when true, returns an object with additional information.

**Params**

* `globs` **{String|Array}**: One or more glob patterns.
* `options` **{Object=}**
* `returns` **{Function=}**: Returns a matcher function.

**Example**

```js
const picomatch = require('picomatch');
// picomatch(glob[, options]);

const isMatch = picomatch('*.!(*a)');
console.log(isMatch('a.a')); //=> false
console.log(isMatch('a.b')); //=> true
```

### [.test](lib/picomatch.js#L117)

Test `input` with the given `regex`. This is used by the main `picomatch()` function to test the input string.

**Params**

* `input` **{String}**: String to test.
* `regex` **{RegExp}**
* `returns` **{Object}**: Returns an object with matching info.

**Example**

```js
const picomatch = require('picomatch');
// picomatch.test(input, regex[, options]);

console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\/([^/]*?))$/));
// { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }
```

### [.matchBase](lib/picomatch.js#L161)

Match the basename of a filepath.

**Params**

* `input` **{String}**: String to test.
* `glob` **{RegExp|String}**: Glob pattern or regex created by [.makeRe](#makeRe).
* `returns` **{Boolean}**

**Example**

```js
const picomatch = require('picomatch');
// picomatch.matchBase(input, glob[, options]);
console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true
```

### [.isMatch](lib/picomatch.js#L183)

Returns true if **any** of the given glob `patterns` match the specified `string`.

**Params**

* **{String|Array}**: str The string to test.
* **{String|Array}**: patterns One or more glob patterns to use for matching.
* **{Object}**: See available [options](#options).
* `returns` **{Boolean}**: Returns true if any patterns match `str`

**Example**

```js
const picomatch = require('picomatch');
// picomatch.isMatch(string, patterns[, options]);

console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true
console.log(picomatch.isMatch('a.a', 'b.*')); //=> false
```

### [.parse](lib/picomatch.js#L199)

Parse a glob pattern to create the source string for a regular expression.

**Params**

* `pattern` **{String}**
* `options` **{Object}**
* `returns` **{Object}**: Returns an object with useful properties and output to be used as a regex source string.

**Example**

```js
const picomatch = require('picomatch');
const result = picomatch.parse(pattern[, options]);
```

### [.scan](lib/picomatch.js#L231)

Scan a glob pattern to separate the pattern into segments.

**Params**

* `input` **{String}**: Glob pattern to scan.
* `options` **{Object}**
* `returns` **{Object}**: Returns an object with

**Example**

```js
const picomatch = require('picomatch');
// picomatch.scan(input[, options]);

const result = picomatch.scan('!./foo/*.js');
console.log(result);
{ prefix: '!./',
  input: '!./foo/*.js',
  start: 3,
  base: 'foo',
  glob: '*.js',
  isBrace: false,
  isBracket: false,
  isGlob: true,
  isExtglob: false,
  isGlobstar: false,
  negated: true }
```

### [.compileRe](lib/picomatch.js#L245)

Compile a regular expression from the `state` object returned by the
[parse()](#parse) method.

**Params**

* `state` **{Object}**
* `options` **{Object}**
* `returnOutput` **{Boolean}**: Intended for implementors, this argument allows you to return the raw output from the parser.
* `returnState` **{Boolean}**: Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.
* `returns` **{RegExp}**

### [.makeRe](lib/picomatch.js#L286)

Create a regular expression from a parsed glob pattern.

**Params**

* `state` **{String}**: The object returned from the `.parse` method.
* `options` **{Object}**
* `returnOutput` **{Boolean}**: Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.
* `returnState` **{Boolean}**: Implementors may use this argument to return the state from the parsed glob with the returned regular expression.
* `returns` **{RegExp}**: Returns a regex created from the given pattern.

**Example**

```js
const picomatch = require('picomatch');
const state = picomatch.parse('*.js');
// picomatch.compileRe(state[, options]);

console.log(picomatch.compileRe(state));
//=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
```

### [.toRegex](lib/picomatch.js#L321)

Create a regular expression from the given regex source string.

**Params**

* `source` **{String}**: Regular expression source string.
* `options` **{Object}**
* `returns` **{RegExp}**

**Example**

```js
const picomatch = require('picomatch');
// picomatch.toRegex(source[, options]);

const { output } = picomatch.parse('*.js');
console.log(picomatch.toRegex(output));
//=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
```

<br>

## Options

### Picomatch options

The following options may be used with the main `picomatch()` function or any of the methods on the picomatch API.

| **Option** | **Type** | **Default value** | **Description** |
| --- | --- | --- | --- |
| `basename`            | `boolean`      | `false`     | If set, then patterns without slashes will be matched against the basename of the path if it contains slashes.  For example, `a?b` would match the path `/xyz/123/acb`, but not `/xyz/acb/123`. |
| `bash`                | `boolean`      | `false`     | Follow bash matching rules more strictly - disallows backslashes as escape characters, and treats single stars as globstars (`**`). |
| `capture`             | `boolean`      | `undefined` | Return regex matches in supporting methods. |
| `contains`            | `boolean`      | `undefined` | Allows glob to match any part of the given string(s). |
| `cwd`                 | `string`       | `process.cwd()` | Current working directory. Used by `picomatch.split()` |
| `debug`               | `boolean`      | `undefined` | Debug regular expressions when an error is thrown. |
| `dot`                 | `boolean`      | `false`     | Enable dotfile matching. By default, dotfiles are ignored unless a `.` is explicitly defined in the pattern, or `options.dot` is true |
| `expandRange`         | `function`     | `undefined` | Custom function for expanding ranges in brace patterns, such as `{a..z}`. The function receives the range values as two arguments, and it must return a string to be used in the generated regex. It's recommended that returned strings be wrapped in parentheses. |
| `failglob`            | `boolean`      | `false`     | Throws an error if no matches are found. Based on the bash option of the same name. |
| `fastpaths`           | `boolean`      | `true`      | To speed up processing, full parsing is skipped for a handful common glob patterns. Disable this behavior by setting this option to `false`. |
| `flags`               | `string`      | `undefined` | Regex flags to use in the generated regex. If defined, the `nocase` option will be overridden. |
| [format](#optionsformat) | `function` | `undefined` | Custom function for formatting the returned string. This is useful for removing leading slashes, converting Windows paths to Posix paths, etc. |
| `ignore`              | `array\|string` | `undefined` | One or more glob patterns for excluding strings that should not be matched from the result. |
| `keepQuotes`          | `boolean`      | `false`     | Retain quotes in the generated regex, since quotes may also be used as an alternative to backslashes.  |
| `literalBrackets`     | `boolean`      | `undefined` | When `true`, brackets in the glob pattern will be escaped so that only literal brackets will be matched. |
| `matchBase`           | `boolean`      | `false`     | Alias for `basename` |
| `maxLength`           | `boolean`      | `65536`     | Limit the max length of the input string. An error is thrown if the input string is longer than this value. |
| `nobrace`             | `boolean`      | `false`     | Disable brace matching, so that `{a,b}` and `{1..3}` would be treated as literal characters. |
| `nobracket`           | `boolean`      | `undefined` | Disable matching with regex brackets. |
| `nocase`              | `boolean`      | `false`     | Make matching case-insensitive. Equivalent to the regex `i` flag. Note that this option is overridden by the `flags` option. |
| `nodupes`             | `boolean`      | `true`      | Deprecated, use `nounique` instead. This option will be removed in a future major release. By default duplicates are removed. Disable uniquification by setting this option to false. |
| `noext`               | `boolean`      | `false`     | Alias for `noextglob` |
| `noextglob`           | `boolean`      | `false`     | Disable support for matching with extglobs (like `+(a\|b)`) |
| `noglobstar`          | `boolean`      | `false`     | Disable support for matching nested directories with globstars (`**`) |
| `nonegate`            | `boolean`      | `false`     | Disable support for negating with leading `!` |
| `noquantifiers`       | `boolean`      | `false`     | Disable support for regex quantifiers (like `a{1,2}`) and treat them as brace patterns to be expanded. |
| [onIgnore](#optionsonIgnore) | `function` | `undefined` | Function to be called on ignored items. |
| [onMatch](#optionsonMatch) | `function` | `undefined` | Function to be called on matched items. |
| [onResult](#optionsonResult) | `function` | `undefined` | Function to be called on all items, regardless of whether or not they are matched or ignored. |
| `posix`               | `boolean`      | `false`     | Support POSIX character classes ("posix brackets"). |
| `posixSlashes`        | `boolean`      | `undefined` | Convert all slashes in file paths to forward slashes. This does not convert slashes in the glob pattern itself |
| `prepend`             | `boolean`      | `undefined` | String to prepend to the generated regex used for matching. |
| `regex`               | `boolean`      | `false`     | Use regular expression rules for `+` (instead of matching literal `+`), and for stars that follow closing parentheses or brackets (as in `)*` and `]*`). |
| `strictBrackets`      | `boolean`      | `undefined` | Throw an error if brackets, braces, or parens are imbalanced. |
| `strictSlashes`       | `boolean`      | `undefined` | When true, picomatch won't match trailing slashes with single stars. |
| `unescape`            | `boolean`      | `undefined` | Remove backslashes preceding escaped characters in the glob pattern. By default, backslashes are retained. |
| `unixify`             | `boolean`      | `undefined` | Alias for `posixSlashes`, for backwards compatibility. |

picomatch has automatic detection for regex positive and negative lookbehinds. If the pattern contains a negative lookbehind, you must be using Node.js >= 8.10 or else picomatch will throw an error.

### Scan Options

In addition to the main [picomatch options](#picomatch-options), the following options may also be used with the [.scan](#scan) method.

| **Option** | **Type** | **Default value** | **Description** |
| --- | --- | --- | --- |
| `tokens` | `boolean` | `false` | When `true`, the returned object will include an array of tokens (objects), representing each path "segment" in the scanned glob pattern |
| `parts` | `boolean` | `false` | When `true`, the returned object will include an array of strings representing each path "segment" in the scanned glob pattern. This is automatically enabled when `options.tokens` is true |

**Example**

```js
const picomatch = require('picomatch');
const result = picomatch.scan('!./foo/*.js', { tokens: true });
console.log(result);
// {
//   prefix: '!./',
//   input: '!./foo/*.js',
//   start: 3,
//   base: 'foo',
//   glob: '*.js',
//   isBrace: false,
//   isBracket: false,
//   isGlob: true,
//   isExtglob: false,
//   isGlobstar: false,
//   negated: true,
//   maxDepth: 2,
//   tokens: [
//     { value: '!./', depth: 0, isGlob: false, negated: true, isPrefix: true },
//     { value: 'foo', depth: 1, isGlob: false },
//     { value: '*.js', depth: 1, isGlob: true }
//   ],
//   slashes: [ 2, 6 ],
//   parts: [ 'foo', '*.js' ]
// }
```

<br>

### Options Examples

#### options.expandRange

**Type**: `function`

**Default**: `undefined`

Custom function for expanding ranges in brace patterns. The [fill-range](https://github.com/jonschlinkert/fill-range) library is ideal for this purpose, or you can use custom code to do whatever you need.

**Example**

The following example shows how to create a glob that matches a folder

```js
const fill = require('fill-range');
const regex = pm.makeRe('foo/{01..25}/bar', {
  expandRange(a, b) {
    return `(${fill(a, b, { toRegex: true })})`;
  }
});

console.log(regex);
//=> /^(?:foo\/((?:0[1-9]|1[0-9]|2[0-5]))\/bar)$/

console.log(regex.test('foo/00/bar'))  // false
console.log(regex.test('foo/01/bar'))  // true
console.log(regex.test('foo/10/bar')) // true
console.log(regex.test('foo/22/bar')) // true
console.log(regex.test('foo/25/bar')) // true
console.log(regex.test('foo/26/bar')) // false
```

#### options.format

**Type**: `function`

**Default**: `undefined`

Custom function for formatting strings before they're matched.

**Example**

```js
// strip leading './' from strings
const format = str => str.replace(/^\.\//, '');
const isMatch = picomatch('foo/*.js', { format });
console.log(isMatch('./foo/bar.js')); //=> true
```

#### options.onMatch

```js
const onMatch = ({ glob, regex, input, output }) => {
  console.log({ glob, regex, input, output });
};

const isMatch = picomatch('*', { onMatch });
isMatch('foo');
isMatch('bar');
isMatch('baz');
```

#### options.onIgnore

```js
const onIgnore = ({ glob, regex, input, output }) => {
  console.log({ glob, regex, input, output });
};

const isMatch = picomatch('*', { onIgnore, ignore: 'f*' });
isMatch('foo');
isMatch('bar');
isMatch('baz');
```

#### options.onResult

```js
const onResult = ({ glob, regex, input, output }) => {
  console.log({ glob, regex, input, output });
};

const isMatch = picomatch('*', { onResult, ignore: 'f*' });
isMatch('foo');
isMatch('bar');
isMatch('baz');
```

<br>
<br>

## Globbing features

* [Basic globbing](#basic-globbing) (Wildcard matching)
* [Advanced globbing](#advanced-globbing) (extglobs, posix brackets, brace matching)

### Basic globbing

| **Character** | **Description** |
| --- | --- |
| `*` | Matches any character zero or more times, excluding path separators. Does _not match_ path separators or hidden files or directories ("dotfiles"), unless explicitly enabled by setting the `dot` option to `true`. |
| `**` | Matches any character zero or more times, including path separators. Note that `**` will only match path separators (`/`, and `\\` on Windows) when they are the only characters in a path segment. Thus, `foo**/bar` is equivalent to `foo*/bar`, and `foo/a**b/bar` is equivalent to `foo/a*b/bar`, and _more than two_ consecutive stars in a glob path segment are regarded as _a single star_. Thus, `foo/***/bar` is equivalent to `foo/*/bar`. |
| `?` | Matches any character excluding path separators one time. Does _not match_ path separators or leading dots.  |
| `[abc]` | Matches any characters inside the brackets. For example, `[abc]` would match the characters `a`, `b` or `c`, and nothing else. |

#### Matching behavior vs. Bash

Picomatch's matching features and expected results in unit tests are based on Bash's unit tests and the Bash 4.3 specification, with the following exceptions:

* Bash will match `foo/bar/baz` with `*`. Picomatch only matches nested directories with `**`.
* Bash greedily matches with negated extglobs. For example, Bash 4.3 says that `!(foo)*` should match `foo` and `foobar`, since the trailing `*` bracktracks to match the preceding pattern. This is very memory-inefficient, and IMHO, also incorrect. Picomatch would return `false` for both `foo` and `foobar`.

<br>

### Advanced globbing

* [extglobs](#extglobs)
* [POSIX brackets](#posix-brackets)
* [Braces](#brace-expansion)

#### Extglobs

| **Pattern** | **Description** |
| --- | --- |
| `@(pattern)` | Match _only one_ consecutive occurrence of `pattern` |
| `*(pattern)` | Match _zero or more_ consecutive occurrences of `pattern` |
| `+(pattern)` | Match _one or more_ consecutive occurrences of `pattern` |
| `?(pattern)` | Match _zero or **one**_ consecutive occurrences of `pattern` |
| `!(pattern)` | Match _anything but_ `pattern` |

**Examples**

```js
const pm = require('picomatch');

// *(pattern) matches ZERO or more of "pattern"
console.log(pm.isMatch('a', 'a*(z)')); // true
console.log(pm.isMatch('az', 'a*(z)')); // true
console.log(pm.isMatch('azzz', 'a*(z)')); // true

// +(pattern) matches ONE or more of "pattern"
console.log(pm.isMatch('a', 'a*(z)')); // true
console.log(pm.isMatch('az', 'a*(z)')); // true
console.log(pm.isMatch('azzz', 'a*(z)')); // true

// supports multiple extglobs
console.log(pm.isMatch('foo.bar', '!(foo).!(bar)')); // false

// supports nested extglobs
console.log(pm.isMatch('foo.bar', '!(!(foo)).!(!(bar))')); // true
```

#### POSIX brackets

POSIX classes are disabled by default. Enable this feature by setting the `posix` option to true.

**Enable POSIX bracket support**

```js
console.log(pm.makeRe('[[:word:]]+', { posix: true }));
//=> /^(?:(?=.)[A-Za-z0-9_]+\/?)$/
```

**Supported POSIX classes**

The following named POSIX bracket expressions are supported:

* `[:alnum:]` - Alphanumeric characters, equ `[a-zA-Z0-9]`
* `[:alpha:]` - Alphabetical characters, equivalent to `[a-zA-Z]`.
* `[:ascii:]` - ASCII characters, equivalent to `[\\x00-\\x7F]`.
* `[:blank:]` - Space and tab characters, equivalent to `[ \\t]`.
* `[:cntrl:]` - Control characters, equivalent to `[\\x00-\\x1F\\x7F]`.
* `[:digit:]` - Numerical digits, equivalent to `[0-9]`.
* `[:graph:]` - Graph characters, equivalent to `[\\x21-\\x7E]`.
* `[:lower:]` - Lowercase letters, equivalent to `[a-z]`.
* `[:print:]` - Print characters, equivalent to `[\\x20-\\x7E ]`.
* `[:punct:]` - Punctuation and symbols, equivalent to `[\\-!"#$%&\'()\\*+,./:;<=>?@[\\]^_`{|}~]`.
* `[:space:]` - Extended space characters, equivalent to `[ \\t\\r\\n\\v\\f]`.
* `[:upper:]` - Uppercase letters, equivalent to `[A-Z]`.
* `[:word:]` -  Word characters (letters, numbers and underscores), equivalent to `[A-Za-z0-9_]`.
* `[:xdigit:]` - Hexadecimal digits, equivalent to `[A-Fa-f0-9]`.

See the [Bash Reference Manual](https://www.gnu.org/software/bash/manual/html_node/Pattern-Matching.html) for more information.

### Braces

Picomatch does not do brace expansion. For [brace expansion](https://www.gnu.org/software/bash/manual/html_node/Brace-Expansion.html) and advanced matching with braces, use [micromatch](https://github.com/micromatch/micromatch) instead. Picomatch has very basic support for braces.

### Matching special characters as literals

If you wish to match the following special characters in a filepath, and you want to use these characters in your glob pattern, they must be escaped with backslashes or quotes:

**Special Characters**

Some characters that are used for matching in regular expressions are also regarded as valid file path characters on some platforms.

To match any of the following characters as literals: `$^*+?()[]

Examples:

```js
console.log(pm.makeRe('foo/bar \\(1\\)'));
console.log(pm.makeRe('foo/bar \\(1\\)'));
```

<br>
<br>

## Library Comparisons

The following table shows which features are supported by [minimatch](https://github.com/isaacs/minimatch), [micromatch](https://github.com/micromatch/micromatch), [picomatch](https://github.com/micromatch/picomatch), [nanomatch](https://github.com/micromatch/nanomatch), [extglob](https://github.com/micromatch/extglob), [braces](https://github.com/micromatch/braces), and [expand-brackets](https://github.com/micromatch/expand-brackets).

| **Feature** | `minimatch` | `micromatch` | `picomatch` | `nanomatch` | `extglob` | `braces` | `expand-brackets` |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Wildcard matching (`*?+`) | ✔ | ✔ | ✔ | ✔ | - | - | - |
| Advancing globbing        | ✔ | ✔ | ✔ | - | - | - | - |
| Brace _matching_          | ✔ | ✔ | ✔ | - | - | ✔ | - |
| Brace _expansion_         | ✔ | ✔ | - | - | - | ✔ | - |
| Extglobs                  | partial | ✔ | ✔ | - | ✔ | - | - |
| Posix brackets            | - | ✔ | ✔ | - | - | - | ✔ |
| Regular expression syntax | - | ✔ | ✔ | ✔ | ✔ | - | ✔ |
| File system operations    | - | - | - | - | - | - | - |

<br>
<br>

## Benchmarks

Performance comparison of picomatch and minimatch.

```
# .makeRe star
  picomatch x 1,993,050 ops/sec ±0.51% (91 runs sampled)
  minimatch x 627,206 ops/sec ±1.96% (87 runs sampled))

# .makeRe star; dot=true
  picomatch x 1,436,640 ops/sec ±0.62% (91 runs sampled)
  minimatch x 525,876 ops/sec ±0.60% (88 runs sampled)

# .makeRe globstar
  picomatch x 1,592,742 ops/sec ±0.42% (90 runs sampled)
  minimatch x 962,043 ops/sec ±1.76% (91 runs sampled)d)

# .makeRe globstars
  picomatch x 1,615,199 ops/sec ±0.35% (94 runs sampled)
  minimatch x 477,179 ops/sec ±1.33% (91 runs sampled)

# .makeRe with leading star
  picomatch x 1,220,856 ops/sec ±0.40% (92 runs sampled)
  minimatch x 453,564 ops/sec ±1.43% (94 runs sampled)

# .makeRe - basic braces
  picomatch x 392,067 ops/sec ±0.70% (90 runs sampled)
  minimatch x 99,532 ops/sec ±2.03% (87 runs sampled))
```

<br>
<br>

## Philosophies

The goal of this library is to be blazing fast, without compromising on accuracy.

**Accuracy**

The number one of goal of this library is accuracy. However, it's not unusual for different glob implementations to have different rules for matching behavior, even with simple wildcard matching. It gets increasingly more complicated when combinations of different features are combined, like when extglobs are combined with globstars, braces, slashes, and so on: `!(**/{a,b,*/c})`.

Thus, given that there is no canonical glob specification to use as a single source of truth when differences of opinion arise regarding behavior, sometimes we have to implement our best judgement and rely on feedback from users to make improvements.

**Performance**

Although this library performs well in benchmarks, and in most cases it's faster than other popular libraries we benchmarked against, we will always choose accuracy over performance. It's not helpful to anyone if our library is faster at returning the wrong answer.

<br>
<br>

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

Please read the [contributing guide](.github/contributing.md) for advice on opening issues, pull requests, and coding standards.

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

### License

Copyright © 2017-present, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).
# is-glob [![NPM version](https://img.shields.io/npm/v/is-glob.svg?style=flat)](https://www.npmjs.com/package/is-glob) [![NPM monthly downloads](https://img.shields.io/npm/dm/is-glob.svg?style=flat)](https://npmjs.org/package/is-glob) [![NPM total downloads](https://img.shields.io/npm/dt/is-glob.svg?style=flat)](https://npmjs.org/package/is-glob) [![Build Status](https://img.shields.io/github/workflow/status/micromatch/is-glob/dev)](https://github.com/micromatch/is-glob/actions)

> Returns `true` if the given string looks like a glob pattern or an extglob pattern. This makes it easy to create code that only uses external modules like node-glob when necessary, resulting in much faster code execution and initialization time, and a better user experience.

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save is-glob
```

You might also be interested in [is-valid-glob](https://github.com/jonschlinkert/is-valid-glob) and [has-glob](https://github.com/jonschlinkert/has-glob).

## Usage

```js
var isGlob = require('is-glob');
```

### Default behavior

**True**

Patterns that have glob characters or regex patterns will return `true`:

```js
isGlob('!foo.js');
isGlob('*.js');
isGlob('**/abc.js');
isGlob('abc/*.js');
isGlob('abc/(aaa|bbb).js');
isGlob('abc/[a-z].js');
isGlob('abc/{a,b}.js');
//=> true
```

Extglobs

```js
isGlob('abc/@(a).js');
isGlob('abc/!(a).js');
isGlob('abc/+(a).js');
isGlob('abc/*(a).js');
isGlob('abc/?(a).js');
//=> true
```

**False**

Escaped globs or extglobs return `false`:

```js
isGlob('abc/\\@(a).js');
isGlob('abc/\\!(a).js');
isGlob('abc/\\+(a).js');
isGlob('abc/\\*(a).js');
isGlob('abc/\\?(a).js');
isGlob('\\!foo.js');
isGlob('\\*.js');
isGlob('\\*\\*/abc.js');
isGlob('abc/\\*.js');
isGlob('abc/\\(aaa|bbb).js');
isGlob('abc/\\[a-z].js');
isGlob('abc/\\{a,b}.js');
//=> false
```

Patterns that do not have glob patterns return `false`:

```js
isGlob('abc.js');
isGlob('abc/def/ghi.js');
isGlob('foo.js');
isGlob('abc/@.js');
isGlob('abc/+.js');
isGlob('abc/?.js');
isGlob();
isGlob(null);
//=> false
```

Arrays are also `false` (If you want to check if an array has a glob pattern, use [has-glob](https://github.com/jonschlinkert/has-glob)):

```js
isGlob(['**/*.js']);
isGlob(['foo.js']);
//=> false
```

### Option strict

When `options.strict === false` the behavior is less strict in determining if a pattern is a glob. Meaning that
some patterns that would return `false` may return `true`. This is done so that matching libraries like [micromatch](https://github.com/micromatch/micromatch) have a chance at determining if the pattern is a glob or not.

**True**

Patterns that have glob characters or regex patterns will return `true`:

```js
isGlob('!foo.js', {strict: false});
isGlob('*.js', {strict: false});
isGlob('**/abc.js', {strict: false});
isGlob('abc/*.js', {strict: false});
isGlob('abc/(aaa|bbb).js', {strict: false});
isGlob('abc/[a-z].js', {strict: false});
isGlob('abc/{a,b}.js', {strict: false});
//=> true
```

Extglobs

```js
isGlob('abc/@(a).js', {strict: false});
isGlob('abc/!(a).js', {strict: false});
isGlob('abc/+(a).js', {strict: false});
isGlob('abc/*(a).js', {strict: false});
isGlob('abc/?(a).js', {strict: false});
//=> true
```

**False**

Escaped globs or extglobs return `false`:

```js
isGlob('\\!foo.js', {strict: false});
isGlob('\\*.js', {strict: false});
isGlob('\\*\\*/abc.js', {strict: false});
isGlob('abc/\\*.js', {strict: false});
isGlob('abc/\\(aaa|bbb).js', {strict: false});
isGlob('abc/\\[a-z].js', {strict: false});
isGlob('abc/\\{a,b}.js', {strict: false});
//=> false
```

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Related projects

You might also be interested in these projects:

* [assemble](https://www.npmjs.com/package/assemble): Get the rocks out of your socks! Assemble makes you fast at creating web projects… [more](https://github.com/assemble/assemble) | [homepage](https://github.com/assemble/assemble "Get the rocks out of your socks! Assemble makes you fast at creating web projects. Assemble is used by thousands of projects for rapid prototyping, creating themes, scaffolds, boilerplates, e-books, UI components, API documentation, blogs, building websit")
* [base](https://www.npmjs.com/package/base): Framework for rapidly creating high quality, server-side node.js applications, using plugins like building blocks | [homepage](https://github.com/node-base/base "Framework for rapidly creating high quality, server-side node.js applications, using plugins like building blocks")
* [update](https://www.npmjs.com/package/update): Be scalable! Update is a new, open source developer framework and CLI for automating updates… [more](https://github.com/update/update) | [homepage](https://github.com/update/update "Be scalable! Update is a new, open source developer framework and CLI for automating updates of any kind in code projects.")
* [verb](https://www.npmjs.com/package/verb): Documentation generator for GitHub projects. Verb is extremely powerful, easy to use, and is used… [more](https://github.com/verbose/verb) | [homepage](https://github.com/verbose/verb "Documentation generator for GitHub projects. Verb is extremely powerful, easy to use, and is used on hundreds of projects of all sizes to generate everything from API docs to readmes.")

### Contributors

| **Commits** | **Contributor** |  
| --- | --- |  
| 47 | [jonschlinkert](https://github.com/jonschlinkert) |  
| 5  | [doowb](https://github.com/doowb) |  
| 1  | [phated](https://github.com/phated) |  
| 1  | [danhper](https://github.com/danhper) |  
| 1  | [paulmillr](https://github.com/paulmillr) |  

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

### License

Copyright © 2019, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.8.0, on March 27, 2019._This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
TypeScript is authored by:

 - 0verk1ll
 - Abubaker Bashir
 - Adam Freidin
 - Adam Postma
 - Adi Dahiya
 - Aditya Daflapurkar
 - Adnan Chowdhury
 - Adrian Leonhard
 - Adrien Gibrat
 - Ahmad Farid
 - Ajay Poshak
 - Alan Agius
 - Alan Pierce
 - Alessandro Vergani
 - Alex Chugaev
 - Alex Eagle
 - Alex Khomchenko
 - Alex Ryan
 - Alexander
 - Alexander Kuvaev
 - Alexander Rusakov
 - Alexander Tarasyuk
 - Ali Sabzevari
 - Aluan Haddad
 - amaksimovich2
 - Anatoly Ressin
 - Anders Hejlsberg
 - Anders Kaseorg
 - Andre Sutherland
 - Andreas Martin
 - Andrej Baran
 - Andrew
 - Andrew Branch
 - Andrew Casey
 - Andrew Faulkner
 - Andrew Ochsner
 - Andrew Stegmaier
 - Andrew Z Allen
 - Andrey Roenko
 - Andrii Dieiev
 - András Parditka
 - Andy Hanson
 - Anil Anar
 - Anix
 - Anton Khlynovskiy
 - Anton Tolmachev
 - Anubha Mathur
 - AnyhowStep
 - Armando Aguirre
 - Arnaud Tournier
 - Arnav Singh
 - Arpad Borsos
 - Artem Tyurin
 - Arthur Ozga
 - Asad Saeeduddin
 - Austin Cummings
 - Avery Morin
 - Aziz Khambati
 - Basarat Ali Syed
 - @begincalendar
 - Ben Duffield
 - Ben Lichtman
 - Ben Mosher
 - Benedikt Meurer
 - Benjamin Bock
 - Benjamin Lichtman
 - Benny Neugebauer
 - BigAru
 - Bill Ticehurst
 - Blaine Bublitz
 - Blake Embrey
 - @bluelovers
 - @bootstraponline
 - Bowden Kelly
 - Bowden Kenny
 - Brad Zacher
 - Brandon Banks
 - Brandon Bloom
 - Brandon Slade
 - Brendan Kenny
 - Brett Mayen
 - Brian Terlson
 - Bryan Forbes
 - Caitlin Potter
 - Caleb Sander
 - Cameron Taggart
 - @cedvdb
 - Charles
 - Charles Pierce
 - Charly POLY
 - Chris Bubernak
 - Chris Patterson
 - christian
 - Christophe Vidal
 - Chuck Jazdzewski
 - Clay Miller
 - Colby Russell
 - Colin Snover
 - Collins Abitekaniza
 - Connor Clark
 - Cotton Hou
 - csigs
 - Cyrus Najmabadi
 - Dafrok Zhang
 - Dahan Gong
 - Daiki Nishikawa
 - Dan Corder
 - Dan Freeman
 - Dan Quirk
 - Dan Rollo
 - Daniel Gooss
 - Daniel Imms
 - Daniel Krom
 - Daniel Król
 - Daniel Lehenbauer
 - Daniel Rosenwasser
 - David Li
 - David Sheldrick
 - David Sherret
 - David Souther
 - David Staheli
 - Denis Nedelyaev
 - Derek P Sifford
 - Dhruv Rajvanshi
 - Dick van den Brink
 - Diogo Franco (Kovensky)
 - Dirk Bäumer
 - Dirk Holtwick
 - Dmitrijs Minajevs
 - Dom Chen
 - Donald Pipowitch
 - Doug Ilijev
 - dreamran43@gmail.com
 - @e-cloud
 - Ecole Keine
 - Eddie Jaoude
 - Edward Thomson
 - EECOLOR
 - Eli Barzilay
 - Elizabeth Dinella
 - Ely Alamillo
 - Eric Grube
 - Eric Tsang
 - Erik Edrosa
 - Erik McClenney
 - Esakki Raj
 - Ethan Resnick
 - Ethan Rubio
 - Eugene Timokhov
 - Evan Cahill
 - Evan Martin
 - Evan Sebastian
 - ExE Boss
 - Eyas Sharaiha
 - Fabian Cook
 - @falsandtru
 - Filipe Silva
 - @flowmemo
 - Forbes Lindesay
 - Francois Hendriks
 - Francois Wouts
 - Frank Wallis
 - František Žiacik
 - Frederico Bittencourt
 - fullheightcoding
 - Gabe Moothart
 - Gabriel Isenberg
 - Gabriela Araujo Britto
 - Gabriela Britto
 - Gao Sheng
 - gb714us
 - Gilad Peleg
 - Godfrey Chan
 - Gorka Hernández Estomba
 - Graeme Wicksted
 - Guillaume Salles
 - Guy Bedford
 - hafiz
 - Halasi Tamás
 - Hendrik Liebau
 - Henry Mercer
 - Herrington Darkholme
 - Hoang Pham
 - Holger Jeromin
 - Homa Wong
 - Hye Sung Jung
 - Iain Monro
 - @IdeaHunter
 - Igor Novozhilov
 - Igor Oleinikov
 - Ika
 - iliashkolyar
 - IllusionMH
 - Ingvar Stepanyan
 - Ingvar Stepanyan
 - Isiah Meadows
 - ispedals
 - Ivan Enderlin
 - Ivo Gabe de Wolff
 - Iwata Hidetaka
 - Jack Bates
 - Jack Williams
 - Jake Boone
 - Jakub Korzeniowski
 - Jakub Młokosiewicz
 - James Henry
 - James Keane
 - James Whitney
 - Jan Melcher
 - Jason Freeman
 - Jason Jarrett
 - Jason Killian
 - Jason Ramsay
 - JBerger
 - Jean Pierre
 - Jed Mao
 - Jeff Wilcox
 - Jeffrey Morlan
 - Jesse Schalken
 - Jesse Trinity
 - Jing Ma
 - Jiri Tobisek
 - Joe Calzaretta
 - Joe Chung
 - Joel Day
 - Joey Watts
 - Johannes Rieken
 - John Doe
 - John Vilk
 - Jonathan Bond-Caron
 - Jonathan Park
 - Jonathan Toland
 - Jordan Harband
 - Jordi Oliveras Rovira
 - Joscha Feth
 - Joseph Wunderlich
 - Josh Abernathy
 - Josh Goldberg
 - Josh Kalderimis
 - Josh Soref
 - Juan Luis Boya García
 - Julian Williams
 - Justin Bay
 - Justin Johansson
 - jwbay
 - K. Preißer
 - Kagami Sascha Rosylight
 - Kanchalai Tanglertsampan
 - karthikkp
 - Kate Miháliková
 - Keen Yee Liau
 - Keith Mashinter
 - Ken Howard
 - Kenji Imamula
 - Kerem Kat
 - Kevin Donnelly
 - Kevin Gibbons
 - Kevin Lang
 - Khải
 - Kitson Kelly
 - Klaus Meinhardt
 - Kris Zyp
 - Kyle Kelley
 - Kārlis Gaņģis
 - laoxiong
 - Leon Aves
 - Limon Monte
 - Lorant Pinter
 - Lucien Greathouse
 - Luka Hartwig
 - Lukas Elmer
 - M.Yoshimura
 - Maarten Sijm
 - Magnus Hiie
 - Magnus Kulke
 - Manish Bansal
 - Manish Giri
 - Marcus Noble
 - Marin Marinov
 - Marius Schulz
 - Markus Johnsson
 - Markus Wolf
 - Martin
 - Martin Hiller
 - Martin Johns
 - Martin Probst
 - Martin Vseticka
 - Martyn Janes
 - Masahiro Wakame
 - Mateusz Burzyński
 - Matt Bierner
 - Matt McCutchen
 - Matt Mitchell
 - Matthew Aynalem
 - Matthew Miller
 - Mattias Buelens
 - Max Heiber
 - Maxwell Paul Brickner
 - @meyer
 - Micah Zoltu
 - @micbou
 - Michael
 - Michael Crane
 - Michael Henderson
 - Michael Tamm
 - Michael Tang
 - Michal Przybys
 - Mike Busyrev
 - Mike Morearty
 - Milosz Piechocki
 - Mine Starks
 - Minh Nguyen
 - Mohamed Hegazy
 - Mohsen Azimi
 - Mukesh Prasad
 - Myles Megyesi
 - Nathan Day
 - Nathan Fenner
 - Nathan Shively-Sanders
 - Nathan Yee
 - ncoley
 - Nicholas Yang
 - Nicu Micleușanu
 - @nieltg
 - Nima Zahedi
 - Noah Chen
 - Noel Varanda
 - Noel Yoo
 - Noj Vek
 - nrcoley
 - Nuno Arruda
 - Oleg Mihailik
 - Oleksandr Chekhovskyi
 - Omer Sheikh
 - Orta Therox
 - Orta Therox
 - Oskar Grunning
 - Oskar Segersva¨rd
 - Oussama Ben Brahim
 - Ozair Patel
 - Patrick McCartney
 - Patrick Zhong
 - Paul Koerbitz
 - Paul van Brenk
 - @pcbro
 - Pedro Maltez
 - Pete Bacon Darwin
 - Peter Burns
 - Peter Šándor
 - Philip Pesca
 - Philippe Voinov
 - Pi Lanningham
 - Piero Cangianiello
 - Pierre-Antoine Mills
 - @piloopin
 - Pranav Senthilnathan
 - Prateek Goel
 - Prateek Nayak
 - Prayag Verma
 - Priyantha Lankapura
 - @progre
 - Punya Biswal
 - r7kamura
 - Rado Kirov
 - Raj Dosanjh
 - rChaser53
 - Reiner Dolp
 - Remo H. Jansen
 - @rflorian
 - Rhys van der Waerden
 - @rhysd
 - Ricardo N Feliciano
 - Richard Karmazín
 - Richard Knoll
 - Roger Spratley
 - Ron Buckton
 - Rostislav Galimsky
 - Rowan Wyborn
 - rpgeeganage
 - Ruwan Pradeep Geeganage
 - Ryan Cavanaugh
 - Ryan Clarke
 - Ryohei Ikegami
 - Salisbury, Tom
 - Sam Bostock
 - Sam Drugan
 - Sam El-Husseini
 - Sam Lanning
 - Sangmin Lee
 - Sanket Mishra
 - Sarangan Rajamanickam
 - Sasha Joseph
 - Sean Barag
 - Sergey Rubanov
 - Sergey Shandar
 - Sergey Tychinin
 - Sergii Bezliudnyi
 - Sergio Baidon
 - Sharon Rolel
 - Sheetal Nandi
 - Shengping Zhong
 - Sheon Han
 - Shyyko Serhiy
 - Siddharth Singh
 - sisisin
 - Slawomir Sadziak
 - Solal Pirelli
 - Soo Jae Hwang
 - Stan Thomas
 - Stanislav Iliev
 - Stanislav Sysoev
 - Stas Vilchik
 - Stephan Ginthör
 - Steve Lucco
 - @styfle
 - Sudheesh Singanamalla
 - Suhas
 - Suhas Deshpande
 - superkd37
 - Sébastien Arod
 - @T18970237136
 - @t_
 - Tan Li Hau
 - Tapan Prakash
 - Taras Mankovski
 - Tarik Ozket
 - Tetsuharu Ohzeki
 - The Gitter Badger
 - Thomas den Hollander
 - Thorsten Ball
 - Tien Hoanhtien
 - Tim Lancina
 - Tim Perry
 - Tim Schaub
 - Tim Suchanek
 - Tim Viiding-Spader
 - Tingan Ho
 - Titian Cernicova-Dragomir
 - tkondo
 - Todd Thomson
 - togru
 - Tom J
 - Torben Fitschen
 - Toxyxer
 - @TravCav
 - Troy Tae
 - TruongSinh Tran-Nguyen
 - Tycho Grouwstra
 - uhyo
 - Vadi Taslim
 - Vakhurin Sergey
 - Valera Rozuvan
 - Vilic Vane
 - Vimal Raghubir
 - Vladimir Kurchatkin
 - Vladimir Matveev
 - Vyacheslav Pukhanov
 - Wenlu Wang
 - Wes Souza
 - Wesley Wigham
 - William Orr
 - Wilson Hobbs
 - xiaofa
 - xl1
 - Yacine Hmito
 - Yang Cao
 - York Yao
 - @yortus
 - Yoshiki Shibukawa
 - Yuichi Nukiyama
 - Yuval Greenfield
 - Yuya Tanaka
 - Z
 - Zeeshan Ahmed
 - Zev Spitz
 - Zhengbo Li
 - Zixiang Li
 - @Zzzen
 - 阿卡琳

# TypeScript

[![GitHub Actions CI](https://github.com/microsoft/TypeScript/workflows/CI/badge.svg)](https://github.com/microsoft/TypeScript/actions?query=workflow%3ACI)
[![Devops Build Status](https://dev.azure.com/typescript/TypeScript/_apis/build/status/Typescript/node10)](https://dev.azure.com/typescript/TypeScript/_build?definitionId=7)
[![npm version](https://badge.fury.io/js/typescript.svg)](https://www.npmjs.com/package/typescript)
[![Downloads](https://img.shields.io/npm/dm/typescript.svg)](https://www.npmjs.com/package/typescript)

[TypeScript](https://www.typescriptlang.org/) is a language for application-scale JavaScript. TypeScript adds optional types to JavaScript that support tools for large-scale JavaScript applications for any browser, for any host, on any OS. TypeScript compiles to readable, standards-based JavaScript. Try it out at the [playground](https://www.typescriptlang.org/play/), and stay up to date via [our blog](https://blogs.msdn.microsoft.com/typescript) and [Twitter account](https://twitter.com/typescript).

Find others who are using TypeScript at [our community page](https://www.typescriptlang.org/community/).

## Installing

For the latest stable version:

```bash
npm install -g typescript
```

For our nightly builds:

```bash
npm install -g typescript@next
```

## Contribute

There are many ways to [contribute](https://github.com/microsoft/TypeScript/blob/main/CONTRIBUTING.md) to TypeScript.
* [Submit bugs](https://github.com/microsoft/TypeScript/issues) and help us verify fixes as they are checked in.
* Review the [source code changes](https://github.com/microsoft/TypeScript/pulls).
* Engage with other TypeScript users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/typescript).
* Help each other in the [TypeScript Community Discord](https://discord.gg/typescript).
* Join the [#typescript](https://twitter.com/search?q=%23TypeScript) discussion on Twitter.
* [Contribute bug fixes](https://github.com/microsoft/TypeScript/blob/main/CONTRIBUTING.md).
* Read the archived language specification ([docx](https://github.com/microsoft/TypeScript/blob/main/doc/TypeScript%20Language%20Specification%20-%20ARCHIVED.docx?raw=true),
 [pdf](https://github.com/microsoft/TypeScript/blob/main/doc/TypeScript%20Language%20Specification%20-%20ARCHIVED.pdf?raw=true), [md](https://github.com/microsoft/TypeScript/blob/main/doc/spec-ARCHIVED.md)).

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see
the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)
with any additional questions or comments.

## Documentation

*  [TypeScript in 5 minutes](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html)
*  [Programming handbook](https://www.typescriptlang.org/docs/handbook/intro.html)
*  [Homepage](https://www.typescriptlang.org/)

## Building

In order to build the TypeScript compiler, ensure that you have [Git](https://git-scm.com/downloads) and [Node.js](https://nodejs.org/) installed.

Clone a copy of the repo:

```bash
git clone https://github.com/microsoft/TypeScript.git
```

Change to the TypeScript directory:

```bash
cd TypeScript
```

Install [Gulp](https://gulpjs.com/) tools and dev dependencies:

```bash
npm install -g gulp
npm ci
```

Use one of the following to build and test:

```
gulp local             # Build the compiler into built/local.
gulp clean             # Delete the built compiler.
gulp LKG               # Replace the last known good with the built one.
                       # Bootstrapping step to be executed when the built compiler reaches a stable state.
gulp tests             # Build the test infrastructure using the built compiler.
gulp runtests          # Run tests using the built compiler and test infrastructure.
                       # You can override the specific suite runner used or specify a test for this command.
                       # Use --tests=<testPath> for a specific test and/or --runner=<runnerName> for a specific suite.
                       # Valid runners include conformance, compiler, fourslash, project, user, and docker
                       # The user and docker runners are extended test suite runners - the user runner
                       # works on disk in the tests/cases/user directory, while the docker runner works in containers.
                       # You'll need to have the docker executable in your system path for the docker runner to work.
gulp runtests-parallel # Like runtests, but split across multiple threads. Uses a number of threads equal to the system
                       # core count by default. Use --workers=<number> to adjust this.
gulp baseline-accept   # This replaces the baseline test results with the results obtained from gulp runtests.
gulp lint              # Runs eslint on the TypeScript source.
gulp help              # List the above commands.
```


## Usage

```bash
node built/local/tsc.js hello.ts
```


## Roadmap

For details on our planned features and future direction please refer to our [roadmap](https://github.com/microsoft/TypeScript/wiki/Roadmap).
# Read This!

**These files are not meant to be edited by hand.**
If you need to make modifications, the respective files should be changed within the repository's top-level `src` directory.
Running `gulp LKG` will then appropriately update the files in this directory.
<!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK -->

## Security

Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).

If you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc751383(v=technet.10)), please report it to us as described below.

## Reporting Security Issues

**Please do not report security vulnerabilities through public GitHub issues.**

Instead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://msrc.microsoft.com/create-report).

If you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://www.microsoft.com/en-us/msrc/pgp-key-msrc).

You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc). 

Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:

  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)
  * Full paths of source file(s) related to the manifestation of the issue
  * The location of the affected source code (tag/branch/commit or direct URL)
  * Any special configuration required to reproduce the issue
  * Step-by-step instructions to reproduce the issue
  * Proof-of-concept or exploit code (if possible)
  * Impact of the issue, including how an attacker might exploit the issue

This information will help us triage your report more quickly.

If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://microsoft.com/msrc/bounty) page for more details about our active programs.

## Preferred Languages

We prefer all communications to be in English.

## Policy

Microsoft follows the principle of [Coordinated Vulnerability Disclosure](https://www.microsoft.com/en-us/msrc/cvd).

<!-- END MICROSOFT SECURITY.MD BLOCK -->

# flat-cache - Changelog
## v3.0.4
- **Refactoring**
  - add files by name to the list of exported files - [89a2698]( https://github.com/royriojas/flat-cache/commit/89a2698 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 02:35:39

    
## v3.0.3
- **Bug Fixes**
  - Fix wrong eslint command - [f268e42]( https://github.com/royriojas/flat-cache/commit/f268e42 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 02:15:04

    
## v3.0.2
- **Refactoring**
  - Update the files paths - [6983a80]( https://github.com/royriojas/flat-cache/commit/6983a80 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:58:39

    
  - Move code to src/ - [18ed6e8]( https://github.com/royriojas/flat-cache/commit/18ed6e8 ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:57:17

    
  - Change eslint-cache location - [beed74c]( https://github.com/royriojas/flat-cache/commit/beed74c ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:48:32

    
## v3.0.1
- **Refactoring**
  - Remove unused deps - [8c6d9dc]( https://github.com/royriojas/flat-cache/commit/8c6d9dc ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:43:29

    
## v3.0.0
- **Refactoring**
  - Fix engines - [52b824c]( https://github.com/royriojas/flat-cache/commit/52b824c ), [Roy Riojas](https://github.com/Roy Riojas), 08/11/2020 01:01:52

    
- **Other changes**
  - Replace write with combination of mkdir and writeFile ([#49](https://github.com/royriojas/flat-cache/issues/49)) - [ef48276]( https://github.com/royriojas/flat-cache/commit/ef48276 ), [Bogdan Chadkin](https://github.com/Bogdan Chadkin), 08/11/2020 00:17:15

    Node v10 introduced a great "recursive" option for mkdir which allows to
    get rid from mkdirp package and easily rewrite "write" package usage
    with two function calls.
    
    https://nodejs.org/api/fs.html#fs_fs_mkdir_path_options_callback
  - Added a testcase for clearAll ([#48](https://github.com/royriojas/flat-cache/issues/48)) - [45b51ca]( https://github.com/royriojas/flat-cache/commit/45b51ca ), [Aaron Chen](https://github.com/Aaron Chen), 21/05/2020 08:40:03

    
  - requet node>=10 - [a5c482c]( https://github.com/royriojas/flat-cache/commit/a5c482c ), [yumetodo](https://github.com/yumetodo), 10/04/2020 23:14:53

    thanks @SuperITMan
    
  - Update README.md - [29fe40b]( https://github.com/royriojas/flat-cache/commit/29fe40b ), [Roy Riojas](https://github.com/Roy Riojas), 10/04/2020 20:08:05

    
  - reduce vulnerability to 1 - [e9db1b2]( https://github.com/royriojas/flat-cache/commit/e9db1b2 ), [yumetodo](https://github.com/yumetodo), 30/03/2020 11:10:43

    
  - reduce vulnerabilities dependencies to 8 - [b58d196]( https://github.com/royriojas/flat-cache/commit/b58d196 ), [yumetodo](https://github.com/yumetodo), 30/03/2020 10:54:56

    
  - use prettier instead of esbeautifier - [03b1db7]( https://github.com/royriojas/flat-cache/commit/03b1db7 ), [yumetodo](https://github.com/yumetodo), 30/03/2020 10:27:14

    
  - update proxyquire - [c2f048d]( https://github.com/royriojas/flat-cache/commit/c2f048d ), [yumetodo](https://github.com/yumetodo), 30/03/2020 10:16:16

    
  - update flatted and mocha - [a0e56da]( https://github.com/royriojas/flat-cache/commit/a0e56da ), [yumetodo](https://github.com/yumetodo), 30/03/2020 09:46:45

    mocha > mkdirp is updated
    istanble >>> optimist > minimist is not updated
    
  - drop support node.js < 10 in develop - [beba691]( https://github.com/royriojas/flat-cache/commit/beba691 ), [yumetodo](https://github.com/yumetodo), 18/03/2020 01:31:09

    see mkdirp
    
  - npm aufit fix(still remains) - [ce166cb]( https://github.com/royriojas/flat-cache/commit/ce166cb ), [yumetodo](https://github.com/yumetodo), 18/03/2020 01:18:08

    37 vulnerabilities required manual review and could not be updated
    
  - updtate sinon - [9f2d1b6]( https://github.com/royriojas/flat-cache/commit/9f2d1b6 ), [yumetodo](https://github.com/yumetodo), 18/03/2020 01:17:51

    
  - apply eslint-plugin-mocha - [07343b5]( https://github.com/royriojas/flat-cache/commit/07343b5 ), [yumetodo](https://github.com/yumetodo), 13/03/2020 22:17:21

    
  - Less strint version check ([#44](https://github.com/royriojas/flat-cache/issues/44)) - [92aca1c]( https://github.com/royriojas/flat-cache/commit/92aca1c ), [Wojciech Maj](https://github.com/Wojciech Maj), 13/11/2019 16:18:25

    * Use ^ version matching for production dependencies
    
    * Run npm audit fix
    
- **Bug Fixes**
  - update dependencies and use eslint directly - [73fbed2]( https://github.com/royriojas/flat-cache/commit/73fbed2 ), [yumetodo](https://github.com/yumetodo), 18/03/2020 01:17:27

    
## v2.0.1
- **Refactoring**
  - upgrade node modules to latest versions - [6402ed3]( https://github.com/royriojas/flat-cache/commit/6402ed3 ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 18:47:05

    
## v2.0.0
- **Bug Fixes**
  - upgrade package.json lock file - [8d21c7b]( https://github.com/royriojas/flat-cache/commit/8d21c7b ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 17:03:13

    
  - Use the same versions of node_js that eslint use - [8d23379]( https://github.com/royriojas/flat-cache/commit/8d23379 ), [Roy Riojas](https://github.com/Roy Riojas), 08/01/2019 16:25:11

    
- **Other changes**
  - Replace circular-json with flatted ([#36](https://github.com/royriojas/flat-cache/issues/36)) - [b93aced]( https://github.com/royriojas/flat-cache/commit/b93aced ), [C. K. Tang](https://github.com/C. K. Tang), 08/01/2019 17:03:01

    
  - Change JSON parser from circular-json to flatted & 1 more changes ([#37](https://github.com/royriojas/flat-cache/issues/37)) - [745e65a]( https://github.com/royriojas/flat-cache/commit/745e65a ), [Andy Chen](https://github.com/Andy Chen), 08/01/2019 16:17:20

    * Change JSON parser from circular-json to flatted & 1 more changes
    
    * Change JSON parser from circular-json
    * Audited 2 vulnerabilities
    
    * Update package.json
    
    * Update Engine require
    
    * There's a bunch of dependencies in this pkg requires node >=4, so I changed it to 4
    
    * Remove and add node versions
    
    * I have seen this pkg is not available with node 0.12 so I removed it
    * I have added a popular used LTS version of node - 10
    
## v1.3.4
- **Refactoring**
  - Add del.js and utils.js to the list of files to be beautified - [9d0ca9b]( https://github.com/royriojas/flat-cache/commit/9d0ca9b ), [Roy Riojas](https://github.com/Roy Riojas), 14/11/2018 12:19:02

    
## v1.3.3
- **Refactoring**
  - Make sure package-lock.json is up to date - [a7d2598]( https://github.com/royriojas/flat-cache/commit/a7d2598 ), [Roy Riojas](https://github.com/Roy Riojas), 14/11/2018 11:36:08

    
- **Other changes**
  - Removed the need for del ([#33](https://github.com/royriojas/flat-cache/issues/33)) - [c429012]( https://github.com/royriojas/flat-cache/commit/c429012 ), [S. Gilroy](https://github.com/S. Gilroy), 13/11/2018 13:56:37

    * Removed the need for del
    
    Removed the need for del as newer versions have broken backwards
    compatibility. del mainly uses rimraf for deleting folders
    and files, replaceing it with rimraf only is a minimal change.
    
    * Disable glob on rimraf calls
    
    * Added glob disable to wrong call
    
    * Wrapped rimraf to simplify solution
    
## v1.3.2
- **Refactoring**
  - remove yarn.lock file - [704c6c4]( https://github.com/royriojas/flat-cache/commit/704c6c4 ), [Roy Riojas](https://github.com/Roy Riojas), 07/11/2018 15:41:08

    
- **Other changes**
  - replace circular-json with flatted ([#23](https://github.com/royriojas/flat-cache/issues/23))" - [db12d74]( https://github.com/royriojas/flat-cache/commit/db12d74 ), [Roy Riojas](https://github.com/Roy Riojas), 07/11/2018 15:40:39

    This reverts commit 00f689277a75e85fef28e6a048fad227afc525e6.
    
## v1.3.1
- **Refactoring**
  - upgrade deps to remove some security warnings - [f405719]( https://github.com/royriojas/flat-cache/commit/f405719 ), [Roy Riojas](https://github.com/Roy Riojas), 06/11/2018 12:07:31

    
- **Bug Fixes**
  - replace circular-json with flatted ([#23](https://github.com/royriojas/flat-cache/issues/23)) - [00f6892]( https://github.com/royriojas/flat-cache/commit/00f6892 ), [Terry](https://github.com/Terry), 05/11/2018 18:44:16

    
- **Other changes**
  - update del to v3.0.0 ([#26](https://github.com/royriojas/flat-cache/issues/26)) - [d42883f]( https://github.com/royriojas/flat-cache/commit/d42883f ), [Patrick Silva](https://github.com/Patrick Silva), 03/11/2018 01:00:44

    Closes <a target="_blank" class="info-link" href="https://github.com/royriojas/flat-cache/issues/25"><span>#25</span></a>
## v1.3.0
- **Other changes**
  - Added #all method ([#16](https://github.com/royriojas/flat-cache/issues/16)) - [12293be]( https://github.com/royriojas/flat-cache/commit/12293be ), [Ozair Patel](https://github.com/Ozair Patel), 25/09/2017 14:46:38

    * Added #all method
    
    * Added #all method test
    
    * Updated readme
    
    * Added yarn.lock
    
    * Added more keys for #all test
    
    * Beautified file
    
  - fix changelog title style ([#14](https://github.com/royriojas/flat-cache/issues/14)) - [af8338a]( https://github.com/royriojas/flat-cache/commit/af8338a ), [前端小武](https://github.com/前端小武), 19/12/2016 20:34:48

    
## v1.2.2
- **Bug Fixes**
  - Do not crash if cache file is invalid JSON. ([#13](https://github.com/royriojas/flat-cache/issues/13)) - [87beaa6]( https://github.com/royriojas/flat-cache/commit/87beaa6 ), [Roy Riojas](https://github.com/Roy Riojas), 19/12/2016 18:03:35

    Fixes <a target="_blank" class="info-link" href="https://github.com/royriojas/flat-cache/issues/12"><span>#12</span></a>
    
    Not sure under which situations a cache file might exist that does
    not contain a valid JSON structure, but just in case to cover
    the possibility of this happening a try catch block has been added
    
    If the cache is somehow not valid the cache will be discarded an a
    a new cache will be stored instead
- **Other changes**
  - Added travis ci support for modern node versions ([#11](https://github.com/royriojas/flat-cache/issues/11)) - [1c2b1f7]( https://github.com/royriojas/flat-cache/commit/1c2b1f7 ), [Amila Welihinda](https://github.com/Amila Welihinda), 10/11/2016 23:47:52

    
  - Bumping `circular-son` version ([#10](https://github.com/royriojas/flat-cache/issues/10)) - [4d5e861]( https://github.com/royriojas/flat-cache/commit/4d5e861 ), [Andrea Giammarchi](https://github.com/Andrea Giammarchi), 02/08/2016 07:13:52

    As mentioned in https://github.com/WebReflection/circular-json/issues/25 `circular-json` wan't rightly implementing the license field.
    
    Latest version bump changed only that bit so that ESLint should now be happy.
## v1.2.1
- **Bug Fixes**
  - Add missing utils.js file to the package. closes [#8](https://github.com/royriojas/flat-cache/issues/8) - [ec10cf2]( https://github.com/royriojas/flat-cache/commit/ec10cf2 ), [Roy Riojas](https://github.com/Roy Riojas), 01/08/2016 02:18:57

    
## v1.2.0
- **Documentation**
  - Add documentation about noPrune option - [23e11f9]( https://github.com/royriojas/flat-cache/commit/23e11f9 ), [Roy Riojas](https://github.com/Roy Riojas), 01/08/2016 02:06:49

    
## v1.0.11
- **Features**
  - Add noPrune option to cache.save() method. closes [#7](https://github.com/royriojas/flat-cache/issues/7) - [2c8016a]( https://github.com/royriojas/flat-cache/commit/2c8016a ), [Roy Riojas](https://github.com/Roy Riojas), 01/08/2016 02:00:29

    
  - Add json read and write utility based on circular-json - [c31081e]( https://github.com/royriojas/flat-cache/commit/c31081e ), [Jean Ponchon](https://github.com/Jean Ponchon), 28/07/2016 08:58:17

    
- **Bug Fixes**
  - Remove UTF16 BOM stripping - [4a41e22]( https://github.com/royriojas/flat-cache/commit/4a41e22 ), [Jean Ponchon](https://github.com/Jean Ponchon), 29/07/2016 02:18:06

    Since we control both writing and reading of JSON stream, there no needs 
    to handle unicode BOM.
  - Use circular-json to handle circular references (fix [#5](https://github.com/royriojas/flat-cache/issues/5)) - [cd7aeed]( https://github.com/royriojas/flat-cache/commit/cd7aeed ), [Jean Ponchon](https://github.com/Jean Ponchon), 25/07/2016 11:11:59

    
- **Tests Related fixes**
  - Add missing file from eslint test - [d6fa3c3]( https://github.com/royriojas/flat-cache/commit/d6fa3c3 ), [Jean Ponchon](https://github.com/Jean Ponchon), 29/07/2016 02:15:51

    
  - Add test for circular json serialization / deserialization - [07d2ddd]( https://github.com/royriojas/flat-cache/commit/07d2ddd ), [Jean Ponchon](https://github.com/Jean Ponchon), 28/07/2016 08:59:36

    
- **Refactoring**
  - Remove unused read-json-sync - [2be1c24]( https://github.com/royriojas/flat-cache/commit/2be1c24 ), [Jean Ponchon](https://github.com/Jean Ponchon), 28/07/2016 08:59:18

    
- **Build Scripts Changes**
  - travis tests on 0.12 and 4x - [3a613fd]( https://github.com/royriojas/flat-cache/commit/3a613fd ), [royriojas](https://github.com/royriojas), 15/11/2015 14:34:40

    
## v1.0.10
- **Build Scripts Changes**
  - add eslint-fix task - [fd29e52]( https://github.com/royriojas/flat-cache/commit/fd29e52 ), [royriojas](https://github.com/royriojas), 01/11/2015 15:04:08

    
  - make sure the test script also verify beautification and linting of files before running tests - [e94e176]( https://github.com/royriojas/flat-cache/commit/e94e176 ), [royriojas](https://github.com/royriojas), 01/11/2015 11:54:48

    
- **Other changes**
  - add clearAll for cacheDir - [97383d9]( https://github.com/royriojas/flat-cache/commit/97383d9 ), [xieyaowu](https://github.com/xieyaowu), 31/10/2015 21:02:18

    
## v1.0.9
- **Bug Fixes**
  - wrong default values for changelogx user repo name - [7bb52d1]( https://github.com/royriojas/flat-cache/commit/7bb52d1 ), [royriojas](https://github.com/royriojas), 11/09/2015 15:59:30

    
## v1.0.8
- **Build Scripts Changes**
  - test against node 4 - [c395b66]( https://github.com/royriojas/flat-cache/commit/c395b66 ), [royriojas](https://github.com/royriojas), 11/09/2015 15:51:39

    
## v1.0.7
- **Other changes**
  - Move dependencies into devDep - [7e47099]( https://github.com/royriojas/flat-cache/commit/7e47099 ), [Bogdan Chadkin](https://github.com/Bogdan Chadkin), 11/09/2015 15:10:57

    
- **Documentation**
  - Add missing changelog link - [f51197a]( https://github.com/royriojas/flat-cache/commit/f51197a ), [royriojas](https://github.com/royriojas), 11/09/2015 14:48:05

    
## v1.0.6
- **Build Scripts Changes**
  - Add helpers/code check scripts - [bdb82f3]( https://github.com/royriojas/flat-cache/commit/bdb82f3 ), [royriojas](https://github.com/royriojas), 11/09/2015 14:44:31

    
## v1.0.5
- **Documentation**
  - better description for the module - [436817f]( https://github.com/royriojas/flat-cache/commit/436817f ), [royriojas](https://github.com/royriojas), 11/09/2015 14:35:33

    
- **Other changes**
  - Update dependencies - [be88aa3]( https://github.com/royriojas/flat-cache/commit/be88aa3 ), [Bogdan Chadkin](https://github.com/Bogdan Chadkin), 11/09/2015 13:47:41

    
## v1.0.4
- **Refactoring**
  - load a cache file using the full filepath - [b8f68c2]( https://github.com/royriojas/flat-cache/commit/b8f68c2 ), [Roy Riojas](https://github.com/Roy Riojas), 30/08/2015 04:19:14

    
- **Documentation**
  - Add documentation about `clearAll` and `clearCacheById` - [13947c1]( https://github.com/royriojas/flat-cache/commit/13947c1 ), [Roy Riojas](https://github.com/Roy Riojas), 01/03/2015 23:44:05

    
- **Features**
  - Add methods to remove the cache documents created - [af40443]( https://github.com/royriojas/flat-cache/commit/af40443 ), [Roy Riojas](https://github.com/Roy Riojas), 01/03/2015 23:39:27

    
## v1.0.1
- **Other changes**
  - Update README.md - [c2b6805]( https://github.com/royriojas/flat-cache/commit/c2b6805 ), [Roy Riojas](https://github.com/Roy Riojas), 26/02/2015 04:28:07

    
## v1.0.0
- **Refactoring**
  - flat-cache v.1.0.0 - [c984274]( https://github.com/royriojas/flat-cache/commit/c984274 ), [Roy Riojas](https://github.com/Roy Riojas), 26/02/2015 04:11:50

    
- **Other changes**
  - Initial commit - [d43cccf]( https://github.com/royriojas/flat-cache/commit/d43cccf ), [Roy Riojas](https://github.com/Roy Riojas), 26/02/2015 01:12:16

    
# flat-cache
> A stupidly simple key/value storage using files to persist the data

[![NPM Version](https://img.shields.io/npm/v/flat-cache.svg?style=flat)](https://npmjs.org/package/flat-cache)
[![tests](https://github.com/jaredwray/flat-cache/actions/workflows/tests.yaml/badge.svg?branch=master)](https://github.com/jaredwray/flat-cache/actions/workflows/tests.yaml)
[![codecov](https://codecov.io/github/jaredwray/flat-cache/branch/master/graph/badge.svg?token=KxR95XT3NF)](https://codecov.io/github/jaredwray/flat-cache)
[![npm](https://img.shields.io/npm/dm/flat-cache)](https://npmjs.com/package/flat-cache)

## install

```bash
npm i --save flat-cache
```

## Usage

```js
var flatCache = require('flat-cache')
// loads the cache, if one does not exists for the given
// Id a new one will be prepared to be created
var cache = flatCache.load('cacheId');

// sets a key on the cache
cache.setKey('key', { foo: 'var' });

// get a key from the cache
cache.getKey('key') // { foo: 'var' }

// fetch the entire persisted object
cache.all() // { 'key': { foo: 'var' } }

// remove a key
cache.removeKey('key'); // removes a key from the cache

// save it to disk
cache.save(); // very important, if you don't save no changes will be persisted.
// cache.save( true /* noPrune */) // can be used to prevent the removal of non visited keys

// loads the cache from a given directory, if one does
// not exists for the given Id a new one will be prepared to be created
var cache = flatCache.load('cacheId', path.resolve('./path/to/folder'));

// The following methods are useful to clear the cache
// delete a given cache
flatCache.clearCacheById('cacheId') // removes the cacheId document if one exists.

// delete all cache
flatCache.clearAll(); // remove the cache directory
```

## Motivation for this module

I needed a super simple and dumb **in-memory cache** with optional disk persistance in order to make
a script that will beutify files with `esformatter` only execute on the files that were changed since the last run.
To make that possible we need to store the `fileSize` and `modificationTime` of the files. So a simple `key/value`
storage was needed and Bam! this module was born.

## Important notes
- If no directory is especified when the `load` method is called, a folder named `.cache` will be created
  inside the module directory when `cache.save` is called. If you're committing your `node_modules` to any vcs, you
  might want to ignore the default `.cache` folder, or specify a custom directory.
- The values set on the keys of the cache should be `stringify-able` ones, meaning no circular references
- All the changes to the cache state are done to memory
- I could have used a timer or `Object.observe` to deliver the changes to disk, but I wanted to keep this module
  intentionally dumb and simple
- Non visited keys are removed when `cache.save()` is called. If this is not desired, you can pass `true` to the save call
  like: `cache.save( true /* noPrune */ )`.

## License

MIT

## Changelog

[changelog](./changelog.md)
Browser-friendly inheritance fully compatible with standard node.js
[inherits](http://nodejs.org/api/util.html#util_util_inherits_constructor_superconstructor).

This package exports standard `inherits` from node.js `util` module in
node environment, but also provides alternative browser-friendly
implementation through [browser
field](https://gist.github.com/shtylman/4339901). Alternative
implementation is a literal copy of standard one located in standalone
module to avoid requiring of `util`. It also has a shim for old
browsers with no `Object.create` support.

While keeping you sure you are using standard `inherits`
implementation in node.js environment, it allows bundlers such as
[browserify](https://github.com/substack/node-browserify) to not
include full `util` package to your client code if all you need is
just `inherits` function. It worth, because browser shim for `util`
package is large and `inherits` is often the single function you need
from it.

It's recommended to use this package instead of
`require('util').inherits` for any code that has chances to be used
not only in node.js but in browser too.

## usage

```js
var inherits = require('inherits');
// then use exactly as the standard one
```

## note on version ~1.0

Version ~1.0 had completely different motivation and is not compatible
neither with 2.0 nor with standard node.js `inherits`.

If you are using version ~1.0 and planning to switch to ~2.0, be
careful:

* new version uses `super_` instead of `super` for referencing
  superclass
* new version overwrites current prototype while old one preserves any
  existing fields on it
# dir-glob [![Build Status](https://travis-ci.org/kevva/dir-glob.svg?branch=master)](https://travis-ci.org/kevva/dir-glob)

> Convert directories to glob compatible strings


## Install

```
$ npm install dir-glob
```


## Usage

```js
const dirGlob = require('dir-glob');

(async () => {
	console.log(await dirGlob(['index.js', 'test.js', 'fixtures']));
	//=> ['index.js', 'test.js', 'fixtures/**']

	console.log(await dirGlob(['index.js', 'inner_folder'], {cwd: 'fixtures'}));
	//=> ['index.js', 'inner_folder/**']

	console.log(await dirGlob(['lib/**', 'fixtures'], {
		files: ['test', 'unicorn']
		extensions: ['js']
	}));
	//=> ['lib/**', 'fixtures/**/test.js', 'fixtures/**/unicorn.js']

	console.log(await dirGlob(['lib/**', 'fixtures'], {
		files: ['test', 'unicorn', '*.jsx'],
		extensions: ['js', 'png']
	}));
	//=> ['lib/**', 'fixtures/**/test.{js,png}', 'fixtures/**/unicorn.{js,png}', 'fixtures/**/*.jsx']
})();
```


## API

### dirGlob(input, options?)

Returns a `Promise<string[]>` with globs.

### dirGlob.sync(input, options?)

Returns a `string[]` with globs.

#### input

Type: `string | string[]`

Paths.

#### options

Type: `object`

##### extensions

Type: `string[]`

Append extensions to the end of your globs.

##### files

Type: `string[]`

Only glob for certain files.

##### cwd

Type: `string[]`

Test in specific directory.
A JSON with color names and its values. Based on http://dev.w3.org/csswg/css-color/#named-colors.

[![NPM](https://nodei.co/npm/color-name.png?mini=true)](https://nodei.co/npm/color-name/)


```js
var colors = require('color-name');
colors.red //[255,0,0]
```

<a href="LICENSE"><img src="https://upload.wikimedia.org/wikipedia/commons/0/0c/MIT_logo.svg" width="120"/></a>
# p-locate [![Build Status](https://travis-ci.com/sindresorhus/p-locate.svg?branch=master)](https://travis-ci.com/github/sindresorhus/p-locate)

> Get the first fulfilled promise that satisfies the provided testing function

Think of it like an async version of [`Array#find`](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Array/find).

## Install

```
$ npm install p-locate
```

## Usage

Here we find the first file that exists on disk, in array order.

```js
const pathExists = require('path-exists');
const pLocate = require('p-locate');

const files = [
	'unicorn.png',
	'rainbow.png', // Only this one actually exists on disk
	'pony.png'
];

(async () => {
	const foundPath = await pLocate(files, file => pathExists(file));

	console.log(foundPath);
	//=> 'rainbow'
})();
```

*The above is just an example. Use [`locate-path`](https://github.com/sindresorhus/locate-path) if you need this.*

## API

### pLocate(input, tester, options?)

Returns a `Promise` that is fulfilled when `tester` resolves to `true` or the iterable is done, or rejects if any of the promises reject. The fulfilled value is the current iterable value or `undefined` if `tester` never resolved to `true`.

#### input

Type: `Iterable<Promise | unknown>`

An iterable of promises/values to test.

#### tester(element)

Type: `Function`

This function will receive resolved values from `input` and is expected to return a `Promise<boolean>` or `boolean`.

#### options

Type: `object`

##### concurrency

Type: `number`\
Default: `Infinity`\
Minimum: `1`

Number of concurrently pending promises returned by `tester`.

##### preserveOrder

Type: `boolean`\
Default: `true`

Preserve `input` order when searching.

Disable this to improve performance if you don't care about the order.

## Related

- [p-map](https://github.com/sindresorhus/p-map) - Map over promises concurrently
- [p-filter](https://github.com/sindresorhus/p-filter) - Filter promises concurrently
- [p-any](https://github.com/sindresorhus/p-any) - Wait for any promise to be fulfilled
- [More…](https://github.com/sindresorhus/promise-fun)

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-p-locate?utm_source=npm-p-locate&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
<h1 align="center">
	<img width="250" src="https://jaredwray.com/images/keyv.svg" alt="keyv">
	<br>
	<br>
</h1>

> Simple key-value storage with support for multiple backends

[![build](https://github.com/jaredwray/keyv/actions/workflows/tests.yaml/badge.svg)](https://github.com/jaredwray/keyv/actions/workflows/tests.yaml)
[![codecov](https://codecov.io/gh/jaredwray/keyv/branch/main/graph/badge.svg?token=bRzR3RyOXZ)](https://codecov.io/gh/jaredwray/keyv)
[![npm](https://img.shields.io/npm/dm/keyv.svg)](https://www.npmjs.com/package/keyv)
[![npm](https://img.shields.io/npm/v/keyv.svg)](https://www.npmjs.com/package/keyv)

Keyv provides a consistent interface for key-value storage across multiple backends via storage adapters. It supports TTL based expiry, making it suitable as a cache or a persistent key-value store.

## Features

There are a few existing modules similar to Keyv, however Keyv is different because it:

- Isn't bloated
- Has a simple Promise based API
- Suitable as a TTL based cache or persistent key-value store
- [Easily embeddable](#add-cache-support-to-your-module) inside another module
- Works with any storage that implements the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) API
- Handles all JSON types plus `Buffer`
- Supports namespaces
- Wide range of [**efficient, well tested**](#official-storage-adapters) storage adapters
- Connection errors are passed through (db failures won't kill your app)
- Supports the current active LTS version of Node.js or higher

## Usage

Install Keyv.

```
npm install --save keyv
```

By default everything is stored in memory, you can optionally also install a storage adapter.

```
npm install --save @keyv/redis
npm install --save @keyv/mongo
npm install --save @keyv/sqlite
npm install --save @keyv/postgres
npm install --save @keyv/mysql
npm install --save @keyv/etcd
```

Create a new Keyv instance, passing your connection string if applicable. Keyv will automatically load the correct storage adapter.

```js
const Keyv = require('keyv');

// One of the following
const keyv = new Keyv();
const keyv = new Keyv('redis://user:pass@localhost:6379');
const keyv = new Keyv('mongodb://user:pass@localhost:27017/dbname');
const keyv = new Keyv('sqlite://path/to/database.sqlite');
const keyv = new Keyv('postgresql://user:pass@localhost:5432/dbname');
const keyv = new Keyv('mysql://user:pass@localhost:3306/dbname');
const keyv = new Keyv('etcd://localhost:2379');

// Handle DB connection errors
keyv.on('error', err => console.log('Connection Error', err));

await keyv.set('foo', 'expires in 1 second', 1000); // true
await keyv.set('foo', 'never expires'); // true
await keyv.get('foo'); // 'never expires'
await keyv.delete('foo'); // true
await keyv.clear(); // undefined
```

### Namespaces

You can namespace your Keyv instance to avoid key collisions and allow you to clear only a certain namespace while using the same database.

```js
const users = new Keyv('redis://user:pass@localhost:6379', { namespace: 'users' });
const cache = new Keyv('redis://user:pass@localhost:6379', { namespace: 'cache' });

await users.set('foo', 'users'); // true
await cache.set('foo', 'cache'); // true
await users.get('foo'); // 'users'
await cache.get('foo'); // 'cache'
await users.clear(); // undefined
await users.get('foo'); // undefined
await cache.get('foo'); // 'cache'
```

### Custom Serializers

Keyv uses [`json-buffer`](https://github.com/dominictarr/json-buffer) for data serialization to ensure consistency across different backends.

You can optionally provide your own serialization functions to support extra data types or to serialize to something other than JSON.

```js
const keyv = new Keyv({ serialize: JSON.stringify, deserialize: JSON.parse });
```

**Warning:** Using custom serializers means you lose any guarantee of data consistency. You should do extensive testing with your serialisation functions and chosen storage engine.

## Official Storage Adapters

The official storage adapters are covered by [over 150 integration tests](https://github.com/jaredwray/keyv/actions/workflows/tests.yaml) to guarantee consistent behaviour. They are lightweight, efficient wrappers over the DB clients making use of indexes and native TTLs where available.

Database | Adapter | Native TTL
---|---|---
Redis | [@keyv/redis](https://github.com/jaredwray/keyv/tree/master/packages/redis) | Yes
MongoDB | [@keyv/mongo](https://github.com/jaredwray/keyv/tree/master/packages/mongo) | Yes 
SQLite | [@keyv/sqlite](https://github.com/jaredwray/keyv/tree/master/packages/sqlite) | No 
PostgreSQL | [@keyv/postgres](https://github.com/jaredwray/keyv/tree/master/packages/postgres) | No 
MySQL | [@keyv/mysql](https://github.com/jaredwray/keyv/tree/master/packages/mysql) | No 
Etcd | [@keyv/etcd](https://github.com/jaredwray/keyv/tree/master/packages/etcd) | Yes
Memcache | [@keyv/memcache](https://github.com/jaredwray/keyv/tree/master/packages/memcache) | Yes

## Third-party Storage Adapters

You can also use third-party storage adapters or build your own. Keyv will wrap these storage adapters in TTL functionality and handle complex types internally.

```js
const Keyv = require('keyv');
const myAdapter = require('./my-storage-adapter');

const keyv = new Keyv({ store: myAdapter });
```

Any store that follows the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) api will work.

```js
new Keyv({ store: new Map() });
```

For example, [`quick-lru`](https://github.com/sindresorhus/quick-lru) is a completely unrelated module that implements the Map API.

```js
const Keyv = require('keyv');
const QuickLRU = require('quick-lru');

const lru = new QuickLRU({ maxSize: 1000 });
const keyv = new Keyv({ store: lru });
```

The following are third-party storage adapters compatible with Keyv:

- [quick-lru](https://github.com/sindresorhus/quick-lru) - Simple "Least Recently Used" (LRU) cache
- [keyv-file](https://github.com/zaaack/keyv-file) - File system storage adapter for Keyv
- [keyv-dynamodb](https://www.npmjs.com/package/keyv-dynamodb) - DynamoDB storage adapter for Keyv
- [keyv-lru](https://www.npmjs.com/package/keyv-lru) - LRU storage adapter for Keyv
- [keyv-null](https://www.npmjs.com/package/keyv-null) - Null storage adapter for Keyv
- [keyv-firestore ](https://github.com/goto-bus-stop/keyv-firestore) – Firebase Cloud Firestore adapter for Keyv
- [keyv-mssql](https://github.com/pmorgan3/keyv-mssql) - Microsoft Sql Server adapter for Keyv
- [keyv-azuretable](https://github.com/howlowck/keyv-azuretable) - Azure Table Storage/API adapter for Keyv
- [keyv-arango](https://github.com/TimMikeladze/keyv-arango) - ArangoDB storage adapter for Keyv
- [keyv-momento](https://github.com/momentohq/node-keyv-adaptor/) - Momento storage adapter for Keyv

## Add Cache Support to your Module

Keyv is designed to be easily embedded into other modules to add cache support. The recommended pattern is to expose a `cache` option in your modules options which is passed through to Keyv. Caching will work in memory by default and users have the option to also install a Keyv storage adapter and pass in a connection string, or any other storage that implements the `Map` API.

You should also set a namespace for your module so you can safely call `.clear()` without clearing unrelated app data.

Inside your module:

```js
class AwesomeModule {
	constructor(opts) {
		this.cache = new Keyv({
			uri: typeof opts.cache === 'string' && opts.cache,
			store: typeof opts.cache !== 'string' && opts.cache,
			namespace: 'awesome-module'
		});
	}
}
```

Now it can be consumed like this:

```js
const AwesomeModule = require('awesome-module');

// Caches stuff in memory by default
const awesomeModule = new AwesomeModule();

// After npm install --save keyv-redis
const awesomeModule = new AwesomeModule({ cache: 'redis://localhost' });

// Some third-party module that implements the Map API
const awesomeModule = new AwesomeModule({ cache: some3rdPartyStore });
```

## Compression

Keyv supports `gzip` and `brotli` compression. To enable compression, pass the `compress` option to the constructor.

```js
const KeyvGzip = require('@keyv/compress-gzip');
const Keyv = require('keyv');

const keyvGzip = new KeyvGzip();
const keyv = new Keyv({ compression: KeyvGzip });
```

You can also pass a custom compression function to the `compression` option. Following the pattern of the official compression adapters.

### Want to build your own? 

Great! Keyv is designed to be easily extended. You can build your own compression adapter by following the pattern of the official compression adapters based on this interface:

```typescript
interface CompressionAdapter {
	async compress(value: any, options?: any);
	async decompress(value: any, options?: any);
	async serialize(value: any);
	async deserialize(value: any);
}
```

In addition to the interface, you can test it with our compression test suite using @keyv/test-suite:

```js
const {keyvCompresstionTests} = require('@keyv/test-suite');
const KeyvGzip = require('@keyv/compress-gzip');

keyvCompresstionTests(test, new KeyvGzip());
```

## API

### new Keyv([uri], [options])

Returns a new Keyv instance.

The Keyv instance is also an `EventEmitter` that will emit an `'error'` event if the storage adapter connection fails.

### uri

Type: `String`<br>
Default: `undefined`

The connection string URI.

Merged into the options object as options.uri.

### options

Type: `Object`

The options object is also passed through to the storage adapter. Check your storage adapter docs for any extra options.

#### options.namespace

Type: `String`<br>
Default: `'keyv'`

Namespace for the current instance.

#### options.ttl

Type: `Number`<br>
Default: `undefined`

Default TTL. Can be overridden by specififying a TTL on `.set()`.

#### options.compression

Type: `@keyv/compress-<compression_package_name>`<br>
Default: `undefined`

Compression package to use. See [Compression](#compression) for more details.

#### options.serialize

Type: `Function`<br>
Default: `JSONB.stringify`

A custom serialization function.

#### options.deserialize

Type: `Function`<br>
Default: `JSONB.parse`

A custom deserialization function.

#### options.store

Type: `Storage adapter instance`<br>
Default: `new Map()`

The storage adapter instance to be used by Keyv.

#### options.adapter

Type: `String`<br>
Default: `undefined`

Specify an adapter to use. e.g `'redis'` or `'mongodb'`.

### Instance

Keys must always be strings. Values can be of any type.

#### .set(key, value, [ttl])

Set a value.

By default keys are persistent. You can set an expiry TTL in milliseconds.

Returns a promise which resolves to `true`.

#### .get(key, [options])

Returns a promise which resolves to the retrieved value.

##### options.raw

Type: `Boolean`<br>
Default: `false`

If set to true the raw DB object Keyv stores internally will be returned instead of just the value.

This contains the TTL timestamp.

#### .delete(key)

Deletes an entry.

Returns a promise which resolves to `true` if the key existed, `false` if not.

#### .clear()

Delete all entries in the current namespace.

Returns a promise which is resolved when the entries have been cleared.

#### .iterator()

Iterate over all entries of the current namespace.

Returns a iterable that can be iterated by for-of loops. For example:

```js
// please note that the "await" keyword should be used here
for await (const [key, value] of this.keyv.iterator()) {
  console.log(key, value);
};
```

# How to Contribute

In this section of the documentation we will cover:

1) How to set up this repository locally
2) How to get started with running commands
3) How to contribute changes using Pull Requests

## Dependencies

This package requires the following dependencies to run:

1) [Yarn V1](https://yarnpkg.com/getting-started/install)
3) [Docker](https://docs.docker.com/get-docker/)

## Setting up your workspace

To contribute to this repository, start by setting up this project locally:

1) Fork this repository into your Git account
2) Clone the forked repository to your local directory using `git clone`
3) Install any of the above missing dependencies

## Launching the project

Once the project is installed locally, you are ready to start up its services:

1) Ensure that your Docker service is running.
2) From the root directory of your project, run the `yarn` command in the command prompt to install yarn.
3) Run the `yarn bootstrap` command to  install any necessary dependencies.
4) Run `yarn test:services:start` to start up this project's Docker container. The container will launch all services within your workspace.

## Available Commands

Once the project is running, you can execute a variety of commands. The root workspace and each subpackage contain a `package.json` file with a  `scripts` field listing all the commands that can be executed from that directory. This project also supports native `yarn`, and `docker` commands.

Here, we'll cover the primary commands that can be executed from the root directory. Unless otherwise noted, these commands can also be executed from a subpackage. If executed from a subpackage, they will only affect that subpackage, rather than the entire workspace.

### `yarn`

The `yarn` command installs yarn in the workspace.

### `yarn bootstrap`

The `yarn bootstrap` command installs all dependencies in the workspace.

### `yarn test:services:start`

The `yarn test:services:start` command starts up the project's Docker container, launching all services in the workspace. This command must be executed from the root directory.

### `yarn test:services:stop`

The `yarn test:services:stop` command brings down the project's Docker container, halting all services. This command must be executed from the root directory.

### `yarn test`

The `yarn test` command runs all tests in the workspace.

### `yarn clean`

The `yarn clean` command removes yarn and all dependencies installed by yarn. After executing this command, you must repeat the steps in *Setting up your workspace* to rebuild your workspace.

## Contributing Changes

Now that you've set up your workspace, you're ready to contribute changes to the `keyv` repository.

1) Make any changes that you would like to contribute in your local workspace.
2) After making these changes, ensure that the project's tests still pass by executing the `yarn test` command in the root directory.
3) Commit your changes and push them to your forked repository.
4) Navigate to the original `keyv` repository and go the *Pull Requests* tab.
5) Click the *New pull request* button, and open a pull request for the branch in your repository that contains your changes.
6) Once your pull request is created, ensure that all checks have passed and that your branch has no conflicts with the base branch. If there are any issues, resolve these changes in your local repository, and then commit and push them to git.
7) Similarly, respond to any reviewer comments or requests for changes by making edits to your local repository and pushing them to Git.
8) Once the pull request has been reviewed, those with write access to the branch will be able to merge your changes into the `keyv` repository.

If you need more information on the steps to create a pull request, you can find a detailed walkthrough in the [Github documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork)

## License

MIT © Jared Wray
<h1 align="center">TypeScript-ESTree Types</h1>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/types"><img src="https://img.shields.io/npm/v/@typescript-eslint/types.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/types"><img src="https://img.shields.io/npm/dm/@typescript-eslint/types.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

This package exists to help us reduce cycles and provide lighter-weight packages at runtime.
You probably don't want to use it directly.

If you're building an ESLint plugin, consider using [`@typescript-eslint/utils`](../utils).
If you're parsing TypeScript code, consider using [`@typescript-eslint/typescript-estree`](../typescript-estree).

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
<h1 align="center">TypeScript ESTree</h1>

<p align="center">A parser that converts TypeScript source code into an <a href="https://github.com/estree/estree">ESTree</a>-compatible form</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/typescript-estree"><img src="https://img.shields.io/npm/v/@typescript-eslint/typescript-estree.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/typescript-estree"><img src="https://img.shields.io/npm/dm/@typescript-eslint/typescript-estree.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

## Getting Started

**[You can find our Getting Started docs here](https://typescript-eslint.io/docs/linting)**

## About

This parser is somewhat generic and robust, and could be used to power any use-case which requires taking TypeScript source code and producing an ESTree-compatible AST.

In fact, it is already used within these hyper-popular open-source projects to power their TypeScript support:

- [ESLint](https://eslint.org), the pluggable linting utility for JavaScript and JSX
- [Prettier](https://prettier.io), an opinionated code formatter

## Installation

```sh
yarn add -D @typescript-eslint/typescript-estree
```

## API

### Parsing

#### `parse(code, options)`

Parses the given string of code with the options provided and returns an ESTree-compatible AST.

```ts
interface ParseOptions {
  /**
   * create a top-level comments array containing all comments
   */
  comment?: boolean;

  /**
   * An array of modules to turn explicit debugging on for.
   * - 'typescript-eslint' is the same as setting the env var `DEBUG=typescript-eslint:*`
   * - 'eslint' is the same as setting the env var `DEBUG=eslint:*`
   * - 'typescript' is the same as setting `extendedDiagnostics: true` in your tsconfig compilerOptions
   *
   * For convenience, also supports a boolean:
   * - true === ['typescript-eslint']
   * - false === []
   */
  debugLevel?: boolean | ('typescript-eslint' | 'eslint' | 'typescript')[];

  /**
   * Cause the parser to error if it encounters an unknown AST node type (useful for testing).
   * This case only usually occurs when TypeScript releases new features.
   */
  errorOnUnknownASTType?: boolean;

  /**
   * Absolute (or relative to `cwd`) path to the file being parsed.
   */
  filePath?: string;

  /**
   * Enable parsing of JSX.
   * For more details, see https://www.typescriptlang.org/docs/handbook/jsx.html
   *
   * NOTE: this setting does not effect known file types (.js, .cjs, .mjs, .jsx, .ts, .mts, .cts, .tsx, .json) because the
   * TypeScript compiler has its own internal handling for known file extensions.
   *
   * For the exact behavior, see https://github.com/typescript-eslint/typescript-eslint/tree/main/packages/parser#parseroptionsecmafeaturesjsx
   */
  jsx?: boolean;

  /**
   * Controls whether the `loc` information to each node.
   * The `loc` property is an object which contains the exact line/column the node starts/ends on.
   * This is similar to the `range` property, except it is line/column relative.
   */
  loc?: boolean;

  /*
   * Allows overriding of function used for logging.
   * When value is `false`, no logging will occur.
   * When value is not provided, `console.log()` will be used.
   */
  loggerFn?: Function | false;

  /**
   * Controls whether the `range` property is included on AST nodes.
   * The `range` property is a [number, number] which indicates the start/end index of the node in the file contents.
   * This is similar to the `loc` property, except this is the absolute index.
   */
  range?: boolean;

  /**
   * Set to true to create a top-level array containing all tokens from the file.
   */
  tokens?: boolean;
}

const PARSE_DEFAULT_OPTIONS: ParseOptions = {
  comment: false,
  errorOnUnknownASTType: false,
  filePath: 'estree.ts', // or 'estree.tsx', if you pass jsx: true
  jsx: false,
  loc: false,
  loggerFn: undefined,
  range: false,
  tokens: false,
};

declare function parse(
  code: string,
  options: ParseOptions = PARSE_DEFAULT_OPTIONS,
): TSESTree.Program;
```

Example usage:

```js
import { parse } from '@typescript-eslint/typescript-estree';

const code = `const hello: string = 'world';`;
const ast = parse(code, {
  loc: true,
  range: true,
});
```

#### `parseAndGenerateServices(code, options)`

Parses the given string of code with the options provided and returns an ESTree-compatible AST. Accepts additional options which can be used to generate type information along with the AST.

```ts
interface ParseAndGenerateServicesOptions extends ParseOptions {
  /**
   * Causes the parser to error if the TypeScript compiler returns any unexpected syntax/semantic errors.
   */
  errorOnTypeScriptSyntacticAndSemanticIssues?: boolean;

  /**
   * ***EXPERIMENTAL FLAG*** - Use this at your own risk.
   *
   * Causes TS to use the source files for referenced projects instead of the compiled .d.ts files.
   * This feature is not yet optimized, and is likely to cause OOMs for medium to large projects.
   *
   * This flag REQUIRES at least TS v3.9, otherwise it does nothing.
   *
   * See: https://github.com/typescript-eslint/typescript-eslint/issues/2094
   */
  EXPERIMENTAL_useSourceOfProjectReferenceRedirect?: boolean;

  /**
   * When `project` is provided, this controls the non-standard file extensions which will be parsed.
   * It accepts an array of file extensions, each preceded by a `.`.
   */
  extraFileExtensions?: string[];

  /**
   * Absolute (or relative to `tsconfigRootDir`) path to the file being parsed.
   * When `project` is provided, this is required, as it is used to fetch the file from the TypeScript compiler's cache.
   */
  filePath?: string;

  /**
   * Allows the user to control whether or not two-way AST node maps are preserved
   * during the AST conversion process.
   *
   * By default: the AST node maps are NOT preserved, unless `project` has been specified,
   * in which case the maps are made available on the returned `parserServices`.
   *
   * NOTE: If `preserveNodeMaps` is explicitly set by the user, it will be respected,
   * regardless of whether or not `project` is in use.
   */
  preserveNodeMaps?: boolean;

  /**
   * Absolute (or relative to `tsconfigRootDir`) paths to the tsconfig(s).
   * If this is provided, type information will be returned.
   */
  project?: string | string[];

  /**
   * If you provide a glob (or globs) to the project option, you can use this option to ignore certain folders from
   * being matched by the globs.
   * This accepts an array of globs to ignore.
   *
   * By default, this is set to ["/node_modules/"]
   */
  projectFolderIgnoreList?: string[];

  /**
   * The absolute path to the root directory for all provided `project`s.
   */
  tsconfigRootDir?: string;

  /**
   * An array of one or more instances of TypeScript Program objects to be used for type information.
   * This overrides any program or programs that would have been computed from the `project` option.
   * All linted files must be part of the provided program(s).
   */
  programs?: Program[];

  /**
   ***************************************************************************************
   * IT IS RECOMMENDED THAT YOU DO NOT USE THIS OPTION, AS IT CAUSES PERFORMANCE ISSUES. *
   ***************************************************************************************
   *
   * When passed with `project`, this allows the parser to create a catch-all, default program.
   * This means that if the parser encounters a file not included in any of the provided `project`s,
   * it will not error, but will instead parse the file and its dependencies in a new program.
   */
  createDefaultProgram?: boolean;

  /**
   * ESLint (and therefore typescript-eslint) is used in both "single run"/one-time contexts,
   * such as an ESLint CLI invocation, and long-running sessions (such as continuous feedback
   * on a file in an IDE).
   *
   * When typescript-eslint handles TypeScript Program management behind the scenes, this distinction
   * is important because there is significant overhead to managing the so called Watch Programs
   * needed for the long-running use-case.
   *
   * When allowAutomaticSingleRunInference is enabled, we will use common heuristics to infer
   * whether or not ESLint is being used as part of a single run.
   */
  allowAutomaticSingleRunInference?: boolean;

  /**
   * Path to a file exporting a custom ModuleResolver.
   */
  moduleResolver?: string;
}

interface ParserServices {
  program: ts.Program;
  esTreeNodeToTSNodeMap: WeakMap<TSESTree.Node, ts.Node | ts.Token>;
  tsNodeToESTreeNodeMap: WeakMap<ts.Node | ts.Token, TSESTree.Node>;
  hasFullTypeInformation: boolean;
}

interface ParseAndGenerateServicesResult<T extends TSESTreeOptions> {
  ast: TSESTree.Program;
  services: ParserServices;
}

const PARSE_AND_GENERATE_SERVICES_DEFAULT_OPTIONS: ParseOptions = {
  ...PARSE_DEFAULT_OPTIONS,
  errorOnTypeScriptSyntacticAndSemanticIssues: false,
  extraFileExtensions: [],
  preserveNodeMaps: false, // or true, if you do not set this, but pass `project`
  project: undefined,
  projectFolderIgnoreList: ['/node_modules/'],
  tsconfigRootDir: process.cwd(),
};

declare function parseAndGenerateServices(
  code: string,
  options: ParseOptions = PARSE_DEFAULT_OPTIONS,
): ParseAndGenerateServicesResult;
```

Example usage:

```js
import { parseAndGenerateServices } from '@typescript-eslint/typescript-estree';

const code = `const hello: string = 'world';`;
const { ast, services } = parseAndGenerateServices(code, {
  filePath: '/some/path/to/file/foo.ts',
  loc: true,
  project: './tsconfig.json',
  range: true,
});
```

#### `parseWithNodeMaps(code, options)`

Parses the given string of code with the options provided and returns both the ESTree-compatible AST as well as the node maps.
This allows you to work with both ASTs without the overhead of types that may come with `parseAndGenerateServices`.

```ts
interface ParseWithNodeMapsResult<T extends TSESTreeOptions> {
  ast: TSESTree.Program;
  esTreeNodeToTSNodeMap: ParserServices['esTreeNodeToTSNodeMap'];
  tsNodeToESTreeNodeMap: ParserServices['tsNodeToESTreeNodeMap'];
}

declare function parseWithNodeMaps(
  code: string,
  options: ParseOptions = PARSE_DEFAULT_OPTIONS,
): ParseWithNodeMapsResult;
```

Example usage:

```js
import { parseWithNodeMaps } from '@typescript-eslint/typescript-estree';

const code = `const hello: string = 'world';`;
const { ast, esTreeNodeToTSNodeMap, tsNodeToESTreeNodeMap } = parseWithNodeMaps(
  code,
  {
    loc: true,
    range: true,
  },
);
```

### `TSESTree`, `AST_NODE_TYPES` and `AST_TOKEN_TYPES`

Types for the AST produced by the parse functions.

- `TSESTree` is a namespace which contains object types representing all of the AST Nodes produced by the parser.
- `AST_NODE_TYPES` is an enum which provides the values for every single AST node's `type` property.
- `AST_TOKEN_TYPES` is an enum which provides the values for every single AST token's `type` property.

### Utilities

#### `createProgram(configFile, projectDirectory)`

This serves as a utility method for users of the `ParseOptions.programs` feature to create a TypeScript program instance from a config file.

```ts
declare function createProgram(
  configFile: string,
  projectDirectory: string = process.cwd(),
): import('typescript').Program;
```

Example usage:

```js
const tsESTree = require('@typescript-eslint/typescript-estree');

const program = tsESTree.createProgram('tsconfig.json');
const code = `const hello: string = 'world';`;
const { ast, services } = parseAndGenerateServices(code, {
  filePath: '/some/path/to/file/foo.ts',
  loc: true,
  program,
  range: true,
});
```

## Supported TypeScript Version

See the [Supported TypeScript Version](../../README.md#supported-typescript-version) section in the project root.

If you use a non-supported version of TypeScript, the parser will log a warning to the console.

**Please ensure that you are using a supported version before submitting any issues/bug reports.**

## Reporting Issues

Please check the current list of open and known issues and ensure the issue has not been reported before. When creating a new issue provide as much information about your environment as possible. This includes:

- TypeScript version
- The `typescript-estree` version

## AST Alignment Tests

A couple of years after work on this parser began, the TypeScript Team at Microsoft began [officially supporting TypeScript parsing via Babel](https://blogs.msdn.microsoft.com/typescript/2018/08/27/typescript-and-babel-7/).

I work closely with the TypeScript Team and we are gradually aligning the AST of this project with the one produced by Babel's parser. To that end, I have created a full test harness to compare the ASTs of the two projects which runs on every PR, please see [the code](https://github.com/typescript-eslint/typescript-eslint/tree/main/packages/typescript-estree/tests/ast-alignment) for more details.

## Debugging

If you encounter a bug with the parser that you want to investigate, you can turn on the debug logging via setting the environment variable: `DEBUG=typescript-eslint:*`.
I.e. in this repo you can run: `DEBUG=typescript-eslint:* yarn lint`.

## License

TypeScript ESTree inherits from the the original TypeScript ESLint Parser license, as the majority of the work began there. It is licensed under a permissive BSD 2-clause license.

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
<h1 align="center">Utils for ESLint Plugins</h1>

<p align="center">Utilities for working with TypeScript + ESLint together.</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/utils"><img src="https://img.shields.io/npm/v/@typescript-eslint/utils.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/utils"><img src="https://img.shields.io/npm/dm/@typescript-eslint/utils.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

## Exports

| Name                                                           | Description                                                                                                                                                                                                                       |
| -------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [`ASTUtils`](./src/ast-utils)                                  | Tools for operating on the ESTree AST. Also includes the [`eslint-utils`](https://www.npmjs.com/package/eslint-utils) package, correctly typed to work with the types found in `TSESTree`                                         |
| [`ESLintUtils`](./src/eslint-utils)                            | Tools for creating ESLint rules with TypeScript.                                                                                                                                                                                  |
| `JSONSchema`                                                   | Types from the [`@types/json-schema`](https://www.npmjs.com/package/@types/json-schema) package, re-exported to save you having to manually import them. Also ensures you're using the same version of the types as this package. |
| [`TSESLint`](./src/ts-eslint)                                  | Types for ESLint, correctly typed to work with the types found in `TSESTree`.                                                                                                                                                     |
| [`TSESLintScope`](./src/ts-eslint-scope)                       | The [`eslint-scope`](https://www.npmjs.com/package/eslint-scope) package, correctly typed to work with the types found in both `TSESTree` and `TSESLint`                                                                          |
| [`TSESTree`](../types/src/ts-estree.ts)                        | Types for the TypeScript flavor of ESTree created by `@typescript-eslint/typescript-estree`.                                                                                                                                      |
| [`AST_NODE_TYPES`](../types/src/ast-node-types.ts)             | An enum with the names of every single _node_ found in `TSESTree`.                                                                                                                                                                |
| [`AST_TOKEN_TYPES`](../types/src/ast-token-types.ts)           | An enum with the names of every single _token_ found in `TSESTree`.                                                                                                                                                               |
| [`ParserServices`](../typescript-estree/src/parser-options.ts) | Typing for the parser services provided when parsing a file using `@typescript-eslint/typescript-estree`.                                                                                                                         |

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
<h1 align="center">TypeScript ESLint Parser</h1>

<p align="center">An ESLint parser which leverages <a href="https://github.com/typescript-eslint/typescript-eslint/tree/main/packages/typescript-estree">TypeScript ESTree</a> to allow for ESLint to lint TypeScript source code.</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/parser"><img src="https://img.shields.io/npm/v/@typescript-eslint/parser.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/parser"><img src="https://img.shields.io/npm/dm/@typescript-eslint/parser.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

## Getting Started

**[You can find our Getting Started docs here](https://typescript-eslint.io/docs/linting)**

These docs walk you through setting up ESLint, this parser, and our plugin. If you know what you're doing and just want to quick start, read on...

## Quick-start

### Installation

```bash
$ yarn add -D typescript @typescript-eslint/parser
$ npm i --save-dev typescript @typescript-eslint/parser
```

### Usage

In your ESLint configuration file, set the `parser` property:

```json
{
  "parser": "@typescript-eslint/parser"
}
```

There is sometimes an incorrect assumption that the parser itself is what does everything necessary to facilitate the use of ESLint with TypeScript. In actuality, it is the combination of the parser _and_ one or more plugins which allow you to maximize your usage of ESLint with TypeScript.

For example, once this parser successfully produces an AST for the TypeScript source code, it might well contain some information which simply does not exist in a standard JavaScript context, such as the data for a TypeScript-specific construct, like an `interface`.

The core rules built into ESLint, such as `indent` have no knowledge of such constructs, so it is impossible to expect them to work out of the box with them.

Instead, you also need to make use of one more plugins which will add or extend rules with TypeScript-specific features.

By far the most common case will be installing the [`@typescript-eslint/eslint-plugin`](https://github.com/typescript-eslint/typescript-eslint/tree/main/packages/eslint-plugin) plugin, but there are also other relevant options available such a [`@typescript-eslint/eslint-plugin-tslint`](https://github.com/typescript-eslint/typescript-eslint/tree/main/packages/eslint-plugin-tslint).

## Configuration

The following additional configuration options are available by specifying them in [`parserOptions`](https://eslint.org/docs/user-guide/configuring/language-options#specifying-parser-options) in your ESLint configuration file.

```ts
interface ParserOptions {
  ecmaFeatures?: {
    jsx?: boolean;
    globalReturn?: boolean;
  };
  ecmaVersion?: number | 'latest';

  jsxPragma?: string | null;
  jsxFragmentName?: string | null;
  lib?: string[];

  project?: string | string[];
  projectFolderIgnoreList?: string[];
  tsconfigRootDir?: string;
  extraFileExtensions?: string[];
  warnOnUnsupportedTypeScriptVersion?: boolean;

  program?: import('typescript').Program;
  moduleResolver?: string;

  emitDecoratorMetadata?: boolean;
}
```

### `parserOptions.ecmaFeatures.jsx`

Default `false`.

Enable parsing JSX when `true`. More details can be found [here](https://www.typescriptlang.org/docs/handbook/jsx.html).

**NOTE:** this setting does not affect known file types (`.js`, `.mjs`, `.cjs`, `.jsx`, `.ts`, `.mts`, `.cts`, `.tsx`, `.json`) because the TypeScript compiler has its own internal handling for known file extensions.

<!-- https://github.com/microsoft/TypeScript/blob/d6e483b8dabd8fd37c00954c3f2184bb7f1eb90c/src/compiler/utilities.ts#L6281-L6285 -->

The exact behavior is as follows:

- `.js`, `.mjs`, `.cjs`, `.jsx`, `.tsx` files are always parsed as if this is `true`.
- `.ts`, `.mts`, `.cts` files are always parsed as if this is `false`.
- For "unknown" extensions (`.md`, `.vue`):
  - If `parserOptions.project` is _not_ provided:
    - The setting will be respected.
  - If `parserOptions.project` is provided (i.e. you are using rules with type information):
    - **always parsed as if this is `false`**

### `parserOptions.ecmaFeatures.globalReturn`

Default `false`.

This options allows you to tell the parser if you want to allow global `return` statements in your codebase.

### `parserOptions.ecmaVersion`

Default `2018`.

Accepts any valid ECMAScript version number or `'latest'`:

- A version: es3, es5, es6, es7, es8, es9, es10, es11, es12, es13, ..., or
- A year: es2015, es2016, es2017, es2018, es2019, es2020, es2021, es2022, ..., or
- `'latest'`

When it's a version or a year, the value **must** be a number - so do not include the `es` prefix.

Specifies the version of ECMAScript syntax you want to use. This is used by the parser to determine how to perform scope analysis, and it affects the default

### `parserOptions.jsxPragma`

Default `'React'`

The identifier that's used for JSX Elements creation (after transpilation).
If you're using a library other than React (like `preact`), then you should change this value. If you are using the [new JSX transform](https://reactjs.org/blog/2020/09/22/introducing-the-new-jsx-transform.html) you can set this to `null`.

This should not be a member expression - just the root identifier (i.e. use `"React"` instead of `"React.createElement"`).

If you provide `parserOptions.project`, you do not need to set this, as it will automatically detected from the compiler.

### `parserOptions.jsxFragmentName`

Default `null`

The identifier that's used for JSX fragment elements (after transpilation).
If `null`, assumes transpilation will always use a member of the configured `jsxPragma`.
This should not be a member expression - just the root identifier (i.e. use `"h"` instead of `"h.Fragment"`).

If you provide `parserOptions.project`, you do not need to set this, as it will automatically detected from the compiler.

### `parserOptions.lib`

Default `['es2018']`

For valid options, see the [TypeScript compiler options](https://www.typescriptlang.org/tsconfig#lib).

Specifies the TypeScript `lib`s that are available. This is used by the scope analyser to ensure there are global variables declared for the types exposed by TypeScript.

If you provide `parserOptions.project`, you do not need to set this, as it will automatically detected from the compiler.

### `parserOptions.project`

Default `undefined`.

This option allows you to provide a path to your project's `tsconfig.json`. **This setting is required if you want to use rules which require type information**. Relative paths are interpreted relative to the current working directory if `tsconfigRootDir` is not set. If you intend on running ESLint from directories other than the project root, you should consider using `tsconfigRootDir`.

- Accepted values:

  ```js
  // path
  project: './tsconfig.json';

  // glob pattern
  project: './packages/**/tsconfig.json';

  // array of paths and/or glob patterns
  project: ['./packages/**/tsconfig.json', './separate-package/tsconfig.json'];
  ```

- If you use project references, TypeScript will not automatically use project references to resolve files. This means that you will have to add each referenced tsconfig to the `project` field either separately, or via a glob.

- TypeScript will ignore files with duplicate filenames in the same folder (for example, `src/file.ts` and `src/file.js`). TypeScript purposely ignore all but one of the files, only keeping the one file with the highest priority extension (the extension priority order (from highest to lowest) is `.ts`, `.tsx`, `.d.ts`, `.js`, `.jsx`). For more info see #955.

- Note that if this setting is specified and `createDefaultProgram` is not, you must only lint files that are included in the projects as defined by the provided `tsconfig.json` files. If your existing configuration does not include all of the files you would like to lint, you can create a separate `tsconfig.eslint.json` as follows:

  ```jsonc
  {
    // extend your base config so you don't have to redefine your compilerOptions
    "extends": "./tsconfig.json",
    "include": [
      "src/**/*.ts",
      "test/**/*.ts",
      "typings/**/*.ts",
      // etc

      // if you have a mixed JS/TS codebase, don't forget to include your JS files
      "src/**/*.js"
    ]
  }
  ```

### `parserOptions.tsconfigRootDir`

Default `undefined`.

This option allows you to provide the root directory for relative tsconfig paths specified in the `project` option above.

### `parserOptions.projectFolderIgnoreList`

Default `["**/node_modules/**"]`.

This option allows you to ignore folders from being included in your provided list of `project`s.
This is useful if you have configured glob patterns, but want to make sure you ignore certain folders.

It accepts an array of globs to exclude from the `project` globs.

For example, by default it will ensure that a glob like `./**/tsconfig.json` will not match any `tsconfig`s within your `node_modules` folder (some npm packages do not exclude their source files from their published packages).

### `parserOptions.extraFileExtensions`

Default `undefined`.

This option allows you to provide one or more additional file extensions which should be considered in the TypeScript Program compilation.
The default extensions are `['.js', '.mjs', '.cjs', '.jsx', '.ts', '.mts', '.cts', '.tsx']`.
Add extensions starting with `.`, followed by the file extension. E.g. for a `.vue` file use `"extraFileExtensions": [".vue"]`.

### `parserOptions.warnOnUnsupportedTypeScriptVersion`

Default `true`.

This option allows you to toggle the warning that the parser will give you if you use a version of TypeScript which is not explicitly supported

### `parserOptions.createDefaultProgram`

Default `false`.

This option allows you to request that when the `project` setting is specified, files will be allowed when not included in the projects defined by the provided `tsconfig.json` files. **Using this option will incur significant performance costs. This option is primarily included for backwards-compatibility.** See the **`project`** section above for more information.

### `parserOptions.programs`

Default `undefined`.

This option allows you to programmatically provide an array of one or more instances of a TypeScript Program object that will provide type information to rules.
This will override any programs that would have been computed from `parserOptions.project` or `parserOptions.createDefaultProgram`.
All linted files must be part of the provided program(s).

### `parserOptions.moduleResolver`

Default `undefined`.

This option allows you to provide a custom module resolution. The value should point to a JS file that default exports (`export default`, or `module.exports =`, or `export =`) a file with the following interface:

```ts
interface ModuleResolver {
  version: 1;
  resolveModuleNames(
    moduleNames: string[],
    containingFile: string,
    reusedNames: string[] | undefined,
    redirectedReference: ts.ResolvedProjectReference | undefined,
    options: ts.CompilerOptions,
  ): (ts.ResolvedModule | undefined)[];
}
```

[Refer to the TypeScript Wiki for an example on how to write the `resolveModuleNames` function](https://github.com/Microsoft/TypeScript/wiki/Using-the-Compiler-API#customizing-module-resolution).

Note that if you pass custom programs via `options.programs` this option will not have any effect over them (you can simply add the custom resolution on them directly).

### `parserOptions.emitDecoratorMetadata`

Default `undefined`.

This option allow you to tell parser to act as if `emitDecoratorMetadata: true` is set in `tsconfig.json`, but without [type-aware linting](https://typescript-eslint.io/docs/linting/type-linting). In other words, you don't have to specify `parserOptions.project` in this case, making the linting process faster.

## Utilities

### `createProgram(configFile, projectDirectory)`

This serves as a utility method for users of the `parserOptions.programs` feature to create a TypeScript program instance from a config file.

```ts
declare function createProgram(
  configFile: string,
  projectDirectory?: string,
): import('typescript').Program;
```

Example usage in .eslintrc.js:

```js
const parser = require('@typescript-eslint/parser');
const programs = [parser.createProgram('tsconfig.json')];
module.exports = {
  parserOptions: {
    programs,
  },
};
```

## Supported TypeScript Version

Please see [`typescript-eslint`](https://github.com/typescript-eslint/typescript-eslint) for the supported TypeScript version.

**Please ensure that you are using a supported version before submitting any issues/bug reports.**

## Reporting Issues

Please use the `@typescript-eslint/parser` issue template when creating your issue and fill out the information requested as best you can. This will really help us when looking into your issue.

## License

TypeScript ESLint Parser is licensed under a permissive BSD 2-clause license.

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
<h1 align="center">Type utils for ESLint Plugins</h1>

<p align="center">Type utilities for working with TypeScript within ESLint rules.</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/type-utils"><img src="https://img.shields.io/npm/v/@typescript-eslint/type-utils.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/type-utils"><img src="https://img.shields.io/npm/dm/@typescript-eslint/type-utils.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

This utilities in this package are separated from `@typescript-eslint/utils` so that that package does not require a dependency on `typescript`.

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
<h1 align="center">TypeScript Scope Manager</h1>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/scope-manager"><img src="https://img.shields.io/npm/v/@typescript-eslint/scope-manager.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/scope-manager"><img src="https://img.shields.io/npm/dm/@typescript-eslint/scope-manager.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

This is a fork of [`eslint-scope`](https://github.com/eslint/eslint-scope), enhanced to support TypeScript functionality.
[You can view the original license for the code here](https://github.com/eslint/eslint-scope/blob/dbddf14d5771b21b5da704213e4508c660ca1c64/LICENSE).

This package is consumed automatically by [`@typescript-eslint/parser`](../parser).
You probably don't want to use it directly.

## Getting Started

**[You can find our Getting Started docs here](https://typescript-eslint.io/docs/linting)**

## Installation

```bash
$ yarn add -D typescript @typescript-eslint/scope-manager
$ npm i --save-dev typescript @typescript-eslint/scope-manager
```

## API

### `analyze(tree, options)`

Analyses a given AST and returns the resulting `ScopeManager`.

```ts
interface AnalyzeOptions {
  /**
   * Known visitor keys.
   */
  childVisitorKeys?: Record<string, string[]> | null;

  /**
   * Which ECMAScript version is considered.
   * Defaults to `2018`.
   * `'latest'` is converted to 1e8 at parser.
   */
  ecmaVersion?: EcmaVersion | 1e8;

  /**
   * Whether the whole script is executed under node.js environment.
   * When enabled, the scope manager adds a function scope immediately following the global scope.
   * Defaults to `false`.
   */
  globalReturn?: boolean;

  /**
   * Implied strict mode (if ecmaVersion >= 5).
   * Defaults to `false`.
   */
  impliedStrict?: boolean;

  /**
   * The identifier that's used for JSX Element creation (after transpilation).
   * This should not be a member expression - just the root identifier (i.e. use "React" instead of "React.createElement").
   * Defaults to `"React"`.
   */
  jsxPragma?: string;

  /**
   * The identifier that's used for JSX fragment elements (after transpilation).
   * If `null`, assumes transpilation will always use a member on `jsxFactory` (i.e. React.Fragment).
   * This should not be a member expression - just the root identifier (i.e. use "h" instead of "h.Fragment").
   * Defaults to `null`.
   */
  jsxFragmentName?: string | null;

  /**
   * The lib used by the project.
   * This automatically defines a type variable for any types provided by the configured TS libs.
   * For more information, see https://www.typescriptlang.org/tsconfig#lib
   *
   * Defaults to the lib for the provided `ecmaVersion`.
   */
  lib?: Lib[];

  /**
   * The source type of the script.
   */
  sourceType?: 'script' | 'module';

  /**
   * Emit design-type metadata for decorated declarations in source.
   * Defaults to `false`.
   */
  emitDecoratorMetadata?: boolean;
}
```

Example usage:

```ts
import { analyze } from '@typescript-eslint/scope-manager';
import { parse } from '@typescript-eslint/typescript-estree';

const code = `const hello: string = 'world';`;
const ast = parse(code, {
  // note that scope-manager requires ranges on the AST
  range: true,
});
const scope = analyze(ast, {
  ecmaVersion: 2020,
  sourceType: 'module',
});
```

## References

- https://eslint.org/docs/developer-guide/scope-manager-interface
- https://github.com/eslint/eslint-scope

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
# `comma-spacing`

Enforces consistent spacing before and after commas.

## Rule Details

This rule extends the base [`eslint/comma-spacing`](https://eslint.org/docs/rules/comma-spacing) rule.
It adds support for trailing comma in a types parameters list.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "comma-spacing": "off",
  "@typescript-eslint/comma-spacing": ["error"]
}
```

## Options

See [`eslint/comma-spacing` options](https://eslint.org/docs/rules/comma-spacing#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/comma-spacing.md)

</sup>
# `no-floating-promises`

Requires Promise-like statements to be handled appropriately.

A "floating" Promise is one that is created without any code set up to handle any errors it might throw.

Floating Promises can cause several issues, such as improperly sequenced operations, ignored Promise rejections, and more.

Valid ways of handling a Promise-valued statement include:

- `await`ing it
- `return`ing it
- Calling its `.then()` with two arguments
- Calling its `.catch()` with one argument

:::tip
`no-floating-promises` only detects unhandled Promise _statements_.
See [`no-misused-promises`](./no-misused-promises.md) for detecting code that provides Promises to _logical_ locations such as if statements.
:::

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const promise = new Promise((resolve, reject) => resolve('value'));
promise;

async function returnsPromise() {
  return 'value';
}
returnsPromise().then(() => {});

Promise.reject('value').catch();

Promise.reject('value').finally();
```

### ✅ Correct

```ts
const promise = new Promise((resolve, reject) => resolve('value'));
await promise;

async function returnsPromise() {
  return 'value';
}
returnsPromise().then(
  () => {},
  () => {},
);

Promise.reject('value').catch(() => {});

Promise.reject('value').finally(() => {});
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if true, checking void expressions will be skipped
  ignoreVoid?: boolean;
  // if true, checking for async iife will be skipped
  ignoreIIFE?: boolean;
};

const defaults = {
  ignoreVoid: true,
  ignoreIIFE: false,
};
```

### `ignoreVoid`

This allows you to stop the rule reporting promises consumed with void operator.
This can be a good way to explicitly mark a promise as intentionally not awaited.

Examples of **correct** code for this rule with `{ ignoreVoid: true }`:

```ts
async function returnsPromise() {
  return 'value';
}
void returnsPromise();

void Promise.reject('value');
```

With this option set to `true`, and if you are using `no-void`, you should turn on the [`allowAsStatement`](https://eslint.org/docs/rules/no-void#allowasstatement) option.

### `ignoreIIFE`

This allows you to skip checking of async IIFEs (Immediately Invocated function Expressions).

Examples of **correct** code for this rule with `{ ignoreIIFE: true }`:

```ts
await(async function () {
  await res(1);
})();

(async function () {
  await res(1);
})();
```

## When Not To Use It

If you do not use Promise-like values in your codebase, or want to allow them to remain unhandled.

## Related To

- [`no-misused-promises`](./no-misused-promises.md)
# `no-require-imports`

Disallows invocation of `require()`.

Prefer the newer ES6-style imports over `require()`.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
var lib = require('lib');
let lib2 = require('lib2');
var lib5 = require('lib5'),
  lib6 = require('lib6');
import lib8 = require('lib8');
```

### ✅ Correct

```ts
import { l } from 'lib';
var lib3 = load('not_an_import');
var lib4 = lib2.subImport;
var lib7 = 700;
import lib9 = lib2.anotherSubImport;
import lib10 from 'lib10';
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-require-imports": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about TypeScript module syntax, then you will not need this rule.
# `prefer-enum-initializers`

Requires each enum member value to be explicitly initialized.

This rule recommends having each `enum`s member value explicitly initialized.

`enum`s are a practical way to organize semantically related constant values. However, by implicitly defining values, `enum`s can lead to unexpected bugs if it's modified without paying attention to the order of its items.

## Rule Details

`enum`s infers sequential numbers automatically when initializers are omitted:

```ts
enum Status {
  Open, // infer 0
  Closed, // infer 1
}
```

If a new member is added to the top of `Status`, both `Open` and `Closed` would have its values altered:

```ts
enum Status {
  Pending, // infer 0
  Open, // infer 1
  Closed, // infer 2
}
```

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
enum Status {
  Open = 1,
  Close,
}

enum Direction {
  Up,
  Down,
}

enum Color {
  Red,
  Green = 'Green'
  Blue = 'Blue',
}
```

### ✅ Correct

```ts
enum Status {
  Open = 'Open',
  Close = 'Close',
}

enum Direction {
  Up = 1,
  Down = 2,
}

enum Color {
  Red = 'Red',
  Green = 'Green',
  Blue = 'Blue',
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-enum-initializers": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about `enum`s having implicit values you can safely disable this rule.
# `promise-function-async`

Requires any function or method that returns a Promise to be marked async.

Ensures that each function is only capable of:

- returning a rejected promise, or
- throwing an Error object.

In contrast, non-`async` `Promise` - returning functions are technically capable of either.
Code that handles the results of those functions will often need to handle both cases, which can get complex.
This rule's practice removes a requirement for creating code to handle both cases.

## Rule Details

Examples of code for this rule

<!--tabs-->

### ❌ Incorrect

```ts
const arrowFunctionReturnsPromise = () => Promise.resolve('value');

function functionReturnsPromise() {
  return Promise.resolve('value');
}
```

### ✅ Correct

```ts
const arrowFunctionReturnsPromise = async () => Promise.resolve('value');

async function functionReturnsPromise() {
  return Promise.resolve('value');
}
```

## Options

Options may be provided as an object with:

- `allowAny` to indicate that `any` or `unknown` shouldn't be considered Promises (`true` by default).
- `allowedPromiseNames` to indicate any extra names of classes or interfaces to be considered Promises when returned.

In addition, each of the following properties may be provided, and default to `true`:

- `checkArrowFunctions`
- `checkFunctionDeclarations`
- `checkFunctionExpressions`
- `checkMethodDeclarations`

```json
{
  "@typescript-eslint/promise-function-async": [
    "error",
    {
      "allowedPromiseNames": ["Thenable"],
      "checkArrowFunctions": true,
      "checkFunctionDeclarations": true,
      "checkFunctionExpressions": true,
      "checkMethodDeclarations": true
    }
  ]
}
```
# `array-type`

Requires using either `T[]` or `Array<T>` for arrays.

Using the same style for array definitions across your codebase makes it easier for your developers to read and understand the types.

## Rule Details

This rule aims to standardize usage of array types within your codebase.

## Options

```ts
type ArrayOption = 'array' | 'generic' | 'array-simple';
type Options = {
  default: ArrayOption;
  readonly?: ArrayOption;
};

const defaultOptions: Options = {
  default: 'array',
};
```

The rule accepts an options object with the following properties:

- `default` - sets the array type expected for mutable cases.
- `readonly` - sets the array type expected for readonly arrays. If this is omitted, then the value for `default` will be used.

Each property can be set to one of three strings: `'array' | 'generic' | 'array-simple'`.

The default config will enforce that all mutable and readonly arrays use the `'array'` syntax.

### `"array"`

Always use `T[]` or `readonly T[]` for all array types.

<!--tabs-->

#### ❌ Incorrect

```ts
const x: Array<string> = ['a', 'b'];
const y: ReadonlyArray<string> = ['a', 'b'];
```

#### ✅ Correct

```ts
const x: string[] = ['a', 'b'];
const y: readonly string[] = ['a', 'b'];
```

### `"generic"`

Always use `Array<T>` or `ReadonlyArray<T>` for all array types.

<!--tabs-->

#### ❌ Incorrect

```ts
const x: string[] = ['a', 'b'];
const y: readonly string[] = ['a', 'b'];
```

#### ✅ Correct

```ts
const x: Array<string> = ['a', 'b'];
const y: ReadonlyArray<string> = ['a', 'b'];
```

### `"array-simple"`

Use `T[]` or `readonly T[]` for simple types (i.e. types which are just primitive names or type references).
Use `Array<T>` or `ReadonlyArray<T>` for all other types (union types, intersection types, object types, function types, etc).

<!--tabs-->

#### ❌ Incorrect

```ts
const a: (string | number)[] = ['a', 'b'];
const b: { prop: string }[] = [{ prop: 'a' }];
const c: (() => void)[] = [() => {}];
const d: Array<MyType> = ['a', 'b'];
const e: Array<string> = ['a', 'b'];
const f: ReadonlyArray<string> = ['a', 'b'];
```

#### ✅ Correct

```ts
const a: Array<string | number> = ['a', 'b'];
const b: Array<{ prop: string }> = [{ prop: 'a' }];
const c: Array<() => void> = [() => {}];
const d: MyType[] = ['a', 'b'];
const e: string[] = ['a', 'b'];
const f: readonly string[] = ['a', 'b'];
```

## Combination Matrix

This matrix lists all possible option combinations and their expected results for different types of Arrays.

| defaultOption  | readonlyOption | Array with simple type | Array with non simple type | Readonly array with simple type | Readonly array with non simple type |
| -------------- | -------------- | ---------------------- | -------------------------- | ------------------------------- | ----------------------------------- |
| `array`        |                | `number[]`             | `(Foo & Bar)[]`            | `readonly number[]`             | `readonly (Foo & Bar)[]`            |
| `array`        | `array`        | `number[]`             | `(Foo & Bar)[]`            | `readonly number[]`             | `readonly (Foo & Bar)[]`            |
| `array`        | `array-simple` | `number[]`             | `(Foo & Bar)[]`            | `readonly number[]`             | `ReadonlyArray<Foo & Bar>`          |
| `array`        | `generic`      | `number[]`             | `(Foo & Bar)[]`            | `ReadonlyArray<number>`         | `ReadonlyArray<Foo & Bar>`          |
| `array-simple` |                | `number[]`             | `Array<Foo & Bar>`         | `readonly number[]`             | `ReadonlyArray<Foo & Bar>`          |
| `array-simple` | `array`        | `number[]`             | `Array<Foo & Bar>`         | `readonly number[]`             | `readonly (Foo & Bar)[]`            |
| `array-simple` | `array-simple` | `number[]`             | `Array<Foo & Bar>`         | `readonly number[]`             | `ReadonlyArray<Foo & Bar>`          |
| `array-simple` | `generic`      | `number[]`             | `Array<Foo & Bar>`         | `ReadonlyArray<number>`         | `ReadonlyArray<Foo & Bar>`          |
| `generic`      |                | `Array<number>`        | `Array<Foo & Bar>`         | `ReadonlyArray<number>`         | `ReadonlyArray<Foo & Bar>`          |
| `generic`      | `array`        | `Array<number>`        | `Array<Foo & Bar>`         | `readonly number[]`             | `readonly (Foo & Bar)[]`            |
| `generic`      | `array-simple` | `Array<number>`        | `Array<Foo & Bar>`         | `readonly number[]`             | `ReadonlyArray<Foo & Bar>`          |
| `generic`      | `generic`      | `Array<number>`        | `Array<Foo & Bar>`         | `ReadonlyArray<number>`         | `ReadonlyArray<Foo & Bar>`          |
# `no-parameter-properties`

Disallows the use of parameter properties in class constructors.

Parameter properties can be confusing to those new to TypeScript as they are less explicit than other ways
of declaring and initializing class members.

## Rule Details

This rule disallows the use of parameter properties in constructors, forcing the user to explicitly
declare all properties in the class.

## Options

This rule, in its default state, does not require any argument and would completely disallow the use of parameter properties.
If you would like to allow certain types of parameter properties then you may pass an object with the following options:

- `allows`, an array containing one or more of the allowed modifiers. Valid values are:
  - `readonly`, allows **readonly** parameter properties.
  - `private`, allows **private** parameter properties.
  - `protected`, allows **protected** parameter properties.
  - `public`, allows **public** parameter properties.
  - `private readonly`, allows **private readonly** parameter properties.
  - `protected readonly`, allows **protected readonly** parameter properties.
  - `public readonly`, allows **public readonly** parameter properties.

### default

Examples of code for this rule with no options at all:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}
```

### readonly

Examples of code for the `{ "allows": ["readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(readonly name: string) {}
}
```

### private

Examples of code for the `{ "allows": ["private"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(private name: string) {}
}
```

### protected

Examples of code for the `{ "allows": ["protected"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}
```

### public

Examples of code for the `{ "allows": ["public"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(public name: string) {}
}
```

### private readonly

Examples of code for the `{ "allows": ["private readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}
```

### protected readonly

Examples of code for the `{ "allows": ["protected readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}
```

### public readonly

Examples of code for the `{ "allows": ["public readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

## When Not To Use It

If you don't care about the using parameter properties in constructors, then you will not need this rule.
# `require-array-sort-compare`

Requires `Array#sort` calls to always provide a `compareFunction`.

This rule prevents invoking the `Array#sort()` method without providing a `compare` argument.

When called without a compare function, `Array#sort()` converts all non-undefined array elements into strings and then compares said strings based off their UTF-16 code units.

The result is that elements are sorted alphabetically, regardless of their type.
When sorting numbers, this results in the classic "10 before 2" order:

```ts
[1, 2, 3, 10, 20, 30].sort(); //→ [1, 10, 2, 20, 3, 30]
```

This also means that `Array#sort` does not always sort consistently, as elements may have custom `#toString` implementations that are not deterministic; this trap is noted in the language specification thusly:

:::note
Method calls performed by the `ToString` abstract operations in steps 5 and 7 have the potential to cause `SortCompare` to not behave as a consistent comparison function.

https://www.ecma-international.org/ecma-262/9.0/#sec-sortcompare
:::

## Rule Details

This rule aims to ensure all calls of the native `Array#sort` method provide a `compareFunction`, while ignoring calls to user-defined `sort` methods.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const array: any[];
const stringArray: string[];

array.sort();

// String arrays should be sorted using `String#localeCompare`.
stringArray.sort();
```

### ✅ Correct

```ts
const array: any[];
const userDefinedType: { sort(): void };

array.sort((a, b) => a - b);
array.sort((a, b) => a.localeCompare(b));

userDefinedType.sort();
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  /**
   * If true, an array which all elements are string is ignored.
   */
  ignoreStringArrays?: boolean;
};

const defaults = {
  ignoreStringArrays: false,
};
```

### `ignoreStringArrays`

Examples of code for this rule with `{ ignoreStringArrays: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const one = 1;
const two = 2;
const three = 3;
[one, two, three].sort();
```

#### ✅ Correct

```ts
const one = '1';
const two = '2';
const three = '3';
[one, two, three].sort();
```

## When Not To Use It

If you understand the language specification enough, you can turn this rule off safely.
# `no-unnecessary-type-arguments`

Disallows type arguments that are equal to the default.

Warns if an explicitly specified type argument is the default for that type parameter.

## Rule Details

Type parameters in TypeScript may specify a default value.
For example:

```ts
function f<T = number>() {}
```

It is redundant to provide an explicit type parameter equal to that default.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
function f<T = number>() {}
f<number>();

function g<T = number, U = string>() {}
g<string, string>();

class C<T = number> {}
function h(c: C<number>) {}
new C<number>();
class D extends C<number> {}

interface I<T = number> {}
class Impl implements I<number> {}
```

### ✅ Correct

```ts
function f<T = number>() {}
f<string>();

function g<T = number, U = string>() {}
g<number, number>();

class C<T = number> {}
new C<string>();
class D extends C<string> {}

interface I<T = number> {}
class Impl implements I<string> {}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unnecessary-type-arguments": "warn"
  }
}
```

This rule is not configurable.
# `ban-ts-comment`

Disallows `@ts-<directive>` comments or requires descriptions after directive.

TypeScript provides several directive comments that can be used to alter how it processes files.
Using these to suppress TypeScript Compiler Errors reduces the effectiveness of TypeScript overall.

The directive comments supported by TypeScript are:

```ts
// @ts-expect-error
// @ts-ignore
// @ts-nocheck
// @ts-check
```

## Rule Details

This rule lets you set which directive comments you want to allow in your codebase.
By default, only `@ts-check` is allowed, as it enables rather than suppresses errors.

The configuration looks like this:

```ts
interface Options {
  'ts-expect-error'?: boolean | 'allow-with-description';
  'ts-ignore'?: boolean | 'allow-with-description';
  'ts-nocheck'?: boolean | 'allow-with-description';
  'ts-check'?: boolean | 'allow-with-description';
  minimumDescriptionLength?: number;
}

const defaultOptions: Options = {
  'ts-expect-error': 'allow-with-description',
  'ts-ignore': true,
  'ts-nocheck': true,
  'ts-check': false,
  minimumDescriptionLength: 3,
};
```

### `ts-expect-error`, `ts-ignore`, `ts-nocheck`, `ts-check` directives

A value of `true` for a particular directive means that this rule will report if it finds any usage of said directive.

<!--tabs-->

#### ❌ Incorrect

```ts
if (false) {
  // @ts-ignore: Unreachable code error
  console.log('hello');
}
if (false) {
  /*
  @ts-ignore: Unreachable code error
  */
  console.log('hello');
}
```

#### ✅ Correct

```ts
if (false) {
  // Compiler warns about unreachable code error
  console.log('hello');
}
```

### `allow-with-description`

A value of `'allow-with-description'` for a particular directive means that this rule will report if it finds a directive that does not have a description following the directive (on the same line).

For example, with `{ 'ts-expect-error': 'allow-with-description' }`:

<!--tabs-->

#### ❌ Incorrect

```ts
if (false) {
  // @ts-expect-error
  console.log('hello');
}
if (false) {
  /* @ts-expect-error */
  console.log('hello');
}
```

#### ✅ Correct

```ts
if (false) {
  // @ts-expect-error: Unreachable code error
  console.log('hello');
}
if (false) {
  /*
  @ts-expect-error: Unreachable code error
  */
  console.log('hello');
}
```

### `minimumDescriptionLength`

Use `minimumDescriptionLength` to set a minimum length for descriptions when using the `allow-with-description` option for a directive.

For example, with `{ 'ts-expect-error': 'allow-with-description', minimumDescriptionLength: 10 }` the following pattern is:

<!--tabs-->

#### ❌ Incorrect

```ts
if (false) {
  // @ts-expect-error: TODO
  console.log('hello');
}
```

#### ✅ Correct

```ts
if (false) {
  // @ts-expect-error The rationale for this override is described in issue #1337 on GitLab
  console.log('hello');
}
```

## When Not To Use It

If you want to use all of the TypeScript directives.

## Further Reading

- TypeScript [Type Checking JavaScript Files](https://www.typescriptlang.org/docs/handbook/type-checking-javascript-files.html)
# `no-non-null-asserted-optional-chain`

Disallows non-null assertions after an optional chain expression.

## Rule Details

Optional chain expressions are designed to return `undefined` if the optional property is nullish.
Using non-null assertions after an optional chain expression is wrong, and introduces a serious type safety hole into your code.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
/* eslint @typescript-eslint/no-non-null-asserted-optional-chain: "error" */

foo?.bar!;
foo?.bar()!;

// Prior to TS3.9, foo?.bar!.baz meant (foo?.bar).baz - i.e. the non-null assertion is applied to the entire chain so far.
// For TS3.9 and greater, the non-null assertion is only applied to the property itself, so it's safe.
// The following is incorrect code if you're using less than TS3.9
foo?.bar!.baz;
foo?.bar!();
foo?.bar!().baz;
```

### ✅ Correct

```ts
/* eslint @typescript-eslint/no-non-null-asserted-optional-chain: "error" */

foo?.bar;
(foo?.bar).baz;
foo?.bar();
foo?.bar();
foo?.bar().baz;

// The following is correct code if you're using TS3.9 or greater
foo?.bar!.baz;
foo?.bar!();
foo?.bar!().baz;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-non-null-asserted-optional-chain": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are not using TypeScript 3.7 (or greater), then you will not need to use this rule, as the operator is not supported.

## Further Reading

- [TypeScript 3.7 Release Notes](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html)
- [Optional Chaining Proposal](https://github.com/tc39/proposal-optional-chaining/)
# `no-confusing-void-expression`

Requires expressions of type void to appear in statement position.

Returning the results of an expression whose type is void can be misleading.
Attempting to do so is likely a symptom of expecting a different return type from a function.
Even if used correctly, it can be misleading for other developers,
who don't know what a particular function does and if its result matters.

This rule provides automatic fixes for most common cases.

## Examples

<!--tabs-->

### ❌ Incorrect

```ts
// somebody forgot that `alert` doesn't return anything
const response = alert('Are you sure?');
console.log(alert('Are you sure?'));

// it's not obvious whether the chained promise will contain the response (fixable)
promise.then(value => window.postMessage(value));

// it looks like we are returning the result of `console.error` (fixable)
function doSomething() {
  if (!somethingToDo) {
    return console.error('Nothing to do!');
  }

  console.log('Doing a thing...');
}
```

### ✅ Correct

```ts
// just a regular void function in a statement position
alert('Hello, world!');

// this function returns a boolean value so it's ok
const response = confirm('Are you sure?');
console.log(confirm('Are you sure?'));

// now it's obvious that `postMessage` doesn't return any response
promise.then(value => {
  window.postMessage(value);
});

// now it's explicit that we want to log the error and return early
function doSomething() {
  if (!somethingToDo) {
    console.error('Nothing to do!');
    return;
  }

  console.log('Doing a thing...');
}

// using logical expressions for their side effects is fine
cond && console.log('true');
cond || console.error('false');
cond ? console.log('true') : console.error('false');
```

## Options

An object option can be specified. Each boolean flag makes the rule less strict.

```ts
type Options = {
  ignoreArrowShorthand?: boolean;
  ignoreVoidOperator?: boolean;
};

const defaults: Options = {
  ignoreArrowShorthand: false,
  ignoreVoidOperator: false,
};
```

### `ignoreArrowShorthand`

`false` by default.

```json
{
  "@typescript-eslint/no-confusing-void-expression": [
    "error",
    { "ignoreArrowShorthand": true }
  ]
}
```

It might be undesirable to wrap every arrow function shorthand expression with braces.
Especially when using Prettier formatter, which spreads such code across 3 lines instead of 1.

Examples of additional **correct** code with this option enabled:

```ts
promise.then(value => window.postMessage(value));
```

### `ignoreVoidOperator`

`false` by default.

```json
{
  "@typescript-eslint/no-confusing-void-expression": [
    "error",
    { "ignoreVoidOperator": true }
  ]
}
```

It might be preferable to only use some distinct syntax
to explicitly mark the confusing but valid usage of void expressions.
This option allows void expressions which are explicitly wrapped in the `void` operator.
This can help avoid confusion among other developers as long as they are made aware of this code style.

This option also changes the automatic fixes for common cases to use the `void` operator.
It also enables a suggestion fix to wrap the void expression with `void` operator for every problem reported.

Examples of additional **correct** code with this option enabled:

```ts
// now it's obvious that we don't expect any response
promise.then(value => void window.postMessage(value));

// now it's explicit that we don't want to return anything
function doSomething() {
  if (!somethingToDo) {
    return void console.error('Nothing to do!');
  }

  console.log('Doing a thing...');
}

// we are sure that we want to always log `undefined`
console.log(void alert('Hello, world!'));
```

## When Not To Use It

The return type of a function can be inspected by going to its definition or hovering over it in an IDE.
If you don't care about being explicit about the void type in actual code then don't use this rule.
Also, if you prefer concise coding style then also don't use it.
# `require-await`

Disallows async functions which have no `await` expression.

## Rule Details

This rule extends the base [`eslint/require-await`](https://eslint.org/docs/rules/require-await) rule.
It uses type information to add support for `async` functions that return a `Promise`.

Examples of **correct** code for this rule:

```ts
async function returnsPromise1() {
  return Promise.resolve(1);
}

const returnsPromise2 = () => returnsPromise1();
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "require-await": "off",
  "@typescript-eslint/require-await": "error"
}
```

## Options

See [`eslint/require-await` options](https://eslint.org/docs/rules/require-await#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/require-await.md)

</sup>
# `no-dupe-class-members`

Disallows duplicate class members.

## Rule Details

This rule extends the base [`eslint/no-dupe-class-members`](https://eslint.org/docs/rules/no-dupe-class-members) rule.
It adds support for TypeScript's method overload definitions.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-dupe-class-members": "off",
  "@typescript-eslint/no-dupe-class-members": ["error"]
}
```

## Options

See [`eslint/no-dupe-class-members` options](https://eslint.org/docs/rules/no-dupe-class-members#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-dupe-class-members.md)

</sup>
# `ban-types`

Disallows certain types.

Some builtin types have aliases, some types are considered dangerous or harmful.
It's often a good idea to ban certain types to help with consistency and safety.

## Rule Details

This rule bans specific types and can suggest alternatives.
Note that it does not ban the corresponding runtime objects from being used.

## Options

```ts
type Options = {
  types?: {
    [typeName: string]:
      | false
      | string
      | {
          message: string;
          fixWith?: string;
        };
  };
  extendDefaults?: boolean;
};
```

The rule accepts a single object as options.

### `types`

An object whose keys are the types you want to ban, and the values are error messages.

The type can either be a type name literal (`Foo`), a type name with generic parameter instantiation(s) (`Foo<Bar>`), the empty object literal (`{}`), or the empty tuple type (`[]`).

The values can be:

- A string, which is the error message to be reported; or
- `false` to specifically un-ban this type (useful when you are using `extendDefaults`); or
- An object with the following properties:
  - `message: string` - the message to display when the type is matched.
  - `fixWith?: string` - a string to replace the banned type with when the fixer is run. If this is omitted, no fix will be done.

### `extendDefaults`

If you're specifying custom `types`, you can set this to `true` to extend the default `types` configuration. This is a convenience option to save you copying across the defaults when adding another type.

If this is `false`, the rule will _only_ use the types defined in your configuration.

Example configuration:

```jsonc
{
  "@typescript-eslint/ban-types": [
    "error",
    {
      "types": {
        // add a custom message to help explain why not to use it
        "Foo": "Don't use Foo because it is unsafe",

        // add a custom message, AND tell the plugin how to fix it
        "OldAPI": {
          "message": "Use NewAPI instead",
          "fixWith": "NewAPI"
        },

        // un-ban a type that's banned by default
        "{}": false
      },
      "extendDefaults": true
    }
  ]
}
```

### Default Options

The default options provide a set of "best practices", intended to provide safety and standardization in your codebase:

- Don't use the upper-case primitive types, you should use the lower-case types for consistency.
- Avoid the `Function` type, as it provides little safety for the following reasons:
  - It provides no type safety when calling the value, which means it's easy to provide the wrong arguments.
  - It accepts class declarations, which will fail when called, as they are called without the `new` keyword.
- Avoid the `Object` and `{}` types, as they mean "any non-nullish value".
  - This is a point of confusion for many developers, who think it means "any object type".
  - See [this comment for more information](https://github.com/typescript-eslint/typescript-eslint/issues/2063#issuecomment-675156492).

:::important

The default options suggest using `Record<string, unknown>`; this was a stylistic decision, as the built-in `Record` type is considered to look cleaner.

:::

<details>
<summary>Default Options</summary>

```ts
const defaultTypes = {
  String: {
    message: 'Use string instead',
    fixWith: 'string',
  },
  Boolean: {
    message: 'Use boolean instead',
    fixWith: 'boolean',
  },
  Number: {
    message: 'Use number instead',
    fixWith: 'number',
  },
  Symbol: {
    message: 'Use symbol instead',
    fixWith: 'symbol',
  },
  BigInt: {
    message: 'Use bigint instead',
    fixWith: 'bigint',
  },

  Function: {
    message: [
      'The `Function` type accepts any function-like value.',
      'It provides no type safety when calling the function, which can be a common source of bugs.',
      'It also accepts things like class declarations, which will throw at runtime as they will not be called with `new`.',
      'If you are expecting the function to accept certain arguments, you should explicitly define the function shape.',
    ].join('\n'),
  },

  // object typing
  Object: {
    message: [
      'The `Object` type actually means "any non-nullish value", so it is marginally better than `unknown`.',
      '- If you want a type meaning "any object", you probably want `Record<string, unknown>` instead.',
      '- If you want a type meaning "any value", you probably want `unknown` instead.',
    ].join('\n'),
  },
  '{}': {
    message: [
      '`{}` actually means "any non-nullish value".',
      '- If you want a type meaning "any object", you probably want `Record<string, unknown>` instead.',
      '- If you want a type meaning "any value", you probably want `unknown` instead.',
    ].join('\n'),
  },
};
```

</details>

### Examples

Examples of code with the default options:

<!--tabs-->

#### ❌ Incorrect

```ts
// use lower-case primitives for consistency
const str: String = 'foo';
const bool: Boolean = true;
const num: Number = 1;
const symb: Symbol = Symbol('foo');
const bigInt: BigInt = 1n;

// use a proper function type
const func: Function = () => 1;

// use safer object types
const capitalObj1: Object = 1;
const capitalObj2: Object = { a: 'string' };

const curly1: {} = 1;
const curly2: {} = { a: 'string' };
```

#### ✅ Correct

```ts
// use lower-case primitives for consistency
const str: string = 'foo';
const bool: boolean = true;
const num: number = 1;
const symb: symbol = Symbol('foo');
const bigInt: bigint = 1n;

// use a proper function type
const func: () => number = () => 1;

// use safer object types
const lowerObj: object = {};

const capitalObj1: number = 1;
const capitalObj2: { a: string } = { a: 'string' };

const curly1: number = 1;
const curly2: Record<'a', string> = { a: 'string' };
```
# `prefer-return-this-type`

Enforces that `this` is used when only `this` type is returned.

[Method chaining](https://en.wikipedia.org/wiki/Method_chaining) is a common pattern in OOP languages and TypeScript provides a special [polymorphic this type](https://www.typescriptlang.org/docs/handbook/2/classes.html#this-types).
If any type other than `this` is specified as the return type of these chaining methods, TypeScript will fail to cast it when invoking in subclass.

```ts
class Animal {
  eat(): Animal {
    console.log("I'm moving!");
    return this;
  }
}

class Cat extends Animal {
  meow(): Cat {
    console.log('Meow~');
    return this;
  }
}

const cat = new Cat();
// Error: Property 'meow' does not exist on type 'Animal'.
// because `eat` returns `Animal` and not all animals meow.
cat.eat().meow();

// the error can be fixed by removing the return type of `eat` or use `this` as the return type.
class Animal {
  eat(): this {
    console.log("I'm moving!");
    return this;
  }
}

class Cat extends Animal {
  meow(): this {
    console.log('Meow~');
    return this;
  }
}

const cat = new Cat();
// no errors. Because `eat` returns `Cat` now
cat.eat().meow();
```

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
class Foo {
  f1(): Foo {
    return this;
  }
  f2 = (): Foo => {
    return this;
  };
  f3(): Foo | undefined {
    return Math.random() > 0.5 ? this : undefined;
  }
}
```

### ✅ Correct

```ts
class Foo {
  f1(): this {
    return this;
  }
  f2() {
    return this;
  }
  f3 = (): this => {
    return this;
  };
  f4 = () => {
    return this;
  };
}

class Base {}
class Derived extends Base {
  f(): Base {
    return this;
  }
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-return-this-type": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't use method chaining or explicit return values, you can safely turn this rule off.
# `your-rule-name`

Your rule description here.

## Rule Details

To fill out: tell us more about this rule.

<!--tabs-->

### ❌ Incorrect

```ts
// To fill out: incorrect code
```

### ✅ Correct

```ts
// To fill out: correct code
```

## Options

This rule is not configurable.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/your-rule-name": "error"
  }
}
```

If not configurable: This rule is not configurable.

If configurable...

```ts
type Options = {
  someOption?: boolean;
};

const defaultOptions: Options = {
  someOption: false,
};
```

## When Not To Use It

To fill out: why wouldn't you want to use this rule?
For example if this rule requires a feature released in a certain TS version.
# `no-explicit-any`

Disallows the `any` type.

Using the `any` type defeats the purpose of using TypeScript.
When `any` is used, all compiler type checks around that value are ignored.

## Rule Details

This rule doesn't allow `any` types to be defined.
It aims to keep TypeScript maximally useful.
TypeScript has a compiler flag for `--noImplicitAny` that will prevent
an `any` type from being implied by the compiler, but doesn't prevent
`any` from being explicitly used.

<!--tabs-->

### ❌ Incorrect

```ts
const age: any = 'seventeen';
```

```ts
const ages: any[] = ['seventeen'];
```

```ts
const ages: Array<any> = ['seventeen'];
```

```ts
function greet(): any {}
```

```ts
function greet(): any[] {}
```

```ts
function greet(): Array<any> {}
```

```ts
function greet(): Array<Array<any>> {}
```

```ts
function greet(param: Array<any>): string {}
```

```ts
function greet(param: Array<any>): Array<any> {}
```

### ✅ Correct

```ts
const age: number = 17;
```

```ts
const ages: number[] = [17];
```

```ts
const ages: Array<number> = [17];
```

```ts
function greet(): string {}
```

```ts
function greet(): string[] {}
```

```ts
function greet(): Array<string> {}
```

```ts
function greet(): Array<Array<string>> {}
```

```ts
function greet(param: Array<string>): string {}
```

```ts
function greet(param: Array<string>): Array<string> {}
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if true, auto-fixing will be made available in which the "any" type is converted to an "unknown" type
  fixToUnknown: boolean;
  // specify if arrays from the rest operator are considered okay
  ignoreRestArgs: boolean;
};

const defaults = {
  fixToUnknown: false,
  ignoreRestArgs: false,
};
```

### `ignoreRestArgs`

A boolean to specify if arrays from the rest operator are considered okay. `false` by default.

Examples of **incorrect** code for the `{ "ignoreRestArgs": false }` option:

```ts
/*eslint @typescript-eslint/no-explicit-any: ["error", { "ignoreRestArgs": false }]*/

function foo1(...args: any[]): void {}
function foo2(...args: readonly any[]): void {}
function foo3(...args: Array<any>): void {}
function foo4(...args: ReadonlyArray<any>): void {}

declare function bar(...args: any[]): void;

const baz = (...args: any[]) => {};
const qux = function (...args: any[]) {};

type Quux = (...args: any[]) => void;
type Quuz = new (...args: any[]) => void;

interface Grault {
  (...args: any[]): void;
}
interface Corge {
  new (...args: any[]): void;
}
interface Garply {
  f(...args: any[]): void;
}
```

Examples of **correct** code for the `{ "ignoreRestArgs": true }` option:

```ts
/*eslint @typescript-eslint/no-explicit-any: ["error", { "ignoreRestArgs": true }]*/

function foo1(...args: any[]): void {}
function foo2(...args: readonly any[]): void {}
function foo3(...args: Array<any>): void {}
function foo4(...args: ReadonlyArray<any>): void {}

declare function bar(...args: any[]): void;

const baz = (...args: any[]) => {};
const qux = function (...args: any[]) {};

type Quux = (...args: any[]) => void;
type Quuz = new (...args: any[]) => void;

interface Grault {
  (...args: any[]): void;
}
interface Corge {
  new (...args: any[]): void;
}
interface Garply {
  f(...args: any[]): void;
}
```

## When Not To Use It

If an unknown type or a library without typings is used
and you want to be able to specify `any`.

## Further Reading

- TypeScript [any type](https://www.typescriptlang.org/docs/handbook/basic-types.html#any)
# `no-useless-empty-export`

Disallows empty exports that don't change anything in a module file.

## Rule Details

An empty `export {}` statement is sometimes useful in TypeScript code to turn a file that would otherwise be a script file into a module file.
Per the TypeScript Handbook [Modules](https://www.typescriptlang.org/docs/handbook/modules.html) page:

> In TypeScript, just as in ECMAScript 2015, any file containing a top-level import or export is considered a module.
> Conversely, a file without any top-level import or export declarations is treated as a script whose contents are available in the global scope (and therefore to modules as well).

However, an `export {}` statement does nothing if there are any other top-level import or export statements in a file.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
export const value = 'Hello, world!';
export {};
```

```ts
import 'some-other-module';
export {};
```

### ✅ Correct

```ts
export const value = 'Hello, world!';
```

```ts
import 'some-other-module';
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-useless-empty-export": "warn"
  }
}
```

This rule is not configurable.
# `indent`

Enforces consistent indentation.

## Warning

PLEASE READ THIS ISSUE BEFORE USING THIS RULE [#1824](https://github.com/typescript-eslint/typescript-eslint/issues/1824)

## Rule Details

This rule extends the base [`eslint/indent`](https://eslint.org/docs/rules/indent) rule.
It adds support for TypeScript nodes.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "indent": "off",
  "@typescript-eslint/indent": ["error"]
}
```

## Options

See [`eslint/indent` options](https://eslint.org/docs/rules/indent#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/indent.md)

</sup>
# `non-nullable-type-assertion-style`

Enforces non-null assertions over explicit type casts.

This rule detects when an `as` cast is doing the same job as a `!` would, and suggests fixing the code to be an `!`.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const maybe = Math.random() > 0.5 ? '' : undefined;

const definitely = maybe as string;
const alsoDefinitely = <string>maybe;
```

### ✅ Correct

```ts
const maybe = Math.random() > 0.5 ? '' : undefined;

const definitely = maybe!;
const alsoDefinitely = maybe!;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/non-nullable-type-assertion-style": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't mind having unnecessarily verbose type casts, you can avoid this rule.
# `no-base-to-string`

Requires `.toString()` to only be called on objects which provide useful information when stringified.

JavaScript will call `toString()` on an object when it is converted to a string, such as when `+` adding to a string or in `${}` template literals.

The default Object `.toString()` returns `"[object Object]"`, so this rule requires stringified objects define a more useful `.toString()` method.

Note that `Function` provides its own `.toString()` that returns the function's code.
Functions are not flagged by this rule.

This rule has some overlap with [`restrict-plus-operands`](./restrict-plus-operands.md) and [`restrict-template-expressions`](./restrict-template-expressions.md).

## Rule Details

This rule prevents accidentally defaulting to the base Object `.toString()` method.

<!--tabs-->

### ❌ Incorrect

```ts
// Passing an object or class instance to string concatenation:
'' + {};

class MyClass {}
const value = new MyClass();
value + '';

// Interpolation and manual .toString() calls too:
`Value: ${value}`;
({}.toString());
```

### ✅ Correct

```ts
// These types all have useful .toString()s
'Text' + true;
`Value: ${123}`;
`Arrays too: ${[1, 2, 3]}`;
(() => {}).toString();

// Defining a custom .toString class is considered acceptable
class CustomToString {
  toString() {
    return 'Hello, world!';
  }
}
`Value: ${new CustomToString()}`;

const literalWithToString = {
  toString: () => 'Hello, world!',
};

`Value: ${literalWithToString}`;
```

## Options

```ts
type Options = {
  ignoredTypeNames?: string[];
};

const defaultOptions: Options = {
  ignoredTypeNames: ['RegExp'],
};
```

### `ignoredTypeNames`

A string array of type names to ignore, this is useful for types missing `toString()` (but actually has `toString()`).
There are some types missing `toString()` in old version TypeScript, like `RegExp`, `URL`, `URLSearchParams` etc.

The following patterns are considered correct with the default options `{ ignoredTypeNames: ["RegExp"] }`:

```ts
`${/regex/}`;
'' + /regex/;
/regex/.toString();
let value = /regex/;
value.toString();
let text = `${value}`;
```

## When Not To Use It

If you don't mind `"[object Object]"` in your strings, then you will not need this rule.

- [`Object.prototype.toString()` MDN documentation](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/toString)
# `no-extra-parens`

Disallows unnecessary parentheses.

## Rule Details

This rule extends the base [`eslint/no-extra-parens`](https://eslint.org/docs/rules/no-extra-parens) rule.
It adds support for TypeScript type assertions.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-extra-parens": "off",
  "@typescript-eslint/no-extra-parens": ["error"]
}
```

## Options

See [`eslint/no-extra-parens` options](https://eslint.org/docs/rules/no-extra-parens#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-extra-parens.md)

</sup>
# `no-dynamic-delete`

Disallows using the `delete` operator on computed key expressions.

Deleting dynamically computed keys can be dangerous and in some cases not well optimized.

## Rule Details

Using the `delete` operator on keys that aren't runtime constants could be a sign that you're using the wrong data structures.
Using `Object`s with added and removed keys can cause occasional edge case bugs, such as if a key is named `"hasOwnProperty"`.
Consider using a `Map` or `Set` if you’re storing collections of objects.

<!--tabs-->

### ❌ Incorrect

```ts
// Can be replaced with the constant equivalents, such as container.aaa
delete container['aaa'];
delete container['Infinity'];

// Dynamic, difficult-to-reason-about lookups
const name = 'name';
delete container[name];
delete container[name.toUpperCase()];
```

### ✅ Correct

```ts
const container: { [i: string]: number } = {
  /* ... */
};

// Constant runtime lookups by string index
delete container.aaa;

// Constants that must be accessed by []
delete container[7];
delete container['-Infinity'];
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-dynamic-delete": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

When you know your keys are safe to delete, this rule can be unnecessary.
Some environments such as older browsers might not support `Map` and `Set`.

Do not consider this rule as performance advice before profiling your code's bottlenecks.
Even repeated minor performance slowdowns likely do not significantly affect your application's general perceived speed.
# `object-curly-spacing`

Enforces consistent spacing inside braces.

## Rule Details

This rule extends the base [`eslint/object-curly-spacing`](https://eslint.org/docs/rules/object-curly-spacing) rule.
It adds support for TypeScript's object types.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "object-curly-spacing": "off",
  "@typescript-eslint/object-curly-spacing": ["error"]
}
```

## Options

See [`eslint/object-curly-spacing` options](https://eslint.org/docs/rules/object-curly-spacing#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/object-curly-spacing.md)

</sup>
# `no-redeclare`

Disallows variable redeclaration.

## Rule Details

This rule extends the base [`eslint/no-redeclare`](https://eslint.org/docs/rules/no-redeclare) rule.
It adds support for TypeScript function overloads, and declaration merging.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-redeclare": "off",
  "@typescript-eslint/no-redeclare": ["error"]
}
```

## Options

See [`eslint/no-redeclare` options](https://eslint.org/docs/rules/no-redeclare#options).
This rule adds the following options:

```ts
interface Options extends BaseNoRedeclareOptions {
  ignoreDeclarationMerge?: boolean;
}

const defaultOptions: Options = {
  ...baseNoRedeclareDefaultOptions,
  ignoreDeclarationMerge: true,
};
```

### `ignoreDeclarationMerge`

When set to `true`, the rule will ignore declaration merges between the following sets:

- interface + interface
- namespace + namespace
- class + interface
- class + namespace
- class + interface + namespace
- function + namespace
- enum + namespace

Examples of **correct** code with `{ ignoreDeclarationMerge: true }`:

```ts
interface A {
  prop1: 1;
}
interface A {
  prop2: 2;
}

namespace Foo {
  export const a = 1;
}
namespace Foo {
  export const b = 2;
}

class Bar {}
namespace Bar {}

function Baz() {}
namespace Baz {}
```

**Note:** Even with this option set to true, this rule will report if you name a type and a variable the same name. **_This is intentional_**.
Declaring a variable and a type and a variable the same is usually an accident, and it can lead to hard-to-understand code.
If you have a rare case where you're intentionally naming a type the same name as a variable, use a disable comment. For example:

```ts
type something = string;
// eslint-disable-next-line @typescript-eslint/no-redeclare -- intentionally naming the variable the same as the type
const something = 2;
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-redeclare.md)

</sup>
# `no-extra-non-null-assertion`

Disallows extra non-null assertion.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const foo: { bar: number } | null = null;
const bar = foo!!!.bar;
```

```ts
function foo(bar: number | undefined) {
  const bar: number = bar!!!;
}
```

```ts
function foo(bar?: { n: number }) {
  return bar!?.n;
}
```

### ✅ Correct

```ts
const foo: { bar: number } | null = null;
const bar = foo!.bar;
```

```ts
function foo(bar: number | undefined) {
  const bar: number = bar!;
}
```

```ts
function foo(bar?: { n: number }) {
  return bar?.n;
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-extra-non-null-assertion": "error"
  }
}
```

This rule is not configurable.
# `prefer-readonly-parameter-types`

Requires function parameters to be typed as `readonly` to prevent accidental mutation of inputs.

Mutating function arguments can lead to confusing, hard to debug behavior.
Whilst it's easy to implicitly remember to not modify function arguments, explicitly typing arguments as readonly provides clear contract to consumers.
This contract makes it easier for a consumer to reason about if a function has side-effects.

## Rule Details

This rule allows you to enforce that function parameters resolve to readonly types.
A type is considered readonly if:

- it is a primitive type (`string`, `number`, `boolean`, `symbol`, or an enum),
- it is a function signature type,
- it is a readonly array type whose element type is considered readonly.
- it is a readonly tuple type whose elements are all considered readonly.
- it is an object type whose properties are all marked as readonly, and whose values are all considered readonly.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
function array1(arg: string[]) {} // array is not readonly
function array2(arg: readonly string[][]) {} // array element is not readonly
function array3(arg: [string, number]) {} // tuple is not readonly
function array4(arg: readonly [string[], number]) {} // tuple element is not readonly
// the above examples work the same if you use ReadonlyArray<T> instead

function object1(arg: { prop: string }) {} // property is not readonly
function object2(arg: { readonly prop: string; prop2: string }) {} // not all properties are readonly
function object3(arg: { readonly prop: { prop2: string } }) {} // nested property is not readonly
// the above examples work the same if you use Readonly<T> instead

interface CustomArrayType extends ReadonlyArray<string> {
  prop: string; // note: this property is mutable
}
function custom1(arg: CustomArrayType) {}

interface CustomFunction {
  (): void;
  prop: string; // note: this property is mutable
}
function custom2(arg: CustomFunction) {}

function union(arg: string[] | ReadonlyArray<number[]>) {} // not all types are readonly

// rule also checks function types
interface Foo {
  (arg: string[]): void;
}
interface Foo {
  new (arg: string[]): void;
}
const x = { foo(arg: string[]): void; };
function foo(arg: string[]);
type Foo = (arg: string[]) => void;
interface Foo {
  foo(arg: string[]): void;
}
```

### ✅ Correct

```ts
function array1(arg: readonly string[]) {}
function array2(arg: readonly (readonly string[])[]) {}
function array3(arg: readonly [string, number]) {}
function array4(arg: readonly [readonly string[], number]) {}
// the above examples work the same if you use ReadonlyArray<T> instead

function object1(arg: { readonly prop: string }) {}
function object2(arg: { readonly prop: string; readonly prop2: string }) {}
function object3(arg: { readonly prop: { readonly prop2: string } }) {}
// the above examples work the same if you use Readonly<T> instead

interface CustomArrayType extends ReadonlyArray<string> {
  readonly prop: string;
}
function custom1(arg: Readonly<CustomArrayType>) {}
// interfaces that extend the array types are not considered arrays, and thus must be made readonly.

interface CustomFunction {
  (): void;
  readonly prop: string;
}
function custom2(arg: CustomFunction) {}

function union(arg: readonly string[] | ReadonlyArray<number[]>) {}

function primitive1(arg: string) {}
function primitive2(arg: number) {}
function primitive3(arg: boolean) {}
function primitive4(arg: unknown) {}
function primitive5(arg: null) {}
function primitive6(arg: undefined) {}
function primitive7(arg: any) {}
function primitive8(arg: never) {}
function primitive9(arg: string | number | undefined) {}

function fnSig(arg: () => void) {}

enum Foo { a, b }
function enum(arg: Foo) {}

function symb1(arg: symbol) {}
const customSymbol = Symbol('a');
function symb2(arg: typeof customSymbol) {}

// function types
interface Foo {
  (arg: readonly string[]): void;
}
interface Foo {
  new (arg: readonly string[]): void;
}
const x = { foo(arg: readonly string[]): void; };
function foo(arg: readonly string[]);
type Foo = (arg: readonly string[]) => void;
interface Foo {
  foo(arg: readonly string[]): void;
}
```

## Options

```ts
interface Options {
  checkParameterProperties?: boolean;
  ignoreInferredTypes?: boolean;
}

const defaultOptions: Options = {
  checkParameterProperties: true,
  ignoreInferredTypes: false,
  treatMethodsAsReadonly: false,
};
```

### `checkParameterProperties`

This option allows you to enable or disable the checking of parameter properties.
Because parameter properties create properties on the class, it may be undesirable to force them to be readonly.

Examples of code for this rule with `{checkParameterProperties: true}`:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(private paramProp: string[]) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(private paramProp: readonly string[]) {}
}
```

<!--/tabs-->

Examples of **correct** code for this rule with `{checkParameterProperties: false}`:

```ts
class Foo {
  constructor(
    private paramProp1: string[],
    private paramProp2: readonly string[],
  ) {}
}
```

### `ignoreInferredTypes`

This option allows you to ignore parameters which don't explicitly specify a type. This may be desirable in cases where an external dependency specifies a callback with mutable parameters, and manually annotating the callback's parameters is undesirable.

Examples of code for this rule with `{ignoreInferredTypes: true}`:

<!--tabs-->

#### ❌ Incorrect

```ts
import { acceptsCallback, CallbackOptions } from 'external-dependency';

acceptsCallback((options: CallbackOptions) => {});
```

<details>
<summary>external-dependency.d.ts</summary>

```ts
export interface CallbackOptions {
  prop: string;
}
type Callback = (options: CallbackOptions) => void;
type AcceptsCallback = (callback: Callback) => void;

export const acceptsCallback: AcceptsCallback;
```

</details>

#### ✅ Correct

```ts
import { acceptsCallback } from 'external-dependency';

acceptsCallback(options => {});
```

<details>
<summary>external-dependency.d.ts</summary>

```ts
export interface CallbackOptions {
  prop: string;
}
type Callback = (options: CallbackOptions) => void;
type AcceptsCallback = (callback: Callback) => void;

export const acceptsCallback: AcceptsCallback;
```

</details>

### `treatMethodsAsReadonly`

This option allows you to treat all mutable methods as though they were readonly. This may be desirable when you are never reassigning methods.

Examples of code for this rule with `{treatMethodsAsReadonly: false}`:

<!--tabs-->

#### ❌ Incorrect

```ts
type MyType = {
  readonly prop: string;
  method(): string; // note: this method is mutable
};
function foo(arg: MyType) {}
```

#### ✅ Correct

```ts
type MyType = Readonly<{
  prop: string;
  method(): string;
}>;
function foo(arg: MyType) {}

type MyOtherType = {
  readonly prop: string;
  readonly method: () => string;
};
function bar(arg: MyOtherType) {}
```

<!--/tabs-->

Examples of **correct** code for this rule with `{treatMethodsAsReadonly: true}`:

```ts
type MyType = {
  readonly prop: string;
  method(): string; // note: this method is mutable
};
function foo(arg: MyType) {}
```
# `no-restricted-imports`

Disallows specified modules when loaded by `import`.

## Rule Details

This rule extends the base [`eslint/no-restricted-imports`](https://eslint.org/docs/rules/no-restricted-imports) rule.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-restricted-imports": "off",
  "@typescript-eslint/no-restricted-imports": ["error"]
}
```

## Options

See [`eslint/no-restricted-imports` options](https://eslint.org/docs/rules/no-restricted-imports#options).
This rule adds the following options:

### `allowTypeImports`

(default: `false`)

You can specify this option for a specific path or pattern as follows:

```jsonc
"@typescript-eslint/no-restricted-imports": ["error", {
  "paths": [{
    "name": "import-foo",
    "message": "Please use import-bar instead.",
    "allowTypeImports": true
  }, {
    "name": "import-baz",
    "message": "Please use import-quux instead.",
    "allowTypeImports": true
  }]
}]
```

When set to `true`, the rule will allow [Type-Only Imports](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-8.html#type-only-imports-and-export).

Examples of code with the above config:

<!--tabs-->

#### ❌ Incorrect

```ts
import foo from 'import-foo';
export { Foo } from 'import-foo';

import baz from 'import-baz';
export { Baz } from 'import-baz';
```

#### ✅ Correct

```ts
import { foo } from 'other-module';

import type foo from 'import-foo';
export type { Foo } from 'import-foo';

import type baz from 'import-baz';
export type { Baz } from 'import-baz';
```
# `no-unnecessary-type-assertion`

Disallows type assertions that do not change the type of an expression.

This rule prohibits using a type assertion that does not change the type of an expression.

## Rule Details

This rule aims to prevent unnecessary type assertions.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const foo = 3;
const bar = foo!;
```

```ts
const foo = <3>3;
```

```ts
type Foo = 3;
const foo = <Foo>3;
```

```ts
type Foo = 3;
const foo = 3 as Foo;
```

```ts
function foo(x: number): number {
  return x!; // unnecessary non-null
}
```

### ✅ Correct

```ts
const foo = <number>3;
```

```ts
const foo = 3 as number;
```

```ts
const foo = 'foo' as const;
```

```ts
function foo(x: number | undefined): number {
  return x!;
}
```

## Options

This rule optionally takes an object with a single property `typesToIgnore`, which can be set to a list of type names to ignore.

For example, with `@typescript-eslint/no-unnecessary-type-assertion: ["error", { typesToIgnore: ['Foo'] }]`, the following is **correct** code":

```ts
type Foo = 3;
const foo: Foo = 3;
```

## When Not To Use It

If you don't care about having no-op type assertions in your code, then you can turn off this rule.
# `prefer-regexp-exec`

Enforces `RegExp#exec` over `String#match` if no global flag is provided.

As `String#match` is defined to be the same as `RegExp#exec` when the regular expression does not include the `g` flag, prefer a consistent usage.

## Rule Details

This rule is aimed at enforcing a consistent way to apply regular expressions to strings.

From [`String#match` on MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/match):

> If the regular expression does not include the g flag, returns the same result as `RegExp.exec()`.

`RegExp#exec` may also be slightly faster than `String#match`; this is the reason to choose it as the preferred usage.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
'something'.match(/thing/);

'some things are just things'.match(/thing/);

const text = 'something';
const search = /thing/;
text.match(search);
```

### ✅ Correct

```ts
/thing/.exec('something');

'some things are just things'.match(/thing/g);

const text = 'something';
const search = /thing/;
search.exec(text);
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-regexp-exec": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you prefer consistent use of `String#match` for both, with `g` flag and without it, you can turn this rule off.
# `keyword-spacing`

Enforces consistent spacing before and after keywords.

## Rule Details

This rule extends the base [`eslint/keyword-spacing`](https://eslint.org/docs/rules/keyword-spacing) rule.
This version adds support for generic type parameters on function calls.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "keyword-spacing": "off",
  "@typescript-eslint/keyword-spacing": ["error"]
}
```

## Options

See [`eslint/keyword-spacing` options](https://eslint.org/docs/rules/keyword-spacing#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/keyword-spacing.md)

</sup>
# `member-ordering`

Requires a consistent member declaration order.

A consistent ordering of fields, methods and constructors can make interfaces, type literals, classes and class expressions easier to read, navigate, and edit.

## Rule Details

This rule aims to standardize the way class declarations, class expressions, interfaces and type literals are structured and ordered.

## Options

```ts
interface Options {
  default?: OrderConfig;
  classes?: OrderConfig;
  classExpressions?: OrderConfig;
  interfaces?: OrderConfig;
  typeLiterals?: OrderConfig;
}

type OrderConfig = MemberType[] | SortedOrderConfig | 'never';

interface SortedOrderConfig {
  memberTypes?: MemberType[] | 'never';
  order: 'alphabetically' | 'alphabetically-case-insensitive' | 'as-written';
}

// See below for the more specific MemberType strings
type MemberType = string | string[];
```

You can configure `OrderConfig` options for:

- **`default`**: all constructs (used as a fallback)
- **`classes`**?: override ordering specifically for classes
- **`classExpressions`**?: override ordering specifically for class expressions
- **`interfaces`**?: override ordering specifically for interfaces
- **`typeLiterals`**?: override ordering specifically for type literals

The `OrderConfig` settings for each kind of construct may configure sorting on one or both two levels:

- **`memberType`**: organizing on member type groups such as methods vs. properties
- **`order`**: organizing based on member names, such as alphabetically

### Groups

You can define many different groups based on different attributes of members.
The supported member attributes are, in order:

- **Accessibility** (`'public' | 'protected' | 'private'`)
- **Decoration** (`'decorated'`): Whether the member has an explicit accessibility decorator
- **Kind** (`'call-signature' | 'constructor' | 'field' | 'get' | 'method' | 'set' | 'signature'`)

Member attributes may be joined with a `'-'` to combine into more specific groups.
For example, `'public-field'` would come before `'private-field'`.

### Default configuration

The default configuration looks as follows:

```jsonc
{
  "default": [
    // Index signature
    "signature",

    // Fields
    "public-static-field",
    "protected-static-field",
    "private-static-field",

    "public-decorated-field",
    "protected-decorated-field",
    "private-decorated-field",

    "public-instance-field",
    "protected-instance-field",
    "private-instance-field",

    "public-abstract-field",
    "protected-abstract-field",
    "private-abstract-field",

    "public-field",
    "protected-field",
    "private-field",

    "static-field",
    "instance-field",
    "abstract-field",

    "decorated-field",

    "field",

    // Constructors
    "public-constructor",
    "protected-constructor",
    "private-constructor",

    "constructor",

    // Getters
    "public-static-get",
    "protected-static-get",
    "private-static-get",

    "public-decorated-get",
    "protected-decorated-get",
    "private-decorated-get",

    "public-instance-get",
    "protected-instance-get",
    "private-instance-get",

    "public-abstract-get",
    "protected-abstract-get",
    "private-abstract-get",

    "public-get",
    "protected-get",
    "private-get",

    "static-get",
    "instance-get",
    "abstract-get",

    "decorated-get",

    "get",

    // Setters
    "public-static-set",
    "protected-static-set",
    "private-static-set",

    "public-decorated-set",
    "protected-decorated-set",
    "private-decorated-set",

    "public-instance-set",
    "protected-instance-set",
    "private-instance-set",

    "public-abstract-set",
    "protected-abstract-set",
    "private-abstract-set",

    "public-set",
    "protected-set",
    "private-set",

    "static-set",
    "instance-set",
    "abstract-set",

    "decorated-set",

    "set",

    // Methods
    "public-static-method",
    "protected-static-method",
    "private-static-method",

    "public-decorated-method",
    "protected-decorated-method",
    "private-decorated-method",

    "public-instance-method",
    "protected-instance-method",
    "private-instance-method",

    "public-abstract-method",
    "protected-abstract-method",
    "private-abstract-method",

    "public-method",
    "protected-method",
    "private-method",

    "static-method",
    "instance-method",
    "abstract-method",

    "decorated-method",

    "method"
  ]
}
```

:::note
The default configuration contains member group types which contain other member types.
This is intentional to provide better error messages.
:::

:::tip
By default, the members are not sorted.
If you want to sort them alphabetically, you have to provide a custom configuration.
:::

## Examples

### General Order on All Constructs

This config specifies the order for all constructs.
It ignores member types other than signatures, methods, constructors, and fields.
It also ignores accessibility and scope.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "default": ["signature", "method", "constructor", "field"] }
    ]
  }
}
```

<!--tabs-->

#### ❌ Incorrect

```ts
interface Foo {
  B: string; // -> field

  new (); // -> constructor

  A(): void; // -> method

  [Z: string]: any; // -> signature
}
```

```ts
type Foo = {
  B: string; // -> field

  // no constructor

  A(): void; // -> method

  // no signature
};
```

```ts
class Foo {
  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field

  constructor() {} // -> constructor

  public static A(): void {} // -> method
  public B(): void {} // -> method

  [Z: string]: any; // -> signature
}
```

```ts
const Foo = class {
  private C: string; // -> field
  public D: string; // -> field

  constructor() {} // -> constructor

  public static A(): void {} // -> method
  public B(): void {} // -> method

  [Z: string]: any; // -> signature

  protected static E: string; // -> field
};
```

#### ✅ Correct

```ts
interface Foo {
  [Z: string]: any; // -> signature

  A(): void; // -> method

  new (); // -> constructor

  B: string; // -> field
}
```

```ts
type Foo = {
  // no signature

  A(): void; // -> method

  // no constructor

  B: string; // -> field
};
```

```ts
class Foo {
  [Z: string]: any; // -> signature

  public static A(): void {} // -> method
  public B(): void {} // -> method

  constructor() {} // -> constructor

  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field
}
```

```ts
const Foo = class {
  [Z: string]: any; // -> signature

  public static A(): void {} // -> method
  public B(): void {} // -> method

  constructor() {} // -> constructor

  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field
};
```

### Classes

#### Public Instance Methods Before Public Static Fields

This config specifies that public instance methods should come first before public static fields.
Everything else can be placed anywhere.
It doesn't apply to interfaces or type literals as accessibility and scope are not part of them.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "default": ["public-instance-method", "public-static-field"] }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
class Foo {
  private C: string; // (irrelevant)

  public D: string; // (irrelevant)

  public static E: string; // -> public static field

  constructor() {} // (irrelevant)

  public static A(): void {} // (irrelevant)

  [Z: string]: any; // (irrelevant)

  public B(): void {} // -> public instance method
}
```

```ts
const Foo = class {
  private C: string; // (irrelevant)

  [Z: string]: any; // (irrelevant)

  public static E: string; // -> public static field

  public D: string; // (irrelevant)

  constructor() {} // (irrelevant)

  public static A(): void {} // (irrelevant)

  public B(): void {} // -> public instance method
};
```

##### ✅ Correct

```ts
class Foo {
  public B(): void {} // -> public instance method

  private C: string; // (irrelevant)

  public D: string; // (irrelevant)

  public static E: string; // -> public static field

  constructor() {} // (irrelevant)

  public static A(): void {} // (irrelevant)

  [Z: string]: any; // (irrelevant)
}
```

```ts
const Foo = class {
  public B(): void {} // -> public instance method

  private C: string; // (irrelevant)

  [Z: string]: any; // (irrelevant)

  public D: string; // (irrelevant)

  constructor() {} // (irrelevant)

  public static A(): void {} // (irrelevant)

  public static E: string; // -> public static field
};
```

#### Static Fields Before Instance Fields

This config specifies that static fields should come before instance fields, with public static fields first.
It doesn't apply to interfaces or type literals as accessibility and scope are not part of them.

```jsonc
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "default": ["public-static-field", "static-field", "instance-field"] }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
class Foo {
  private E: string; // -> instance field

  private static B: string; // -> static field
  protected static C: string; // -> static field
  private static D: string; // -> static field

  public static A: string; // -> public static field

  [Z: string]: any; // (irrelevant)
}
```

```ts
const foo = class {
  public T(): void {} // method (irrelevant)

  private static B: string; // -> static field

  constructor() {} // constructor (irrelevant)

  private E: string; // -> instance field

  protected static C: string; // -> static field
  private static D: string; // -> static field

  [Z: string]: any; // signature (irrelevant)

  public static A: string; // -> public static field
};
```

##### ✅ Correct

```ts
class Foo {
  public static A: string; // -> public static field

  private static B: string; // -> static field
  protected static C: string; // -> static field
  private static D: string; // -> static field

  private E: string; // -> instance field

  [Z: string]: any; // (irrelevant)
}
```

```ts
const foo = class {
  [Z: string]: any; // -> signature (irrelevant)

  public static A: string; // -> public static field

  constructor() {} // -> constructor (irrelevant)

  private static B: string; // -> static field
  protected static C: string; // -> static field
  private static D: string; // -> static field

  private E: string; // -> instance field

  public T(): void {} // -> method (irrelevant)
};
```

#### Class Declarations

This config only specifies an order for classes: methods, then the constructor, then fields.
It does not apply to class expressions (use `classExpressions` for them).
Default settings will be used for class declarations and all other syntax constructs other than class declarations.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "classes": ["method", "constructor", "field"] }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
class Foo {
  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field

  constructor() {} // -> constructor

  public static A(): void {} // -> method
  public B(): void {} // -> method
}
```

##### ✅ Correct

```ts
class Foo {
  public static A(): void {} // -> method
  public B(): void {} // -> method

  constructor() {} // -> constructor

  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field
}
```

#### Class Expressions

This config only specifies an order for classes expressions: methods, then the constructor, then fields.
It does not apply to class declarations (use `classes` for them).
Default settings will be used for class declarations and all other syntax constructs other than class expressions.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "classExpressions": ["method", "constructor", "field"] }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
const foo = class {
  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field

  constructor() {} // -> constructor

  public static A(): void {} // -> method
  public B(): void {} // -> method
};
```

##### ✅ Correct

```ts
const foo = class {
  public static A(): void {} // -> method
  public B(): void {} // -> method

  constructor() {} // -> constructor

  private C: string; // -> field
  public D: string; // -> field
  protected static E: string; // -> field
};
```

### Interfaces

This config only specifies an order for interfaces: signatures, then methods, then constructors, then fields.
It does not apply to type literals (use `typeLiterals` for them).
Default settings will be used for type literals and all other syntax constructs other than class expressions.

:::note
These member types are the only ones allowed for `interfaces`.
:::

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "interfaces": ["signature", "method", "constructor", "field"] }
    ]
  }
}
```

<!--tabs-->

#### ❌ Incorrect

```ts
interface Foo {
  B: string; // -> field

  new (); // -> constructor

  A(): void; // -> method

  [Z: string]: any; // -> signature
}
```

#### ✅ Correct

```ts
interface Foo {
  [Z: string]: any; // -> signature

  A(): void; // -> method

  new (); // -> constructor

  B: string; // -> field
}
```

### Type Literals

This config only specifies an order for type literals: signatures, then methods, then constructors, then fields.
It does not apply to interfaces (use `interfaces` for them).
Default settings will be used for interfaces and all other syntax constructs other than class expressions.

:::note
These member types are the only ones allowed for `typeLiterals`.
:::

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "typeLiterals": ["signature", "method", "constructor", "field"] }
    ]
  }
}
```

<!--tabs-->

#### ❌ Incorrect

```ts
type Foo = {
  B: string; // -> field

  A(): void; // -> method

  new (); // -> constructor

  [Z: string]: any; // -> signature
};
```

#### ✅ Correct

```ts
type Foo = {
  [Z: string]: any; // -> signature

  A(): void; // -> method

  new (); // -> constructor

  B: string; // -> field
};
```

### Sorting Options

#### Sorting Alphabetically Within Member Groups

This config specifies that within each `memberTypes` group, members are in an alphabetic case-sensitive order.
You can copy and paste the default order from [Default Configuration](#default-configuration).

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      {
        "default": {
          "memberTypes": [
            /* <Default Order> */
          ],
          "order": "alphabetically"
        }
      }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
interface Foo {
  a: x;
  B: x;
  c: x;

  B(): void;
  c(): void;
  a(): void;
}
```

##### ✅ Correct

```ts
interface Foo {
  B: x;
  a: x;
  c: x;

  B(): void;
  a(): void;
  c(): void;
}
```

#### Sorting Alphabetically Case Insensitive Within Member Groups

This config specifies that within each `memberTypes` group, members are in an alphabetic case-sensitive order.
You can copy and paste the default order from [Default Configuration](#default-configuration).

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      {
        "default": {
          "memberTypes": [
            /* <Default Order> */
          ],
          "order": "alphabetically-case-insensitive"
        }
      }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
interface Foo {
  B: x;
  a: x;
  c: x;

  B(): void;
  c(): void;
  a(): void;
}
```

##### ✅ Correct

```ts
interface Foo {
  a: x;
  B: x;
  c: x;

  a(): void;
  B(): void;
  c(): void;
}
```

#### Sorting Alphabetically Ignoring Member Groups

This config specifies that members are all sorted in an alphabetic case-sensitive order.
It ignores any member group types completely by specifying `"never"` for `memberTypes`.

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/member-ordering": [
      "error",
      { "default": { "memberTypes": "never", "order": "alphabetically" } }
    ]
  }
}
```

<!--tabs-->

##### ❌ Incorrect

```ts
interface Foo {
  static c = 0;
  b(): void;
  a: boolean;

  [a: string]: number; // Order doesn't matter (no sortable identifier)
  new (): Bar; // Order doesn't matter (no sortable identifier)
  (): Baz; // Order doesn't matter (no sortable identifier)
}
```

##### ✅ Correct

```ts
interface Foo {
  a: boolean;
  b(): void;
  static c = 0;

  [a: string]: number; // Order doesn't matter (no sortable identifier)
  new (): Bar; // Order doesn't matter (no sortable identifier)
  (): Baz; // Order doesn't matter (no sortable identifier)
}
```

## All Supported Options

### Member Types (Granular Form)

There are multiple ways to specify the member types.
The most explicit and granular form is the following:

```jsonc
[
  // Index signature
  "signature",

  // Fields
  "public-static-field",
  "protected-static-field",
  "private-static-field",
  "public-decorated-field",
  "protected-decorated-field",
  "private-decorated-field",
  "public-instance-field",
  "protected-instance-field",
  "private-instance-field",
  "public-abstract-field",
  "protected-abstract-field",
  "private-abstract-field",

  // Constructors
  "public-constructor",
  "protected-constructor",
  "private-constructor",

  // Getters
  "public-static-get",
  "protected-static-get",
  "private-static-get",

  "public-decorated-get",
  "protected-decorated-get",
  "private-decorated-get",

  "public-instance-get",
  "protected-instance-get",
  "private-instance-get",

  "public-abstract-get",
  "protected-abstract-get",
  "private-abstract-get",

  "public-get",
  "protected-get",
  "private-get",

  "static-get",
  "instance-get",
  "abstract-get",

  "decorated-get",

  "get",

  // Setters
  "public-static-set",
  "protected-static-set",
  "private-static-set",

  "public-decorated-set",
  "protected-decorated-set",
  "private-decorated-set",

  "public-instance-set",
  "protected-instance-set",
  "private-instance-set",

  "public-abstract-set",
  "protected-abstract-set",
  "private-abstract-set",

  "public-set",
  "protected-set",
  "private-set",

  "static-set",
  "instance-set",
  "abstract-set",

  "decorated-set",

  "set",

  // Methods
  "public-static-method",
  "protected-static-method",
  "private-static-method",
  "public-decorated-method",
  "protected-decorated-method",
  "private-decorated-method",
  "public-instance-method",
  "protected-instance-method",
  "private-instance-method",
  "public-abstract-method",
  "protected-abstract-method",
  "private-abstract-method"
]
```

:::note
If you only specify some of the possible types, the non-specified ones can have any particular order.
This means that they can be placed before, within or after the specified types and the linter won't complain about it.
:::

### Member Group Types (With Accessibility, Ignoring Scope)

It is also possible to group member types by their accessibility (`static`, `instance`, `abstract`), ignoring their scope.

```jsonc
[
  // Index signature
  // No accessibility for index signature.

  // Fields
  "public-field", // = ["public-static-field", "public-instance-field"]
  "protected-field", // = ["protected-static-field", "protected-instance-field"]
  "private-field", // = ["private-static-field", "private-instance-field"]

  // Constructors
  // Only the accessibility of constructors is configurable. See below.

  // Getters
  "public-get", // = ["public-static-get", "public-instance-get"]
  "protected-get", // = ["protected-static-get", "protected-instance-get"]
  "private-get", // = ["private-static-get", "private-instance-get"]

  // Setters
  "public-set", // = ["public-static-set", "public-instance-set"]
  "protected-set", // = ["protected-static-set", "protected-instance-set"]
  "private-set", // = ["private-static-set", "private-instance-set"]

  // Methods
  "public-method", // = ["public-static-method", "public-instance-method"]
  "protected-method", // = ["protected-static-method", "protected-instance-method"]
  "private-method" // = ["private-static-method", "private-instance-method"]
]
```

### Member Group Types (With Accessibility and a Decorator)

It is also possible to group methods or fields with a decorator separately, optionally specifying
their accessibility.

```jsonc
[
  // Index signature
  // No decorators for index signature.

  // Fields
  "public-decorated-field",
  "protected-decorated-field",
  "private-decorated-field",

  "decorated-field", // = ["public-decorated-field", "protected-decorated-field", "private-decorated-field"]

  // Constructors
  // There are no decorators for constructors.

  // Getters
  "public-decorated-get",
  "protected-decorated-get",
  "private-decorated-get",

  "decorated-get" // = ["public-decorated-get", "protected-decorated-get", "private-decorated-get"]

  // Setters
  "public-decorated-set",
  "protected-decorated-set",
  "private-decorated-set",

  "decorated-set" // = ["public-decorated-set", "protected-decorated-set", "private-decorated-set"]

  // Methods
  "public-decorated-method",
  "protected-decorated-method",
  "private-decorated-method",

  "decorated-method" // = ["public-decorated-method", "protected-decorated-method", "private-decorated-method"]
]
```

### Member Group Types (With Scope, Ignoring Accessibility)

Another option is to group the member types by their scope (`public`, `protected`, `private`), ignoring their accessibility.

```jsonc
[
  // Index signature
  // No scope for index signature.

  // Fields
  "static-field", // = ["public-static-field", "protected-static-field", "private-static-field"]
  "instance-field", // = ["public-instance-field", "protected-instance-field", "private-instance-field"]
  "abstract-field", // = ["public-abstract-field", "protected-abstract-field", "private-abstract-field"]

  // Constructors
  "constructor", // = ["public-constructor", "protected-constructor", "private-constructor"]

  // Getters
  "static-get", // = ["public-static-get", "protected-static-get", "private-static-get"]
  "instance-get", // = ["public-instance-get", "protected-instance-get", "private-instance-get"]
  "abstract-get" // = ["public-abstract-get", "protected-abstract-get", "private-abstract-get"]

  // Setters
  "static-set", // = ["public-static-set", "protected-static-set", "private-static-set"]
  "instance-set", // = ["public-instance-set", "protected-instance-set", "private-instance-set"]
  "abstract-set" // = ["public-abstract-set", "protected-abstract-set", "private-abstract-set"]

  // Methods
  "static-method", // = ["public-static-method", "protected-static-method", "private-static-method"]
  "instance-method", // = ["public-instance-method", "protected-instance-method", "private-instance-method"]
  "abstract-method" // = ["public-abstract-method", "protected-abstract-method", "private-abstract-method"]
]
```

### Member Group Types (With Scope and Accessibility)

The third grouping option is to ignore both scope and accessibility.

```jsonc
[
  // Index signature
  // No grouping for index signature.

  // Fields
  "field", // = ["public-static-field", "protected-static-field", "private-static-field", "public-instance-field", "protected-instance-field", "private-instance-field",
  //              "public-abstract-field", "protected-abstract-field", private-abstract-field"]

  // Constructors
  // Only the accessibility of constructors is configurable.

  // Getters
  "get" // = ["public-static-get", "protected-static-get", "private-static-get", "public-instance-get", "protected-instance-get", "private-instance-get",
  //                "public-abstract-get", "protected-abstract-get", "private-abstract-get"]

  // Setters
  "set" // = ["public-static-set", "protected-static-set", "private-static-set", "public-instance-set", "protected-instance-set", "private-instance-set",
  //                "public-abstract-set", "protected-abstract-set", "private-abstract-set"]

  // Methods
  "method" // = ["public-static-method", "protected-static-method", "private-static-method", "public-instance-method", "protected-instance-method", "private-instance-method",
  //                "public-abstract-method", "protected-abstract-method", "private-abstract-method"]
]
```

### Grouping Different Member Types at the Same Rank

It is also possible to group different member types at the same rank.

```jsonc
[
  // Index signature
  "signature",

  // Fields
  "field",

  // Constructors
  "constructor",

  // Getters and Setters at the same rank
  ["get", "set"],

  // Methods
  "method"
]
```

## When Not To Use It

If you don't care about the general order of your members, then you will not need this rule.
# `no-use-before-define`

Disallows the use of variables before they are defined.

## Rule Details

This rule extends the base [`eslint/no-use-before-define`](https://eslint.org/docs/rules/no-use-before-define) rule.
It adds support for `type`, `interface` and `enum` declarations.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-use-before-define": "off",
  "@typescript-eslint/no-use-before-define": ["error"]
}
```

## Options

See [`eslint/no-use-before-define` options](https://eslint.org/docs/rules/no-use-before-define#options).
This rule adds the following options:

```ts
interface Options extends BaseNoUseBeforeDefineOptions {
  enums?: boolean;
  typedefs?: boolean;
  ignoreTypeReferences?: boolean;
}

const defaultOptions: Options = {
  ...baseNoUseBeforeDefineDefaultOptions,
  enums: true,
  typedefs: true,
  ignoreTypeReferences: true,
};
```

### `enums`

If this is `true`, this rule warns every reference to a enum before the enum declaration.
If this is `false`, this rule will ignore references to enums, when the reference is in a child scope.

Examples of code for the `{ "enums": true }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
/*eslint no-use-before-define: ["error", { "enums": true }]*/

const x = Foo.FOO;

enum Foo {
  FOO,
}
```

#### ✅ Correct

```ts
/*eslint no-use-before-define: ["error", { "enums": false }]*/

function foo() {
  return Foo.FOO;
}

enum Foo {
  FOO,
}
```

### `typedefs`

If this is `true`, this rule warns every reference to a type before the type declaration.
If this is `false`, this rule will ignore references to types.

Examples of **correct** code for the `{ "typedefs": false }` option:

```ts
/*eslint no-use-before-define: ["error", { "typedefs": false }]*/

let myVar: StringOrNumber;
type StringOrNumber = string | number;
```

### `ignoreTypeReferences`

If this is `true`, this rule ignores all type references, such as in type annotations and assertions.
If this is `false`, this will will check all type references.

Examples of **correct** code for the `{ "ignoreTypeReferences": true }` option:

```ts
/*eslint no-use-before-define: ["error", { "ignoreTypeReferences": true }]*/

let var1: StringOrNumber;
type StringOrNumber = string | number;

let var2: Enum;
enum Enum {}
```

### Other Options

See [`eslint/no-use-before-define` options](https://eslint.org/docs/rules/no-use-before-define#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-use-before-define.md)

</sup>
# `no-invalid-this`

Disallows `this` keywords outside of classes or class-like objects.

## Rule Details

This rule extends the base [`eslint/no-invalid-this`](https://eslint.org/docs/rules/no-invalid-this) rule.
It adds support for TypeScript's `this` parameters.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-invalid-this": "off",
  "@typescript-eslint/no-invalid-this": ["error"]
}
```

## Options

See [`eslint/no-invalid-this` options](https://eslint.org/docs/rules/no-invalid-this#options).

## When Not To Use It

When you are indifferent as to how your variables are initialized.

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-invalid-this.md)

</sup>
# `no-this-alias`

Disallows aliasing `this`.

This rule prohibits assigning variables to `this`.

## Rule Details

Assigning a variable to `this` instead of properly using arrow lambdas may be a symptom of pre-ES6 practices
or not managing scope well.

Instead of storing a reference to `this` and using it inside a `function () {`:

```js
const self = this;
>
setTimeout(function () {
    self.doWork();
});
```

Use `() =>` arrow lambdas, as they preserve `this` scope for you:

```js
setTimeout(() => {
  this.doWork();
});
```

Examples of **incorrect** code for this rule:

(see the rationale above)

Examples of **correct** code for this rule:

(see the rationale above)

## Options

You can pass an object option:

```jsonc
{
  "@typescript-eslint/no-this-alias": [
    "error",
    {
      "allowDestructuring": false, // Disallow `const { props, state } = this`; true by default
      "allowedNames": ["self"] // Allow `const self = this`; `[]` by default
    }
  ]
}
```

## When Not To Use It

If you need to assign `this` to variables, you shouldn’t use this rule.
# `no-empty-function`

Disallows empty functions.

## Rule Details

This rule extends the base [`eslint/no-empty-function`](https://eslint.org/docs/rules/no-empty-function) rule.
It adds support for handling TypeScript specific code that would otherwise trigger the rule.

One example of valid TypeScript specific code that would otherwise trigger the `no-empty-function` rule is the use of [parameter properties](https://www.typescriptlang.org/docs/handbook/classes.html#parameter-properties) in constructor functions.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-empty-function": "off",
  "@typescript-eslint/no-empty-function": ["error"]
}
```

## Options

See [`eslint/no-empty-function` options](https://eslint.org/docs/rules/no-empty-function#options).
This rule adds the following options:

```ts
type AdditionalAllowOptionEntries =
  | 'private-constructors'
  | 'protected-constructors'
  | 'decoratedFunctions'
  | 'overrideMethods';

type AllowOptionEntries =
  | BaseNoEmptyFunctionAllowOptionEntries
  | AdditionalAllowOptionEntries;

interface Options extends BaseNoEmptyFunctionOptions {
  allow?: Array<AllowOptionEntries>;
}
const defaultOptions: Options = {
  ...baseNoEmptyFunctionDefaultOptions,
  allow: [],
};
```

### allow: `private-constructors`

Examples of correct code for the `{ "allow": ["private-constructors"] }` option:

```ts
class Foo {
  private constructor() {}
}
```

### allow: `protected-constructors`

Examples of correct code for the `{ "allow": ["protected-constructors"] }` option:

```ts
class Foo {
  protected constructor() {}
}
```

### allow: `decoratedFunctions`

Examples of correct code for the `{ "allow": ["decoratedFunctions"] }` option:

```ts
@decorator()
function foo() {}

class Foo {
  @decorator()
  foo() {}
}
```

### allow: `overrideMethods`

Examples of correct code for the `{ "allow": ["overrideMethods"] }` option:

```ts
abstract class Base {
  protected greet(): void {
    console.log('Hello!');
  }
}

class Foo extends Base {
  protected override greet(): void {}
}
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-empty-function": "off",
  "@typescript-eslint/no-empty-function": ["error"]
}
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-empty-function.md)

</sup>
# `semi`

Requires or disallows semicolons instead of ASI.

This rule enforces consistent use of semicolons after statements.

## Rule Details

This rule extends the base [`eslint/semi`](https://eslint.org/docs/rules/semi) rule.
It adds support for TypeScript features that require semicolons.

See also the [`@typescript-eslint/member-delimiter-style`](member-delimiter-style.md) rule, which allows you to specify the delimiter for `type` and `interface` members.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "semi": "off",
  "@typescript-eslint/semi": ["error"]
}
```

## Options

See [`eslint/semi` options](https://eslint.org/docs/rules/semi#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/semi.md)

</sup>
# `no-useless-constructor`

Disallows unnecessary constructors.

## Rule Details

This rule extends the base [`eslint/no-useless-constructor`](https://eslint.org/docs/rules/no-useless-constructor) rule.
It adds support for:

- constructors marked as `protected` / `private` (i.e. marking a constructor as non-public),
- `public` constructors when there is no superclass,
- constructors with only parameter properties.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-useless-constructor": "off",
  "@typescript-eslint/no-useless-constructor": ["error"]
}
```

## Options

See [`eslint/no-useless-constructor` options](https://eslint.org/docs/rules/no-useless-constructor#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-useless-constructor.md)

</sup>

## Caveat

This lint rule will report on constructors whose sole purpose is to change visibility of a parent constructor.
See [discussion on this rule's lack of type information](https://github.com/typescript-eslint/typescript-eslint/issues/3820#issuecomment-917821240) for context.
# `no-unused-expressions`

Disallows unused expressions.

## Rule Details

This rule extends the base [`eslint/no-unused-expressions`](https://eslint.org/docs/rules/no-unused-expressions) rule.
It adds support for optional call expressions `x?.()`, and directive in module declarations.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-unused-expressions": "off",
  "@typescript-eslint/no-unused-expressions": ["error"]
}
```

## Options

See [`eslint/no-unused-expressions` options](https://eslint.org/docs/rules/no-unused-expressions#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-unused-expressions.md)

</sup>
# `no-unsafe-member-access`

Disallows member access on a value with type `any`.

Despite your best intentions, the `any` type can sometimes leak into your codebase.
Member access on `any` typed variables is not checked at all by TypeScript, so it creates a potential safety hole, and source of bugs in your codebase.

## Rule Details

This rule disallows member access on any variable that is typed as `any`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
declare const anyVar: any;
declare const nestedAny: { prop: any };

anyVar.a;
anyVar.a.b;
anyVar['a'];
anyVar['a']['b'];

nestedAny.prop.a;
nestedAny.prop['a'];

const key = 'a';
nestedAny.prop[key];

// Using an any to access a member is unsafe
const arr = [1, 2, 3];
arr[anyVar];
nestedAny[anyVar];
```

### ✅ Correct

```ts
declare const properlyTyped: { prop: { a: string } };

properlyTyped.prop.a;
properlyTyped.prop['a'];

const key = 'a';
properlyTyped.prop[key];

const arr = [1, 2, 3];
arr[1];
const idx = 1;
arr[idx];
arr[idx++];
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unsafe-member-access": "error"
  }
}
```

This rule is not configurable.

## Related To

- [`no-explicit-any`](./no-explicit-any.md)
# `prefer-namespace-keyword`

Requires using `namespace` keyword over `module` keyword to declare custom TypeScript modules.

In an effort to prevent further confusion between custom TypeScript modules and the new ES2015 modules, starting
with TypeScript `v1.5` the keyword `namespace` is now the preferred way to declare custom TypeScript modules.

## Rule Details

This rule aims to standardize the way modules are declared.

## When Not To Use It

If you are using the ES2015 module syntax, then you will not need this rule.

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-namespace-keyword": "error"
  }
}
```

This rule is not configurable.

## Further Reading

- [Modules](https://www.typescriptlang.org/docs/handbook/modules.html)
- [Namespaces](https://www.typescriptlang.org/docs/handbook/namespaces.html)
- [Namespaces and Modules](https://www.typescriptlang.org/docs/handbook/namespaces-and-modules.html)
# `no-unsafe-return`

Disallows returning a value with type `any` from a function.

Despite your best intentions, the `any` type can sometimes leak into your codebase.
Returned `any` typed values are not checked at all by TypeScript, so it creates a potential safety hole, and source of bugs in your codebase.

## Rule Details

This rule disallows returning `any` or `any[]` from a function.
This rule also compares the return type to the function's declared/inferred return type to ensure you don't return an unsafe `any` in a generic position to a receiver that's expecting a specific type. For example, it will error if you return `Set<any>` from a function declared as returning `Set<string>`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
function foo1() {
  return 1 as any;
}
function foo2() {
  return Object.create(null);
}
const foo3 = () => {
  return 1 as any;
};
const foo4 = () => Object.create(null);

function foo5() {
  return [] as any[];
}
function foo6() {
  return [] as Array<any>;
}
function foo7() {
  return [] as readonly any[];
}
function foo8() {
  return [] as Readonly<any[]>;
}
const foo9 = () => {
  return [] as any[];
};
const foo10 = () => [] as any[];

const foo11 = (): string[] => [1, 2, 3] as any[];

// generic position examples
function assignability1(): Set<string> {
  return new Set<any>([1]);
}
type TAssign = () => Set<string>;
const assignability2: TAssign = () => new Set<any>([true]);
```

### ✅ Correct

```ts
function foo1() {
  return 1;
}
function foo2() {
  return Object.create(null) as Record<string, unknown>;
}

const foo3 = () => [];
const foo4 = () => ['a'];

function assignability1(): Set<string> {
  return new Set<string>(['foo']);
}
type TAssign = () => Set<string>;
const assignability2: TAssign = () => new Set(['foo']);
```

<!--/tabs-->

There are cases where the rule allows to return `any` to `unknown`.

Examples of `any` to `unknown` return that are allowed.

```ts
function foo1(): unknown {
  return JSON.parse(singleObjString); // Return type for JSON.parse is any.
}

function foo2(): unknown[] {
  return [] as any[];
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unsafe-return": "error"
  }
}
```

This rule is not configurable.

## Related To

- [`no-explicit-any`](./no-explicit-any.md)
## DEPRECATED

This rule has been deprecated in favour of the [`naming-convention`](./naming-convention.md) rule.

<!--
This doc file has been left on purpose because `camelcase` is a core eslint rule.
This exists to help direct people to the replacement rule.
-->
# `init-declarations`

Requires or disallows initialization in variable declarations.

## Rule Details

This rule extends the base [`eslint/init-declarations`](https://eslint.org/docs/rules/init-declarations) rule.
It adds support for TypeScript's `declare` variables.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "init-declarations": "off",
  "@typescript-eslint/init-declarations": ["error"]
}
```

## Options

See [`eslint/init-declarations` options](https://eslint.org/docs/rules/init-declarations#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/init-declarations.md)

</sup>
# `no-misused-new`

Enforces valid definition of `new` and `constructor`.

Warns on apparent attempts to define constructors for interfaces or `new` for classes.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
class C {
  new(): C;
}

interface I {
  new (): I;
  constructor(): void;
}
```

### ✅ Correct

```ts
class C {
  constructor() {}
}
interface I {
  new (): C;
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-misused-new": "error"
  }
}
```

This rule is not configurable.
# `no-unnecessary-qualifier`

Disallows unnecessary namespace qualifiers.

## Rule Details

This rule aims to let users know when a namespace or enum qualifier is unnecessary,
whether used for a type or for a value.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
namespace A {
  export type B = number;
  const x: A.B = 3;
}
```

```ts
namespace A {
  export const x = 3;
  export const y = A.x;
}
```

```ts
enum A {
  B,
  C = A.B,
}
```

```ts
namespace A {
  export namespace B {
    export type T = number;
    const x: A.B.T = 3;
  }
}
```

### ✅ Correct

```ts
namespace X {
  export type T = number;
}

namespace Y {
  export const x: X.T = 3;
}
```

```ts
enum A {
  X,
  Y,
}

enum B {
  Z = A.X,
}
```

```ts
namespace X {
  export type T = number;
  namespace Y {
    type T = string;
    const x: X.T = 0;
  }
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unnecessary-qualifier": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about having unneeded namespace or enum qualifiers, then you don't need to use this rule.
# `default-param-last`

Enforces default parameters to be last.

## Rule Details

This rule extends the base [`eslint/default-param-last`](https://eslint.org/docs/rules/default-param-last) rule.
It adds support for optional parameters.

<!--tabs-->

### ❌ Incorrect

```ts
/* eslint @typescript-eslint/default-param-last: ["error"] */

function f(a = 0, b: number) {}
function f(a: number, b = 0, c: number) {}
function f(a: number, b?: number, c: number) {}
class Foo {
  constructor(public a = 10, private b: number) {}
}
class Foo {
  constructor(public a?: number, private b: number) {}
}
```

### ✅ Correct

```ts
/* eslint @typescript-eslint/default-param-last: ["error"] */

function f(a = 0) {}
function f(a: number, b = 0) {}
function f(a: number, b?: number) {}
function f(a: number, b?: number, c = 0) {}
function f(a: number, b = 0, c?: number) {}
class Foo {
  constructor(public a, private b = 0) {}
}
class Foo {
  constructor(public a, private b?: number) {}
}
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "default-param-last": "off",
  "@typescript-eslint/default-param-last": ["error"]
}
```

## Options

See [`eslint/default-param-last` options](https://eslint.org/docs/rules/default-param-last#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/default-param-last.md)

</sup>
# `no-namespace`

Disallows custom TypeScript modules and namespaces.

Custom TypeScript modules (`module foo {}`) and namespaces (`namespace foo {}`) are considered outdated
ways to organize TypeScript code. ES2015 module syntax is now preferred (`import`/`export`).

This rule still allows the use of TypeScript module declarations to describe external APIs (`declare module 'foo' {}`).

## Rule Details

This rule aims to standardize the way modules are declared.

## Options

This rule, in its default state, does not require any argument. If you would like to enable one
or more of the following you may pass an object with the options set as follows:

- `allowDeclarations` set to `true` will allow you to `declare` custom TypeScript modules and namespaces (Default: `false`).
- `allowDefinitionFiles` set to `true` will allow you to `declare` and use custom TypeScript modules and namespaces
  inside definition files (Default: `true`).

Examples of code for the default `{ "allowDeclarations": false, "allowDefinitionFiles": true }` options:

<!--tabs-->

### ❌ Incorrect

```ts
module foo {}
namespace foo {}

declare module foo {}
declare namespace foo {}
```

### ✅ Correct

```ts
declare module 'foo' {}

// anything inside a d.ts file
```

<!--/tabs-->

### `allowDeclarations`

Examples of code for the `{ "allowDeclarations": true }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
module foo {}
namespace foo {}
```

#### ✅ Correct

```ts
declare module 'foo' {}
declare module foo {}
declare namespace foo {}

declare global {
  namespace foo {}
}

declare module foo {
  namespace foo {}
}
```

<!--/tabs-->

Examples of code for the `{ "allowDeclarations": false }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
module foo {}
namespace foo {}
declare module foo {}
declare namespace foo {}
```

#### ✅ Correct

```ts
declare module 'foo' {}
```

### `allowDefinitionFiles`

Examples of code for the `{ "allowDefinitionFiles": true }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
// if outside a d.ts file
module foo {}
namespace foo {}

// if outside a d.ts file and allowDeclarations = false
module foo {}
namespace foo {}
declare module foo {}
declare namespace foo {}
```

#### ✅ Correct

```ts
declare module 'foo' {}

// anything inside a d.ts file
```

## When Not To Use It

If you are using the ES2015 module syntax, then you will not need this rule.

## Further Reading

- [Modules](https://www.typescriptlang.org/docs/handbook/modules.html)
- [Namespaces](https://www.typescriptlang.org/docs/handbook/namespaces.html)
- [Namespaces and Modules](https://www.typescriptlang.org/docs/handbook/namespaces-and-modules.html)
# `space-before-blocks`

Enforces consistent spacing before blocks.

## Rule Details

This rule extends the base [`eslint/space-before-blocks`](https://eslint.org/docs/rules/space-before-blocks) rule.
It adds support for interfaces and enums:

### ❌ Incorrect

```ts
enum Breakpoint{
  Large, Medium;
}

interface State{
  currentBreakpoint: Breakpoint;
}
```

### ✅ Correct

```ts
enum Breakpoint {
  Large, Medium;
}

interface State {
  currentBreakpoint: Breakpoint;
}
```

In case a more specific options object is passed these blocks will follow `classes` configuration option.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "space-before-blocks": "off",
  "@typescript-eslint/space-before-blocks": ["error"]
}
```

## Options

See [`eslint/space-before-blocks` options](https://eslint.org/docs/rules/space-before-blocks#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/master/docs/rules/space-before-blocks.md)

</sup>
# `naming-convention`

Enforces naming conventions for everything across a codebase.

Enforcing naming conventions helps keep the codebase consistent, and reduces overhead when thinking about how to name a variable.
Additionally, a well-designed style guide can help communicate intent, such as by enforcing all private properties begin with an `_`, and all global-level constants are written in `UPPER_CASE`.

There are many different rules that have existed over time, but they have had the problem of not having enough granularity, meaning it was hard to have a well defined style guide, and most of the time you needed 3 or more rules at once to enforce different conventions, hoping they didn't conflict.

## Rule Details

This rule allows you to enforce conventions for any identifier, using granular selectors to create a fine-grained style guide.

:::note

This rule only needs type information in specific cases, detailed below.

:::

## Options

This rule accepts an array of objects, with each object describing a different naming convention.
Each property will be described in detail below. Also see the examples section below for illustrated examples.

```ts
type Options = {
  // format options
  format:
    | (
        | 'camelCase'
        | 'strictCamelCase'
        | 'PascalCase'
        | 'StrictPascalCase'
        | 'snake_case'
        | 'UPPER_CASE'
      )[]
    | null;
  custom?: {
    regex: string;
    match: boolean;
  };
  leadingUnderscore?:
    | 'forbid'
    | 'require'
    | 'requireDouble'
    | 'allow'
    | 'allowDouble'
    | 'allowSingleOrDouble';
  trailingUnderscore?:
    | 'forbid'
    | 'require'
    | 'requireDouble'
    | 'allow'
    | 'allowDouble'
    | 'allowSingleOrDouble';
  prefix?: string[];
  suffix?: string[];

  // selector options
  selector: Selector | Selector[];
  filter?:
    | string
    | {
        regex: string;
        match: boolean;
      };
  // the allowed values for these are dependent on the selector - see below
  modifiers?: Modifiers<Selector>[];
  types?: Types<Selector>[];
}[];

// the default config is similar to ESLint's camelcase rule but more strict
const defaultOptions: Options = [
  {
    selector: 'default',
    format: ['camelCase'],
    leadingUnderscore: 'allow',
    trailingUnderscore: 'allow',
  },

  {
    selector: 'variable',
    format: ['camelCase', 'UPPER_CASE'],
    leadingUnderscore: 'allow',
    trailingUnderscore: 'allow',
  },

  {
    selector: 'typeLike',
    format: ['PascalCase'],
  },
];
```

### Format Options

Every single selector can have the same set of format options.
For information about how each selector is applied, see ["How does the rule evaluate a name's format?"](#how-does-the-rule-evaluate-a-names-format).

#### `format`

The `format` option defines the allowed formats for the identifier. This option accepts an array of the following values, and the identifier can match any of them:

- `camelCase` - standard camelCase format - no underscores are allowed between characters, and consecutive capitals are allowed (i.e. both `myID` and `myId` are valid).
- `strictCamelCase` - same as `camelCase`, but consecutive capitals are not allowed (i.e. `myId` is valid, but `myID` is not).
- `PascalCase` - same as `camelCase`, except the first character must be upper-case.
- `StrictPascalCase` - same as `strictCamelCase`, except the first character must be upper-case.
- `snake_case` - standard snake_case format - all characters must be lower-case, and underscores are allowed.
- `UPPER_CASE` - same as `snake_case`, except all characters must be upper-case.

Instead of an array, you may also pass `null`. This signifies "this selector shall not have its format checked".
This can be useful if you want to enforce no particular format for a specific selector, after applying a group selector.

#### `custom`

The `custom` option defines a custom regex that the identifier must (or must not) match. This option allows you to have a bit more finer-grained control over identifiers, letting you ban (or force) certain patterns and substrings.
Accepts an object with the following properties:

- `regex` - a string that is then passed into RegExp to create a new regular expression: `new RegExp(regex)`
- `match` - true if the identifier _must_ match the `regex`, false if the identifier _must not_ match the `regex`.

#### `filter`

The `filter` option operates similar to `custom`, accepting the same shaped object, except that it controls if the rest of the configuration should or should not be applied to an identifier.

You can use this to include or exclude specific identifiers from specific configurations.

Accepts an object with the following properties:

- `regex` - a string that is then passed into RegExp to create a new regular expression: `new RegExp(regex)`
- `match` - true if the identifier _must_ match the `regex`, false if the identifier _must not_ match the `regex`.

Alternatively, `filter` accepts a regular expression (anything accepted into `new RegExp(filter)`). In this case, it's treated as if you had passed an object with the regex and `match: true`.

#### `leadingUnderscore` / `trailingUnderscore`

The `leadingUnderscore` / `trailingUnderscore` options control whether leading/trailing underscores are considered valid. Accepts one of the following values:

- `forbid` - a leading/trailing underscore is not allowed at all.
- `require` - a single leading/trailing underscore must be included.
- `requireDouble` - two leading/trailing underscores must be included.
- `allow` - existence of a single leading/trailing underscore is not explicitly enforced.
- `allowDouble` - existence of a double leading/trailing underscore is not explicitly enforced.
- `allowSingleOrDouble` - existence of a single or a double leading/trailing underscore is not explicitly enforced.

#### `prefix` / `suffix`

The `prefix` / `suffix` options control which prefix/suffix strings must exist for the identifier. Accepts an array of strings.

If these are provided, the identifier must start with one of the provided values. For example, if you provide `{ prefix: ['IFace', 'Class', 'Type'] }`, then the following names are valid: `IFaceFoo`, `ClassBar`, `TypeBaz`, but the name `Bang` is not valid, as it contains none of the prefixes.

**Note:** As [documented above](#format-options), the prefix is trimmed before format is validated, therefore PascalCase must be used to allow variables such as `isEnabled` using the prefix `is`.

### Selector Options

- `selector` allows you to specify what types of identifiers to target.
  - Accepts one or array of selectors to define an option block that applies to one or multiple selectors.
  - For example, if you provide `{ selector: ['variable', 'function'] }`, then it will apply the same option to variable and function nodes.
  - See [Allowed Selectors, Modifiers and Types](#allowed-selectors-modifiers-and-types) below for the complete list of allowed selectors.
- `modifiers` allows you to specify which modifiers to granularly apply to, such as the accessibility (`private`/`public`/`protected`), or if the thing is `static`, etc.
  - The name must match _all_ of the modifiers.
  - For example, if you provide `{ modifiers: ['private', 'static', 'readonly'] }`, then it will only match something that is `private static readonly`, and something that is just `private` will not match.
  - The following `modifiers` are allowed:
    - `const` - matches a variable declared as being `const` (`const x = 1`).
    - `destructured` - matches a variable declared via an object destructuring pattern (`const {x, z = 2}`).
      - Note that this does not match renamed destructured properties (`const {x: y, a: b = 2}`).
    - `global` - matches a variable/function declared in the top-level scope.
    - `exported` - matches anything that is exported from the module.
    - `unused` - matches anything that is not used.
    - `requiresQuotes` - matches any name that requires quotes as it is not a valid identifier (i.e. has a space, a dash, etc in it).
    - `public` - matches any member that is either explicitly declared as `public`, or has no visibility modifier (i.e. implicitly public).
    - `readonly`, `static`, `abstract`, `protected`, `private` - matches any member explicitly declared with the given modifier.
- `types` allows you to specify which types to match. This option supports simple, primitive types only (`boolean`, `string`, `number`, `array`, `function`).
  - The name must match _one_ of the types.
  - **_NOTE - Using this option will require that you lint with type information._**
  - For example, this lets you do things like enforce that `boolean` variables are prefixed with a verb.
  - The following `types` are allowed:
    - `boolean` matches any type assignable to `boolean | null | undefined`
    - `string` matches any type assignable to `string | null | undefined`
    - `number` matches any type assignable to `number | null | undefined`
    - `array` matches any type assignable to `Array<unknown> | null | undefined`
    - `function` matches any type assignable to `Function | null | undefined`

The ordering of selectors does not matter. The implementation will automatically sort the selectors to ensure they match from most-specific to least specific. It will keep checking selectors in that order until it finds one that matches the name. See ["How does the rule automatically order selectors?"](#how-does-the-rule-automatically-order-selectors)

#### Allowed Selectors, Modifiers and Types

There are two types of selectors, individual selectors, and grouped selectors.

##### Individual Selectors

Individual Selectors match specific, well-defined sets. There is no overlap between each of the individual selectors.

- `variable` - matches any `var` / `let` / `const` variable name.
  - Allowed `modifiers`: `const`, `destructured`, `global`, `exported`, `unused`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `function` - matches any named function declaration or named function expression.
  - Allowed `modifiers`: `global`, `exported`, `unused`.
  - Allowed `types`: none.
- `parameter` - matches any function parameter. Does not match parameter properties.
  - Allowed `modifiers`: `destructured`, `unused`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `classProperty` - matches any class property. Does not match properties that have direct function expression or arrow function expression values.
  - Allowed `modifiers`: `abstract`, `private`, `protected`, `public`, `readonly`, `requiresQuotes`, `static`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `objectLiteralProperty` - matches any object literal property. Does not match properties that have direct function expression or arrow function expression values.
  - Allowed `modifiers`: `public`, `requiresQuotes`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `typeProperty` - matches any object type property. Does not match properties that have direct function expression or arrow function expression values.
  - Allowed `modifiers`: `public`, `readonly`, `requiresQuotes`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `parameterProperty` - matches any parameter property.
  - Allowed `modifiers`: `private`, `protected`, `public`, `readonly`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `classMethod` - matches any class method. Also matches properties that have direct function expression or arrow function expression values. Does not match accessors.
  - Allowed `modifiers`: `abstract`, `private`, `protected`, `public`, `requiresQuotes`, `static`.
  - Allowed `types`: none.
- `objectLiteralMethod` - matches any object literal method. Also matches properties that have direct function expression or arrow function expression values. Does not match accessors.
  - Allowed `modifiers`: `public`, `requiresQuotes`.
  - Allowed `types`: none.
- `typeMethod` - matches any object type method. Also matches properties that have direct function expression or arrow function expression values. Does not match accessors.
  - Allowed `modifiers`: `public`, `requiresQuotes`.
  - Allowed `types`: none.
- `accessor` - matches any accessor.
  - Allowed `modifiers`: `abstract`, `private`, `protected`, `public`, `requiresQuotes`, `static`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `enumMember` - matches any enum member.
  - Allowed `modifiers`: `requiresQuotes`.
  - Allowed `types`: none.
- `class` - matches any class declaration.
  - Allowed `modifiers`: `abstract`, `exported`, `unused`.
  - Allowed `types`: none.
- `interface` - matches any interface declaration.
  - Allowed `modifiers`: `exported`, `unused`.
  - Allowed `types`: none.
- `typeAlias` - matches any type alias declaration.
  - Allowed `modifiers`: `exported`, `unused`.
  - Allowed `types`: none.
- `enum` - matches any enum declaration.
  - Allowed `modifiers`: `exported`, `unused`.
  - Allowed `types`: none.
- `typeParameter` - matches any generic type parameter declaration.
  - Allowed `modifiers`: `unused`.
  - Allowed `types`: none.

##### Group Selectors

Group Selectors are provided for convenience, and essentially bundle up sets of individual selectors.

- `default` - matches everything.
  - Allowed `modifiers`: all modifiers.
  - Allowed `types`: none.
- `variableLike` - matches the same as `variable`, `function` and `parameter`.
  - Allowed `modifiers`: `unused`.
  - Allowed `types`: none.
- `memberLike` - matches the same as `property`, `parameterProperty`, `method`, `accessor`, `enumMember`.
  - Allowed `modifiers`: `private`, `protected`, `public`, `static`, `readonly`, `abstract`, `requiresQuotes`.
  - Allowed `types`: none.
- `typeLike` - matches the same as `class`, `interface`, `typeAlias`, `enum`, `typeParameter`.
  - Allowed `modifiers`: `abstract`, `unused`.
  - Allowed `types`: none.
- `property` - matches the same as `classProperty`, `objectLiteralProperty`, `typeProperty`.
  - Allowed `modifiers`: `private`, `protected`, `public`, `static`, `readonly`, `abstract`, `requiresQuotes`.
  - Allowed `types`: `boolean`, `string`, `number`, `function`, `array`.
- `method` - matches the same as `classMethod`, `objectLiteralMethod`, `typeMethod`.
  - Allowed `modifiers`: `private`, `protected`, `public`, `static`, `readonly`, `abstract`, `requiresQuotes`.
  - Allowed `types`: none.

## FAQ

This is a big rule, and there's a lot of docs. Here are a few clarifications that people often ask about or figure out via trial-and-error.

### How does the rule evaluate a selector?

Each selector is checked in the following way:

1. check the `selector`
   1. if `selector` is one individual selector → the name's type must be of that type.
   1. if `selector` is a group selector → the name's type must be one of the grouped types.
   1. if `selector` is an array of selectors → apply the above for each selector in the array.
1. check the `filter`
   1. if `filter` is omitted → skip this step.
   1. if the name matches the `filter` → continue evaluating this selector.
   1. if the name does not match the `filter` → skip this selector and continue to the next selector.
1. check the `types`
   1. if `types` is omitted → skip this step.
   1. if the name has a type in `types` → continue evaluating this selector.
   1. if the name does not have a type in `types` → skip this selector and continue to the next selector.

A name is considered to pass the config if it:

1. Matches one selector and passes all of that selector's format checks.
2. Matches no selectors.

A name is considered to fail the config if it matches one selector and fails one that selector's format checks.

### How does the rule automatically order selectors?

Each identifier should match exactly one selector. It may match multiple group selectors - but only ever one selector.
With that in mind - the base sort order works out to be:

1. Individual Selectors
2. Grouped Selectors
3. Default Selector

Within each of these categories, some further sorting occurs based on what selector options are supplied:

1. `filter` is given the highest priority above all else.
2. `types`
3. `modifiers`
4. everything else

For example, if you provide the following config:

```ts
[
  /* 1 */ { selector: 'default', format: ['camelCase'] },
  /* 2 */ { selector: 'variable', format: ['snake_case'] },
  /* 3 */ { selector: 'variable', types: ['boolean'], format: ['UPPER_CASE'] },
  /* 4 */ { selector: 'variableLike', format: ['PascalCase'] },
];
```

Then for the code `const x = 1`, the rule will validate the selectors in the following order: `3`, `2`, `4`, `1`.
To clearly spell it out:

- (3) is tested first because it has `types` and is an individual selector.
- (2) is tested next because it is an individual selector.
- (4) is tested next as it is a grouped selector.
- (1) is tested last as it is the base default selector.

Its worth noting that whilst this order is applied, all selectors may not run on a name.
This is explained in ["How does the rule evaluate a name's format?"](#how-does-the-rule-evaluate-a-names-format)

### How does the rule evaluate a name's format?

When the format of an identifier is checked, it is checked in the following order:

1. validate leading underscore
1. validate trailing underscore
1. validate prefix
1. validate suffix
1. validate custom
1. validate format

For steps 1-4, if the identifier matches the option, the matching part will be removed.
This is done so that you can apply formats like PascalCase without worrying about prefixes or underscores causing it to not match.

One final note is that if the name were to become empty via this trimming process, it is considered to match all `format`s. An example of where this might be useful is for generic type parameters, where you want all names to be prefixed with `T`, but also want to allow for the single character `T` name.

Here are some examples to help illustrate

Name: `_IMyInterface`
Selector:

```json
{
  "leadingUnderscore": "require",
  "prefix": ["I"],
  "format": ["UPPER_CASE", "StrictPascalCase"]
}
```

1. `name = _IMyInterface`
1. validate leading underscore
   1. config is provided
   1. check name → pass
   1. Trim underscore → `name = IMyInterface`
1. validate trailing underscore
   1. config is not provided → skip
1. validate prefix
   1. config is provided
   1. check name → pass
   1. Trim prefix → `name = MyInterface`
1. validate suffix
   1. config is not provided → skip
1. validate custom
   1. config is not provided → skip
1. validate format
   1. for each format...
      1. `format = 'UPPER_CASE'`
         1. check format → fail.
            - Important to note that if you supply multiple formats - the name only needs to match _one_ of them!
      1. `format = 'StrictPascalCase'`
         1. check format → success.
1. **_success_**

Name: `IMyInterface`
Selector:

```json
{
  "format": ["StrictPascalCase"],
  "trailingUnderscore": "allow",
  "custom": {
    "regex": "^I[A-Z]",
    "match": false
  }
}
```

1. `name = IMyInterface`
1. validate leading underscore
   1. config is not provided → skip
1. validate trailing underscore
   1. config is provided
   1. check name → pass
   1. Trim underscore → `name = IMyInterface`
1. validate prefix
   1. config is not provided → skip
1. validate suffix
   1. config is not provided → skip
1. validate custom
   1. config is provided
   1. `regex = new RegExp("^I[A-Z]")`
   1. `regex.test(name) === custom.match`
   1. **_fail_** → report and exit

### What happens if I provide a `modifiers` to a Group Selector?

Some group selectors accept `modifiers`. For the most part these will work exactly the same as with individual selectors.
There is one exception to this in that a modifier might not apply to all individual selectors covered by a group selector.

For example - `memberLike` includes the `enumMember` selector, and it allows the `protected` modifier.
An `enumMember` can never ever be `protected`, which means that the following config will never match any `enumMember`:

```json
{
  "selector": "memberLike",
  "modifiers": ["protected"]
}
```

To help with matching, members that cannot specify an accessibility will always have the `public` modifier. This means that the following config will always match any `enumMember`:

```json
{
  "selector": "memberLike",
  "modifiers": ["public"]
}
```

## Examples

### Enforce that all variables, functions and properties follow are camelCase

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    { "selector": "variableLike", "format": ["camelCase"] }
  ]
}
```

### Enforce that private members are prefixed with an underscore

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "memberLike",
      "modifiers": ["private"],
      "format": ["camelCase"],
      "leadingUnderscore": "require"
    }
  ]
}
```

### Enforce that boolean variables are prefixed with an allowed verb

**Note:** As [documented above](#format-options), the prefix is trimmed before format is validated, thus PascalCase must be used to allow variables such as `isEnabled`.

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "variable",
      "types": ["boolean"],
      "format": ["PascalCase"],
      "prefix": ["is", "should", "has", "can", "did", "will"]
    }
  ]
}
```

### Enforce that all variables are either in camelCase or UPPER_CASE

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "variable",
      "format": ["camelCase", "UPPER_CASE"]
    }
  ]
}
```

### Enforce that all const variables are in UPPER_CASE

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "variable",
      "modifiers": ["const"],
      "format": ["UPPER_CASE"]
    }
  ]
}
```

### Enforce that type parameters (generics) are prefixed with `T`

This allows you to emulate the old `generic-type-naming` rule.

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "typeParameter",
      "format": ["PascalCase"],
      "prefix": ["T"]
    }
  ]
}
```

### Enforce that interface names do not begin with an `I`

This allows you to emulate the old `interface-name-prefix` rule.

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "interface",
      "format": ["PascalCase"],
      "custom": {
        "regex": "^I[A-Z]",
        "match": false
      }
    }
  ]
}
```

### Enforce that variable and function names are in camelCase

This allows you to lint multiple type with same pattern.

```json
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": ["variable", "function"],
      "format": ["camelCase"],
      "leadingUnderscore": "allow"
    }
  ]
}
```

### Ignore properties that **_require_** quotes

Sometimes you have to use a quoted name that breaks the convention (for example, HTTP headers).
If this is a common thing in your codebase, then you have a few options.

If you simply want to allow all property names that require quotes, you can use the `requiresQuotes` modifier to match any property name that _requires_ quoting, and use `format: null` to ignore the name.

```jsonc
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": [
        "classProperty",
        "objectLiteralProperty",
        "typeProperty",
        "classMethod",
        "objectLiteralMethod",
        "typeMethod",
        "accessor",
        "enumMember"
      ],
      "format": null,
      "modifiers": ["requiresQuotes"]
    }
  ]
}
```

If you have a small and known list of exceptions, you can use the `filter` option to ignore these specific names only:

```jsonc
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "property",
      "format": ["strictCamelCase"],
      "filter": {
        // you can expand this regex to add more allowed names
        "regex": "^(Property-Name-One|Property-Name-Two)$",
        "match": false
      }
    }
  ]
}
```

You can use the `filter` option to ignore names with specific characters:

```jsonc
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "property",
      "format": ["strictCamelCase"],
      "filter": {
        // you can expand this regex as you find more cases that require quoting that you want to allow
        "regex": "[- ]",
        "match": false
      }
    }
  ]
}
```

Note that there is no way to ignore any name that is quoted - only names that are required to be quoted.
This is intentional - adding quotes around a name is not an escape hatch for proper naming.
If you want an escape hatch for a specific name - you should can use an [`eslint-disable` comment](https://eslint.org/docs/user-guide/configuring#disabling-rules-with-inline-comments).

### Ignore destructured names

Sometimes you might want to allow destructured properties to retain their original name, even if it breaks your naming convention.

You can use the `destructured` modifier to match these names, and explicitly set `format: null` to apply no formatting:

```jsonc
{
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "variable",
      "modifiers": ["destructured"],
      "format": null
    }
  ]
}
```

### Enforce the codebase follows ESLint's `camelcase` conventions

```json
{
  "camelcase": "off",
  "@typescript-eslint/naming-convention": [
    "error",
    {
      "selector": "default",
      "format": ["camelCase"]
    },

    {
      "selector": "variable",
      "format": ["camelCase", "UPPER_CASE"]
    },
    {
      "selector": "parameter",
      "format": ["camelCase"],
      "leadingUnderscore": "allow"
    },

    {
      "selector": "memberLike",
      "modifiers": ["private"],
      "format": ["camelCase"],
      "leadingUnderscore": "require"
    },

    {
      "selector": "typeLike",
      "format": ["PascalCase"]
    }
  ]
}
```

## When Not To Use It

If you do not want to enforce naming conventions for anything.
# `switch-exhaustiveness-check`

Requires switch-case statements to be exhaustive with union type.

Union type may have a lot of parts. It's easy to forget to consider all cases in switch. This rule reminds which parts are missing. If domain of the problem requires to have only a partial switch, developer may _explicitly_ add a default clause.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
type Day =
  | 'Monday'
  | 'Tuesday'
  | 'Wednesday'
  | 'Thursday'
  | 'Friday'
  | 'Saturday'
  | 'Sunday';

const day = 'Monday' as Day;
let result = 0;

switch (day) {
  case 'Monday': {
    result = 1;
    break;
  }
}
```

### ✅ Correct

```ts
type Day =
  | 'Monday'
  | 'Tuesday'
  | 'Wednesday'
  | 'Thursday'
  | 'Friday'
  | 'Saturday'
  | 'Sunday';

const day = 'Monday' as Day;
let result = 0;

switch (day) {
  case 'Monday': {
    result = 1;
    break;
  }
  case 'Tuesday': {
    result = 2;
    break;
  }
  case 'Wednesday': {
    result = 3;
    break;
  }
  case 'Thursday': {
    result = 4;
    break;
  }
  case 'Friday': {
    result = 5;
    break;
  }
  case 'Saturday': {
    result = 6;
    break;
  }
  case 'Sunday': {
    result = 7;
    break;
  }
}
```

### ✅ Correct

```ts
type Day =
  | 'Monday'
  | 'Tuesday'
  | 'Wednesday'
  | 'Thursday'
  | 'Friday'
  | 'Saturday'
  | 'Sunday';

const day = 'Monday' as Day;
let result = 0;

switch (day) {
  case 'Monday': {
    result = 1;
    break;
  }
  default: {
    result = 42;
  }
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/switch-exhaustiveness-check": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If program doesn't have union types with many parts. Downside of this rule is the need for type information, so it's slower than regular rules.
# `no-implicit-any-catch`

Disallows usage of the implicit `any` type in catch clauses.

TypeScript 4.0 added support for adding an explicit `any` or `unknown` type annotation on a catch clause variable.

By default, TypeScript will type a catch clause variable as `any`, so explicitly annotating it as `unknown` can add a lot of safety to your codebase.

The `noImplicitAny` flag in TypeScript does not cover this for backwards compatibility reasons, however you can use `useUnknownInCatchVariables` (part of `strict`) instead of this rule.

## DEPRECATED

## Rule Details

This rule requires an explicit type to be declared on a catch clause variable.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
try {
  // ...
} catch (e) {
  // ...
}
```

### ✅ Correct

<!-- TODO: prettier currently removes the type annotations, re-enable this once prettier is updated -->
<!-- prettier-ignore-start -->

```ts
try {
  // ...
} catch (e: unknown) {
  // ...
}
```

<!-- prettier-ignore-end -->

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if false, disallow specifying `: any` as the error type as well. See also `no-explicit-any`
  allowExplicitAny: boolean;
};

const defaults = {
  allowExplicitAny: false,
};
```

### `allowExplicitAny`

The follow is is **_not_** considered a warning with `{ allowExplicitAny: true }`

<!-- TODO: prettier currently removes the type annotations, re-enable this once prettier is updated -->
<!-- prettier-ignore-start -->

```ts
try {
  // ...
} catch (e: any) {
  // ...
}
```

<!-- prettier-ignore-end -->

## When Not To Use It

If you are not using TypeScript 4.0 (or greater), then you will not be able to use this rule, annotations on catch clauses is not supported.

## Further Reading

- [TypeScript 4.0 Release Notes](https://devblogs.microsoft.com/typescript/announcing-typescript-4-0/#unknown-on-catch)
# `prefer-literal-enum-member`

Requires all enum members to be literal values.

TypeScript allows the value of an enum member to be many different kinds of valid JavaScript expressions. However, because enums create their own scope whereby each enum member becomes a variable in that scope, unexpected values could be used at runtime. Example:

```ts
const imOutside = 2;
const b = 2;
enum Foo {
  outer = imOutside,
  a = 1,
  b = a,
  c = b,
  // does c == Foo.b == Foo.c == 1?
  // or does c == b == 2?
}
```

The answer is that `Foo.c` will be `1` at runtime. The [playground](https://www.typescriptlang.org/play/#src=const%20imOutside%20%3D%202%3B%0D%0Aconst%20b%20%3D%202%3B%0D%0Aenum%20Foo%20%7B%0D%0A%20%20%20%20outer%20%3D%20imOutside%2C%0D%0A%20%20%20%20a%20%3D%201%2C%0D%0A%20%20%20%20b%20%3D%20a%2C%0D%0A%20%20%20%20c%20%3D%20b%2C%0D%0A%20%20%20%20%2F%2F%20does%20c%20%3D%3D%20Foo.b%20%3D%3D%20Foo.c%20%3D%3D%201%3F%0D%0A%20%20%20%20%2F%2F%20or%20does%20c%20%3D%3D%20b%20%3D%3D%202%3F%0D%0A%7D) illustrates this quite nicely.

## Rule Details

This rule is meant to prevent unexpected results in code by requiring the use of literal values as enum members to prevent unexpected runtime behavior. Template literals, arrays, objects, constructors, and all other expression types can end up using a variable from its scope or the parent scope, which can result in the same unexpected behavior at runtime.

## Options

- `allowBitwiseExpressions` set to `true` will allow you to use bitwise expressions in enum initializer (Default: `false`).

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const str = 'Test';
enum Invalid {
  A = str, // Variable assignment
  B = {}, // Object assignment
  C = `A template literal string`, // Template literal
  D = new Set(1, 2, 3), // Constructor in assignment
  E = 2 + 2, // Expression assignment
}
```

### ✅ Correct

```ts
enum Valid {
  A,
  B = 'TestStr', // A regular string
  C = 4, // A number
  D = null,
  E = /some_regex/,
}
```

<!--/tabs-->

### `allowBitwiseExpressions`

Examples of code for the `{ "allowBitwiseExpressions": true }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
const x = 1;
enum Foo {
  A = x << 0,
  B = x >> 0,
  C = x >>> 0,
  D = x | 0,
  E = x & 0,
  F = x ^ 0,
  G = ~x,
}
```

#### ✅ Correct

```ts
enum Foo {
  A = 1 << 0,
  B = 1 >> 0,
  C = 1 >>> 0,
  D = 1 | 0,
  E = 1 & 0,
  F = 1 ^ 0,
  G = ~1,
}
```

## When Not To Use It

If you want use anything other than simple literals as an enum value.
# `no-unsafe-assignment`

Disallows assigning a value with type `any` to variables and properties.

Despite your best intentions, the `any` type can sometimes leak into your codebase.
Assigning an `any` typed value to a variable can be hard to pick up on, particularly if it leaks in from an external library. Operations on the variable will not be checked at all by TypeScript, so it creates a potential safety hole, and source of bugs in your codebase.

## Rule Details

This rule disallows assigning `any` to a variable, and assigning `any[]` to an array destructuring.
This rule also compares the assigned type to the variable's type to ensure you don't assign an unsafe `any` in a generic position to a receiver that's expecting a specific type. For example, it will error if you assign `Set<any>` to a variable declared as `Set<string>`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const x = 1 as any,
  y = 1 as any;
const [x] = 1 as any;
const [x] = [] as any[];
const [x] = [1 as any];
[x] = [1] as [any];

function foo(a = 1 as any) {}
class Foo {
  constructor(private a = 1 as any) {}
}
class Foo {
  private a = 1 as any;
}

// generic position examples
const x: Set<string> = new Set<any>();
const x: Map<string, string> = new Map<string, any>();
const x: Set<string[]> = new Set<any[]>();
const x: Set<Set<Set<string>>> = new Set<Set<Set<any>>>();
```

### ✅ Correct

```ts
const x = 1,
  y = 1;
const [x] = [1];
[x] = [1] as [number];

function foo(a = 1) {}
class Foo {
  constructor(private a = 1) {}
}
class Foo {
  private a = 1;
}

// generic position examples
const x: Set<string> = new Set<string>();
const x: Map<string, string> = new Map<string, string>();
const x: Set<string[]> = new Set<string[]>();
const x: Set<Set<Set<string>>> = new Set<Set<Set<string>>>();
```

<!--/tabs-->

There are cases where the rule allows assignment of `any` to `unknown`.

Example of `any` to `unknown` assignment that are allowed.

```ts
const x: unknown = y as any;
const x: unknown[] = y as any[];
const x: Set<unknown> = y as Set<any>;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unsafe-assignment": "error"
  }
}
```

This rule is not configurable.

## Related To

- [`no-explicit-any`](./no-explicit-any.md)
# `no-unsafe-call`

Disallows calling a value with type `any`.

Despite your best intentions, the `any` type can sometimes leak into your codebase.
The arguments to, and return value of calling an `any` typed variable are not checked at all by TypeScript, so it creates a potential safety hole, and source of bugs in your codebase.

## Rule Details

This rule disallows calling any variable that is typed as `any`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
declare const anyVar: any;
declare const nestedAny: { prop: any };

anyVar();
anyVar.a.b();

nestedAny.prop();
nestedAny.prop['a']();

new anyVar();
new nestedAny.prop();

anyVar`foo`;
nestedAny.prop`foo`;
```

### ✅ Correct

```ts
declare const typedVar: () => void;
declare const typedNested: { prop: { a: () => void } };

typedVar();
typedNested.prop.a();

(() => {})();

new Map();

String.raw`foo`;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unsafe-call": "error"
  }
}
```

This rule is not configurable.

## Related To

- [`no-explicit-any`](./no-explicit-any.md)
# `consistent-type-definitions`

Enforces type definitions to consistently use either `interface` or `type`.

There are two ways to define a type.

```ts
// type alias
type T1 = {
  a: string;
  b: number;
};

// interface keyword
interface T2 {
  a: string;
  b: number;
}
```

## Options

This rule accepts one string option:

- `"interface"`: enforce using `interface`s for object type definitions.
- `"type"`: enforce using `type`s for object type definitions.

For example:

```jsonc
{
  // Use type for object definitions
  "@typescript-eslint/consistent-type-definitions": ["error", "type"]
}
```

### `interface`

Examples of code with `interface` option.

<!--tabs-->

#### ❌ Incorrect

```ts
type T = { x: number };
```

#### ✅ Correct

```ts
type T = string;
type Foo = string | {};

interface T {
  x: number;
}
```

### `type`

Examples of code with `type` option.

<!--tabs-->

#### ❌ Incorrect

```ts
interface T {
  x: number;
}
```

#### ✅ Correct

```ts
type T = { x: number };
```

## When Not To Use It

If you specifically want to use an interface or type literal for stylistic reasons, you can disable this rule.
# `class-literal-property-style`

Enforces that literals on classes are exposed in a consistent style.

When writing TypeScript applications, it's typically safe to store literal values on classes using fields with the `readonly` modifier to prevent them from being reassigned.
When writing TypeScript libraries that could be used by JavaScript users however, it's typically safer to expose these literals using `getter`s, since the `readonly` modifier is enforced at compile type.

## Rule Details

This rule aims to ensure that literals exposed by classes are done so consistently, in one of the two style described above.
By default this rule prefers the `fields` style as it means JS doesn't have to setup & teardown a function closure.

:::note

This rule only checks for constant _literal_ values (string, template string, number, bigint, boolean, regexp, null). It does not check objects or arrays, because a readonly field behaves differently to a getter in those cases. It also does not check functions, as it is a common pattern to use readonly fields with arrow function values as auto-bound methods.
This is because these types can be mutated and carry with them more complex implications about their usage.

:::

### The `fields` style

This style checks for any getter methods that return literal values, and requires them to be defined using fields with the `readonly` modifier instead.

Examples of code with the `fields` style:

<!--tabs-->

#### ❌ Incorrect

```ts
/* eslint @typescript-eslint/class-literal-property-style: ["error", "fields"] */

class Mx {
  public static get myField1() {
    return 1;
  }

  private get ['myField2']() {
    return 'hello world';
  }
}
```

#### ✅ Correct

```ts
/* eslint @typescript-eslint/class-literal-property-style: ["error", "fields"] */

class Mx {
  public readonly myField1 = 1;

  // not a literal
  public readonly myField2 = [1, 2, 3];

  private readonly ['myField3'] = 'hello world';

  public get myField4() {
    return `hello from ${window.location.href}`;
  }
}
```

### The `getters` style

This style checks for any `readonly` fields that are assigned literal values, and requires them to be defined as getters instead.
This style pairs well with the [`@typescript-eslint/prefer-readonly`](prefer-readonly.md) rule,
as it will identify fields that can be `readonly`, and thus should be made into getters.

Examples of code with the `getters` style:

<!--tabs-->

#### ❌ Incorrect

```ts
/* eslint @typescript-eslint/class-literal-property-style: ["error", "getters"] */

class Mx {
  readonly myField1 = 1;
  readonly myField2 = `hello world`;
  private readonly myField3 = 'hello world';
}
```

#### ✅ Correct

```ts
/* eslint @typescript-eslint/class-literal-property-style: ["error", "getters"] */

class Mx {
  // no readonly modifier
  public myField1 = 'hello';

  // not a literal
  public readonly myField2 = [1, 2, 3];

  public static get myField3() {
    return 1;
  }

  private get ['myField4']() {
    return 'hello world';
  }
}
```

## When Not To Use It

When you have no strong preference, or do not wish to enforce a particular style
for how literal values are exposed by your classes.
# `quotes`

Enforces the consistent use of either backticks, double, or single quotes.

## Rule Details

This rule extends the base [`eslint/quotes`](https://eslint.org/docs/rules/quotes) rule.
It adds support for TypeScript features which allow quoted names, but not backtick quoted names.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "quotes": "off",
  "@typescript-eslint/quotes": ["error"]
}
```

## Options

See [`eslint/quotes` options](https://eslint.org/docs/rules/quotes#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/quotes.md)

</sup>
# `member-delimiter-style`

Requires a specific member delimiter style for interfaces and type literals.

Enforces a consistent member delimiter style in interfaces and type literals. There are three member delimiter styles primarily used in TypeScript:

- Semicolon style (default, preferred in TypeScript).

<!-- prettier-ignore -->
```ts
interface Foo {
    name: string;
    greet(): void;
}

type Bar = {
    name: string;
    greet(): void;
}
```

- Comma style (JSON style).

<!-- prettier-ignore -->
```ts
interface Foo {
    name: string,
    greet(): void,
}

type Bar = {
    name: string,
    greet(): void,
}
```

- Line break (none) style.

<!-- prettier-ignore -->
```ts
interface Foo {
    name: string
    greet(): void
}

type Bar = {
    name: string
    greet(): void
}
```

The rule also enforces the presence (or absence) of the delimiter in the last member of the interface and/or type literal.
Finally, this rule can enforce separate delimiter syntax for single line declarations.

## Rule Details

This rule aims to standardize the way interface and type literal members are delimited.

## Options

```ts
interface BaseConfig {
  multiline?: {
    delimiter?: 'none' | 'semi' | 'comma';
    requireLast?: boolean;
  };
  singleline?: {
    delimiter?: 'semi' | 'comma';
    requireLast?: boolean;
  };
}
type Config = BaseConfig & {
  overrides?: {
    interface?: BaseConfig;
    typeLiteral?: BaseConfig;
  };
  multilineDetection?: 'brackets' | 'last-member';
};
```

Default config:

```json
{
  "multiline": {
    "delimiter": "semi",
    "requireLast": true
  },
  "singleline": {
    "delimiter": "semi",
    "requireLast": false
  },
  "multilineDetection": "brackets"
}
```

`multiline` config only applies to multiline `interface`/`type` definitions.
`singleline` config only applies to single line `interface`/`type` definitions.
The two configs are entirely separate, and do not effect one another.

`multilineDetection` determines what counts as multiline

- `"brackets"` (default) any newlines in the type or interface make it multiline.
- `"last-member"` if the last member of the interface is on the same line as the last bracket, it is counted as a single line.

### `delimiter`

Accepts three values (or two for `singleline`):

- `comma` - each member should be delimited with a comma (`,`).
- `semi` - each member should be delimited with a semicolon (`;`).
- `none` - each member should be delimited with nothing.

:::note
`none` is not an option for `singleline` because having no delimiter between members on a single line is a syntax error in TS.
:::

### `requireLast`

Determines whether or not the last member in the `interface`/`type` should have a delimiter:

- `true` - the last member **_must_** have a delimiter.
- `false` - the last member **_must not_** have a delimiter.

### `overrides`

Allows you to specify options specifically for either `interface`s or `type` definitions / inline `type`s.

For example, to require commas for `type`s, and semicolons for multiline `interface`s:

```json
{
  "multiline": {
    "delimiter": "comma",
    "requireLast": true
  },
  "singleline": {
    "delimiter": "comma",
    "requireLast": true
  },
  "overrides": {
    "interface": {
      "multiline": {
        "delimiter": "semi",
        "requireLast": true
      }
    }
  }
}
```

## Examples

Examples of code for this rule with the default config:

<!--tabs-->

### ❌ Incorrect

<!-- prettier-ignore -->
```ts
// missing semicolon delimiter
interface Foo {
    name: string
    greet(): string
}

// using incorrect delimiter
interface Bar {
    name: string,
    greet(): string,
}

// missing last member delimiter
interface Baz {
    name: string;
    greet(): string
}

// incorrect delimiter
type FooBar = { name: string, greet(): string }

// last member should not have delimiter
type FooBar = { name: string; greet(): string; }
```

### ✅ Correct

<!-- prettier-ignore -->
```ts
interface Foo {
    name: string;
    greet(): string;
}

interface Foo { name: string }

type Bar = {
    name: string;
    greet(): string;
}

type Bar = { name: string }

type FooBar = { name: string; greet(): string }
```

## When Not To Use It

If you don't care about enforcing a consistent member delimiter in interfaces and type literals, then you will not need this rule.
# `no-duplicate-imports`

Disallows duplicate imports.

## DEPRECATED

This rule has been deprecated in favour of the [`import/no-duplicates`](https://github.com/import-js/eslint-plugin-import/blob/HEAD/docs/rules/no-duplicates.md) rule.

## Rule Details

This rule extends the base [`eslint/no-duplicate-imports`](https://eslint.org/docs/rules/no-duplicate-imports) rule.
This version adds support for type-only import and export.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-duplicate-imports": "off",
  "@typescript-eslint/no-duplicate-imports": ["error"]
}
```

## Options

See [`eslint/no-duplicate-imports` options](https://eslint.org/docs/rules/no-duplicate-imports#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-duplicate-imports.md)

</sup>
# `no-loss-of-precision`

Disallows literal numbers that lose precision.

## Rule Details

This rule extends the base [`eslint/no-loss-of-precision`](https://eslint.org/docs/rules/no-loss-of-precision) rule.
It adds support for [numeric separators](https://github.com/tc39/proposal-numeric-separator).
Note that this rule requires ESLint v7.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-loss-of-precision": "off",
  "@typescript-eslint/no-loss-of-precision": ["error"]
}
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-loss-of-precision.md)

</sup>
# `no-throw-literal`

Disallows throwing literals as exceptions.

It is considered good practice to only `throw` the `Error` object itself or an object using the `Error` object as base objects for user-defined exceptions.
The fundamental benefit of `Error` objects is that they automatically keep track of where they were built and originated.

This rule restricts what can be thrown as an exception. When it was first created, it only prevented literals from being thrown (hence the name), but it has now been expanded to only allow expressions which have a possibility of being an `Error` object. With the `allowThrowingAny` and `allowThrowingUnknown`, it can be configured to only allow throwing values which are guaranteed to be an instance of `Error`.

## Rule Details

This rule is aimed at maintaining consistency when throwing exception by disallowing to throw literals and other expressions which cannot possibly be an `Error` object.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
/*eslint @typescript-eslint/no-throw-literal: "error"*/

throw 'error';

throw 0;

throw undefined;

throw null;

const err = new Error();
throw 'an ' + err;

const err = new Error();
throw `${err}`;

const err = '';
throw err;

function err() {
  return '';
}
throw err();

const foo = {
  bar: '',
};
throw foo.bar;
```

### ✅ Correct

```ts
/*eslint @typescript-eslint/no-throw-literal: "error"*/

throw new Error();

throw new Error("error");

const e = new Error("error");
throw e;

try {
    throw new Error("error");
} catch (e) {
    throw e;
}

const err = new Error();
throw err;

function err() {
  return new Error();
}
throw err();

const foo = {
  bar: new Error();
}
throw foo.bar;

class CustomError extends Error {
  // ...
};
throw new CustomError();
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-throw-literal": "off",
  "@typescript-eslint/no-throw-literal": ["error"]
}
```

### Options

```jsonc
{
  "@typescript-eslint/no-throw-literal": [
    "error",
    {
      "allowThrowingAny": true, // Default is to allow throwing values of type any
      "allowThrowingUnknown": true // Default is to allow throwing values of type unknown
    }
  ]
}
```

---

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-throw-literal.md)

</sup>
# `unbound-method`

Enforces unbound methods are called with their expected scope.

Warns when a method is used outside of a method call.

Class functions don't preserve the class scope when passed as standalone variables.

If your function does not access `this`, [you can annotate it with `this: void`](https://www.typescriptlang.org/docs/handbook/2/functions.html#declaring-this-in-a-function), or consider using an arrow function instead.

If you're working with `jest`, you can use [`eslint-plugin-jest`'s version of this rule](https://github.com/jest-community/eslint-plugin-jest/blob/main/docs/rules/unbound-method.md) to lint your test files, which knows when it's ok to pass an unbound method to `expect` calls.

## Rule Details

Examples of code for this rule

<!--tabs-->

### ❌ Incorrect

```ts
class MyClass {
  public log(): void {
    console.log(this);
  }
}

const instance = new MyClass();

// This logs the global scope (`window`/`global`), not the class instance
const myLog = instance.log;
myLog();

// This log might later be called with an incorrect scope
const { log } = instance;

// arith.double may refer to `this` internally
const arith = {
  double(x: number): number {
    return x * 2;
  },
};
const { double } = arith;
```

### ✅ Correct

```ts
class MyClass {
  public logUnbound(): void {
    console.log(this);
  }

  public logBound = () => console.log(this);
}

const instance = new MyClass();

// logBound will always be bound with the correct scope
const { logBound } = instance;
logBound();

// .bind and lambdas will also add a correct scope
const dotBindLog = instance.logBound.bind(instance);
const innerLog = () => instance.logBound();

// arith.double explicitly declares that it does not refer to `this` internally
const arith = {
  double(this: void, x: number): number {
    return x * 2;
  },
};
const { double } = arith;
```

## Options

The rule accepts an options object with the following property:

- `ignoreStatic` to not check whether `static` methods are correctly bound

### `ignoreStatic`

Examples of **correct** code for this rule with `{ ignoreStatic: true }`:

```ts
class OtherClass {
  static log() {
    console.log(OtherClass);
  }
}

// With `ignoreStatic`, statics are assumed to not rely on a particular scope
const { log } = OtherClass;

log();
```

## Example

```json
{
  "@typescript-eslint/unbound-method": [
    "error",
    {
      "ignoreStatic": true
    }
  ]
}
```

## When Not To Use It

If your code intentionally waits to bind methods after use, such as by passing a `scope: this` along with the method, you can disable this rule.

If you're wanting to use `toBeCalled` and similar matches in `jest` tests, you can disable this rule for your test files in favor of [`eslint-plugin-jest`'s version of this rule](https://github.com/jest-community/eslint-plugin-jest/blob/main/docs/rules/unbound-method.md).
# `consistent-indexed-object-style`

Requires or disallows the `Record` type.

TypeScript supports defining object show keys can be flexible using an index signature. TypeScript also has a builtin type named `Record` to create an empty object defining only an index signature. For example, the following types are equal:

```ts
interface Foo {
  [key: string]: unknown;
}

type Foo = {
  [key: string]: unknown;
};

type Foo = Record<string, unknown>;
```

## Options

- `"record"`: Set to `"record"` to only allow the `Record` type. Set to `"index-signature"` to only allow index signatures. (Defaults to `"record"`)

For example:

```json
{
  "@typescript-eslint/consistent-indexed-object-style": [
    "error",
    "index-signature"
  ]
}
```

## Rule Details

This rule enforces a consistent way to define records.

### `record`

Examples of code with `record` option.

<!--tabs-->

#### ❌ Incorrect

```ts
interface Foo {
  [key: string]: unknown;
}

type Foo = {
  [key: string]: unknown;
};
```

#### ✅ Correct

```ts
type Foo = Record<string, unknown>;
```

### `index-signature`

Examples of code with `index-signature` option.

<!--tabs-->

#### ❌ Incorrect

```ts
type Foo = Record<string, unknown>;
```

#### ✅ Correct

```ts
interface Foo {
  [key: string]: unknown;
}

type Foo = {
  [key: string]: unknown;
};
```
# `prefer-optional-chain`

Enforces using concise optional chain expressions instead of chained logical ands.

TypeScript 3.7 added support for the optional chain operator.
This operator allows you to safely access properties and methods on objects when they are potentially `null` or `undefined`.

```ts
type T = {
  a?: {
    b?: {
      c: string;
      method?: () => void;
    };
  };
};

function myFunc(foo: T | null) {
  return foo?.a?.b?.c;
}
// is roughly equivalent to
function myFunc(foo: T | null) {
  return foo && foo.a && foo.a.b && foo.a.b.c;
}
// or
function myFunc(foo: T | null) {
  return (((foo || {}).a || {}).b || {}).c;
}

function myFunc(foo: T | null) {
  return foo?.['a']?.b?.c;
}
// is roughly equivalent to
function myFunc(foo: T | null) {
  return foo && foo['a'] && foo['a'].b && foo['a'].b.c;
}

function myFunc(foo: T | null) {
  return foo?.a?.b?.method?.();
}
// is roughly equivalent to
function myFunc(foo: T | null) {
  return foo && foo.a && foo.a.b && foo.a.b.method && foo.a.b.method();
}
```

Because the optional chain operator _only_ chains when the property value is `null` or `undefined`, it is much safer than relying upon logical AND operator chaining `&&`; which chains on any _truthy_ value.

## Rule Details

This rule aims enforce the usage of the safer operator.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
foo && foo.a && foo.a.b && foo.a.b.c;
foo && foo['a'] && foo['a'].b && foo['a'].b.c;
foo && foo.a && foo.a.b && foo.a.b.method && foo.a.b.method();

(((foo || {}).a || {}).b || {}).c;
(((foo || {})['a'] || {}).b || {}).c;

// this rule also supports converting chained strict nullish checks:
foo &&
  foo.a != null &&
  foo.a.b !== null &&
  foo.a.b.c != undefined &&
  foo.a.b.c.d !== undefined &&
  foo.a.b.c.d.e;
```

### ✅ Correct

```ts
foo?.a?.b?.c;
foo?.['a']?.b?.c;
foo?.a?.b?.method?.();

foo?.a?.b?.c?.d?.e;
```

**Note:** there are a few edge cases where this rule will false positive. Use your best judgement when evaluating reported errors.

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-optional-chain": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are not using TypeScript 3.7 (or greater), then you will not be able to use this rule, as the operator is not supported.

## Further Reading

- [TypeScript 3.7 Release Notes](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html)
- [Optional Chaining Proposal](https://github.com/tc39/proposal-optional-chaining/)
# `brace-style`

Enforces consistent brace style for blocks.

## Rule Details

This rule extends the base [`eslint/brace-style`](https://eslint.org/docs/rules/brace-style) rule.
It adds support for `enum`, `interface`, `namespace` and `module` declarations.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "brace-style": "off",
  "@typescript-eslint/brace-style": ["error"]
}
```

## Options

See [`eslint/brace-style` options](https://eslint.org/docs/rules/brace-style#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/brace-style.md)

</sup>
# `no-unused-vars`

Disallows unused variables.

## Rule Details

This rule extends the base [`eslint/no-unused-vars`](https://eslint.org/docs/rules/no-unused-vars) rule.
It adds support for TypeScript features, such as types.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-unused-vars": "off",
  "@typescript-eslint/no-unused-vars": ["error"]
}
```

## Options

See [`eslint/no-unused-vars` options](https://eslint.org/docs/rules/no-unused-vars#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-unused-vars.md)

</sup>
---
title: Overview
sidebar_label: Overview
pagination_next: null
pagination_prev: null
slug: /
---

`@typescript-eslint/eslint-plugin` includes over 100 rules that detect best practice violations, bugs, and/or stylistic issues specifically for TypeScript code.
See [Configs](/docs/linting/configs) for how to enable recommended rules using configs.

## Supported Rules

<!-- begin base rule list -->

**Key**: :white_check_mark: = recommended, :lock: = strict, :wrench: = fixable, :thought_balloon: = requires type information

| Name                                                                                                         | Description                                                                                                  | :white_check_mark::lock: | :wrench: | :thought_balloon: |
| ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------ | ------------------------ | -------- | ----------------- |
| [`@typescript-eslint/adjacent-overload-signatures`](./adjacent-overload-signatures.md)                       | Require that member overloads be consecutive                                                                 | :white_check_mark:       |          |                   |
| [`@typescript-eslint/array-type`](./array-type.md)                                                           | Require using either `T[]` or `Array<T>` for arrays                                                          | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/await-thenable`](./await-thenable.md)                                                   | Disallow awaiting a value that is not a Thenable                                                             | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/ban-ts-comment`](./ban-ts-comment.md)                                                   | Disallow `@ts-<directive>` comments or require descriptions after directive                                  | :white_check_mark:       |          |                   |
| [`@typescript-eslint/ban-tslint-comment`](./ban-tslint-comment.md)                                           | Disallow `// tslint:<rule-flag>` comments                                                                    | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/ban-types`](./ban-types.md)                                                             | Disallow certain types                                                                                       | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/class-literal-property-style`](./class-literal-property-style.md)                       | Enforce that literals on classes are exposed in a consistent style                                           | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-generic-constructors`](./consistent-generic-constructors.md)                 | Enforce specifying generic type arguments on type annotation or constructor name of a constructor call       | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-indexed-object-style`](./consistent-indexed-object-style.md)                 | Require or disallow the `Record` type                                                                        | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-type-assertions`](./consistent-type-assertions.md)                           | Enforce consistent usage of type assertions                                                                  | :lock:                   |          |                   |
| [`@typescript-eslint/consistent-type-definitions`](./consistent-type-definitions.md)                         | Enforce type definitions to consistently use either `interface` or `type`                                    | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-type-exports`](./consistent-type-exports.md)                                 | Enforce consistent usage of type exports                                                                     |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/consistent-type-imports`](./consistent-type-imports.md)                                 | Enforce consistent usage of type imports                                                                     |                          | :wrench: |                   |
| [`@typescript-eslint/explicit-function-return-type`](./explicit-function-return-type.md)                     | Require explicit return types on functions and class methods                                                 |                          |          |                   |
| [`@typescript-eslint/explicit-member-accessibility`](./explicit-member-accessibility.md)                     | Require explicit accessibility modifiers on class properties and methods                                     |                          | :wrench: |                   |
| [`@typescript-eslint/explicit-module-boundary-types`](./explicit-module-boundary-types.md)                   | Require explicit return and argument types on exported functions' and classes' public class methods          |                          |          |                   |
| [`@typescript-eslint/member-delimiter-style`](./member-delimiter-style.md)                                   | Require a specific member delimiter style for interfaces and type literals                                   |                          | :wrench: |                   |
| [`@typescript-eslint/member-ordering`](./member-ordering.md)                                                 | Require a consistent member declaration order                                                                |                          |          |                   |
| [`@typescript-eslint/method-signature-style`](./method-signature-style.md)                                   | Enforce using a particular method signature syntax                                                           |                          | :wrench: |                   |
| [`@typescript-eslint/naming-convention`](./naming-convention.md)                                             | Enforce naming conventions for everything across a codebase                                                  |                          |          | :thought_balloon: |
| [`@typescript-eslint/no-base-to-string`](./no-base-to-string.md)                                             | Require `.toString()` to only be called on objects which provide useful information when stringified         | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/no-confusing-non-null-assertion`](./no-confusing-non-null-assertion.md)                 | Disallow non-null assertion in locations that may be confusing                                               | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/no-confusing-void-expression`](./no-confusing-void-expression.md)                       | Require expressions of type void to appear in statement position                                             |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-duplicate-enum-values`](./no-duplicate-enum-values.md)                               | Disallow duplicate enum member values                                                                        | :lock:                   |          |                   |
| [`@typescript-eslint/no-dynamic-delete`](./no-dynamic-delete.md)                                             | Disallow using the `delete` operator on computed key expressions                                             | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/no-empty-interface`](./no-empty-interface.md)                                           | Disallow the declaration of empty interfaces                                                                 | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-explicit-any`](./no-explicit-any.md)                                                 | Disallow the `any` type                                                                                      | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-extra-non-null-assertion`](./no-extra-non-null-assertion.md)                         | Disallow extra non-null assertion                                                                            | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-extraneous-class`](./no-extraneous-class.md)                                         | Disallow classes used as namespaces                                                                          | :lock:                   |          |                   |
| [`@typescript-eslint/no-floating-promises`](./no-floating-promises.md)                                       | Require Promise-like statements to be handled appropriately                                                  | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-for-in-array`](./no-for-in-array.md)                                                 | Disallow iterating over an array with a for-in loop                                                          | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-inferrable-types`](./no-inferrable-types.md)                                         | Disallow explicit type declarations for variables or parameters initialized to a number, string, or boolean  | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-invalid-void-type`](./no-invalid-void-type.md)                                       | Disallow `void` type outside of generic or return types                                                      | :lock:                   |          |                   |
| [`@typescript-eslint/no-meaningless-void-operator`](./no-meaningless-void-operator.md)                       | Disallow the `void` operator except when used to discard a value                                             | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-misused-new`](./no-misused-new.md)                                                   | Enforce valid definition of `new` and `constructor`                                                          | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-misused-promises`](./no-misused-promises.md)                                         | Disallow Promises in places not designed to handle them                                                      | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-namespace`](./no-namespace.md)                                                       | Disallow custom TypeScript modules and namespaces                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-non-null-asserted-nullish-coalescing`](./no-non-null-asserted-nullish-coalescing.md) | Disallow non-null assertions in the left operand of a nullish coalescing operator                            | :lock:                   |          |                   |
| [`@typescript-eslint/no-non-null-asserted-optional-chain`](./no-non-null-asserted-optional-chain.md)         | Disallow non-null assertions after an optional chain expression                                              | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-non-null-assertion`](./no-non-null-assertion.md)                                     | Disallow non-null assertions using the `!` postfix operator                                                  | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-redundant-type-constituents`](./no-redundant-type-constituents.md)                   | Disallow members of unions and intersections that do nothing or override type information                    |                          |          | :thought_balloon: |
| [`@typescript-eslint/no-require-imports`](./no-require-imports.md)                                           | Disallow invocation of `require()`                                                                           |                          |          |                   |
| [`@typescript-eslint/no-this-alias`](./no-this-alias.md)                                                     | Disallow aliasing `this`                                                                                     | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-type-alias`](./no-type-alias.md)                                                     | Disallow type aliases                                                                                        |                          |          |                   |
| [`@typescript-eslint/no-unnecessary-boolean-literal-compare`](./no-unnecessary-boolean-literal-compare.md)   | Disallow unnecessary equality comparisons against boolean literals                                           | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-condition`](./no-unnecessary-condition.md)                               | Disallow conditionals where the type is always truthy or always falsy                                        | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-qualifier`](./no-unnecessary-qualifier.md)                               | Disallow unnecessary namespace qualifiers                                                                    |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-arguments`](./no-unnecessary-type-arguments.md)                     | Disallow type arguments that are equal to the default                                                        | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-assertion`](./no-unnecessary-type-assertion.md)                     | Disallow type assertions that do not change the type of an expression                                        | :white_check_mark:       | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-constraint`](./no-unnecessary-type-constraint.md)                   | Disallow unnecessary constraints on generic types                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-unsafe-argument`](./no-unsafe-argument.md)                                           | Disallow calling a function with a value with type `any`                                                     | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-assignment`](./no-unsafe-assignment.md)                                       | Disallow assigning a value with type `any` to variables and properties                                       | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-call`](./no-unsafe-call.md)                                                   | Disallow calling a value with type `any`                                                                     | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-member-access`](./no-unsafe-member-access.md)                                 | Disallow member access on a value with type `any`                                                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-return`](./no-unsafe-return.md)                                               | Disallow returning a value with type `any` from a function                                                   | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-useless-empty-export`](./no-useless-empty-export.md)                                 | Disallow empty exports that don't change anything in a module file                                           |                          | :wrench: |                   |
| [`@typescript-eslint/no-var-requires`](./no-var-requires.md)                                                 | Disallow `require` statements except in import statements                                                    | :white_check_mark:       |          |                   |
| [`@typescript-eslint/non-nullable-type-assertion-style`](./non-nullable-type-assertion-style.md)             | Enforce non-null assertions over explicit type casts                                                         | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/parameter-properties`](./parameter-properties.md)                                       | Require or disallow parameter properties in class constructors                                               |                          |          |                   |
| [`@typescript-eslint/prefer-as-const`](./prefer-as-const.md)                                                 | Enforce the use of `as const` over literal type                                                              | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/prefer-enum-initializers`](./prefer-enum-initializers.md)                               | Require each enum member value to be explicitly initialized                                                  |                          |          |                   |
| [`@typescript-eslint/prefer-for-of`](./prefer-for-of.md)                                                     | Enforce the use of `for-of` loop over the standard `for` loop where possible                                 | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-function-type`](./prefer-function-type.md)                                       | Enforce using function types instead of interfaces with call signatures                                      | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/prefer-includes`](./prefer-includes.md)                                                 | Enforce `includes` method over `indexOf` method                                                              | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-literal-enum-member`](./prefer-literal-enum-member.md)                           | Require all enum members to be literal values                                                                | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-namespace-keyword`](./prefer-namespace-keyword.md)                               | Require using `namespace` keyword over `module` keyword to declare custom TypeScript modules                 | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/prefer-nullish-coalescing`](./prefer-nullish-coalescing.md)                             | Enforce using the nullish coalescing operator instead of logical chaining                                    | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/prefer-optional-chain`](./prefer-optional-chain.md)                                     | Enforce using concise optional chain expressions instead of chained logical ands                             | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-readonly`](./prefer-readonly.md)                                                 | Require private members to be marked as `readonly` if they're never modified outside of the constructor      |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-readonly-parameter-types`](./prefer-readonly-parameter-types.md)                 | Require function parameters to be typed as `readonly` to prevent accidental mutation of inputs               |                          |          | :thought_balloon: |
| [`@typescript-eslint/prefer-reduce-type-parameter`](./prefer-reduce-type-parameter.md)                       | Enforce using type parameter when calling `Array#reduce` instead of casting                                  | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-regexp-exec`](./prefer-regexp-exec.md)                                           | Enforce `RegExp#exec` over `String#match` if no global flag is provided                                      |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-return-this-type`](./prefer-return-this-type.md)                                 | Enforce that `this` is used when only `this` type is returned                                                | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-string-starts-ends-with`](./prefer-string-starts-ends-with.md)                   | Enforce using `String#startsWith` and `String#endsWith` over other equivalent methods of checking substrings | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-ts-expect-error`](./prefer-ts-expect-error.md)                                   | Enforce using `@ts-expect-error` over `@ts-ignore`                                                           | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/promise-function-async`](./promise-function-async.md)                                   | Require any function or method that returns a Promise to be marked async                                     |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/require-array-sort-compare`](./require-array-sort-compare.md)                           | Require `Array#sort` calls to always provide a `compareFunction`                                             |                          |          | :thought_balloon: |
| [`@typescript-eslint/restrict-plus-operands`](./restrict-plus-operands.md)                                   | Require both operands of addition to have type `number` or `string`                                          | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/restrict-template-expressions`](./restrict-template-expressions.md)                     | Enforce template literal expressions to be of `string` type                                                  | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/sort-type-union-intersection-members`](./sort-type-union-intersection-members.md)       | Enforce members of a type union/intersection to be sorted alphabetically                                     |                          | :wrench: |                   |
| [`@typescript-eslint/strict-boolean-expressions`](./strict-boolean-expressions.md)                           | Disallow certain types in boolean expressions                                                                |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/switch-exhaustiveness-check`](./switch-exhaustiveness-check.md)                         | Require switch-case statements to be exhaustive with union type                                              |                          |          | :thought_balloon: |
| [`@typescript-eslint/triple-slash-reference`](./triple-slash-reference.md)                                   | Disallow certain triple slash directives in favor of ES6-style import declarations                           | :white_check_mark:       |          |                   |
| [`@typescript-eslint/type-annotation-spacing`](./type-annotation-spacing.md)                                 | Require consistent spacing around type annotations                                                           |                          | :wrench: |                   |
| [`@typescript-eslint/typedef`](./typedef.md)                                                                 | Require type annotations in certain places                                                                   |                          |          |                   |
| [`@typescript-eslint/unbound-method`](./unbound-method.md)                                                   | Enforce unbound methods are called with their expected scope                                                 | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/unified-signatures`](./unified-signatures.md)                                           | Disallow two overloads that could be unified into one with a union or an optional/rest parameter             | :lock:                   |          |                   |

<!-- end base rule list -->

## Extension Rules

In some cases, ESLint provides a rule itself, but it doesn't support TypeScript syntax; either it crashes, or it ignores the syntax, or it falsely reports against it.
In these cases, we create what we call an extension rule; a rule within our plugin that has the same functionality, but also supports TypeScript.

<!-- begin extension rule list -->

**Key**: :white_check_mark: = recommended, :lock: = strict, :wrench: = fixable, :thought_balloon: = requires type information

| Name                                                                                         | Description                                                                          | :white_check_mark::lock: | :wrench: | :thought_balloon: |
| -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | ------------------------ | -------- | ----------------- |
| [`@typescript-eslint/brace-style`](./brace-style.md)                                         | Enforce consistent brace style for blocks                                            |                          | :wrench: |                   |
| [`@typescript-eslint/comma-dangle`](./comma-dangle.md)                                       | Require or disallow trailing commas                                                  |                          | :wrench: |                   |
| [`@typescript-eslint/comma-spacing`](./comma-spacing.md)                                     | Enforce consistent spacing before and after commas                                   |                          | :wrench: |                   |
| [`@typescript-eslint/default-param-last`](./default-param-last.md)                           | Enforce default parameters to be last                                                |                          |          |                   |
| [`@typescript-eslint/dot-notation`](./dot-notation.md)                                       | Enforce dot notation whenever possible                                               | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/func-call-spacing`](./func-call-spacing.md)                             | Require or disallow spacing between function identifiers and their invocations       |                          | :wrench: |                   |
| [`@typescript-eslint/indent`](./indent.md)                                                   | Enforce consistent indentation                                                       |                          | :wrench: |                   |
| [`@typescript-eslint/init-declarations`](./init-declarations.md)                             | Require or disallow initialization in variable declarations                          |                          |          |                   |
| [`@typescript-eslint/keyword-spacing`](./keyword-spacing.md)                                 | Enforce consistent spacing before and after keywords                                 |                          | :wrench: |                   |
| [`@typescript-eslint/lines-between-class-members`](./lines-between-class-members.md)         | Require or disallow an empty line between class members                              |                          | :wrench: |                   |
| [`@typescript-eslint/no-array-constructor`](./no-array-constructor.md)                       | Disallow generic `Array` constructors                                                | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-dupe-class-members`](./no-dupe-class-members.md)                     | Disallow duplicate class members                                                     |                          |          |                   |
| [`@typescript-eslint/no-empty-function`](./no-empty-function.md)                             | Disallow empty functions                                                             | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-extra-parens`](./no-extra-parens.md)                                 | Disallow unnecessary parentheses                                                     |                          | :wrench: |                   |
| [`@typescript-eslint/no-extra-semi`](./no-extra-semi.md)                                     | Disallow unnecessary semicolons                                                      | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-implied-eval`](./no-implied-eval.md)                                 | Disallow the use of `eval()`-like methods                                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-invalid-this`](./no-invalid-this.md)                                 | Disallow `this` keywords outside of classes or class-like objects                    |                          |          |                   |
| [`@typescript-eslint/no-loop-func`](./no-loop-func.md)                                       | Disallow function declarations that contain unsafe references inside loop statements |                          |          |                   |
| [`@typescript-eslint/no-loss-of-precision`](./no-loss-of-precision.md)                       | Disallow literal numbers that lose precision                                         | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-magic-numbers`](./no-magic-numbers.md)                               | Disallow magic numbers                                                               |                          |          |                   |
| [`@typescript-eslint/no-redeclare`](./no-redeclare.md)                                       | Disallow variable redeclaration                                                      |                          |          |                   |
| [`@typescript-eslint/no-restricted-imports`](./no-restricted-imports.md)                     | Disallow specified modules when loaded by `import`                                   |                          |          |                   |
| [`@typescript-eslint/no-shadow`](./no-shadow.md)                                             | Disallow variable declarations from shadowing variables declared in the outer scope  |                          |          |                   |
| [`@typescript-eslint/no-throw-literal`](./no-throw-literal.md)                               | Disallow throwing literals as exceptions                                             | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/no-unused-expressions`](./no-unused-expressions.md)                     | Disallow unused expressions                                                          |                          |          |                   |
| [`@typescript-eslint/no-unused-vars`](./no-unused-vars.md)                                   | Disallow unused variables                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-use-before-define`](./no-use-before-define.md)                       | Disallow the use of variables before they are defined                                |                          |          |                   |
| [`@typescript-eslint/no-useless-constructor`](./no-useless-constructor.md)                   | Disallow unnecessary constructors                                                    | :lock:                   |          |                   |
| [`@typescript-eslint/object-curly-spacing`](./object-curly-spacing.md)                       | Enforce consistent spacing inside braces                                             |                          | :wrench: |                   |
| [`@typescript-eslint/padding-line-between-statements`](./padding-line-between-statements.md) | Require or disallow padding lines between statements                                 |                          | :wrench: |                   |
| [`@typescript-eslint/quotes`](./quotes.md)                                                   | Enforce the consistent use of either backticks, double, or single quotes             |                          | :wrench: |                   |
| [`@typescript-eslint/require-await`](./require-await.md)                                     | Disallow async functions which have no `await` expression                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/return-await`](./return-await.md)                                       | Enforce consistent returning of awaited values                                       |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/semi`](./semi.md)                                                       | Require or disallow semicolons instead of ASI                                        |                          | :wrench: |                   |
| [`@typescript-eslint/space-before-blocks`](./space-before-blocks.md)                         | Enforce consistent spacing before blocks                                             |                          | :wrench: |                   |
| [`@typescript-eslint/space-before-function-paren`](./space-before-function-paren.md)         | Enforce consistent spacing before function parenthesis                               |                          | :wrench: |                   |
| [`@typescript-eslint/space-infix-ops`](./space-infix-ops.md)                                 | Require spacing around infix operators                                               |                          | :wrench: |                   |

<!-- end extension rule list -->
# `no-meaningless-void-operator`

Disallows the `void` operator except when used to discard a value.

Disallows the `void` operator when its argument is already of type `void` or `undefined`.

## Rule Details

The `void` operator is a useful tool to convey the programmer's intent to discard a value. For example, it is recommended as one way of suppressing [`@typescript-eslint/no-floating-promises`](./no-floating-promises.md) instead of adding `.catch()` to a promise.

This rule helps an author catch API changes where previously a value was being discarded at a call site, but the callee changed so it no longer returns a value. When combined with [no-unused-expressions](https://eslint.org/docs/rules/no-unused-expressions), it also helps _readers_ of the code by ensuring consistency: a statement that looks like `void foo();` is **always** discarding a return value, and a statement that looks like `foo();` is **never** discarding a return value.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
void (() => {})();

function foo() {}
void foo();
```

### ✅ Correct

```ts
(() => {})();

function foo() {}
foo(); // nothing to discard

function bar(x: number) {
  void x; // discarding a number
  return 2;
}
void bar(); // discarding a number
```

## Options

This rule accepts a single object option with the following default configuration:

```json
{
  "@typescript-eslint/no-meaningless-void-operator": [
    "error",
    {
      "checkNever": false
    }
  ]
}
```

- `checkNever: true` will suggest removing `void` when the argument has type `never`.
# `prefer-string-starts-ends-with`

Enforces using `String#startsWith` and `String#endsWith` over other equivalent methods of checking substrings.

There are multiple ways to verify if a string starts or ends with a specific string, such as `foo.indexOf('bar') === 0`.

Since ES2015 has added `String#startsWith` and `String#endsWith`, this rule reports other ways to be consistent.

## Rule Details

This rule is aimed at enforcing a consistent way to check whether a string starts or ends with a specific string.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
let foo: string;

// starts with
foo[0] === 'b';
foo.charAt(0) === 'b';
foo.indexOf('bar') === 0;
foo.slice(0, 3) === 'bar';
foo.substring(0, 3) === 'bar';
foo.match(/^bar/) != null;
/^bar/.test(foo);

// ends with
foo[foo.length - 1] === 'b';
foo.charAt(foo.length - 1) === 'b';
foo.lastIndexOf('bar') === foo.length - 3;
foo.slice(-3) === 'bar';
foo.substring(foo.length - 3) === 'bar';
foo.match(/bar$/) != null;
/bar$/.test(foo);
```

### ✅ Correct

```ts
foo.startsWith('bar');
foo.endsWith('bar');
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-string-starts-ends-with": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't mind that style, you can turn this rule off safely.
# `no-non-null-asserted-nullish-coalescing`

Disallows non-null assertions in the left operand of a nullish coalescing operator.

## Rule Details

The nullish coalescing operator is designed to provide a default value when dealing with `null` or `undefined`.
Using non-null assertions in the left operand of the nullish coalescing operator is redundant.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
/* eslint @typescript-eslint/no-non-null-asserted-nullish-coalescing: "error" */

foo! ?? bar;
foo.bazz! ?? bar;
foo!.bazz! ?? bar;
foo()! ?? bar;

let x!: string;
x! ?? '';

let x: string;
x = foo();
x! ?? '';
```

### ✅ Correct

```ts
/* eslint @typescript-eslint/no-non-null-asserted-nullish-coalescing: "error" */

foo ?? bar;
foo ?? bar!;
foo!.bazz ?? bar;
foo!.bazz ?? bar!;
foo() ?? bar;

// This is considered correct code because there's no way for the user to satisfy it.
let x: string;
x! ?? '';
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-non-null-asserted-nullish-coalescing": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are not using TypeScript 3.7 (or greater), then you will not need to use this rule, as the nullish coalescing operator is not supported.

## Further Reading

- [TypeScript 3.7 Release Notes](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html)
- [Nullish Coalescing Proposal](https://github.com/tc39/proposal-nullish-coalescing)
# `prefer-for-of`

Enforces the use of `for-of` loop over the standard `for` loop where possible.

This rule recommends a for-of loop when the loop index is only used to read from an array that is being iterated.

## Rule Details

For cases where the index is only used to read from the array being iterated, a for-of loop is easier to read and write.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```js
for (let i = 0; i < arr.length; i++) {
  console.log(arr[i]);
}
```

### ✅ Correct

```js
for (const x of arr) {
  console.log(x);
}

for (let i = 0; i < arr.length; i++) {
  // i is used to write to arr, so for-of could not be used.
  arr[i] = 0;
}

for (let i = 0; i < arr.length; i++) {
  // i is used independent of arr, so for-of could not be used.
  console.log(i, arr[i]);
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-for-of": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you transpile for browsers that do not support for-of loops, you may wish to use traditional for loops that produce more compact code.
# `no-empty-interface`

Disallows the declaration of empty interfaces.

An empty interface is equivalent to its supertype. If the interface does not implement a supertype, then
the interface is equivalent to an empty object (`{}`). In both cases it can be omitted.

## Rule Details

This rule aims to ensure that only meaningful interfaces are declared in the code.

<!--tabs-->

### ❌ Incorrect

```ts
// an empty interface
interface Foo {}

// an interface with only one supertype (Bar === Foo)
interface Bar extends Foo {}

// an interface with an empty list of supertypes
interface Baz {}
```

### ✅ Correct

```ts
// an interface with any number of members
interface Foo {
  name: string;
}

// same as above
interface Bar {
  age: number;
}

// an interface with more than one supertype
// in this case the interface can be used as a replacement of a union type.
interface Baz extends Foo, Bar {}
```

<!--/tabs-->

### Options

This rule accepts a single object option with the following default configuration:

```json
{
  "@typescript-eslint/no-empty-interface": [
    "error",
    {
      "allowSingleExtends": false
    }
  ]
}
```

- `allowSingleExtends: true` will silence warnings about extending a single interface without adding additional members

## When Not To Use It

If you don't care about having empty/meaningless interfaces, then you will not need this rule.
# `no-unsafe-argument`

Disallows calling a function with a value with type `any`.

Despite your best intentions, the `any` type can sometimes leak into your codebase.
Call a function with `any` typed argument are not checked at all by TypeScript, so it creates a potential safety hole, and source of bugs in your codebase.

## Rule Details

This rule disallows calling a function with `any` in its arguments, and it will disallow spreading `any[]`.
This rule also disallows spreading a tuple type with one of its elements typed as `any`.
This rule also compares the argument's type to the variable's type to ensure you don't pass an unsafe `any` in a generic position to a receiver that's expecting a specific type. For example, it will error if you assign `Set<any>` to an argument declared as `Set<string>`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
declare function foo(arg1: string, arg2: number, arg3: string): void;

const anyTyped = 1 as any;

foo(...anyTyped);
foo(anyTyped, 1, 'a');

const anyArray: any[] = [];
foo(...anyArray);

const tuple1 = ['a', anyTyped, 'b'] as const;
foo(...tuple1);

const tuple2 = [1] as const;
foo('a', ...tuple, anyTyped);

declare function bar(arg1: string, arg2: number, ...rest: string[]): void;
const x = [1, 2] as [number, ...number[]];
foo('a', ...x, anyTyped);

declare function baz(arg1: Set<string>, arg2: Map<string, string>): void;
foo(new Set<any>(), new Map<any, string>());
```

### ✅ Correct

```ts
declare function foo(arg1: string, arg2: number, arg3: string): void;

foo('a', 1, 'b');

const tuple1 = ['a', 1, 'b'] as const;
foo(...tuple1);

declare function bar(arg1: string, arg2: number, ...rest: string[]): void;
const array: string[] = ['a'];
bar('a', 1, ...array);

declare function baz(arg1: Set<string>, arg2: Map<string, string>): void;
foo(new Set<string>(), new Map<string, string>());
```

<!--/tabs-->

There are cases where the rule allows passing an argument of `any` to `unknown`.

Example of `any` to `unknown` assignment that are allowed.

```ts
declare function foo(arg1: unknown, arg2: Set<unkown>, arg3: unknown[]): void;
foo(1 as any, new Set<any>(), [] as any[]);
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unsafe-argument": "error"
  }
}
```

This rule is not configurable.

## Related To

- [`no-explicit-any`](./no-explicit-any.md)
# `consistent-type-exports`

Enforces consistent usage of type exports.

TypeScript 3.8 added support for type-only exports.

Type-only exports allow you to specify that 1 or more named exports are exported as type-only. This allows
transpilers to drop exports without knowing the types of the dependencies.

## Rule Details

This rule aims to standardize the use of type exports style across a codebase.

Given a class `Button`, and an interface `ButtonProps`, examples of code:

<!--tabs-->

### ❌ Incorrect

```ts
interface ButtonProps {
  onClick: () => void;
}
class Button implements ButtonProps {
  onClick() {
    console.log('button!');
  }
}
export { Button, ButtonProps };
```

### ✅ Correct

```ts
interface ButtonProps {
  onClick: () => void;
}
class Button implements ButtonProps {
  onClick() {
    console.log('button!');
  }
}
export { Button };
export type { ButtonProps };
```

## Options

```ts
interface Options {
  fixMixedExportsWithInlineTypeSpecifier?: boolean;
}

const defaultOptions: Options = {
  fixMixedExportsWithInlineTypeSpecifier: false,
};
```

### `fixMixedExportsWithInlineTypeSpecifier`

When this is set to true, the rule will autofix "mixed" export cases using TS 4.5's "inline type specifier".
If you are using a TypeScript version less than 4.5, then you will not be able to use this option.

For example the following code:

```ts
const x = 1;
type T = number;

export { x, T };
```

With `{fixMixedExportsWithInlineTypeSpecifier: true}` will be fixed to:

```ts
const x = 1;
type T = number;

export { x, type T };
```

With `{fixMixedExportsWithInlineTypeSpecifier: false}` will be fixed to:

```ts
const x = 1;
type T = number;

export type { T };
export { x };
```

<!--tabs-->

### ❌ Incorrect

```ts
export { Button } from 'some-library';
export type { ButtonProps } from 'some-library';
```

### ✅ Correct

```ts
export { Button, type ButtonProps } from 'some-library';
```

## When Not To Use It

- If you are using a TypeScript version less than 3.8, then you will not be able to use this rule as type exports are not supported.
- If you specifically want to use both export kinds for stylistic reasons, you can disable this rule.
- If you use `--isolatedModules` the compiler would error if a type is not re-exported using `export type`. If you also don't wish to enforce one style over the other, you can disable this rule.
# `comma-dangle`

Requires or disallows trailing commas.

## Rule Details

This rule extends the base [`eslint/comma-dangle`](https://eslint.org/docs/rules/comma-dangle) rule.
It adds support for TypeScript syntax.

See the [ESLint documentation](https://eslint.org/docs/rules/comma-dangle) for more details on the `comma-dangle` rule.

## Rule Changes

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "comma-dangle": "off",
  "@typescript-eslint/comma-dangle": ["error"]
}
```

In addition to the options supported by the `comma-dangle` rule in ESLint core, the rule adds the following options:

## Options

This rule has a string option and an object option.

- Object option:

  - `"enums"` is for trailing comma in enum. (e.g. `enum Foo = {Bar,}`)
  - `"generics"` is for trailing comma in generic. (e.g. `function foo<T,>() {}`)
  - `"tuples"` is for trailing comma in tuple. (e.g. `type Foo = [string,]`)

- [See the other options allowed](https://eslint.org/docs/rules/comma-dangle#options)

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/comma-dangle.md)

</sup>
# `no-magic-numbers`

Disallows magic numbers.

## Rule Details

This rule extends the base [`eslint/no-magic-numbers`](https://eslint.org/docs/rules/no-magic-numbers) rule.
It adds support for:

- numeric literal types (`type T = 1`),
- `enum` members (`enum Foo { bar = 1 }`),
- `readonly` class properties (`class Foo { readonly bar = 1 }`).

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-magic-numbers": "off",
  "@typescript-eslint/no-magic-numbers": [
    "error",
    {
      /* options */
    }
  ]
}
```

## Options

See [`eslint/no-magic-numbers` options](https://eslint.org/docs/rules/no-magic-numbers#options).
This rule adds the following options:

```ts
interface Options extends BaseNoMagicNumbersOptions {
  ignoreEnums?: boolean;
  ignoreNumericLiteralTypes?: boolean;
  ignoreReadonlyClassProperties?: boolean;
  ignoreTypeIndexes?: boolean;
}

const defaultOptions: Options = {
  ...baseNoMagicNumbersDefaultOptions,
  ignoreEnums: false,
  ignoreNumericLiteralTypes: false,
  ignoreReadonlyClassProperties: false,
  ignoreTypeIndexes: false,
};
```

### `ignoreEnums`

A boolean to specify if enums used in TypeScript are considered okay. `false` by default.

Examples of **incorrect** code for the `{ "ignoreEnums": false }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreEnums": false }]*/

enum foo {
  SECOND = 1000,
}
```

Examples of **correct** code for the `{ "ignoreEnums": true }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreEnums": true }]*/

enum foo {
  SECOND = 1000,
}
```

### `ignoreNumericLiteralTypes`

A boolean to specify if numbers used in TypeScript numeric literal types are considered okay. `false` by default.

Examples of **incorrect** code for the `{ "ignoreNumericLiteralTypes": false }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreNumericLiteralTypes": false }]*/

type SmallPrimes = 2 | 3 | 5 | 7 | 11;
```

Examples of **correct** code for the `{ "ignoreNumericLiteralTypes": true }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreNumericLiteralTypes": true }]*/

type SmallPrimes = 2 | 3 | 5 | 7 | 11;
```

### `ignoreReadonlyClassProperties`

Examples of **incorrect** code for the `{ "ignoreReadonlyClassProperties": false }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreReadonlyClassProperties": false }]*/

class Foo {
  readonly A = 1;
  readonly B = 2;
  public static readonly C = 1;
  static readonly D = 1;
}
```

Examples of **correct** code for the `{ "ignoreReadonlyClassProperties": true }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreReadonlyClassProperties": true }]*/

class Foo {
  readonly A = 1;
  readonly B = 2;
  public static readonly C = 1;
  static readonly D = 1;
}
```

### `ignoreTypeIndexes`

A boolean to specify if numbers used to index types are okay. `false` by default.

Examples of **incorrect** code for the `{ "ignoreTypeIndexes": false }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreTypeIndexes": false }]*/

type Foo = Bar[0];
type Baz = Parameters<Foo>[2];
```

Examples of **correct** code for the `{ "ignoreTypeIndexes": true }` option:

```ts
/*eslint @typescript-eslint/no-magic-numbers: ["error", { "ignoreTypeIndexes": true }]*/

type Foo = Bar[0];
type Baz = Parameters<Foo>[2];
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-magic-numbers.md)

</sup>
# `space-before-function-paren`

Enforces consistent spacing before function parenthesis.

## Rule Details

This rule extends the base [`eslint/space-before-function-paren`](https://eslint.org/docs/rules/space-before-function-paren) rule.
It adds support for generic type parameters on function calls.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "space-before-function-paren": "off",
  "@typescript-eslint/space-before-function-paren": ["error"]
}
```

## Options

See [`eslint/space-before-function-paren` options](https://eslint.org/docs/rules/space-before-function-paren#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/space-before-function-paren.md)

</sup>
# `no-extraneous-class`

Disallows classes used as namespaces.

This rule warns when a class has no non-static members, such as for a class used exclusively as a static namespace.

## Rule Details

Users who come from a [OOP](https://en.wikipedia.org/wiki/Object-oriented_programming) paradigm may wrap their utility functions in an extra class, instead of putting them at the top level of an ECMAScript module.
Doing so is generally unnecessary in JavaScript and TypeScript projects.

- Wrapper classes add extra cognitive complexity to code without adding any structural improvements
  - Whatever would be put on them, such as utility functions, are already organized by virtue of being in a module.
  - As an alternative, you can always `import * as ...` the module to get all of them in a single object.
- IDEs can't provide as good suggestions for static class or namespace imported properties when you start typing property names
- It's more difficult to statically analyze code for unused variables, etc. when they're all on the class (see: [Finding dead code (and dead types) in TypeScript](https://effectivetypescript.com/2020/10/20/tsprune)).

This rule also flags classes that have only a constructor and no fields.
Those classes can generally be replaced with a standalone function.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
class StaticConstants {
  static readonly version = 42;

  static isProduction() {
    return process.env.NODE_ENV === 'production';
  }
}

class HelloWorldLogger {
  constructor() {
    console.log('Hello, world!');
  }
}
```

### ✅ Correct

```ts
export const version = 42;

export function isProduction() {
  return process.env.NODE_ENV === 'production';
}

function logHelloWorld() {
  console.log('Hello, world!');
}
```

## Alternatives

### Individual Exports (Recommended)

Instead of using a static utility class we recommend you individually export the utilities from your module.

<!--tabs-->

#### ❌ Incorrect

```ts
export class Utilities {
  static util1() {
    return Utilities.util3();
  }

  static util2() {
    /* ... */
  }

  static util3() {
    /* ... */
  }
}
```

#### ✅ Correct

```ts
export function util1() {
  return util3();
}

export function util2() {
  /* ... */
}

export function util3() {
  /* ... */
}
```

### Namespace Imports (Not Recommended)

If you strongly prefer to have all constructs from a module available as properties of a single object, you can `import * as` the module.
This is known as a "namespace import".
Namespace imports are sometimes preferable because they keep all properties nested and don't need to be changed as you start or stop using various properties from the module.

However, namespace imports are impacted by these downsides:

- They also don't play as well with tree shaking in modern bundlers
- They require a name prefix before each property's usage

<!--tabs-->

#### ❌ Incorrect

```ts
// utilities.ts
export class Utilities {
  static sayHello() {
    console.log('Hello, world!');
  }
}

// consumers.ts
import { Utilities } from './utilities';

Utilities.sayHello();
```

#### ⚠️ Namespace Imports

```ts
// utilities.ts
export function sayHello() {
  console.log('Hello, world!');
}

// consumers.ts
import * as utilities from './utilities';

utilities.sayHello();
```

#### ✅ Standalone Imports

```ts
// utilities.ts
export function sayHello() {
  console.log('Hello, world!');
}

// consumers.ts
import { sayHello } from './utilities';

sayHello();
```

### Notes on Mutating Variables

One case you need to be careful of is exporting mutable variables.
While class properties can be mutated externally, exported variables are always constant.
This means that importers can only ever read the first value they are assigned and cannot write to the variables.

Needing to write to an exported variable is very rare and is generally considered a code smell.
If you do need it you can accomplish it using getter and setter functions:

<!--tabs-->

#### ❌ Incorrect

```ts
export class Utilities {
  static mutableCount = 1;

  static incrementCount() {
    Utilities.mutableCount += 1;
  }
}
```

#### ✅ Correct

```ts
let mutableCount = 1;

export function getMutableCount() {
  return mutableField;
}

export function incrementCount() {
  mutableField += 1;
}
```

## Options

This rule accepts a single object option.

```ts
type Options = {
  // allow extraneous classes if they only contain a constructor
  allowConstructorOnly?: boolean;
  // allow extraneous classes if they have no body (i.e. are empty)
  allowEmpty?: boolean;
  // allow extraneous classes if they only contain static members
  allowStaticOnly?: boolean;
  // allow extraneous classes if they have a decorator
  allowWithDecorator?: boolean;
};

const defaultOptions: Options = {
  allowConstructorOnly: false,
  allowEmpty: false,
  allowStaticOnly: false,
  allowWithDecorator: false,
};
```

This rule normally bans classes that are empty (have no constructor or fields).
The rule's options each add an exemption for a specific type of class.

### `allowConstructorOnly`

`allowConstructorOnly` adds an exemption for classes that have only a constructor and no fields.

<!--tabs-->

#### ❌ Incorrect

```ts
class NoFields {}
```

#### ✅ Correct

```ts
class NoFields {
  constructor() {
    console.log('Hello, world!');
  }
}
```

### `allowEmpty`

The `allowEmpty` option adds an exemption for classes that are entirely empty.

<!--tabs-->

#### ❌ Incorrect

```ts
class NoFields {
  constructor() {
    console.log('Hello, world!');
  }
}
```

#### ✅ Correct

```ts
class NoFields {}
```

### `allowStaticOnly`

The `allowStaticOnly` option adds an exemption for classes that only contain static members.

:::caution
We strongly recommend against the `allowStaticOnly` exemption.
It works against this rule's primary purpose of discouraging classes used only for static members.
:::

<!--tabs-->

#### ❌ Incorrect

```ts
class EmptyClass {}
```

#### ✅ Correct

```ts
class NotEmptyClass {
  static version = 42;
}
```

### `allowWithDecorator`

The `allowWithDecorator` option adds an exemption for classes that contain a member decorated with a `@` decorator.

<!--tabs-->

#### ❌ Incorrect

```ts
class Constants {
  static readonly version = 42;
}
```

#### ✅ Correct

```ts
class Constants {
  @logOnRead()
  static readonly version = 42;
}
```

## When Not To Use It

You can disable this rule if you are unable -or unwilling- to switch off using classes as namespaces.
# `prefer-function-type`

Enforces using function types instead of interfaces with call signatures.

## Rule Details

This rule suggests using a function type instead of an interface or object type literal with a single call signature.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
interface Foo {
  (): string;
}
```

```ts
function foo(bar: { (): number }): number {
  return bar();
}
```

```ts
interface Foo extends Function {
  (): void;
}
```

```ts
interface MixinMethod {
  // returns the function itself, not the `this` argument.
  (arg: string): this;
}
```

### ✅ Correct

```ts
interface Foo {
  (): void;
  bar: number;
}
```

```ts
function foo(bar: { (): string; baz: number }): string {
  return bar();
}
```

```ts
interface Foo {
  bar: string;
}
interface Bar extends Foo {
  (): void;
}
```

```ts
// returns the `this` argument of function, retaining it's type.
type MixinMethod = <TSelf>(this: TSelf, arg: string) => TSelf;
// a function that returns itself is much clearer in this form.
type ReturnsSelf = (arg: string) => ReturnsSelf;
```

```ts
// multiple call signatures (overloads) is allowed:
interface Overloaded {
  (data: string): number;
  (id: number): string;
}
// this is equivelent to Overloaded interface.
type Intersection = ((data: string) => number) & ((id: number) => string);
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-function-type": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you specifically want to use an interface or type literal with a single call signature for stylistic reasons, you can disable this rule.
# `no-for-in-array`

Disallows iterating over an array with a for-in loop.

This rule prohibits iterating over an array with a for-in loop.

## Rule Details

A for-in loop (`for (var k in o)`) iterates over the properties of an Object.
While it is legal to use for-in loops with array types, it is not common.
for-in will iterate over the indices of the array as strings, omitting any "holes" in
the array.
More common is to use for-of, which iterates over the values of an array.
If you want to iterate over the indices, alternatives include:

```js
array.forEach((value, index) => { ... });
for (const [index, value] of array.entries()) { ... }
for (let i = 0; i < array.length; i++) { ... }
```

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```js
for (const x in [3, 4, 5]) {
  console.log(x);
}
```

### ✅ Correct

```js
for (const x in { a: 3, b: 4, c: 5 }) {
  console.log(x);
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-for-in-array": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you want to iterate through a loop using the indices in an array as strings, you can turn off this rule.
# `restrict-template-expressions`

Enforces template literal expressions to be of `string` type.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
const arg1 = [1, 2];
const msg1 = `arg1 = ${arg1}`;

const arg2 = { name: 'Foo' };
const msg2 = `arg2 = ${arg2 || null}`;
```

### ✅ Correct

```ts
const arg = 'foo';
const msg1 = `arg = ${arg}`;
const msg2 = `arg = ${arg || 'default'}`;

const stringWithKindProp: string & { _kind?: 'MyString' } = 'foo';
const msg3 = `stringWithKindProp = ${stringWithKindProp}`;
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if true, also allow number type in template expressions
  allowNumber?: boolean;
  // if true, also allow boolean type in template expressions
  allowBoolean?: boolean;
  // if true, also allow any in template expressions
  allowAny?: boolean;
  // if true, also allow null and undefined in template expressions
  allowNullish?: boolean;
  // if true, also allow RegExp in template expressions
  allowRegExp?: boolean;
};

const defaults = {
  allowNumber: true,
  allowBoolean: false,
  allowAny: false,
  allowNullish: false,
  allowRegExp: false,
};
```

### `allowNumber`

Examples of additional **correct** code for this rule with `{ allowNumber: true }`:

```ts
const arg = 123;
const msg1 = `arg = ${arg}`;
const msg2 = `arg = ${arg || 'zero'}`;
```

### `allowBoolean`

Examples of additional **correct** code for this rule with `{ allowBoolean: true }`:

```ts
const arg = true;
const msg1 = `arg = ${arg}`;
const msg2 = `arg = ${arg || 'not truthy'}`;
```

### `allowAny`

Examples of additional **correct** code for this rule with `{ allowAny: true }`:

```ts
const user = JSON.parse('{ "name": "foo" }');
const msg1 = `arg = ${user.name}`;
const msg2 = `arg = ${user.name || 'the user with no name'}`;
```

### `allowNullish`

Examples of additional **correct** code for this rule with `{ allowNullish: true }`:

```ts
const arg = condition ? 'ok' : null;
const msg1 = `arg = ${arg}`;
```

### `allowRegExp`

Examples of additional **correct** code for this rule with `{ allowRegExp: true }`:

```ts
const arg = new RegExp('foo');
const msg1 = `arg = ${arg}`;
```

```ts
const arg = /foo/;
const msg1 = `arg = ${arg}`;
```
# `parameter-properties`

Requires or disallows parameter properties in class constructors.

Parameter properties can be confusing to those new to TypeScript as they are less explicit than other ways
of declaring and initializing class members.

## Rule Details

This rule disallows the use of parameter properties in constructors, forcing the user to explicitly
declare all properties in the class.

## Options

This rule, in its default state, does not require any argument and would completely disallow the use of parameter properties.
It may take an options object containing either or both of:

- `"allow"`: allowing certain kinds of properties to be ignored
- `"prefer"`: either `"class-property"` _(default)_ or `"parameter-property"`

### `"allow"`

If you would like to ignore certain kinds of properties then you may pass an object containing `"allow"` as an array of any of the following options:

- `allow`, an array containing one or more of the allowed modifiers. Valid values are:
  - `readonly`, allows **readonly** parameter properties.
  - `private`, allows **private** parameter properties.
  - `protected`, allows **protected** parameter properties.
  - `public`, allows **public** parameter properties.
  - `private readonly`, allows **private readonly** parameter properties.
  - `protected readonly`, allows **protected readonly** parameter properties.
  - `public readonly`, allows **public readonly** parameter properties.

For example, to ignore `public` properties:

```json
{
  "@typescript-eslint/parameter-properties": [
    true,
    {
      "allow": ["public"]
    }
  ]
}
```

### `"prefer"`

By default, the rule prefers class property (`"class-property"`).
You can switch it to instead preferring parameter property with (`"parameter-property"`).

In `"parameter-property"` mode, the rule will issue a report when:

- A class property and constructor parameter have the same name and type
- The constructor parameter is assigned to the class property at the beginning of the constructor

### default

Examples of code for this rule with no options at all:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}
```

### readonly

Examples of code for the `{ "allow": ["readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(readonly name: string) {}
}
```

### private

Examples of code for the `{ "allow": ["private"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(private name: string) {}
}
```

### protected

Examples of code for the `{ "allow": ["protected"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}
```

### public

Examples of code for the `{ "allow": ["public"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(public name: string) {}
}
```

### private readonly

Examples of code for the `{ "allow": ["private readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}
```

### protected readonly

Examples of code for the `{ "allow": ["protected readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}
```

### public readonly

Examples of code for the `{ "allow": ["public readonly"] }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  constructor(readonly name: string) {}
}

class Foo {
  constructor(private name: string) {}
}

class Foo {
  constructor(protected name: string) {}
}

class Foo {
  constructor(public name: string) {}
}

class Foo {
  constructor(private readonly name: string) {}
}

class Foo {
  constructor(protected readonly name: string) {}
}
```

#### ✅ Correct

```ts
class Foo {
  constructor(name: string) {}
}

class Foo {
  constructor(public readonly name: string) {}
}
```

### `"parameter-property"`

Examples of code for the `{ "prefer": "parameter-property" }` option:

<!--tabs-->

#### ❌ Incorrect

```ts
class Foo {
  private name: string;
  constructor(name: string) {
    this.name = name;
  }
}

class Foo {
  public readonly name: string;
  constructor(name: string) {
    this.name = name;
  }
}

class Foo {
  constructor(name: string) {
    this.name = name;
  }
  name: string;
}
```

#### ✅ Correct

```ts
class Foo {
  private differentName: string;
  constructor(name: string) {
    this.differentName = name;
  }
}

class Foo {
  private differentType: number | undefined;
  constructor(differentType: number) {
    this.differentType = differentType;
  }
}

class Foo {
  protected logicInConstructor: string;
  constructor(logicInConstructor: string) {
    console.log('Hello, world!');
    this.logicInConstructor = logicInConstructor;
  }
}
```

## When Not To Use It

If you don't care about the using parameter properties in constructors, then you will not need this rule.
# `adjacent-overload-signatures`

Requires that member overloads be consecutive.

Grouping overloaded members together can improve readability of the code.

## Rule Details

This rule aims to standardize the way overloaded members are organized.

<!--tabs-->

### ❌ Incorrect

```ts
declare namespace Foo {
  export function foo(s: string): void;
  export function foo(n: number): void;
  export function bar(): void;
  export function foo(sn: string | number): void;
}

type Foo = {
  foo(s: string): void;
  foo(n: number): void;
  bar(): void;
  foo(sn: string | number): void;
};

interface Foo {
  foo(s: string): void;
  foo(n: number): void;
  bar(): void;
  foo(sn: string | number): void;
}

class Foo {
  foo(s: string): void;
  foo(n: number): void;
  bar(): void {}
  foo(sn: string | number): void {}
}

export function foo(s: string): void;
export function foo(n: number): void;
export function bar(): void;
export function foo(sn: string | number): void;
```

### ✅ Correct

```ts
declare namespace Foo {
  export function foo(s: string): void;
  export function foo(n: number): void;
  export function foo(sn: string | number): void;
  export function bar(): void;
}

type Foo = {
  foo(s: string): void;
  foo(n: number): void;
  foo(sn: string | number): void;
  bar(): void;
};

interface Foo {
  foo(s: string): void;
  foo(n: number): void;
  foo(sn: string | number): void;
  bar(): void;
}

class Foo {
  foo(s: string): void;
  foo(n: number): void;
  foo(sn: string | number): void {}
  bar(): void {}
}

export function bar(): void;
export function foo(s: string): void;
export function foo(n: number): void;
export function foo(sn: string | number): void;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/adjacent-overload-signatures": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about the general structure of the code, then you will not need this rule.
# `no-var-requires`

Disallows `require` statements except in import statements.

In other words, the use of forms such as `var foo = require("foo")` are banned. Instead use ES6 style imports or `import foo = require("foo")` imports.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
var foo = require('foo');
const foo = require('foo');
let foo = require('foo');
```

### ✅ Correct

```ts
import foo = require('foo');
require('foo');
import foo from 'foo';
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-var-requires": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about TypeScript module syntax, then you will not need this rule.
# `await-thenable`

Disallows awaiting a value that is not a Thenable.

This rule disallows awaiting a value that is not a "Thenable" (an object which has `then` method, such as a Promise).
While it is valid JavaScript to await a non-`Promise`-like value (it will resolve immediately), this pattern is often a programmer error, such as forgetting to add parenthesis to call a function that returns a Promise.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
await 'value';

const createValue = () => 'value';
await createValue();
```

### ✅ Correct

```ts
await Promise.resolve('value');

const createValue = async () => 'value';
await createValue();
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/await-thenable": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you want to allow code to `await` non-Promise values.
This is generally not preferred, but can sometimes be useful for visual consistency.
# `prefer-includes`

Enforces `includes` method over `indexOf` method.

Until ES5, we were using `String#indexOf` method to check whether a string contains an arbitrary substring or not.
Until ES2015, we were using `Array#indexOf` method to check whether an array contains an arbitrary value or not.

ES2015 has added `String#includes` and ES2016 has added `Array#includes`.
It makes code more understandable if we use those `includes` methods for the purpose.

## Rule Details

This rule is aimed at suggesting `includes` method if `indexOf` method was used to check whether an object contains an arbitrary value or not.

If the receiver object of the `indexOf` method call has `includes` method and the two methods have the same parameters, this rule does suggestion.
There are such types: `String`, `Array`, `ReadonlyArray`, and typed arrays.

Additionally, this rule reports the tests of simple regular expressions in favor of `String#includes`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
let str: string;
let array: any[];
let readonlyArray: ReadonlyArray<any>;
let typedArray: UInt8Array;
let maybe: string;
let userDefined: {
  indexOf(x: any): number;
  includes(x: any): boolean;
};

str.indexOf(value) !== -1;
array.indexOf(value) !== -1;
readonlyArray.indexOf(value) === -1;
typedArray.indexOf(value) > -1;
maybe?.indexOf('') !== -1;
userDefined.indexOf(value) >= 0;

// simple RegExp test
/foo/.test(str);
```

### ✅ Correct

```ts
let array: any[];
let readonlyArray: ReadonlyArray<any>;
let typedArray: UInt8Array;
let userDefined: {
  indexOf(x: any): number;
  includes(x: any): boolean;
};
let mismatchExample: {
  indexOf(x: any, fromIndex?: number): number;
  includes(x: any): boolean;
};

str.includes(value);
array.includes(value);
readonlyArray.includes(value);
typedArray.includes(value);
userDefined.includes(value);

// the two methods have different parameters.
mismatchExample.indexOf(value) >= 0;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-includes": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't want to suggest `includes`, you can safely turn this rule off.
# `no-shadow`

Disallows variable declarations from shadowing variables declared in the outer scope.

## Rule Details

This rule extends the base [`eslint/no-shadow`](https://eslint.org/docs/rules/no-shadow) rule.
It adds support for TypeScript's `this` parameters and global augmentation, and adds options for TypeScript features.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-shadow": "off",
  "@typescript-eslint/no-shadow": ["error"]
}
```

## Options

See [`eslint/no-shadow` options](https://eslint.org/docs/rules/no-shadow#options).
This rule adds the following options:

```ts
interface Options extends BaseNoShadowOptions {
  ignoreTypeValueShadow?: boolean;
  ignoreFunctionTypeParameterNameValueShadow?: boolean;
}

const defaultOptions: Options = {
  ...baseNoShadowDefaultOptions,
  ignoreTypeValueShadow: true,
  ignoreFunctionTypeParameterNameValueShadow: true,
};
```

### `ignoreTypeValueShadow`

When set to `true`, the rule will ignore the case when you name a type the same as a variable.

TypeScript allows types and variables to shadow one-another. This is generally safe because you cannot use variables in type locations without a `typeof` operator, so there's little risk of confusion.

Examples of **correct** code with `{ ignoreTypeValueShadow: true }`:

```ts
type Foo = number;
const Foo = 1;

interface Bar {
  prop: number;
}
const Bar = 'test';
```

### `ignoreFunctionTypeParameterNameValueShadow`

When set to `true`, the rule will ignore the case when you name a function type argument the same as a variable.

Each of a function type's arguments creates a value variable within the scope of the function type. This is done so that you can reference the type later using the `typeof` operator:

```ts
type Func = (test: string) => typeof test;

declare const fn: Func;
const result = fn('str'); // typeof result === string
```

This means that function type arguments shadow value variable names in parent scopes:

```ts
let test = 1;
type TestType = typeof test; // === number
type Func = (test: string) => typeof test; // this "test" references the argument, not the variable

declare const fn: Func;
const result = fn('str'); // typeof result === string
```

If you do not use the `typeof` operator in a function type return type position, you can safely turn this option on.

Examples of **correct** code with `{ ignoreFunctionTypeParameterNameValueShadow: true }`:

```ts
const test = 1;
type Func = (test: string) => typeof test;
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-shadow.md)

</sup>
# `explicit-function-return-type`

Requires explicit return types on functions and class methods.

Explicit types for function return values makes it clear to any calling code what type is returned.
This ensures that the return value is assigned to a variable of the correct type; or in the case
where there is no return value, that the calling code doesn't try to use the undefined value when it
shouldn't.

## Rule Details

This rule aims to ensure that the values returned from functions are of the expected type.

<!--tabs-->

### ❌ Incorrect

```ts
// Should indicate that no value is returned (void)
function test() {
  return;
}

// Should indicate that a number is returned
var fn = function () {
  return 1;
};

// Should indicate that a string is returned
var arrowFn = () => 'test';

class Test {
  // Should indicate that no value is returned (void)
  method() {
    return;
  }
}
```

### ✅ Correct

```ts
// No return value should be expected (void)
function test(): void {
  return;
}

// A return value of type number
var fn = function (): number {
  return 1;
};

// A return value of type string
var arrowFn = (): string => 'test';

class Test {
  // No return value should be expected (void)
  method(): void {
    return;
  }
}
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if true, only functions which are part of a declaration will be checked
  allowExpressions?: boolean;
  // if true, type annotations are also allowed on the variable of a function expression rather than on the function directly
  allowTypedFunctionExpressions?: boolean;
  // if true, functions immediately returning another function expression will not be checked
  allowHigherOrderFunctions?: boolean;
  // if true, arrow functions immediately returning a `as const` value will not be checked
  allowDirectConstAssertionInArrowFunctions?: boolean;
  // if true, concise arrow functions that start with the void keyword will not be checked
  allowConciseArrowFunctionExpressionsStartingWithVoid?: boolean;
  /**
   * An array of function/method names that will not have their arguments or their return values checked.
   */
  allowedNames?: string[];
};

const defaults = {
  allowExpressions: false,
  allowTypedFunctionExpressions: true,
  allowHigherOrderFunctions: true,
  allowDirectConstAssertionInArrowFunctions: true,
  allowConciseArrowFunctionExpressionsStartingWithVoid: false,
  allowedNames: [],
};
```

### Configuring in a mixed JS/TS codebase

If you are working on a codebase within which you lint non-TypeScript code (i.e. `.js`/`.mjs`/`.cjs`/`.jsx`), you should ensure that you should use [ESLint `overrides`](https://eslint.org/docs/user-guide/configuring#disabling-rules-only-for-a-group-of-files) to only enable the rule on `.ts`/`.mts`/`.cts`/`.tsx` files. If you don't, then you will get unfixable lint errors reported within `.js`/`.mjs`/`.cjs`/`.jsx` files.

```jsonc
{
  "rules": {
    // disable the rule for all files
    "@typescript-eslint/explicit-function-return-type": "off"
  },
  "overrides": [
    {
      // enable the rule specifically for TypeScript files
      "files": ["*.ts", "*.mts", "*.cts", "*.tsx"],
      "rules": {
        "@typescript-eslint/explicit-function-return-type": ["error"]
      }
    }
  ]
}
```

### `allowExpressions`

Examples of code for this rule with `{ allowExpressions: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
function test() {}

const fn = () => {};

export default () => {};
```

#### ✅ Correct

```ts
node.addEventListener('click', () => {});

node.addEventListener('click', function () {});

const foo = arr.map(i => i * i);
```

### `allowTypedFunctionExpressions`

Examples of code for this rule with `{ allowTypedFunctionExpressions: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
let arrowFn = () => 'test';

let funcExpr = function () {
  return 'test';
};

let objectProp = {
  foo: () => 1,
};
```

#### ✅ Correct

```ts
type FuncType = () => string;

let arrowFn: FuncType = () => 'test';

let funcExpr: FuncType = function() {
  return 'test';
};

let asTyped = (() => '') as () => string;
let castTyped = <() => string>(() => '');

interface ObjectType {
  foo(): number;
}
let objectProp: ObjectType = {
  foo: () => 1,
};
let objectPropAs = {
  foo: () => 1,
} as ObjectType;
let objectPropCast = <ObjectType>{
  foo: () => 1,
};

declare functionWithArg(arg: () => number);
functionWithArg(() => 1);

declare functionWithObjectArg(arg: { method: () => number });
functionWithObjectArg({
  method() {
    return 1;
  },
});
```

### `allowHigherOrderFunctions`

Examples of code for this rule with `{ allowHigherOrderFunctions: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
var arrowFn = () => () => {};

function fn() {
  return function () {};
}
```

#### ✅ Correct

```ts
var arrowFn = () => (): void => {};

function fn() {
  return function (): void {};
}
```

### `allowDirectConstAssertionInArrowFunctions`

Examples of code for this rule with `{ allowDirectConstAssertionInArrowFunctions: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const func = (value: number) => ({ type: 'X', value } as any);
const func = (value: number) => ({ type: 'X', value } as Action);
```

#### ✅ Correct

```ts
const func = (value: number) => ({ foo: 'bar', value } as const);
const func = () => x as const;
```

### `allowConciseArrowFunctionExpressionsStartingWithVoid`

Examples of code for this rule with `{ allowConciseArrowFunctionExpressionsStartingWithVoid: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
var join = (a: string, b: string) => `${a}${b}`;

const log = (message: string) => {
  console.log(message);
};
```

#### ✅ Correct

```ts
var log = (message: string) => void console.log(message);
```

### `allowedNames`

You may pass function/method names you would like this rule to ignore, like so:

```json
{
  "@typescript-eslint/explicit-function-return-type": [
    "error",
    {
      "allowedNames": ["ignoredFunctionName", "ignoredMethodName"]
    }
  ]
}
```

## When Not To Use It

If you don't wish to prevent calling code from using function return values in unexpected ways, then
you will not need this rule.

## Further Reading

- TypeScript [Functions](https://www.typescriptlang.org/docs/handbook/functions.html#function-types)
# `func-call-spacing`

Requires or disallows spacing between function identifiers and their invocations.

## Rule Details

This rule extends the base [`eslint/func-call-spacing`](https://eslint.org/docs/rules/func-call-spacing) rule.
It adds support for generic type parameters on function calls.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "func-call-spacing": "off",
  "@typescript-eslint/func-call-spacing": ["error"]
}
```

## Options

See [`eslint/func-call-spacing` options](https://eslint.org/docs/rules/func-call-spacing#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/func-call-spacing.md)

</sup>
# `no-unnecessary-boolean-literal-compare`

Disallows unnecessary equality comparisons against boolean literals.

Comparing boolean values to boolean literals is unnecessary, those comparisons result in the same booleans. Using the boolean values directly, or via a unary negation (`!value`), is more concise and clearer.

## Rule Details

This rule ensures that you do not include unnecessary comparisons with boolean literals.
A comparison is considered unnecessary if it checks a boolean literal against any variable with just the `boolean` type.
A comparison is **_not_** considered unnecessary if the type is a union of booleans (`string | boolean`, `someObject | boolean`).

**Warning**: Do not use this rule when `strictNullChecks` is disabled.
ESLint is not able to distinguish between `false` and `undefined` or `null` values.
This can cause unintended code changes when using autofix.

**Note**: Throughout this page, only strict equality (`===` and `!==`) are
used in the examples. However, the implementation of the rule does not
distinguish between strict and loose equality. Any example below that uses
`===` would be treated the same way if `==` was used, and any example below
that uses `!==` would be treated the same way if `!=` was used.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
declare const someCondition: boolean;
if (someCondition === true) {
}
```

### ✅ Correct

```ts
declare const someCondition: boolean;
if (someCondition) {
}

declare const someObjectBoolean: boolean | Record<string, unknown>;
if (someObjectBoolean === true) {
}

declare const someStringBoolean: boolean | string;
if (someStringBoolean === true) {
}
```

## Options

The rule accepts an options object with the following properties.

```ts
type Options = {
  // if false, comparisons between a nullable boolean variable to `true` will be checked and fixed
  allowComparingNullableBooleansToTrue?: boolean;
  // if false, comparisons between a nullable boolean variable to `false` will be checked and fixed
  allowComparingNullableBooleansToFalse?: boolean;
};
```

### Defaults

This rule always checks comparisons between a boolean variable and a boolean
literal. Comparisons between nullable boolean variables and boolean literals
are **not** checked by default.

```ts
const defaults = {
  allowComparingNullableBooleansToTrue: true,
  allowComparingNullableBooleansToFalse: true,
};
```

### `allowComparingNullableBooleansToTrue`

Examples of code for this rule with `{ allowComparingNullableBooleansToTrue: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
declare const someUndefinedCondition: boolean | undefined;
if (someUndefinedCondition === true) {
}

declare const someNullCondition: boolean | null;
if (someNullCondition !== true) {
}
```

#### ✅ Correct

```ts
declare const someUndefinedCondition: boolean | undefined;
if (someUndefinedCondition) {
}

declare const someNullCondition: boolean | null;
if (!someNullCondition) {
}
```

### `allowComparingNullableBooleansToFalse`

Examples of code for this rule with `{ allowComparingNullableBooleansToFalse: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
declare const someUndefinedCondition: boolean | undefined;
if (someUndefinedCondition === false) {
}

declare const someNullCondition: boolean | null;
if (someNullCondition !== false) {
}
```

#### ✅ Correct

```ts
declare const someUndefinedCondition: boolean | undefined;
if (someUndefinedCondition ?? true) {
}

declare const someNullCondition: boolean | null;
if (!(someNullCondition ?? true)) {
}
```

## Fixer

|           Comparison           | Fixer Output                    | Notes                                                                               |
| :----------------------------: | ------------------------------- | ----------------------------------------------------------------------------------- |
|     `booleanVar === true`      | `booleanVar`                    |                                                                                     |
|     `booleanVar !== true`      | `!booleanVar`                   |                                                                                     |
|     `booleanVar === false`     | `!booleanVar`                   |                                                                                     |
|     `booleanVar !== false`     | `booleanVar`                    |                                                                                     |
| `nullableBooleanVar === true`  | `nullableBooleanVar`            | Only checked/fixed if the `allowComparingNullableBooleansToTrue` option is `false`  |
| `nullableBooleanVar !== true`  | `!nullableBooleanVar`           | Only checked/fixed if the `allowComparingNullableBooleansToTrue` option is `false`  |
| `nullableBooleanVar === false` | `nullableBooleanVar ?? true`    | Only checked/fixed if the `allowComparingNullableBooleansToFalse` option is `false` |
| `nullableBooleanVar !== false` | `!(nullableBooleanVar ?? true)` | Only checked/fixed if the `allowComparingNullableBooleansToFalse` option is `false` |
# `no-non-null-assertion`

Disallows non-null assertions using the `!` postfix operator.

## Rule Details

Using non-null assertions cancels the benefits of the strict null-checking mode.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
interface Foo {
  bar?: string;
}

const foo: Foo = getFoo();
const includesBaz: boolean = foo.bar!.includes('baz');
```

### ✅ Correct

```ts
interface Foo {
  bar?: string;
}

const foo: Foo = getFoo();
const includesBaz: boolean = foo.bar?.includes('baz') ?? false;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-non-null-assertion": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about strict null-checking, then you will not need this rule.
# `explicit-module-boundary-types`

Requires explicit return and argument types on exported functions' and classes' public class methods.

Explicit types for function return values and arguments makes it clear to any calling code what is the module boundary's input and output.

## Rule Details

This rule aims to ensure that the values returned from a module are of the expected type.

<!--tabs-->

### ❌ Incorrect

```ts
// Should indicate that no value is returned (void)
export function test() {
  return;
}

// Should indicate that a number is returned
export default function () {
  return 1;
}

// Should indicate that a string is returned
export var arrowFn = () => 'test';

// All arguments should be typed
export var arrowFn = (arg): string => `test ${arg}`;
export var arrowFn = (arg: any): string => `test ${arg}`;

export class Test {
  // Should indicate that no value is returned (void)
  method() {
    return;
  }
}
```

### ✅ Correct

```ts
// Function is not exported
function test() {
  return;
}

// A return value of type number
export var fn = function (): number {
  return 1;
};

// A return value of type string
export var arrowFn = (arg: string): string => `test ${arg}`;

// All arguments should be typed
export var arrowFn = (arg: string): string => `test ${arg}`;
export var arrowFn = (arg: unknown): string => `test ${arg}`;

// Class is not exported
class Test {
  method() {
    return;
  }
}
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  /**
   * If true, the rule will not report for arguments that are explicitly typed as `any`
   */
  allowArgumentsExplicitlyTypedAsAny?: boolean;
  /**
   * If true, body-less arrow functions that return an `as const` type assertion will not
   * require an explicit return value annotation.
   * You must still type the parameters of the function.
   */
  allowDirectConstAssertionInArrowFunctions?: boolean;
  /**
   * An array of function/method names that will not have their arguments or their return values checked.
   */
  allowedNames?: string[];
  /**
   * If true, functions immediately returning another function expression will not
   * require an explicit return value annotation.
   * You must still type the parameters of the function.
   */
  allowHigherOrderFunctions?: boolean;
  /**
   * If true, type annotations are also allowed on the variable of a function expression
   * rather than on the function arguments/return value directly.
   */
  allowTypedFunctionExpressions?: boolean;
};

const defaults = {
  allowArgumentsExplicitlyTypedAsAny: false,
  allowDirectConstAssertionInArrowFunctions: true,
  allowedNames: [],
  allowHigherOrderFunctions: true,
  allowTypedFunctionExpressions: true,
};
```

### Configuring in a mixed JS/TS codebase

If you are working on a codebase within which you lint non-TypeScript code (i.e. `.js`/`.mjs`/`.cjs`/`.jsx`), you should ensure that you should use [ESLint `overrides`](https://eslint.org/docs/user-guide/configuring#disabling-rules-only-for-a-group-of-files) to only enable the rule on `.ts`/`.mts`/`.cts`/`.tsx` files. If you don't, then you will get unfixable lint errors reported within `.js`/`.mjs`/`.cjs`/`.jsx` files.

```jsonc
{
  "rules": {
    // disable the rule for all files
    "@typescript-eslint/explicit-module-boundary-types": "off"
  },
  "overrides": [
    {
      // enable the rule specifically for TypeScript files
      "files": ["*.ts", "*.mts", "*.cts", "*.tsx"],
      "rules": {
        "@typescript-eslint/explicit-module-boundary-types": ["error"]
      }
    }
  ]
}
```

### `allowArgumentsExplicitlyTypedAsAny`

Examples of code for this rule with `{ allowArgumentsExplicitlyTypedAsAny: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
export const func = (value: any): number => value + 1;
```

#### ✅ Correct

```ts
export const func = (value: number): number => value + 1;
```

### `allowDirectConstAssertionInArrowFunctions`

Examples of code for this rule with `{ allowDirectConstAssertionInArrowFunctions: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
export const func = (value: number) => ({ type: 'X', value });
export const foo = () => ({
  bar: true,
});
export const bar = () => 1;
```

#### ✅ Correct

```ts
export const func = (value: number) => ({ type: 'X', value } as const);
export const foo = () =>
  ({
    bar: true,
  } as const);
export const bar = () => 1 as const;
```

### `allowedNames`

You may pass function/method names you would like this rule to ignore, like so:

```json
{
  "@typescript-eslint/explicit-module-boundary-types": [
    "error",
    {
      "allowedNames": ["ignoredFunctionName", "ignoredMethodName"]
    }
  ]
}
```

### `allowHigherOrderFunctions`

Examples of code for this rule with `{ allowHigherOrderFunctions: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
export const arrowFn = () => () => {};

export function fn() {
  return function () {};
}

export function foo(outer: string) {
  return function (inner: string) {};
}
```

#### ✅ Correct

```ts
export const arrowFn = () => (): void => {};

export function fn() {
  return function (): void {};
}

export function foo(outer: string) {
  return function (inner: string): void {};
}
```

### `allowTypedFunctionExpressions`

Examples of code for this rule with `{ allowTypedFunctionExpressions: false }`:

<!--tabs-->

#### ❌ Incorrect

```ts
export let arrowFn = () => 'test';

export let funcExpr = function () {
  return 'test';
};

export let objectProp = {
  foo: () => 1,
};

export const foo = bar => {};
```

#### ✅ Correct

```ts
type FuncType = () => string;

export let arrowFn: FuncType = () => 'test';

export let funcExpr: FuncType = function () {
  return 'test';
};

export let asTyped = (() => '') as () => string;
export let castTyped = <() => string>(() => '');

interface ObjectType {
  foo(): number;
}
export let objectProp: ObjectType = {
  foo: () => 1,
};
export let objectPropAs = {
  foo: () => 1,
} as ObjectType;
export let objectPropCast = <ObjectType>{
  foo: () => 1,
};

type FooType = (bar: string) => void;
export const foo: FooType = bar => {};
```

## When Not To Use It

If you wish to make sure all functions have explicit return types, as opposed to only the module boundaries, you can use [explicit-function-return-type](./explicit-function-return-type.md)

## Further Reading

- TypeScript [Functions](https://www.typescriptlang.org/docs/handbook/functions.html#function-types)
# `no-inferrable-types`

Disallows explicit type declarations for variables or parameters initialized to a number, string, or boolean.

Explicit types where they can be easily inferred may add unnecessary verbosity.

## Rule Details

This rule disallows explicit type declarations on parameters, variables
and properties where the type can be easily inferred from its value.

## Options

This rule accepts the following options:

```ts
interface Options {
  ignoreParameters?: boolean;
  ignoreProperties?: boolean;
}
```

### Default

The default options are:

```json
{
  "ignoreParameters": false,
  "ignoreProperties": false
}
```

With these options, the following patterns are:

<!--tabs-->

#### ❌ Incorrect

```ts
const a: bigint = 10n;
const a: bigint = -10n;
const a: bigint = BigInt(10);
const a: bigint = -BigInt(10);
const a: boolean = false;
const a: boolean = true;
const a: boolean = Boolean(null);
const a: boolean = !0;
const a: number = 10;
const a: number = +10;
const a: number = -10;
const a: number = Number('1');
const a: number = +Number('1');
const a: number = -Number('1');
const a: number = Infinity;
const a: number = +Infinity;
const a: number = -Infinity;
const a: number = NaN;
const a: number = +NaN;
const a: number = -NaN;
const a: null = null;
const a: RegExp = /a/;
const a: RegExp = RegExp('a');
const a: RegExp = new RegExp('a');
const a: string = 'str';
const a: string = `str`;
const a: string = String(1);
const a: symbol = Symbol('a');
const a: undefined = undefined;
const a: undefined = void someValue;

class Foo {
  prop: number = 5;
}

function fn(a: number = 5, b: boolean = true) {}
```

#### ✅ Correct

```ts
const a = 10n;
const a = -10n;
const a = BigInt(10);
const a = -BigInt(10);
const a = false;
const a = true;
const a = Boolean(null);
const a = !0;
const a = 10;
const a = +10;
const a = -10;
const a = Number('1');
const a = +Number('1');
const a = -Number('1');
const a = Infinity;
const a = +Infinity;
const a = -Infinity;
const a = NaN;
const a = +NaN;
const a = -NaN;
const a = null;
const a = /a/;
const a = RegExp('a');
const a = new RegExp('a');
const a = 'str';
const a = `str`;
const a = String(1);
const a = Symbol('a');
const a = undefined;
const a = void someValue;

class Foo {
  prop = 5;
}

function fn(a = 5, b = true) {}

function fn(a: number, b: boolean, c: string) {}
```

<!--/tabs-->

### `ignoreParameters`

When set to true, the following pattern is considered valid:

```ts
function foo(a: number = 5, b: boolean = true) {
  // ...
}
```

### `ignoreProperties`

When set to true, the following pattern is considered valid:

```ts
class Foo {
  prop: number = 5;
}
```

## When Not To Use It

If you do not want to enforce inferred types.

## Further Reading

TypeScript [Inference](https://www.typescriptlang.org/docs/handbook/type-inference.html)
# `no-loop-func`

Disallows function declarations that contain unsafe references inside loop statements.

## Rule Details

This rule extends the base [`eslint/no-loop-func`](https://eslint.org/docs/rules/no-loop-func) rule.
It adds support for TypeScript types.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-loop-func": "off",
  "@typescript-eslint/no-loop-func": ["error"]
}
```

## Options

See [`eslint/no-loop-func` options](https://eslint.org/docs/rules/no-loop-func#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-loop-func.md)

</sup>
# `strict-boolean-expressions`

Disallows certain types in boolean expressions.

Forbids usage of non-boolean types in expressions where a boolean is expected.
`boolean` and `never` types are always allowed.
Additional types which are considered safe in a boolean context can be configured via options.

The following nodes are considered boolean expressions and their type is checked:

- Argument to the logical negation operator (`!arg`).
- The condition in a conditional expression (`cond ? x : y`).
- Conditions for `if`, `for`, `while`, and `do-while` statements.
- Operands of logical binary operators (`lhs || rhs` and `lhs && rhs`).
  - Right-hand side operand is ignored when it's not a descendant of another boolean expression.
    This is to allow usage of boolean operators for their short-circuiting behavior.

## Examples

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
// nullable numbers are considered unsafe by default
let num: number | undefined = 0;
if (num) {
  console.log('num is defined');
}

// nullable strings are considered unsafe by default
let str: string | null = null;
if (!str) {
  console.log('str is empty');
}

// nullable booleans are considered unsafe by default
function foo(bool?: boolean) {
  if (bool) {
    bar();
  }
}

// `any`, unconstrained generics and unions of more than one primitive type are disallowed
const foo = <T>(arg: T) => (arg ? 1 : 0);

// always-truthy and always-falsy types are disallowed
let obj = {};
while (obj) {
  obj = getObj();
}
```

### ✅ Correct

```tsx
// Using logical operator short-circuiting is allowed
const Component = () => {
  const entry = map.get('foo') || {};
  return entry && <p>Name: {entry.name}</p>;
};

// nullable values should be checked explicitly against null or undefined
let num: number | undefined = 0;
if (num != null) {
  console.log('num is defined');
}

let str: string | null = null;
if (str != null && !str) {
  console.log('str is empty');
}

function foo(bool?: boolean) {
  if (bool ?? false) {
    bar();
  }
}

// `any` types should be cast to boolean explicitly
const foo = (arg: any) => (Boolean(arg) ? 1 : 0);
```

## Options

```ts
type Options = {
  allowString?: boolean;
  allowNumber?: boolean;
  allowNullableObject?: boolean;
  allowNullableBoolean?: boolean;
  allowNullableString?: boolean;
  allowNullableNumber?: boolean;
  allowAny?: boolean;
};

const defaultOptions: Options = {
  allowString: true,
  allowNumber: true,
  allowNullableObject: true,
  allowNullableBoolean: false,
  allowNullableString: false,
  allowNullableNumber: false,
  allowAny: false,
  allowRuleToRunWithoutStrictNullChecksIKnowWhatIAmDoing: false,
};
```

### `allowString`

Allows `string` in a boolean context.
This is safe because strings have only one falsy value (`""`).
Set this to `false` if you prefer the explicit `str != ""` or `str.length > 0` style.

### `allowNumber`

Allows `number` in a boolean context.
This is safe because numbers have only two falsy values (`0` and `NaN`).
Set this to `false` if you prefer the explicit `num != 0` and `!Number.isNaN(num)` style.

### `allowNullableObject`

Allows `object | function | symbol | null | undefined` in a boolean context.
This is safe because objects, functions and symbols don't have falsy values.
Set this to `false` if you prefer the explicit `obj != null` style.

### `allowNullableBoolean`

Allows `boolean | null | undefined` in a boolean context.
This is unsafe because nullable booleans can be either `false` or nullish.
Set this to `false` if you want to enforce explicit `bool ?? false` or `bool ?? true` style.
Set this to `true` if you don't mind implicitly treating false the same as a nullish value.

### `allowNullableString`

Allows `string | null | undefined` in a boolean context.
This is unsafe because nullable strings can be either an empty string or nullish.
Set this to `true` if you don't mind implicitly treating an empty string the same as a nullish value.

### `allowNullableNumber`

Allows `number | null | undefined` in a boolean context.
This is unsafe because nullable numbers can be either a falsy number or nullish.
Set this to `true` if you don't mind implicitly treating zero or NaN the same as a nullish value.

### `allowAny`

Allows `any` in a boolean context.
This is unsafe for obvious reasons.
Set this to `true` at your own risk.

### `allowRuleToRunWithoutStrictNullChecksIKnowWhatIAmDoing`

If this is set to `false`, then the rule will error on every file whose `tsconfig.json` does _not_ have the `strictNullChecks` compiler option (or `strict`) set to `true`.

Without `strictNullChecks`, TypeScript essentially erases `undefined` and `null` from the types. This means when this rule inspects the types from a variable, **it will not be able to tell that the variable might be `null` or `undefined`**, which essentially makes this rule a lot less useful.

You should be using `strictNullChecks` to ensure complete type-safety in your codebase.

If for some reason you cannot turn on `strictNullChecks`, but still want to use this rule - you can use this option to allow it - but know that the behavior of this rule is _undefined_ with the compiler option turned off. We will not accept bug reports if you are using this option.

## Fixes and Suggestions

This rule provides following fixes and suggestions for particular types in boolean context:

- `boolean` - Always allowed - no fix needed.
- `string` - (when `allowString` is `false`) - Provides following suggestions:
  - Change condition to check string's length (`str` → `str.length > 0`)
  - Change condition to check for empty string (`str` → `str !== ""`)
  - Explicitly cast value to a boolean (`str` → `Boolean(str)`)
- `number` - (when `allowNumber` is `false`):
  - For `array.length` - Provides **autofix**:
    - Change condition to check for 0 (`array.length` → `array.length > 0`)
  - For other number values - Provides following suggestions:
    - Change condition to check for 0 (`num` → `num !== 0`)
    - Change condition to check for NaN (`num` → `!Number.isNaN(num)`)
    - Explicitly cast value to a boolean (`num` → `Boolean(num)`)
- `object | null | undefined` - (when `allowNullableObject` is `false`) - Provides **autofix**:
  - Change condition to check for null/undefined (`maybeObj` → `maybeObj != null`)
- `boolean | null | undefined` - Provides following suggestions:
  - Explicitly treat nullish value the same as false (`maybeBool` → `maybeBool ?? false`)
  - Change condition to check for true/false (`maybeBool` → `maybeBool === true`)
- `string | null | undefined` - Provides following suggestions:
  - Change condition to check for null/undefined (`maybeStr` → `maybeStr != null`)
  - Explicitly treat nullish value the same as an empty string (`maybeStr` → `maybeStr ?? ""`)
  - Explicitly cast value to a boolean (`maybeStr` → `Boolean(maybeStr)`)
- `number | null | undefined` - Provides following suggestions:
  - Change condition to check for null/undefined (`maybeNum` → `maybeNum != null`)
  - Explicitly treat nullish value the same as 0 (`maybeNum` → `maybeNum ?? 0`)
  - Explicitly cast value to a boolean (`maybeNum` → `Boolean(maybeNum)`)
- `any` and `unknown` - Provides following suggestions:
  - Explicitly cast value to a boolean (`value` → `Boolean(value)`)

## Related To

- [no-unnecessary-condition](./no-unnecessary-condition.md) - Similar rule which reports always-truthy and always-falsy values in conditions
# `type-annotation-spacing`

Requires consistent spacing around type annotations.

Spacing around type annotations improves readability of the code. Although the most commonly used style guideline for type annotations in TypeScript prescribes adding a space after the colon, but not before it, it is subjective to the preferences of a project. For example:

<!-- prettier-ignore -->
```ts
// with space after, but not before (default if no option is specified)
let foo: string = "bar";

// with no spaces
let foo:string = "bar";

// with space before and after
let foo : string = "bar";

// with space before, but not after
let foo :string = "bar";

// with spaces before and after the fat arrow (default if no option is specified)
type Foo = (string: name) => string;

// with no spaces between the fat arrow
type Foo = (string: name)=>string;

// with space after, but not before the fat arrow
type Foo = (string: name)=> string;

// with space before, but not after the fat arrow
type Foo = (string: name) =>string;
```

## Rule Details

This rule aims to enforce specific spacing patterns around type annotations and function types in type literals.

## Options

This rule has an object option:

- `"before": false`, (default for colon) disallows spaces before the colon/arrow.
- `"before": true`, (default for arrow) requires a space before the colon/arrow.
- `"after": true`, (default) requires a space after the colon/arrow.
- `"after": false`, disallows spaces after the colon/arrow.
- `"overrides"`, overrides the default options for type annotations with `colon` (e.g. `const foo: string`) and function types with `arrow` (e.g. `type Foo = () => {}`). Additionally allows granular overrides for `variable` (`const foo: string`),`parameter` (`function foo(bar: string) {...}`),`property` (`interface Foo { bar: string }`) and `returnType` (`function foo(): string {...}`) annotations.

### defaults

Examples of code for this rule with no options at all:

<!--tabs-->

#### ❌ Incorrect

<!-- prettier-ignore -->
```ts
let foo:string = "bar";
let foo :string = "bar";
let foo : string = "bar";

function foo():string {}
function foo() :string {}
function foo() : string {}

class Foo {
    name:string;
}

class Foo {
    name :string;
}

class Foo {
    name : string;
}

type Foo = ()=>{};
type Foo = () =>{};
type Foo = ()=> {};
```

#### ✅ Correct

<!-- prettier-ignore -->
```ts
let foo: string = "bar";

function foo(): string {}

class Foo {
    name: string;
}

type Foo = () => {};
```

### after

Examples of code for this rule with `{ "before": false, "after": true }`:

<!--tabs-->

#### ❌ Incorrect

<!-- prettier-ignore -->
```ts
let foo:string = "bar";
let foo :string = "bar";
let foo : string = "bar";

function foo():string {}
function foo() :string {}
function foo() : string {}

class Foo {
    name:string;
}

class Foo {
    name :string;
}

class Foo {
    name : string;
}

type Foo = ()=>{};
type Foo = () =>{};
type Foo = () => {};
```

#### ✅ Correct

<!-- prettier-ignore -->
```ts
let foo: string = "bar";

function foo(): string {}

class Foo {
    name: string;
}

type Foo = ()=> {};
```

### before

Examples of code for this rule with `{ "before": true, "after": true }` options:

<!--tabs-->

#### ❌ Incorrect

<!-- prettier-ignore -->
```ts
let foo: string = "bar";
let foo:string = "bar";
let foo :string = "bar";

function foo(): string {}
function foo():string {}
function foo() :string {}

class Foo {
    name: string;
}

class Foo {
    name:string;
}

class Foo {
    name :string;
}

type Foo = ()=>{};
type Foo = () =>{};
type Foo = ()=> {};
```

#### ✅ Correct

<!-- prettier-ignore -->
```ts
let foo : string = "bar";

function foo() : string {}

class Foo {
    name : string;
}

type Foo = () => {};
```

### overrides - colon

Examples of code for this rule with `{ "before": false, "after": false, overrides: { colon: { before: true, after: true }} }` options:

<!--tabs-->

#### ❌ Incorrect

<!-- prettier-ignore -->
```ts
let foo: string = "bar";
let foo:string = "bar";
let foo :string = "bar";

function foo(): string {}
function foo():string {}
function foo() :string {}

class Foo {
    name: string;
}

class Foo {
    name:string;
}

class Foo {
    name :string;
}

type Foo = () =>{};
type Foo = ()=> {};
type Foo = () => {};
```

#### ✅ Correct

<!-- prettier-ignore -->
```ts
let foo : string = "bar";

function foo() : string {}

class Foo {
    name : string;
}

type Foo = {
    name: (name : string)=>string;
}

type Foo = ()=>{};
```

### overrides - arrow

Examples of code for this rule with `{ "before": false, "after": false, overrides: { arrow: { before: true, after: true }} }` options:

<!--tabs-->

#### ❌ Incorrect

<!-- prettier-ignore -->
```ts
let foo: string = "bar";
let foo : string = "bar";
let foo :string = "bar";

function foo(): string {}
function foo():string {}
function foo() :string {}

class Foo {
    name: string;
}

class Foo {
    name : string;
}

class Foo {
    name :string;
}

type Foo = ()=>{};
type Foo = () =>{};
type Foo = ()=> {};
```

#### ✅ Correct

<!-- prettier-ignore -->
```ts
let foo:string = "bar";

function foo():string {}

class Foo {
    name:string;
}

type Foo = () => {};
```

## When Not To Use It

If you don't want to enforce spacing for your type annotations, you can safely turn this rule off.

## Further Reading

- [TypeScript Type System](https://basarat.gitbooks.io/typescript/docs/types/type-system.html)
- [Type Inference](https://www.typescriptlang.org/docs/handbook/type-inference.html)
# `typedef`

Requires type annotations in certain places.

TypeScript cannot always infer types for all places in code.
Some locations require type annotations for their types to be inferred.

```ts
class ContainsText {
  // There must be a type annotation here to infer the type
  delayedText: string;

  // `typedef` requires a type annotation here to maintain consistency
  immediateTextExplicit: string = 'text';

  // This is still a string type because of its initial value
  immediateTextImplicit = 'text';
}
```

**_Note:_** requiring type annotations unnecessarily can be cumbersome to maintain and generally reduces code readability.
TypeScript is often better at inferring types than easily written type annotations would allow.

**Instead of enabling `typedef`, it is generally recommended to use the `--noImplicitAny` and `--strictPropertyInitialization` compiler options to enforce type annotations only when useful.**

## Rule Details

This rule can enforce type annotations in locations regardless of whether they're required.
This is typically used to maintain consistency for element types that sometimes require them.

> To enforce type definitions existing on call signatures, use `explicit-function-return-type`, or `explicit-module-boundary-types`.

## Options

```ts
type Options = {
  arrayDestructuring?: boolean;
  arrowParameter?: boolean;
  memberVariableDeclaration?: boolean;
  objectDestructuring?: boolean;
  parameter?: boolean;
  propertyDeclaration?: boolean;
  variableDeclaration?: boolean;
  variableDeclarationIgnoreFunction?: boolean;
};

const defaultOptions: Options = {
  arrayDestructuring: false,
  arrowParameter: false,
  memberVariableDeclaration: false,
  objectDestructuring: false,
  parameter: false,
  propertyDeclaration: false,
  variableDeclaration: false,
  variableDeclarationIgnoreFunction: false,
};
```

For example, with the following configuration:

```json
{
  "rules": {
    "@typescript-eslint/typedef": [
      "error",
      {
        "arrowParameter": true,
        "variableDeclaration": true
      }
    ]
  }
}
```

- Type annotations on arrow function parameters are required
- Type annotations on variables are required

### `arrayDestructuring`

Whether to enforce type annotations on variables declared using array destructuring.

Examples of code with `{ "arrayDestructuring": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const [a] = [1];
const [b, c] = [1, 2];
```

#### ✅ Correct

```ts
const [a]: number[] = [1];
const [b]: [number] = [2];
const [c, d]: [boolean, string] = [true, 'text'];

for (const [key, val] of new Map([['key', 1]])) {
}
```

### `arrowParameter`

Whether to enforce type annotations for parameters of arrow functions.

Examples of code with `{ "arrowParameter": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const logsSize = size => console.log(size);

['hello', 'world'].map(text => text.length);

const mapper = {
  map: text => text + '...',
};
```

#### ✅ Correct

```ts
const logsSize = (size: number) => console.log(size);

['hello', 'world'].map((text: string) => text.length);

const mapper = {
  map: (text: string) => text + '...',
};
```

### `memberVariableDeclaration`

Whether to enforce type annotations on member variables of classes.

Examples of code with `{ "memberVariableDeclaration": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
class ContainsText {
  delayedText;
  immediateTextImplicit = 'text';
}
```

#### ✅ Correct

```ts
class ContainsText {
  delayedText: string;
  immediateTextImplicit: string = 'text';
}
```

### `objectDestructuring`

Whether to enforce type annotations on variables declared using object destructuring.

Examples of code with `{ "objectDestructuring": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const { length } = 'text';
const [b, c] = Math.random() ? [1, 2] : [3, 4];
```

#### ✅ Correct

```ts
const { length }: { length: number } = 'text';
const [b, c]: [number, number] = Math.random() ? [1, 2] : [3, 4];

for (const { key, val } of [{ key: 'key', val: 1 }]) {
}
```

### `parameter`

Whether to enforce type annotations for parameters of functions and methods.

Examples of code with `{ "parameter": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
function logsSize(size): void {
  console.log(size);
}

const doublesSize = function (size): number {
  return size * 2;
};

const divider = {
  curriesSize(size): number {
    return size;
  },
  dividesSize: function (size): number {
    return size / 2;
  },
};

class Logger {
  log(text): boolean {
    console.log('>', text);
    return true;
  }
}
```

#### ✅ Correct

```ts
function logsSize(size: number): void {
  console.log(size);
}

const doublesSize = function (size: number): number {
  return size * 2;
};

const divider = {
  curriesSize(size: number): number {
    return size;
  },
  dividesSize: function (size: number): number {
    return size / 2;
  },
};

class Logger {
  log(text: boolean): boolean {
    console.log('>', text);
    return true;
  }
}
```

### `propertyDeclaration`

Whether to enforce type annotations for properties of interfaces and types.

Examples of code with `{ "propertyDeclaration": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
type Members = {
  member;
  otherMember;
};
```

#### ✅ Correct

```ts
type Members = {
  member: boolean;
  otherMember: string;
};
```

### `variableDeclaration`

Whether to enforce type annotations for variable declarations, excluding array and object destructuring.

Examples of code with `{ "variableDeclaration": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const text = 'text';
let initialText = 'text';
let delayedText;
```

#### ✅ Correct

```ts
const text: string = 'text';
let initialText: string = 'text';
let delayedText: string;
```

### `variableDeclarationIgnoreFunction`

Ignore variable declarations for non-arrow and arrow functions.

Examples of code with `{ "variableDeclaration": true, "variableDeclarationIgnoreFunction": true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
const text = 'text';
```

#### ✅ Correct

```ts
const a = (): void => {};
const b = function (): void => {};
const c: () => void = (): void => {};

class Foo {
  a = (): void => {};
  b = function (): void => {};
  c = () => void = (): void => {};
}
```

## When Not To Use It

If you are using stricter TypeScript compiler options, particularly `--noImplicitAny` and/or `--strictPropertyInitialization`, you likely don't need this rule.

In general, if you do not consider the cost of writing unnecessary type annotations reasonable, then do not use this rule.

## Further Reading

- [TypeScript Type System](https://basarat.gitbooks.io/typescript/docs/types/type-system.html)
- [Type Inference](https://www.typescriptlang.org/docs/handbook/type-inference.html)
# `no-invalid-void-type`

Disallows `void` type outside of generic or return types.

Disallows usage of `void` type outside of return types or generic type arguments.
If `void` is used as return type, it shouldn’t be a part of intersection/union type with most other types.

## Rationale

The `void` type means “nothing” or that a function does not return any value,
in contrast with implicit `undefined` type which means that a function returns a value `undefined`.
So “nothing” cannot be mixed with any other types, other than `never`, which accepts all types.
If you need this - use the `undefined` type instead.

## Rule Details

This rule aims to ensure that the `void` type is only used in valid places.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
type PossibleValues = string | number | void;
type MorePossibleValues = string | ((number & any) | (string | void));

function logSomething(thing: void) {}
function printArg<T = void>(arg: T) {}

logAndReturn<void>(undefined);

interface Interface {
  lambda: () => void;
  prop: void;
}

class MyClass {
  private readonly propName: void;
}
```

### ✅ Correct

```ts
type NoOp = () => void;

function noop(): void {}

let trulyUndefined = void 0;

async function promiseMeSomething(): Promise<void> {}

type stillVoid = void | never;
```

## Options

```ts
interface Options {
  allowInGenericTypeArguments?: boolean | string[];
  allowAsThisParameter?: boolean;
}

const defaultOptions: Options = {
  allowInGenericTypeArguments: true,
  allowAsThisParameter: false,
};
```

### `allowInGenericTypeArguments`

This option lets you control if `void` can be used as a valid value for generic type parameters.

Alternatively, you can provide an array of strings which whitelist which types may accept `void` as a generic type parameter.

Any types considered valid by this option will be considered valid as part of a union type with `void`.

This option is `true` by default.

The following patterns are considered warnings with `{ allowInGenericTypeArguments: false }`:

```ts
logAndReturn<void>(undefined);

let voidPromise: Promise<void> = new Promise<void>(() => {});
let voidMap: Map<string, void> = new Map<string, void>();
```

The following patterns are considered warnings with `{ allowInGenericTypeArguments: ['Ex.Mx.Tx'] }`:

```ts
logAndReturn<void>(undefined);

type NotAllowedVoid1 = Mx.Tx<void>;
type NotAllowedVoid2 = Tx<void>;
type NotAllowedVoid3 = Promise<void>;
```

The following patterns are not considered warnings with `{ allowInGenericTypeArguments: ['Ex.Mx.Tx'] }`:

```ts
type AllowedVoid = Ex.Mx.Tx<void>;
type AllowedVoidUnion = void | Ex.Mx.Tx<void>;
```

### `allowAsThisParameter`

This option allows specifying a `this` parameter of a function to be `void` when set to `true`.
This pattern can be useful to explicitly label function types that do not use a `this` argument. [See the TypeScript docs for more information](https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters-in-callbacks).

This option is `false` by default.

The following patterns are considered warnings with `{ allowAsThisParameter: false }` but valid with `{ allowAsThisParameter: true }`:

```ts
function doThing(this: void) {}
class Example {
  static helper(this: void) {}
  callback(this: void) {}
}
```

## When Not To Use It

If you don't care about if `void` is used with other types,
or in invalid places, then you don't need this rule.
# `no-type-alias`

Disallows type aliases.

In TypeScript, type aliases serve three purposes:

- Aliasing other types so that we can refer to them using a simpler name.

```ts
// this...
type Person = {
    firstName: string,
    lastName: string,
    age: number
};

function addPerson(person : Person) { ... }

// is easier to read than this...
function addPerson(person : { firstName: string, lastName: string, age: number}) { ... }
```

- Act sort of like an interface, providing a set of methods and properties that must exist
  in the objects implementing the type.

```ts
type Person = {
    firstName: string,
    lastName: string,
    age: number,
    walk: () => void,
    talk: () => void
};

// you know person will have 3 properties and 2 methods,
// because the structure has already been defined.
var person : Person = { ... }

// so we can be sure that this will work
person.walk();
```

- Act like mapping tools between types to allow quick modifications.

```ts
type Immutable<T> = { readonly [P in keyof T]: T[P] };

type Person = {
  name: string;
  age: number;
};

type ImmutablePerson = Immutable<Person>;

var person: ImmutablePerson = { name: 'John', age: 30 };
person.name = 'Brad'; // error, readonly property
```

When aliasing, the type alias does not create a new type, it just creates a new name
to refer to the original type. So aliasing primitives and other simple types, tuples, unions
or intersections can some times be redundant.

```ts
// this doesn't make much sense
type myString = string;
```

On the other hand, using a type alias as an interface can limit your ability to:

- Reuse your code: interfaces can be extended or implemented by other types. Type aliases cannot.
- Debug your code: interfaces create a new name, so is easy to identify the base type of an object
  while debugging the application.

Finally, mapping types is an advanced technique and leaving it open can quickly become a pain point
in your application.

## Rule Details

This rule disallows the use of type aliases in favor of interfaces
and simplified types (primitives, tuples, unions, intersections, etc).

## Options

This rule, in its default state, does not require any argument. If you would like to enable one
or more of the following you may pass an object with the options set as follows:

- `allowAliases` set to `"always"` will allow you to do aliasing (Defaults to `"never"`).
- `allowCallbacks` set to `"always"` will allow you to use type aliases with callbacks (Defaults to `"never"`)
- `allowConditionalTypes` set to `"always"` will allow you to use type aliases with conditional types (Defaults to `"never"`)
- `allowConstructors` set to `"always"` will allow you to use type aliases with constructors (Defaults to `"never"`)
- `allowLiterals` set to `"always"` will allow you to use type aliases with literal objects (Defaults to `"never"`)
- `allowMappedTypes` set to `"always"` will allow you to use type aliases as mapping tools (Defaults to `"never"`)
- `allowTupleTypes` set to `"always"` will allow you to use type aliases with tuples (Defaults to `"never"`)
- `allowGenerics` set to `"always"` will allow you to use type aliases with generics (Defaults to `"never"`)

### `allowAliases`

This applies to primitive types and reference types.

The setting accepts the following values:

- `"always"` or `"never"` to active or deactivate the feature.
- `"in-unions"`, allows aliasing in union statements, e.g. `type Foo = string | string[];`
- `"in-intersections"`, allows aliasing in intersection statements, e.g. `type Foo = string & string[];`
- `"in-unions-and-intersections"`, allows aliasing in union and/or intersection statements.

Examples of **correct** code for the `{ "allowAliases": "always" }` options:

```ts
// primitives
type Foo = 'a';

type Foo = 'a' | 'b';

type Foo = string;

type Foo = string | string[];

type Foo = string & string[];

type Foo = `foo-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar;

type Foo = Bar | Baz;

type Foo = Bar & Baz;
```

Examples of **incorrect** code for the `{ "allowAliases": "in-unions" }` option:

```ts
// primitives
type Foo = 'a';

type Foo = string;

type Foo = string & string[];

type Foo = `foo-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar;

type Foo = Bar & Baz;
```

Examples of **correct** code for the `{ "allowAliases": "in-unions" }` option:

```ts
// primitives
type Foo = 'a' | 'b';

type Foo = string | string[];

type Foo = `a-${number}` | `b-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar | Baz;
```

Examples of **incorrect** code for the `{ "allowAliases": "in-intersections" }` option:

```ts
// primitives
type Foo = 'a';

type Foo = 'a' | 'b';

type Foo = string;

type Foo = string | string[];

type Foo = `a-${number}` | `b-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar;

type Foo = Bar | Baz;
```

Examples of **correct** code for the `{ "allowAliases": "in-intersections" }` option:

```ts
// primitives
type Foo = string & string[];

type Foo = `a-${number}` & `b-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar & Baz;
```

Examples of **incorrect** code for the `{ "allowAliases": "in-unions-and-intersections" }` option:

```ts
// primitives
type Foo = 'a';

type Foo = string;

type Foo = `foo-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar;
```

Examples of **correct** code for the `{ "allowAliases": "in-unions-and-intersections" }` option:

```ts
// primitives
type Foo = 'a' | 'b';

type Foo = string | string[];

type Foo = string & string[];

type Foo = `a-${number}` & `b-${number}`;

type Foo = `a-${number}` | `b-${number}`;

// reference types
interface Bar {}
class Baz implements Bar {}

type Foo = Bar | Baz;

type Foo = Bar & Baz;
```

### `allowCallbacks`

This applies to function types.

The setting accepts the following values:

- `"always"` or `"never"` to active or deactivate the feature.

Examples of **correct** code for the `{ "allowCallbacks": "always" }` option:

```ts
type Foo = () => void;

type Foo = (name: string) => string;

class Person {}

type Foo = (name: string, age: number) => string | Person;

type Foo = (name: string, age: number) => string & Person;
```

### `allowConditionalTypes`

This applies to conditional types.

Examples of **correct** code for the `{ "allowConditionalTypes": "always" }` option:

```ts
type Foo<T> = T extends number ? number : null;
```

### `allowConstructors`

This applies to constructor types.

The setting accepts the following values:

- `"always"` or `"never"` to active or deactivate the feature.

Examples of **correct** code for the `{ "allowConstructors": "always" }` option:

```ts
type Foo = new () => void;
```

### `allowLiterals`

This applies to literal types (`type Foo = { ... }`).

The setting accepts the following options:

- `"always"` or `"never"` to active or deactivate the feature.
- `"in-unions"`, allows literals in union statements, e.g. `type Foo = string | string[];`
- `"in-intersections"`, allows literals in intersection statements, e.g. `type Foo = string & string[];`
- `"in-unions-and-intersections"`, allows literals in union and/or intersection statements.

Examples of **correct** code for the `{ "allowLiterals": "always" }` options:

```ts
type Foo = {};

type Foo = {
  name: string;
  age: number;
};

type Foo = {
  name: string;
  age: number;
  walk: (miles: number) => void;
};

type Foo = { name: string } | { age: number };

type Foo = { name: string } & { age: number };
```

Examples of **incorrect** code for the `{ "allowLiterals": "in-unions" }` option:

```ts
type Foo = {};

type Foo = {
  name: string;
  age: number;
};

type Foo = {
  name: string;
  age: number;
  walk: (miles: number) => void;
};

type Foo = { name: string } & { age: number };
```

Examples of **correct** code for the `{ "allowLiterals": "in-unions" }` option:

```ts
type Foo = { name: string } | { age: number };
```

Examples of **incorrect** code for the `{ "allowLiterals": "in-intersections" }` option:

```ts
type Foo = {};

type Foo = {
  name: string;
  age: number;
};

type Foo = {
  name: string;
  age: number;
  walk: (miles: number) => void;
};

type Foo = { name: string } | { age: number };
```

Examples of **correct** code for the `{ "allowLiterals": "in-intersections" }` option:

```ts
type Foo = { name: string } & { age: number };
```

Examples of **incorrect** code for the `{ "allowLiterals": "in-unions-and-intersections" }` option:

```ts
type Foo = {};

type Foo = {
  name: string;
  age: number;
};

type Foo = {
  name: string;
  age: number;
  walk: (miles: number) => void;
};
```

Examples of **correct** code for the `{ "allowLiterals": "in-unions-and-intersections" }` option:

```ts
type Foo = { name: string } | { age: number };

type Foo = { name: string } & { age: number };
```

### `allowMappedTypes`

This applies to literal types.

The setting accepts the following values:

- `"always"` or `"never"` to active or deactivate the feature.
- `"in-unions"`, allows aliasing in union statements, e.g. `type Foo = string | string[];`
- `"in-intersections"`, allows aliasing in intersection statements, e.g. `type Foo = string & string[];`
- `"in-unions-and-intersections"`, allows aliasing in union and/or intersection statements.

Examples of **correct** code for the `{ "allowMappedTypes": "always" }` options:

```ts
type Foo<T> = { readonly [P in keyof T]: T[P] };

type Foo<T> = { [P in keyof T]?: T[P] };

type Foo<T, U> =
  | { readonly [P in keyof T]: T[P] }
  | { readonly [P in keyof U]: U[P] };

type Foo<T, U> = { [P in keyof T]?: T[P] } | { [P in keyof U]?: U[P] };

type Foo<T, U> = { readonly [P in keyof T]: T[P] } & {
  readonly [P in keyof U]: U[P];
};

type Foo<T, U> = { [P in keyof T]?: T[P] } & { [P in keyof U]?: U[P] };
```

Examples of **incorrect** code for the `{ "allowMappedTypes": "in-unions" }` option:

```ts
type Foo<T> = { readonly [P in keyof T]: T[P] };

type Foo<T> = { [P in keyof T]?: T[P] };

type Foo<T, U> = { readonly [P in keyof T]: T[P] } & {
  readonly [P in keyof U]: U[P];
};

type Foo<T, U> = { [P in keyof T]?: T[P] } & { [P in keyof U]?: U[P] };
```

Examples of **correct** code for the `{ "allowMappedTypes": "in-unions" }` option:

```ts
type Foo<T, U> =
  | { readonly [P in keyof T]: T[P] }
  | { readonly [P in keyof U]: U[P] };

type Foo<T, U> = { [P in keyof T]?: T[P] } | { [P in keyof U]?: U[P] };
```

Examples of **incorrect** code for the `{ "allowMappedTypes": "in-intersections" }` option:

```ts
type Foo<T> = { readonly [P in keyof T]: T[P] };

type Foo<T> = { [P in keyof T]?: T[P] };

type Foo<T, U> =
  | { readonly [P in keyof T]: T[P] }
  | { readonly [P in keyof U]: U[P] };

type Foo<T, U> = { [P in keyof T]?: T[P] } | { [P in keyof U]?: U[P] };
```

Examples of **correct** code for the `{ "allowMappedTypes": "in-intersections" }` option:

```ts
type Foo<T, U> = { readonly [P in keyof T]: T[P] } & {
  readonly [P in keyof U]: U[P];
};

type Foo<T, U> = { [P in keyof T]?: T[P] } & { [P in keyof U]?: U[P] };
```

Examples of **incorrect** code for the `{ "allowMappedTypes": "in-unions-and-intersections" }` option:

```ts
type Foo<T> = { readonly [P in keyof T]: T[P] };

type Foo<T> = { [P in keyof T]?: T[P] };
```

Examples of **correct** code for the `{ "allowMappedTypes": "in-unions-and-intersections" }` option:

```ts
type Foo<T, U> =
  | { readonly [P in keyof T]: T[P] }
  | { readonly [P in keyof U]: U[P] };

type Foo<T, U> = { [P in keyof T]?: T[P] } | { [P in keyof U]?: U[P] };

type Foo<T, U> = { readonly [P in keyof T]: T[P] } & {
  readonly [P in keyof U]: U[P];
};

type Foo<T, U> = { [P in keyof T]?: T[P] } & { [P in keyof U]?: U[P] };
```

### `allowTupleTypes`

This applies to tuple types (`type Foo = [number]`).

The setting accepts the following options:

- `"always"` or `"never"` to active or deactivate the feature.
- `"in-unions"`, allows tuples in union statements, e.g. `type Foo = [string] | [string, string];`
- `"in-intersections"`, allows tuples in intersection statements, e.g. `type Foo = [string] & [string, string];`
- `"in-unions-and-intersections"`, allows tuples in union and/or intersection statements.

Examples of **correct** code for the `{ "allowTupleTypes": "always" }` options:

```ts
type Foo = [number];

type Foo = [number] | [number, number];

type Foo = [number] & [number, number];

type Foo = [number] | ([number, number] & [string, string]);
```

Examples of **incorrect** code for the `{ "allowTupleTypes": "in-unions" }` option:

```ts
type Foo = [number];

type Foo = [number] & [number, number];

type Foo = [string] & [number];
```

Examples of **correct** code for the `{ "allowTupleTypes": "in-unions" }` option:

```ts
type Foo = [number] | [number, number];

type Foo = [string] | [number];
```

Examples of **incorrect** code for the `{ "allowTupleTypes": "in-intersections" }` option:

```ts
type Foo = [number];

type Foo = [number] | [number, number];

type Foo = [string] | [number];
```

Examples of **correct** code for the `{ "allowTupleTypes": "in-intersections" }` option:

```ts
type Foo = [number] & [number, number];

type Foo = [string] & [number];
```

Examples of **incorrect** code for the `{ "allowTupleTypes": "in-unions-and-intersections" }` option:

```ts
type Foo = [number];

type Foo = [string];
```

Examples of **correct** code for the `{ "allowLiterals": "in-unions-and-intersections" }` option:

```ts
type Foo = [number] & [number, number];

type Foo = [string] | [number];
```

### `allowGenerics`

This applies to generic types, including TypeScript provided global utility types (`type Foo = Record<string, number>`).

The setting accepts the following options:

- `"always"` or `"never"` to active or deactivate the feature.

Examples of **correct** code for the `{ "allowGenerics": "always" }` options:

```ts
type Foo = Bar<string>;

type Foo = Record<string, number>;

type Foo = Readonly<Bar>;

type Foo = Partial<Bar>;

type Foo = Omit<Bar, 'a' | 'b'>;
```

## When Not To Use It

When you can't express some shape with an interface or you need to use a union, tuple type,
callback, etc. that would cause the code to be unreadable or impractical.

## Further Reading

- [Advanced Types](https://www.typescriptlang.org/docs/handbook/advanced-types.html)
# `no-unnecessary-type-constraint`

Disallows unnecessary constraints on generic types.

## Rule Details

Type parameters (`<T>`) may be "constrained" with an `extends` keyword ([docs](https://www.typescriptlang.org/docs/handbook/generics.html#generic-constraints)).
When not provided, type parameters happen to default to:

- As of TypeScript 3.9: `unknown` ([docs](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-9.html#type-parameters-that-extend-any-no-longer-act-as-any))
- Before that, as of 3.5: `any` ([docs](https://devblogs.microsoft.com/typescript/announcing-typescript-3-5/#breaking-changes))

It is therefore redundant to `extend` from these types in later versions of TypeScript.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
interface FooAny<T extends any> {}
interface FooUnknown<T extends unknown> {}

type BarAny<T extends any> = {};
type BarUnknown<T extends unknown> = {};

class BazAny<T extends any> {
  quxUnknown<U extends unknown>() {}
}

class BazUnknown<T extends unknown> {
  quxUnknown<U extends unknown>() {}
}

const QuuxAny = <T extends any>() => {};
const QuuxUnknown = <T extends unknown>() => {};

function QuuzAny<T extends any>() {}
function QuuzUnknown<T extends unknown>() {}
```

### ✅ Correct

```ts
interface Foo<T> {}

type Bar<T> = {};

class Baz<T> {
    qux<U> { }
}

const Quux = <T>() => {};

function Quuz<T>() {}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-unnecessary-type-constraint": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about the specific styles of your type constraints, or never use them in the first place, then you will not need this rule.
# `no-implied-eval`

Disallows the use of `eval()`-like methods.

It's considered a good practice to avoid using `eval()`. There are security and performance implications involved with doing so, which is why many linters recommend disallowing `eval()`. However, there are some other ways to pass a string and have it interpreted as JavaScript code that have similar concerns.

The first is using `setTimeout()`, `setInterval()`, `setImmediate` or `execScript()` (Internet Explorer only), all of which can accept a string of code as their first argument

```ts
setTimeout('alert(`Hi!`);', 100);
```

or using `new Function()`

```ts
const fn = new Function('a', 'b', 'return a + b');
```

This is considered an implied `eval()` because a string of code is
passed in to be interpreted. The same can be done with `setInterval()`, `setImmediate()` and `execScript()`. All interpret the JavaScript code in the global scope.

The best practice is to avoid using `new Function()` or `execScript()` and always use a function for the first argument of `setTimeout()`, `setInterval()` and `setImmediate()`.

## Rule Details

This rule aims to eliminate implied `eval()` through the use of `new Function()`, `setTimeout()`, `setInterval()`, `setImmediate()` or `execScript()`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
/* eslint @typescript-eslint/no-implied-eval: "error" */

setTimeout('alert(`Hi!`);', 100);

setInterval('alert(`Hi!`);', 100);

setImmediate('alert(`Hi!`)');

execScript('alert(`Hi!`)');

window.setTimeout('count = 5', 10);

window.setInterval('foo = bar', 10);

const fn = '() = {}';
setTimeout(fn, 100);

const fn = () => {
  return 'x = 10';
};
setTimeout(fn(), 100);

const fn = new Function('a', 'b', 'return a + b');
```

### ✅ Correct

```ts
/* eslint @typescript-eslint/no-implied-eval: "error" */

setTimeout(function () {
  alert('Hi!');
}, 100);

setInterval(function () {
  alert('Hi!');
}, 100);

setImmediate(function () {
  alert('Hi!');
});

execScript(function () {
  alert('Hi!');
});

const fn = () => {};
setTimeout(fn, 100);

const foo = {
  fn: function () {},
};
setTimeout(foo.fn, 100);
setTimeout(foo.fn.bind(this), 100);

class Foo {
  static fn = () => {};
}

setTimeout(Foo.fn, 100);
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-implied-eval": "off",
  "@typescript-eslint/no-implied-eval": ["error"]
}
```

## When Not To Use It

If you want to allow `new Function()` or `setTimeout()`, `setInterval()`, `setImmediate()` and `execScript()` with string arguments, then you can safely disable this rule.

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-implied-eval.md)

</sup>
# `lines-between-class-members`

Requires or disallows an empty line between class members.

This rule improves readability by enforcing lines between class members. It will not check empty lines before the first member and after the last member. This rule require or disallow an empty line between class members.

## Rule Details

This rule extends the base [`eslint/lines-between-class-members`](https://eslint.org/docs/rules/lines-between-class-members) rule.
It adds support for ignoring overload methods in a class.

See the [ESLint documentation](https://eslint.org/docs/rules/lines-between-class-members) for more details on the `lines-between-class-members` rule.

## Rule Changes

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "lines-between-class-members": "off",
  "@typescript-eslint/lines-between-class-members": ["error"]
}
```

In addition to the options supported by the `lines-between-class-members` rule in ESLint core, the rule adds the following options:

## Options

This rule has a string option and an object option.

- Object option:

  - `"exceptAfterOverload": true` (default) - Skip checking empty lines after overload class members
  - `"exceptAfterOverload": false` - **do not** skip checking empty lines after overload class members

- [See the other options allowed](https://github.com/eslint/eslint/blob/main/docs/rules/lines-between-class-members.md#options)

### `exceptAfterOverload: true`

Examples of **correct** code for the `{ "exceptAfterOverload": true }` option:

```ts
/*eslint @typescript-eslint/lines-between-class-members: ["error", "always", { "exceptAfterOverload": true }]*/

class foo {
  bar(a: string): void;
  bar(a: string, b: string): void;
  bar(a: string, b: string) {}

  baz() {}

  qux() {}
}
```

### `exceptAfterOverload: false`

Examples of **correct** code for the `{ "exceptAfterOverload": false }` option:

```ts
/*eslint @typescript-eslint/lines-between-class-members: ["error", "always", { "exceptAfterOverload": false }]*/

class foo {
  bar(a: string): void;

  bar(a: string, b: string): void;

  bar(a: string, b: string) {}

  baz() {}

  qux() {}
}
```

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/lines-between-class-members.md)

</sup>
# `no-array-constructor`

Disallows generic `Array` constructors.

## Rule Details

This rule extends the base [`eslint/no-array-constructor`](https://eslint.org/docs/rules/no-array-constructor) rule.
It adds support for the generically typed `Array` constructor (`new Array<Foo>()`).

<!--tabs-->

### ❌ Incorrect

```ts
/*eslint no-array-constructor: "error"*/

Array(0, 1, 2);
new Array(0, 1, 2);
```

### ✅ Correct

```ts
/*eslint no-array-constructor: "error"*/

Array<number>(0, 1, 2);
new Array<Foo>(x, y, z);

Array(500);
new Array(someOtherArray.length);
```

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-array-constructor": "off",
  "@typescript-eslint/no-array-constructor": ["error"]
}
```

## Options

See [`eslint/no-array-constructor` options](https://eslint.org/docs/rules/no-array-constructor#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-array-constructor.md)

</sup>
# `no-unnecessary-condition`

Disallows conditionals where the type is always truthy or always falsy.

Any expression being used as a condition must be able to evaluate as truthy or falsy in order to be considered "necessary". Conversely, any expression that always evaluates to truthy or always evaluates to falsy, as determined by the type of the expression, is considered unnecessary and will be flagged by this rule.

The following expressions are checked:

- Arguments to the `&&`, `||` and `?:` (ternary) operators
- Conditions for `if`, `for`, `while`, and `do-while` statements
- Base values of optional chain expressions

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
function head<T>(items: T[]) {
  // items can never be nullable, so this is unnecessary
  if (items) {
    return items[0].toUpperCase();
  }
}

function foo(arg: 'bar' | 'baz') {
  // arg is never nullable or empty string, so this is unnecessary
  if (arg) {
  }
}

function bar<T>(arg: string) {
  // arg can never be nullish, so ?. is unnecessary
  return arg?.length;
}

// Checks array predicate return types, where possible
[
  [1, 2],
  [3, 4],
].filter(t => t); // number[] is always truthy
```

### ✅ Correct

```ts
function head<T>(items: T[]) {
  // Necessary, since items.length might be 0
  if (items.length) {
    return items[0].toUpperCase();
  }
}

function foo(arg: string) {
  // Necessary, since foo might be ''.
  if (arg) {
  }
}

function bar(arg?: string | null) {
  // Necessary, since arg might be nullish
  return arg?.length;
}

[0, 1, 2, 3].filter(t => t); // number can be truthy or falsy
```

## Options

```ts
type Options = {
  // if true, the rule will ignore constant loop conditions
  allowConstantLoopConditions?: boolean;
  // if true, the rule will not error when running with a tsconfig that has strictNullChecks turned **off**
  allowRuleToRunWithoutStrictNullChecksIKnowWhatIAmDoing?: boolean;
};

const defaultOptions: Options = {
  allowConstantLoopConditions: false,
  allowRuleToRunWithoutStrictNullChecksIKnowWhatIAmDoing: false,
};
```

### `allowConstantLoopConditions`

Example of correct code for `{ allowConstantLoopConditions: true }`:

```ts
while (true) {}
for (; true; ) {}
do {} while (true);
```

### `allowRuleToRunWithoutStrictNullChecksIKnowWhatIAmDoing`

If this is set to `false`, then the rule will error on every file whose `tsconfig.json` does _not_ have the `strictNullChecks` compiler option (or `strict`) set to `true`.

Without `strictNullChecks`, TypeScript essentially erases `undefined` and `null` from the types. This means when this rule inspects the types from a variable, **it will not be able to tell that the variable might be `null` or `undefined`**, which essentially makes this rule useless.

You should be using `strictNullChecks` to ensure complete type-safety in your codebase.

If for some reason you cannot turn on `strictNullChecks`, but still want to use this rule - you can use this option to allow it - but know that the behavior of this rule is _undefined_ with the compiler option turned off. We will not accept bug reports if you are using this option.

## When Not To Use It

The main downside to using this rule is the need for type information.

## Related To

- ESLint: [no-constant-condition](https://eslint.org/docs/rules/no-constant-condition) - `no-unnecessary-condition` is essentially a stronger version of `no-constant-condition`, but requires type information.
- [strict-boolean-expressions](./strict-boolean-expressions.md) - a more opinionated version of `no-unnecessary-condition`. `strict-boolean-expressions` enforces a specific code style, while `no-unnecessary-condition` is about correctness.
# `sort-type-union-intersection-members`

Enforces members of a type union/intersection to be sorted alphabetically.

Sorting union (`|`) and intersection (`&`) types can help:

- keep your codebase standardized
- find repeated types
- reduce diff churn

## Rule Details

Sorting within each group is done using the following code:

```ts
const collator = new Intl.Collator('en', {
  sensitivity: 'base',
  numeric: true,
});

function compare(a, b) {
  return collator.compare(a, b) || (a < b ? -1 : a > b ? 1 : 0);
}
```

In other words, the types are sorted alphabetically, case-insensitively and treating numbers like a human would, falling back to character code sorting in case of ties.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
type T1 = B | A;

type T2 = { b: string } & { a: string };

type T3 = [1, 2, 4] & [1, 2, 3];

type T4 =
  | [1, 2, 4]
  | [1, 2, 3]
  | { b: string }
  | { a: string }
  | (() => void)
  | (() => string)
  | 'b'
  | 'a'
  | 'b'
  | 'a'
  | readonly string[]
  | readonly number[]
  | string[]
  | number[]
  | B
  | A
  | string
  | any;
```

### ✅ Correct

```ts
type T1 = A | B;

type T2 = { a: string } & { b: string };

type T3 = [1, 2, 3] & [1, 2, 4];

type T4 =
  | any
  | string
  | A
  | B
  | number[]
  | string[]
  | readonly number[]
  | readonly string[]
  | 'a'
  | 'b'
  | 'a'
  | 'b'
  | (() => string)
  | (() => void)
  | { a: string }
  | { b: string }
  | [1, 2, 3]
  | [1, 2, 4];
```

## Options

```ts
type Options = {
  // true to check intersection types, false otherwise
  checkIntersections?: boolean;
  // true to check union types, false otherwise
  checkUnions?: boolean;
  // the ordering of the groups
  groupOrder?: (
    | 'conditional'
    | 'function'
    | 'import'
    | 'intersection'
    | 'keyword'
    | 'literal'
    | 'named'
    | 'object'
    | 'operator'
    | 'tuple'
    | 'union'
    | 'nullish'
  )[];
};

const defaultOptions: Options = {
  checkIntersections: true,
  checkUnions: true,
  groupOrder: [
    'named',
    'keyword',
    'operator',
    'literal',
    'function',
    'import',
    'conditional',
    'object',
    'tuple',
    'intersection',
    'union',
    'nullish',
  ],
};
```

### `groupOrder`

Each member of the type is placed into a group, and then the rule sorts alphabetically within each group.
The ordering of groups is determined by this option.

- `conditional` - Conditional types (`A extends B ? C : D`)
- `function` - Function and constructor types (`() => void`, `new () => type`)
- `import` - Import types (`import('path')`)
- `intersection` - Intersection types (`A & B`)
- `keyword` - Keyword types (`any`, `string`, etc)
- `literal` - Literal types (`1`, `'b'`, `true`, etc)
- `named` - Named types (`A`, `A['prop']`, `B[]`, `Array<C>`)
- `object` - Object types (`{ a: string }`, `{ [key: string]: number }`)
- `operator` - Operator types (`keyof A`, `typeof B`, `readonly C[]`)
- `tuple` - Tuple types (`[A, B, C]`)
- `union` - Union types (`A | B`)
- `nullish` - `null` and `undefined`
# `prefer-reduce-type-parameter`

Enforces using type parameter when calling `Array#reduce` instead of casting.

It's common to call `Array#reduce` with a generic type, such as an array or object, as the initial value.
Since these values are empty, their types are not usable:

- `[]` has type `never[]`, which can't have items pushed into it as nothing is type `never`
- `{}` has type `{}`, which doesn't have an index signature and so can't have properties added to it

A common solution to this problem is to cast the initial value. While this will work, it's not the most optimal
solution as casting has subtle effects on the underlying types that can allow bugs to slip in.

A better (and lesser known) solution is to pass the type in as a generic parameter to `Array#reduce` explicitly.
This means that TypeScript doesn't have to try to infer the type, and avoids the common pitfalls that come with casting.

## Rule Details

This rule looks for calls to `Array#reduce`, and warns if an initial value is being passed & casted,
suggesting instead to pass the cast type to `Array#reduce` as its generic parameter.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
[1, 2, 3].reduce((arr, num) => arr.concat(num * 2), [] as number[]);

['a', 'b'].reduce(
  (accum, name) => ({
    ...accum,
    [name]: true,
  }),
  {} as Record<string, boolean>,
);
```

### ✅ Correct

```ts
[1, 2, 3].reduce<number[]>((arr, num) => arr.concat(num * 2), []);

['a', 'b'].reduce<Record<string, boolean>>(
  (accum, name) => ({
    ...accum,
    [name]: true,
  }),
  {},
);
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-reduce-type-parameter": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't want to use typechecking in your linting, you can't use this rule.
# `triple-slash-reference`

Disallows certain triple slash directives in favor of ES6-style import declarations.

Use of triple-slash reference type directives is discouraged in favor of the newer `import` style. This rule allows you to ban use of `/// <reference path="" />`, `/// <reference types="" />`, or `/// <reference lib="" />` directives.

## Rule Details

With `{ "path": "never", "types": "never", "lib": "never" }` options set, the following will all be **incorrect** usage:

```ts
/// <reference path="foo" />
/// <reference types="bar" />
/// <reference lib="baz" />
```

Examples of **incorrect** code for the `{ "types": "prefer-import" }` option. Note that these are only errors when **both** styles are used for the **same** module:

```ts
/// <reference types="foo" />
import * as foo from 'foo';
```

```ts
/// <reference types="foo" />
import foo = require('foo');
```

With `{ "path": "always", "types": "always", "lib": "always" }` options set, the following will all be **correct** usage:

```ts
/// <reference path="foo" />
/// <reference types="bar" />
/// <reference lib="baz" />
```

Examples of **correct** code for the `{ "types": "prefer-import" }` option:

```ts
import * as foo from 'foo';
```

```ts
import foo = require('foo');
```

## Options

```ts
type Options = {
  lib?: 'always' | 'never';
  path?: 'always' | 'never';
  types?: 'always' | 'never' | 'prefer-import';
};

const defaultOptions: Options = {
  lib: 'always',
  path: 'never',
  types: 'prefer-import',
};
```

## When To Use It

If you want to ban use of one or all of the triple slash reference directives, or any time you might use triple-slash type reference directives and ES6 import declarations in the same file.

## When Not To Use It

If you want to use all flavors of triple slash reference directives.
# `unified-signatures`

Disallows two overloads that could be unified into one with a union or an optional/rest parameter.

## Rule Details

This rule aims to keep the source code as maintainable as possible by reducing the amount of overloads.

## Options

```ts
type Options = {
  ignoreDifferentlyNamedParameters?: boolean;
};

const defaultOptions: Options = {
  ignoreDifferentlyNamedParameters: false,
};
```

The rule accepts an options object with the following property:

- `ignoreDifferentlyNamedParameters`: whether two parameters with different names at the same index should be considered different even if their types are the same.

Examples of code for this rule with the default options:

<!--tabs-->

### ❌ Incorrect

```ts
function x(x: number): void;
function x(x: string): void;
```

```ts
function y(): void;
function y(...x: number[]): void;
```

### ✅ Correct

```ts
function x(x: number | string): void;
```

```ts
function y(...x: number[]): void;
```

Examples of code for this rule with `ignoreDifferentlyNamedParameters`:

<!--tabs-->

### ❌ Incorrect

```ts
function f(a: number): void;
function f(a: string): void;
```

```ts
function f(...a: number[]): void;
function f(...b: string[]): void;
```

### ✅ Correct

```ts
function f(a: number): void;
function f(b: string): void;
```

```ts
function f(...a: number[]): void;
function f(...a: string[]): void;
```
# `space-infix-ops`

Requires spacing around infix operators.

This rule extends the base [`eslint/space-infix-ops`](https://eslint.org/docs/rules/space-infix-ops) rule.

It also add support for enum members

```ts
enum MyEnum {
  KEY = 'value',
}
```

## How to Use

```jsonc
{
  "space-infix-ops": "off",
  "@typescript-eslint/space-infix-ops": ["error", { "int32Hint": false }]
}
```

## Options

See [`eslint/space-infix-ops` options](https://eslint.org/docs/rules/space-infix-ops#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/space-infix-ops.md)

</sup>
# `consistent-type-assertions`

Enforces consistent usage of type assertions.

## Rule Details

This rule aims to standardize the use of type assertion style across the codebase.

Type assertions are also commonly referred as "type casting" in TypeScript (even though it is technically slightly different to what is understood by type casting in other languages), so you can think of type assertions and type casting referring to the same thing. It is essentially you saying to the TypeScript compiler, "in this case, I know better than you!".

In addition to ensuring that type assertions are written in a consistent way, this rule also helps make your codebase more type-safe.

`const` assertions, [introduced in TypeScript 3.4](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-4.html#const-assertions), is always allowed by this rule. Examples of it include `let x = "hello" as const;` and `let x = <const>"hello";`.

## Options

```ts
type Options =
  | {
      assertionStyle: 'as' | 'angle-bracket';
      objectLiteralTypeAssertions: 'allow' | 'allow-as-parameter' | 'never';
    }
  | {
      assertionStyle: 'never';
    };

const defaultOptions: Options = {
  assertionStyle: 'as',
  objectLiteralTypeAssertions: 'allow',
};
```

### `assertionStyle`

This option defines the expected assertion style. Valid values for `assertionStyle` are:

- `as` will enforce that you always use `... as foo`.
- `angle-bracket` will enforce that you always use `<foo>...`
- `never` will enforce that you do not do any type assertions.

Most codebases will want to enforce not using `angle-bracket` style because it conflicts with JSX syntax, and is confusing when paired with generic syntax.

Some codebases like to go for an extra level of type safety, and ban assertions altogether via the `never` option.

### `objectLiteralTypeAssertions`

Always prefer `const x: T = { ... };` to `const x = { ... } as T;` (or similar with angle brackets). The type assertion in the latter case is either unnecessary or will probably hide an error.

The compiler will warn for excess properties with this syntax, but not missing _required_ fields. For example: `const x: { foo: number } = {};` will fail to compile, but `const x = {} as { foo: number }` will succeed.

The const assertion `const x = { foo: 1 } as const`, introduced in TypeScript 3.4, is considered beneficial and is ignored by this option.

Assertions to `any` are also ignored by this option.

Examples of code for `{ assertionStyle: 'as', objectLiteralTypeAssertions: 'never' }`

<!--tabs-->

#### ❌ Incorrect

```ts
const x = { ... } as T;

function foo() {
  return { ... } as T;
}
```

#### ✅ Correct

```ts
const x: T = { ... };
const y = { ... } as any;
const z = { ... } as unknown;

function foo(): T {
  return { ... };
}
```

<!--/tabs-->

Examples of code for `{ assertionStyle: 'as', objectLiteralTypeAssertions: 'allow-as-parameter' }`

<!--tabs-->

#### ❌ Incorrect

```ts
const x = { ... } as T;

function foo() {
  return { ... } as T;
}
```

#### ✅ Correct

```tsx
const x: T = { ... };
const y = { ... } as any;
const z = { ... } as unknown;
foo({ ... } as T);
new Clazz({ ... } as T);
function foo() { throw { bar: 5 } as Foo }
const foo = <Foo props={{ ... } as Bar}/>;
```

<!--/tabs-->

## When Not To Use It

If you do not want to enforce consistent type assertions.
# `return-await`

Enforces consistent returning of awaited values.

Returning an awaited promise can make sense for better stack trace information as well as for consistent error handling (returned promises will not be caught in an async function try/catch).

## Rule Details

This rule builds on top of the [`eslint/no-return-await`](https://eslint.org/docs/rules/no-return-await) rule.
It expands upon the base rule to add support for optionally requiring `return await` in certain cases.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-return-await": "off",
  "@typescript-eslint/return-await": "error"
}
```

## Options

```ts
type Options = 'in-try-catch' | 'always' | 'never';

const defaultOptions: Options = 'in-try-catch';
```

### `in-try-catch`

Requires that a returned promise must be `await`ed in `try-catch-finally` blocks, and disallows it elsewhere.
Specifically:

- if you `return` a promise within a `try`, then it must be `await`ed.
- if you `return` a promise within a `catch`, and there **_is no_** `finally`, then it **_must not_** be `await`ed.
- if you `return` a promise within a `catch`, and there **_is a_** `finally`, then it **_must_** be `await`ed.
- if you `return` a promise within a `finally`, then it **_must not_** be `await`ed.

Examples of code with `in-try-catch`:

<!--tabs-->

#### ❌ Incorrect

```ts
async function invalidInTryCatch1() {
  try {
    return Promise.resolve('try');
  } catch (e) {}
}

async function invalidInTryCatch2() {
  try {
    throw new Error('error');
  } catch (e) {
    return await Promise.resolve('catch');
  }
}

async function invalidInTryCatch3() {
  try {
    throw new Error('error');
  } catch (e) {
    return Promise.resolve('catch');
  } finally {
    console.log('cleanup');
  }
}

async function invalidInTryCatch4() {
  try {
    throw new Error('error');
  } catch (e) {
    throw new Error('error2');
  } finally {
    return await Promise.resolve('finally');
  }
}

async function invalidInTryCatch5() {
  return await Promise.resolve('try');
}

async function invalidInTryCatch6() {
  return await 'value';
}
```

#### ✅ Correct

```ts
async function validInTryCatch1() {
  try {
    return await Promise.resolve('try');
  } catch (e) {}
}

async function validInTryCatch2() {
  try {
    throw new Error('error');
  } catch (e) {
    return Promise.resolve('catch');
  }
}

async function validInTryCatch3() {
  try {
    throw new Error('error');
  } catch (e) {
    return await Promise.resolve('catch');
  } finally {
    console.log('cleanup');
  }
}

async function validInTryCatch4() {
  try {
    throw new Error('error');
  } catch (e) {
    throw new Error('error2');
  } finally {
    return Promise.resolve('finally');
  }
}

async function validInTryCatch5() {
  return Promise.resolve('try');
}

async function validInTryCatch6() {
  return 'value';
}
```

### `always`

Requires that all returned promises are `await`ed.

Examples of code with `always`:

<!--tabs-->

#### ❌ Incorrect

```ts
async function invalidAlways1() {
  try {
    return Promise.resolve('try');
  } catch (e) {}
}

async function invalidAlways2() {
  return Promise.resolve('try');
}

async function invalidAlways3() {
  return await 'value';
}
```

#### ✅ Correct

```ts
async function validAlways1() {
  try {
    return await Promise.resolve('try');
  } catch (e) {}
}

async function validAlways2() {
  return await Promise.resolve('try');
}

async function validAlways3() {
  return 'value';
}
```

### `never`

Disallows all `await`ing any returned promises.

Examples of code with `never`:

<!--tabs-->

#### ❌ Incorrect

```ts
async function invalidNever1() {
  try {
    return await Promise.resolve('try');
  } catch (e) {}
}

async function invalidNever2() {
  return await Promise.resolve('try');
}

async function invalidNever3() {
  return await 'value';
}
```

#### ✅ Correct

```ts
async function validNever1() {
  try {
    return Promise.resolve('try');
  } catch (e) {}
}

async function validNever2() {
  return Promise.resolve('try');
}

async function validNever3() {
  return 'value';
}
```
# `no-misused-promises`

Disallows Promises in places not designed to handle them.

This rule forbids providing Promises to logical locations such as if statements in places where the TypeScript compiler allows them but they are not handled properly.
These situations can often arise due to a missing `await` keyword or just a misunderstanding of the way async
functions are handled/awaited.

:::tip
`no-misused-promises` only detects code that provides Promises to incorrect _logical_ locations.
See [`no-floating-promises`](./no-floating-promises.md) for detecting unhandled Promise _statements_.
:::

## Rule Details

This rule accepts a single option which is an object with `checksConditionals`,
`checksVoidReturn`, and `checksSpreads` properties indicating which types of
misuse to flag. All are enabled by default.

## Options

```ts
type Options = [
  {
    checksConditionals?: boolean;
    checksVoidReturn?: boolean | ChecksVoidReturnOptions;
    checksSpreads?: boolean;
  },
];

interface ChecksVoidReturnOptions {
  arguments?: boolean;
  attributes?: boolean;
  properties?: boolean;
  returns?: boolean;
  variables?: boolean;
}

const defaultOptions: Options = [
  {
    checksConditionals: true,
    checksVoidReturn: true,
    checksSpreads: true,
  },
];
```

### `"checksConditionals"`

If you don't want to check conditionals, you can configure the rule with `"checksConditionals": false`:

```json
{
  "@typescript-eslint/no-misused-promises": [
    "error",
    {
      "checksConditionals": false
    }
  ]
}
```

Doing so prevents the rule from looking at code like `if (somePromise)`.

### `"checksVoidReturn"`

Likewise, if you don't want functions that return promises where a void return is
expected to be checked, your configuration will look like this:

```json
{
  "@typescript-eslint/no-misused-promises": [
    "error",
    {
      "checksVoidReturn": false
    }
  ]
}
```

You can disable selective parts of the `checksVoidReturn` option by providing an object that disables specific checks.
The following options are supported:

- `arguments`: Disables checking an asynchronous function passed as argument where the parameter type expects a function that returns `void`
- `attributes`: Disables checking an asynchronous function passed as a JSX attribute expected to be a function that returns `void`
- `properties`: Disables checking an asynchronous function passed as an object property expected to be a function that returns `void`
- `returns`: Disables checking an asynchronous function returned in a function whose return type is a function that returns `void`
- `variables`: Disables checking an asynchronous function used as a variable whose return type is a function that returns `void`

For example, if you don't mind that passing a `() => Promise<void>` to a `() => void` parameter or JSX attribute can lead to a floating unhandled Promise:

```json
{
  "@typescript-eslint/no-misused-promises": [
    "error",
    {
      "checksVoidReturn": {
        "arguments": false,
        "attributes": false
      }
    }
  ]
}
```

### `"checksSpreads"`

If you don't want to check object spreads, you can add this configuration:

```json
{
  "@typescript-eslint/no-misused-promises": [
    "error",
    {
      "checksSpreads": false
    }
  ]
}
```

### `checksConditionals: true`

Examples of code for this rule with `checksConditionals: true`:

<!--tabs-->

#### ❌ Incorrect

```ts
const promise = Promise.resolve('value');

if (promise) {
  // Do something
}

const val = promise ? 123 : 456;

while (promise) {
  // Do something
}
```

#### ✅ Correct

```ts
const promise = Promise.resolve('value');

// Always `await` the Promise in a conditional
if (await promise) {
  // Do something
}

const val = (await promise) ? 123 : 456;

while (await promise) {
  // Do something
}
```

<!--/tabs-->

### `checksVoidReturn: true`

Examples of code for this rule with `checksVoidReturn: true`:

<!--tabs-->

#### ❌ Incorrect

```ts
[1, 2, 3].forEach(async value => {
  await doSomething(value);
});

new Promise(async (resolve, reject) => {
  await doSomething();
  resolve();
});

const eventEmitter = new EventEmitter();
eventEmitter.on('some-event', async () => {
  synchronousCall();
  await doSomething();
  otherSynchronousCall();
});
```

#### ✅ Correct

```ts
// for-of puts `await` in outer context
for (const value of [1, 2, 3]) {
  await doSomething(value);
}

// If outer context is not `async`, handle error explicitly
Promise.all(
  [1, 2, 3].map(async value => {
    await doSomething(value);
  }),
).catch(handleError);

// Use an async IIFE wrapper
new Promise((resolve, reject) => {
  // combine with `void` keyword to tell `no-floating-promises` rule to ignore unhandled rejection
  void (async () => {
    await doSomething();
    resolve();
  })();
});

// Name the async wrapper to call it later
const eventEmitter = new EventEmitter();
eventEmitter.on('some-event', () => {
  const handler = async () => {
    await doSomething();
    otherSynchronousCall();
  };

  try {
    synchronousCall();
  } catch (err) {
    handleSpecificError(err);
  }

  handler().catch(handleError);
});
```

<!--/tabs-->

### `checksSpreads: true`

Examples of code for this rule with `checksSpreads: true`:

<!--tabs-->

#### ❌ Incorrect

```ts
const getData = () => someAsyncOperation({ myArg: 'foo' });

return { foo: 42, ...getData() };

const getData2 = async () => {
  await someAsyncOperation({ myArg: 'foo' });
};

return { foo: 42, ...getData2() };
```

#### ✅ Correct

```ts
const getData = () => someAsyncOperation({ myArg: 'foo' });

return { foo: 42, ...(await getData()) };

const getData2 = async () => {
  await someAsyncOperation({ myArg: 'foo' });
};

return { foo: 42, ...(await getData2()) };
```

<!--tabs-->

## When Not To Use It

If you do not use Promises in your codebase or are not concerned with possible
misuses of them outside of what the TypeScript compiler will check.

## Further Reading

- [TypeScript void function assignability](https://github.com/Microsoft/TypeScript/wiki/FAQ#why-are-functions-returning-non-void-assignable-to-function-returning-void)

## Related To

- [`no-floating-promises`](./no-floating-promises.md)
# `prefer-readonly`

Requires private members to be marked as `readonly` if they're never modified outside of the constructor.

This rule enforces that private members are marked as `readonly` if they're never modified outside of the constructor.

## Rule Details

Member variables with the privacy `private` are never permitted to be modified outside of their declaring class.
If that class never modifies their value, they may safely be marked as `readonly`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
class Container {
  // These member variables could be marked as readonly
  private neverModifiedMember = true;
  private onlyModifiedInConstructor: number;

  public constructor(
    onlyModifiedInConstructor: number,
    // Private parameter properties can also be marked as readonly
    private neverModifiedParameter: string,
  ) {
    this.onlyModifiedInConstructor = onlyModifiedInConstructor;
  }
}
```

### ✅ Correct

```ts
class Container {
  // Public members might be modified externally
  public publicMember: boolean;

  // Protected members might be modified by child classes
  protected protectedMember: number;

  // This is modified later on by the class
  private modifiedLater = 'unchanged';

  public mutate() {
    this.modifiedLater = 'mutated';
  }
}
```

## Options

This rule, in its default state, does not require any argument.

### `onlyInlineLambdas`

You may pass `"onlyInlineLambdas": true` as a rule option within an object to restrict checking only to members immediately assigned a lambda value.

```jsonc
{
  "@typescript-eslint/prefer-readonly": ["error", { "onlyInlineLambdas": true }]
}
```

Example of code for the `{ "onlyInlineLambdas": true }` options:

<!--tabs-->

#### ❌ Incorrect

```ts
class Container {
  private onClick = () => {
    /* ... */
  };
}
```

#### ✅ Correct

```ts
class Container {
  private neverModifiedPrivate = 'unchanged';
}
```
# `prefer-ts-expect-error`

Enforces using `@ts-expect-error` over `@ts-ignore`.

TypeScript allows you to suppress all errors on a line by placing a single-line comment or a comment block line starting with `@ts-ignore` immediately before the erroring line.
While powerful, there is no way to know if a `@ts-ignore` is actually suppressing an error without manually investigating what happens when the `@ts-ignore` is removed.

This means its easy for `@ts-ignore`s to be forgotten about, and remain in code even after the error they were suppressing is fixed.
This is dangerous, as if a new error arises on that line it'll be suppressed by the forgotten about `@ts-ignore`, and so be missed.

To address this, TS3.9 ships with a new single-line comment directive: `// @ts-expect-error`.

This directive operates in the same manner as `@ts-ignore`, but will error if the line it's meant to be suppressing doesn't actually contain an error, making it a lot safer.

## Rule Details

This rule looks for usages of `@ts-ignore`, and flags them to be replaced with `@ts-expect-error`.

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
// @ts-ignore
const str: string = 1;

/**
 * Explaining comment
 *
 * @ts-ignore */
const multiLine: number = 'value';

/** @ts-ignore */
const block: string = 1;

const isOptionEnabled = (key: string): boolean => {
  // @ts-ignore: if key isn't in globalOptions it'll be undefined which is false
  return !!globalOptions[key];
};
```

### ✅ Correct

```ts
// @ts-expect-error
const str: string = 1;

/**
 * Explaining comment
 *
 * @ts-expect-error */
const multiLine: number = 'value';

/** @ts-expect-error */
const block: string = 1;

const isOptionEnabled = (key: string): boolean => {
  // @ts-expect-error: if key isn't in globalOptions it'll be undefined which is false
  return !!globalOptions[key];
};
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-ts-expect-error": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are **NOT** using TypeScript 3.9 (or greater), then you will not be able to use this rule, as the directive is not supported

## Further Reading

- [Original Implementing PR](https://github.com/microsoft/TypeScript/pull/36014)
# `consistent-type-imports`

Enforces consistent usage of type imports.

TypeScript 3.8 added support for type-only imports.
Type-only imports allow you to specify that an import can only be used in a type location, allowing certain optimizations within compilers.

## Rule Details

This rule aims to standardize the use of type imports style across the codebase.

## Options

```ts
type Options = {
  prefer: 'type-imports' | 'no-type-imports';
  disallowTypeAnnotations: boolean;
};

const defaultOptions: Options = {
  prefer: 'type-imports',
  disallowTypeAnnotations: true,
};
```

### `prefer`

This option defines the expected import kind for type-only imports. Valid values for `prefer` are:

- `type-imports` will enforce that you always use `import type Foo from '...'` except referenced by metadata of decorators. It is default.
- `no-type-imports` will enforce that you always use `import Foo from '...'`.

Examples of **correct** code with `{prefer: 'type-imports'}`, and **incorrect** code with `{prefer: 'no-type-imports'}`.

```ts
import type { Foo } from 'Foo';
import type Bar from 'Bar';
type T = Foo;
const x: Bar = 1;
```

Examples of **incorrect** code with `{prefer: 'type-imports'}`, and **correct** code with `{prefer: 'no-type-imports'}`.

```ts
import { Foo } from 'Foo';
import Bar from 'Bar';
type T = Foo;
const x: Bar = 1;
```

### `disallowTypeAnnotations`

If `true`, type imports in type annotations (`import()`) is not allowed.
Default is `true`.

Examples of **incorrect** code with `{disallowTypeAnnotations: true}`.

```ts
type T = import('Foo').Foo;
const x: import('Bar') = 1;
```

## When Not To Use It

- If you are not using TypeScript 3.8 (or greater), then you will not be able to use this rule, as type-only imports are not allowed.
- If you specifically want to use both import kinds for stylistic reasons, you can disable this rule.
# `restrict-plus-operands`

Requires both operands of addition to have type `number` or `string`.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
var foo = '5.5' + 5;
var foo = 1n + 1;
```

### ✅ Correct

```ts
var foo = parseInt('5.5', 10) + 10;
var foo = 1n + 1n;
```

## Options

The rule accepts an options object with the following properties:

```ts
type Options = {
  // if true, check compound assignments (`+=`)
  checkCompoundAssignments?: boolean;
  // if true, 'any' itself and `string`,`bigint`, `number` is allowed.
  allowAny?: boolean;
};

const defaults = {
  checkCompoundAssignments: false,
  allowAny: false,
};
```

### `checkCompoundAssignments`

Examples of code for this rule with `{ checkCompoundAssignments: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
/*eslint @typescript-eslint/restrict-plus-operands: ["error", { "checkCompoundAssignments": true }]*/

let foo: string | undefined;
foo += 'some data';

let bar: string = '';
bar += 0;
```

#### ✅ Correct

```ts
/*eslint @typescript-eslint/restrict-plus-operands: ["error", { "checkCompoundAssignments": true }]*/

let foo: number = 0;
foo += 1;

let bar = '';
bar += 'test';
```

### `allowAny`

Examples of code for this rule with `{ allowAny: true }`:

<!--tabs-->

#### ❌ Incorrect

```ts
var fn = (a: any, b: boolean) => a + b;
var fn = (a: any, b: []) => a + b;
var fn = (a: any, b: {}) => a + b;
```

#### ✅ Correct

```ts
var fn = (a: any, b: any) => a + b;
var fn = (a: any, b: string) => a + b;
var fn = (a: any, b: bigint) => a + b;
var fn = (a: any, b: number) => a + b;
```

## How to Use

```json
{
  "@typescript-eslint/restrict-plus-operands": "error"
}
```
# `no-redundant-type-constituents`

Disallows members of unions and intersections that do nothing or override type information.

## Rule Details

Some types can override some other types ("constituents") in a union or intersection and/or be overridden by some other types.
TypeScript's set theory of types includes cases where a constituent type might be useless in the parent union or intersection.

Within `|` unions:

- `any` and `unknown` "override" all other union members
- `never` is dropped from unions in any position except when in a return type position
- primitive types such as `string` "override" any of their literal types such as `""`

Within `&` intersections:

- `any` and `never` "override" all other intersection members
- `unknown` is dropped from intersections
- literal types "override" any primitive types in an intersection
- literal types such as `""` "override" any of their primitive types such as `string`

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
type UnionAny = any | 'foo';
type UnionUnknown = unknown | 'foo';
type UnionNever = never | 'foo';

type UnionBooleanLiteral = boolean | false;
type UnionNumberLiteral = number | 1;
type UnionStringLiteral = string | 'foo';

type IntersectionAny = any & 'foo';
type IntersectionUnknown = string & unknown;
type IntersectionNever = string | never;

type IntersectionBooleanLiteral = boolean & false;
type IntersectionNumberLiteral = number & 1;
type IntersectionStringLiteral = string & 'foo';
```

### ✅ Correct

```ts
type UnionAny = any;
type UnionUnknown = unknown;
type UnionNever = never;

type UnionBooleanLiteral = boolean;
type UnionNumberLiteral = number;
type UnionStringLiteral = string;

type IntersectionAny = any;
type IntersectionUnknown = string;
type IntersectionNever = string;

type IntersectionBooleanLiteral = false;
type IntersectionNumberLiteral = 1;
type IntersectionStringLiteral = 'foo';

type ReturnUnionNever = () => string | never;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-redundant-type-constituents": "warn"
  }
}
```

This rule is not configurable.

## Limitations

This rule plays it safe and only works with bottom types, top types, and comparing literal types to primitive types.
It also does not provide an auto-fixer just yet.

## Further Reading

- [Union Types](https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#union-types)
- [Intersection Types](https://www.typescriptlang.org/docs/handbook/2/objects.html#intersection-types)
- [Bottom Types](https://en.wikipedia.org/wiki/Bottom_type)
- [Top Types](https://en.wikipedia.org/wiki/Top_type)
# `explicit-member-accessibility`

Requires explicit accessibility modifiers on class properties and methods.

Leaving off accessibility modifier and making everything public can make
your interface hard to use by others.
If you make all internal pieces private or protected, your interface will
be easier to use.

## Rule Details

This rule aims to make code more readable and explicit about who can use
which properties.

## Options

```ts
type AccessibilityLevel =
  | 'explicit' // require an accessor (including public)
  | 'no-public' // don't require public
  | 'off'; // don't check

type Options = {
  accessibility?: AccessibilityLevel;
  ignoredMethodNames?: string[];
  overrides?: {
    accessors?: AccessibilityLevel;
    constructors?: AccessibilityLevel;
    methods?: AccessibilityLevel;
    properties?: AccessibilityLevel;
    parameterProperties?: AccessibilityLevel;
  };
};

const defaultOptions: Options = {
  accessibility: 'explicit',
};
```

### Configuring in a mixed JS/TS codebase

If you are working on a codebase within which you lint non-TypeScript code (i.e. `.js`/`.mjs`/`.cjs`/`.jsx`), you should ensure that you should use [ESLint `overrides`](https://eslint.org/docs/user-guide/configuring#disabling-rules-only-for-a-group-of-files) to only enable the rule on `.ts`/`.mts`/`.cts`/`.tsx` files. If you don't, then you will get unfixable lint errors reported within `.js`/`.mjs`/`.cjs`/`.jsx` files.

```jsonc
{
  "rules": {
    // disable the rule for all files
    "@typescript-eslint/explicit-member-accessibility": "off"
  },
  "overrides": [
    {
      // enable the rule specifically for TypeScript files
      "files": ["*.ts", "*.mts", "*.cts", "*.tsx"],
      "rules": {
        "@typescript-eslint/explicit-member-accessibility": ["error"]
      }
    }
  ]
}
```

### `accessibility`

This rule in its default state requires no configuration and will enforce that every class member has an accessibility modifier. If you would like to allow for some implicit public members then you have the following options:

```ts
{
  accessibility: 'explicit',
  overrides: {
    accessors: 'explicit',
    constructors: 'no-public',
    methods: 'explicit',
    properties: 'off',
    parameterProperties: 'explicit'
  }
}
```

Note the above is an example of a possible configuration you could use - it is not the default configuration.

The following patterns are considered incorrect code if no options are provided:

```ts
class Animal {
  constructor(name) {
    // No accessibility modifier
    this.animalName = name;
  }
  animalName: string; // No accessibility modifier
  get name(): string {
    // No accessibility modifier
    return this.animalName;
  }
  set name(value: string) {
    // No accessibility modifier
    this.animalName = value;
  }
  walk() {
    // method
  }
}
```

The following patterns are considered correct with the default options `{ accessibility: 'explicit' }`:

```ts
class Animal {
  public constructor(public breed, name) {
    // Parameter property and constructor
    this.animalName = name;
  }
  private animalName: string; // Property
  get name(): string {
    // get accessor
    return this.animalName;
  }
  set name(value: string) {
    // set accessor
    this.animalName = value;
  }
  public walk() {
    // method
  }
}
```

The following patterns are considered incorrect with the accessibility set to **no-public** `[{ accessibility: 'no-public' }]`:

```ts
class Animal {
  public constructor(public breed, name) {
    // Parameter property and constructor
    this.animalName = name;
  }
  public animalName: string; // Property
  public get name(): string {
    // get accessor
    return this.animalName;
  }
  public set name(value: string) {
    // set accessor
    this.animalName = value;
  }
  public walk() {
    // method
  }
}
```

The following patterns are considered correct with the accessibility set to **no-public** `[{ accessibility: 'no-public' }]`:

```ts
class Animal {
  constructor(protected breed, name) {
    // Parameter property and constructor
    this.name = name;
  }
  private animalName: string; // Property
  get name(): string {
    // get accessor
    return this.animalName;
  }
  private set name(value: string) {
    // set accessor
    this.animalName = value;
  }
  protected walk() {
    // method
  }
}
```

### Overrides

There are three ways in which an override can be used.

- To disallow the use of public on a given member.
- To enforce explicit member accessibility when the root has allowed implicit public accessibility
- To disable any checks on given member type

#### Disallow the use of public on a given member

e.g. `[ { overrides: { constructors: 'no-public' } } ]`

The following patterns are considered incorrect with the example override

```ts
class Animal {
  public constructor(protected animalName) {}
  public get name() {
    return this.animalName;
  }
}
```

The following patterns are considered correct with the example override

```ts
class Animal {
  constructor(protected animalName) {}
  public get name() {
    return this.animalName;
  }
}
```

#### Require explicit accessibility for a given member

e.g. `[ { accessibility: 'no-public', overrides: { properties: 'explicit' } } ]`

The following patterns are considered incorrect with the example override

```ts
class Animal {
  constructor(protected animalName) {}
  get name() {
    return this.animalName;
  }
  protected set name(value: string) {
    this.animalName = value;
  }
  legs: number;
  private hasFleas: boolean;
}
```

The following patterns are considered correct with the example override

```ts
class Animal {
  constructor(protected animalName) {}
  get name() {
    return this.animalName;
  }
  protected set name(value: string) {
    this.animalName = value;
  }
  public legs: number;
  private hasFleas: boolean;
}
```

e.g. `[ { accessibility: 'off', overrides: { parameterProperties: 'explicit' } } ]`

The following code is considered incorrect with the example override

```ts
class Animal {
  constructor(readonly animalName: string) {}
}
```

The following code patterns are considered correct with the example override

```ts
class Animal {
  constructor(public readonly animalName: string) {}
}

class Animal {
  constructor(public animalName: string) {}
}

class Animal {
  constructor(animalName: string) {}
}
```

e.g. `[ { accessibility: 'off', overrides: { parameterProperties: 'no-public' } } ]`

The following code is considered incorrect with the example override

```ts
class Animal {
  constructor(public readonly animalName: string) {}
}
```

The following code is considered correct with the example override

```ts
class Animal {
  constructor(public animalName: string) {}
}
```

#### Disable any checks on given member type

e.g. `[{ overrides: { accessors : 'off' } } ]`

As no checks on the overridden member type are performed all permutations of visibility are permitted for that member type

The follow pattern is considered incorrect for the given configuration

```ts
class Animal {
  constructor(protected animalName) {}
  public get name() {
    return this.animalName;
  }
  get legs() {
    return this.legCount;
  }
}
```

The following patterns are considered correct with the example override

```ts
class Animal {
  public constructor(protected animalName) {}
  public get name() {
    return this.animalName;
  }
  get legs() {
    return this.legCount;
  }
}
```

### Except specific methods

If you want to ignore some specific methods, you can do it by specifying method names. Note that this option does not care for the context, and will ignore every method with these names, which could lead to it missing some cases. You should use this sparingly.
e.g. `[ { ignoredMethodNames: ['specificMethod', 'whateverMethod'] } ]`

```ts
class Animal {
  get specificMethod() {
    console.log('No error because you specified this method on option');
  }
  get whateverMethod() {
    console.log('No error because you specified this method on option');
  }
  public get otherMethod() {
    console.log('This method comply with this rule');
  }
}
```

## When Not To Use It

If you think defaulting to public is a good default, then you should consider using the `no-public` setting. If you want to mix implicit and explicit public members then disable this rule.

## Further Reading

- TypeScript [Accessibility Modifiers](https://www.typescriptlang.org/docs/handbook/classes.html#public-private-and-protected-modifiers)
# `prefer-as-const`

Enforces the use of `as const` over literal type.

This rule recommends usage of `const` assertion when type primitive value is equal to type.

## Rule Details

Examples of code for this rule:

<!--tabs-->

### ❌ Incorrect

```ts
let bar: 2 = 2;
let foo = <'bar'>'bar';
let foo = { bar: 'baz' as 'baz' };
```

### ✅ Correct

```ts
let foo = 'bar';
let foo = 'bar' as const;
let foo: 'bar' = 'bar' as const;
let bar = 'bar' as string;
let foo = <string>'bar';
let foo = { bar: 'baz' };
```

<!--/tabs-->

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/prefer-as-const": "error"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are using TypeScript < 3.4
# `prefer-nullish-coalescing`

Enforces using the nullish coalescing operator instead of logical chaining.

TypeScript 3.7 added support for the nullish coalescing operator.
This operator allows you to safely cascade a value when dealing with `null` or `undefined`.

```ts
function myFunc(foo: string | null) {
  return foo ?? 'a string';
}

// is equivalent to

function myFunc(foo: string | null) {
  return foo !== null && foo !== undefined ? foo : 'a string';
}
```

Because the nullish coalescing operator _only_ coalesces when the original value is `null` or `undefined`, it is much safer than relying upon logical OR operator chaining `||`; which coalesces on any _falsy_ value:

```ts
const emptyString = '';

const nullish1 = emptyString ?? 'unsafe';
const logical1 = emptyString || 'unsafe';

// nullish1 === ''
// logical1 === 'unsafe'

declare const nullString: string | null;

const nullish2 = nullString ?? 'safe';
const logical2 = nullString || 'safe';

// nullish2 === 'safe'
// logical2 === 'safe'
```

## Rule Details

This rule aims enforce the usage of the safer operator.

## Options

```ts
type Options = [
  {
    ignoreConditionalTests?: boolean;
    ignoreMixedLogicalExpressions?: boolean;
  },
];

const defaultOptions = [
  {
    ignoreConditionalTests: true,
    ignoreMixedLogicalExpressions: true,
  },
];
```

### `ignoreConditionalTests`

Setting this option to `true` (the default) will cause the rule to ignore any cases that are located within a conditional test.

Generally expressions within conditional tests intentionally use the falsy fallthrough behavior of the logical or operator, meaning that fixing the operator to the nullish coalesce operator could cause bugs.

If you're looking to enforce stricter conditional tests, you should consider using the `strict-boolean-expressions` rule.

Incorrect code for `ignoreConditionalTests: false`, and correct code for `ignoreConditionalTests: true`:

```ts
declare const a: string | null;
declare const b: string | null;

if (a || b) {
}
while (a || b) {}
do {} while (a || b);
for (let i = 0; a || b; i += 1) {}
a || b ? true : false;
```

Correct code for `ignoreConditionalTests: false`:

```ts
declare const a: string | null;
declare const b: string | null;

if (a ?? b) {
}
while (a ?? b) {}
do {} while (a ?? b);
for (let i = 0; a ?? b; i += 1) {}
a ?? b ? true : false;
```

### `ignoreMixedLogicalExpressions`

Setting this option to `true` (the default) will cause the rule to ignore any logical or expressions that are part of a mixed logical expression (with `&&`).

Generally expressions within mixed logical expressions intentionally use the falsy fallthrough behavior of the logical or operator, meaning that fixing the operator to the nullish coalesce operator could cause bugs.

If you're looking to enforce stricter conditional tests, you should consider using the `strict-boolean-expressions` rule.

Incorrect code for `ignoreMixedLogicalExpressions: false`, and correct code for `ignoreMixedLogicalExpressions: true`:

```ts
declare const a: string | null;
declare const b: string | null;
declare const c: string | null;
declare const d: string | null;

a || (b && c);
(a && b) || c || d;
a || (b && c) || d;
a || (b && c && d);
```

Correct code for `ignoreMixedLogicalExpressions: false`:

```ts
declare const a: string | null;
declare const b: string | null;
declare const c: string | null;
declare const d: string | null;

a ?? (b && c);
(a && b) ?? c ?? d;
a ?? (b && c) ?? d;
a ?? (b && c && d);
```

**_NOTE:_** Errors for this specific case will be presented as suggestions (see below), instead of fixes. This is because it is not always safe to automatically convert `||` to `??` within a mixed logical expression, as we cannot tell the intended precedence of the operator. Note that by design, `??` requires parentheses when used with `&&` or `||` in the same expression.

## When Not To Use It

If you are not using TypeScript 3.7 (or greater), then you will not be able to use this rule, as the operator is not supported.

## Further Reading

- [TypeScript 3.7 Release Notes](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html)
- [Nullish Coalescing Operator Proposal](https://github.com/tc39/proposal-nullish-coalescing/)
# `no-extra-semi`

Disallows unnecessary semicolons.

## Rule Details

This rule extends the base [`eslint/no-extra-semi`](https://eslint.org/docs/rules/no-extra-semi) rule.
It adds support for class properties.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "no-extra-semi": "off",
  "@typescript-eslint/no-extra-semi": ["error"]
}
```

## Options

See [`eslint/no-extra-semi` options](https://eslint.org/docs/rules/no-extra-semi#options).

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/no-extra-semi.md)

</sup>
# `padding-line-between-statements`

Requires or disallows padding lines between statements.

## Rule Details

This rule extends the base [`eslint/padding-line-between-statements`](https://eslint.org/docs/rules/padding-line-between-statements) rule.

**It adds support for TypeScript constructs such as `interface` and `type`.**

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "padding-line-between-statements": "off",
  "@typescript-eslint/padding-line-between-statements": [
    "error",
    {
      "blankLine": "always",
      "prev": "var",
      "next": "return"
    }
  ]
}
```

```jsonc
{
  // Example - Add blank lines before interface and type definitions.
  // note you must disable the base rule as it can report incorrect errors
  "padding-line-between-statements": "off",
  "@typescript-eslint/padding-line-between-statements": [
    "error",
    {
      "blankLine": "always",
      "prev": "*",
      "next": ["interface", "type"]
    }
  ]
}
```

## Options

See [`eslint/padding-line-between-statements` options](https://eslint.org/docs/rules/padding-line-between-statements#options).

In addition to options provided by ESLint, `interface` and `type` can be used as statement types.

**Note:** ESLint `cjs-export` and `cjs-import` statement types are renamed to `exports` and `require` respectively.

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/padding-line-between-statements.md)

</sup>
# `consistent-generic-constructors`

Enforces specifying generic type arguments on type annotation or constructor name of a constructor call.

When constructing a generic class, you can specify the type arguments on either the left-hand side (as a type annotation) or the right-hand side (as part of the constructor call):

```ts
// Left-hand side
const map: Map<string, number> = new Map();

// Right-hand side
const map = new Map<string, number>();
```

This rule ensures that type arguments appear consistently on one side of the declaration.

## Options

```jsonc
{
  "rules": {
    "@typescript-eslint/consistent-generic-constructors": [
      "error",
      "constructor"
    ]
  }
}
```

This rule takes a string option:

- If it's set to `constructor` (default), type arguments that **only** appear on the type annotation are disallowed.
- If it's set to `type-annotation`, type arguments that **only** appear on the constructor are disallowed.

## Rule Details

The rule never reports when there are type parameters on both sides, or neither sides of the declaration. It also doesn't report if the names of the type annotation and the constructor don't match.

### `constructor`

<!--tabs-->

#### ❌ Incorrect

```ts
const map: Map<string, number> = new Map();
const set: Set<string> = new Set();
```

#### ✅ Correct

```ts
const map = new Map<string, number>();
const map: Map<string, number> = new MyMap();
const set = new Set<string>();
const set = new Set();
const set: Set<string> = new Set<string>();
```

### `type-annotation`

<!--tabs-->

#### ❌ Incorrect

```ts
const map = new Map<string, number>();
const set = new Set<string>();
```

#### ✅ Correct

```ts
const map: Map<string, number> = new Map();
const set: Set<string> = new Set();
const set = new Set();
const set: Set<string> = new Set<string>();
```

## When Not To Use It

You can turn this rule off if you don't want to enforce one kind of generic constructor style over the other.
# `dot-notation`

Enforces dot notation whenever possible.

## Rule Details

This rule extends the base [`eslint/dot-notation`](https://eslint.org/docs/rules/dot-notation) rule.
It adds:

- Support for optionally ignoring computed `private` and/or `protected` member access.
- Compatibility with TypeScript's `noPropertyAccessFromIndexSignature` option.

## How to Use

```jsonc
{
  // note you must disable the base rule as it can report incorrect errors
  "dot-notation": "off",
  "@typescript-eslint/dot-notation": ["error"]
}
```

## Options

See [`eslint/dot-notation`](https://eslint.org/docs/rules/dot-notation#options) options.
This rule adds the following options:

```ts
interface Options extends BaseDotNotationOptions {
  allowPrivateClassPropertyAccess?: boolean;
  allowProtectedClassPropertyAccess?: boolean;
  allowIndexSignaturePropertyAccess?: boolean;
}
const defaultOptions: Options = {
  ...baseDotNotationDefaultOptions,
  allowPrivateClassPropertyAccess: false,
  allowProtectedClassPropertyAccess: false,
  allowIndexSignaturePropertyAccess: false,
};
```

If the TypeScript compiler option `noPropertyAccessFromIndexSignature` is set to `true`, then this rule always allows the use of square bracket notation to access properties of types that have a `string` index signature, even if `allowIndexSignaturePropertyAccess` is `false`.

### `allowPrivateClassPropertyAccess`

Example of a correct code when `allowPrivateClassPropertyAccess` is set to `true`

```ts
class X {
  private priv_prop = 123;
}

const x = new X();
x['priv_prop'] = 123;
```

### `allowProtectedClassPropertyAccess`

Example of a correct code when `allowProtectedClassPropertyAccess` is set to `true`

```ts
class X {
  protected protected_prop = 123;
}

const x = new X();
x['protected_prop'] = 123;
```

### `allowIndexSignaturePropertyAccess`

Example of correct code when `allowIndexSignaturePropertyAccess` is set to `true`

```ts
class X {
  [key: string]: number;
}

const x = new X();
x['hello'] = 123;
```

If the TypeScript compiler option `noPropertyAccessFromIndexSignature` is set to `true`, then the above code is always allowed, even if `allowIndexSignaturePropertyAccess` is `false`.

<sup>

Taken with ❤️ [from ESLint core](https://github.com/eslint/eslint/blob/main/docs/rules/dot-notation.md)

</sup>
# `no-duplicate-enum-values`

Disallows duplicate enum member values.

Although TypeScript supports duplicate enum member values, people usually expect members to have unique values within the same enum. Duplicate values can lead to bugs that are hard to track down.

## Rule Details

This rule disallows defining an enum with multiple members initialized to the same value. Now it only enforces on enum members initialized with String or Number literals. Members without initializer or initialized with an expression are not checked by this rule.

<!--tabs-->

### ❌ Incorrect

```ts
enum E {
  A = 0,
  B = 0,
}
```

```ts
enum E {
  A = 'A'
  B = 'A'
}
```

### ✅ Correct

```ts
enum E {
  A = 0,
  B = 1,
}
```

```ts
enum E {
  A = 'A'
  B = 'B'
}
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-duplicate-enum-values": "warn"
  }
}
```

This rule is not configurable.
# `no-confusing-non-null-assertion`

Disallows non-null assertion in locations that may be confusing.

## Rule Details

Using a non-null assertion (`!`) next to an assign or equals check (`=` or `==` or `===`) creates code that is confusing as it looks similar to a not equals check (`!=` `!==`).

```typescript
a! == b; // a non-null assertions(`!`) and an equals test(`==`)
a !== b; // not equals test(`!==`)
a! === b; // a non-null assertions(`!`) and an triple equals test(`===`)
```

<!--tabs-->

### ❌ Incorrect

```ts
interface Foo {
  bar?: string;
  num?: number;
}

const foo: Foo = getFoo();
const isEqualsBar = foo.bar! == 'hello';
const isEqualsNum = 1 + foo.num! == 2;
```

### ✅ Correct

<!-- prettier-ignore -->
```ts
interface Foo {
  bar?: string;
  num?: number;
}

const foo: Foo = getFoo();
const isEqualsBar = foo.bar == 'hello';
const isEqualsNum = (1 + foo.num!) == 2;
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/no-confusing-non-null-assertion": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you don't care about this confusion, then you will not need this rule.

## Further Reading

- [`Issue: Easy misunderstanding: "! ==="`](https://github.com/microsoft/TypeScript/issues/37837) in [TypeScript repo](https://github.com/microsoft/TypeScript)
# `ban-tslint-comment`

Disallows `// tslint:<rule-flag>` comments.

Useful when migrating from TSLint to ESLint. Once TSLint has been removed, this rule helps locate TSLint annotations (e.g. `// tslint:disable`).

## Rule Details

All TSLint [rule flags](https://palantir.github.io/tslint/usage/rule-flags/)

<!--tabs-->

### ❌ Incorrect

```js
/* tslint:disable */
/* tslint:enable */
/* tslint:disable:rule1 rule2 rule3... */
/* tslint:enable:rule1 rule2 rule3... */
// tslint:disable-next-line
someCode(); // tslint:disable-line
// tslint:disable-next-line:rule1 rule2 rule3...
```

### ✅ Correct

```js
// This is a comment that just happens to mention tslint
/* This is a multiline comment that just happens to mention tslint */
someCode(); // This is a comment that just happens to mention tslint
```

## Options

```jsonc
// .eslintrc.json
{
  "rules": {
    "@typescript-eslint/ban-tslint-comment": "warn"
  }
}
```

This rule is not configurable.

## When Not To Use It

If you are still using TSLint.
# `method-signature-style`

Enforces using a particular method signature syntax.

There are two ways to define an object/interface function property.

```ts
// method shorthand syntax
interface T1 {
  func(arg: string): number;
}

// regular property with function type
interface T2 {
  func: (arg: string) => number;
}
```

A good practice is to use the TypeScript's `strict` option (which implies `strictFunctionTypes`) which enables correct typechecking for function properties only (method signatures get old behavior).

TypeScript FAQ:

> A method and a function property of the same type behave differently.
> Methods are always bivariant in their argument, while function properties are contravariant in their argument under `strictFunctionTypes`.

See the reasoning behind that in the [TypeScript PR for the compiler option](https://github.com/microsoft/TypeScript/pull/18654).

## Options

This rule accepts one string option:

- `"property"`: Enforce using property signature for functions. Use this to enforce maximum correctness together with TypeScript's strict mode.
- `"method"`: Enforce using method signature for functions. Use this if you aren't using TypeScript's strict mode and prefer this style.

The default is `"property"`.

### `property`

Examples of code with `property` option.

<!--tabs-->

#### ❌ Incorrect

```ts
interface T1 {
  func(arg: string): number;
}
type T2 = {
  func(arg: boolean): void;
};
interface T3 {
  func(arg: number): void;
  func(arg: string): void;
  func(arg: boolean): void;
}
```

#### ✅ Correct

```ts
interface T1 {
  func: (arg: string) => number;
}
type T2 = {
  func: (arg: boolean) => void;
};
// this is equivalent to the overload
interface T3 {
  func: ((arg: number) => void) &
    ((arg: string) => void) &
    ((arg: boolean) => void);
}
```

### `method`

Examples of code with `method` option.

<!--tabs-->

#### ❌ Incorrect

```ts
interface T1 {
  func: (arg: string) => number;
}
type T2 = {
  func: (arg: boolean) => void;
};
```

#### ✅ Correct

```ts
interface T1 {
  func(arg: string): number;
}
type T2 = {
  func(arg: boolean): void;
};
```

## When Not To Use It

If you don't want to enforce a particular style for object/interface function types, and/or if you don't use `strictFunctionTypes`, then you don't need this rule.
<h1 align="center">ESLint Plugin TypeScript</h1>

<p align="center">An ESLint plugin which provides lint rules for TypeScript codebases.</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/eslint-plugin"><img src="https://img.shields.io/npm/v/@typescript-eslint/eslint-plugin.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/eslint-plugin"><img src="https://img.shields.io/npm/dm/@typescript-eslint/eslint-plugin.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

## Getting Started

- **[You can find our Getting Started docs here](https://typescript-eslint.io/docs/linting)**
- **[You can find our FAQ / Troubleshooting docs here](https://typescript-eslint.io/docs/linting/troubleshooting)**

These docs walk you through setting up ESLint, this plugin, and our parser. If you know what you're doing and just want to quick start, read on...

## Quick-start

### Installation

Make sure you have TypeScript and [`@typescript-eslint/parser`](../parser) installed:

```bash
$ yarn add -D typescript @typescript-eslint/parser
$ npm i --save-dev typescript @typescript-eslint/parser
```

Then install the plugin:

```bash
$ yarn add -D @typescript-eslint/eslint-plugin
$ npm i --save-dev @typescript-eslint/eslint-plugin
```

It is important that you use the same version number for `@typescript-eslint/parser` and `@typescript-eslint/eslint-plugin`.

**Note:** If you installed ESLint globally (using the `-g` flag) then you must also install `@typescript-eslint/eslint-plugin` globally.

### Usage

Add `@typescript-eslint/parser` to the `parser` field and `@typescript-eslint` to the plugins section of your `.eslintrc` configuration file, then configure the rules you want to use under the rules section.

```json
{
  "parser": "@typescript-eslint/parser",
  "plugins": ["@typescript-eslint"],
  "rules": {
    "@typescript-eslint/rule-name": "error"
  }
}
```

You can also enable all the recommended rules for our plugin. Add `plugin:@typescript-eslint/recommended` in extends:

```json
{
  "extends": ["plugin:@typescript-eslint/recommended"]
}
```

### Recommended Configs

You can also use [`eslint:recommended`](https://eslint.org/docs/rules/) (the set of rules which are recommended for all projects by the ESLint Team) with this plugin:

```json
{
  "extends": ["eslint:recommended", "plugin:@typescript-eslint/recommended"]
}
```

As of version 2 of this plugin, _by design_, none of the rules in the main `recommended` config require type-checking in order to run. This means that they are more lightweight and faster to run.

Some highly valuable rules require type-checking in order to be implemented correctly, however, so we provide an additional config you can extend from called `recommended-requiring-type-checking`. You would apply this _in addition_ to the recommended configs previously mentioned, e.g.:

```json
{
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:@typescript-eslint/recommended-requiring-type-checking"
  ]
}
```

Pro Tip: For larger codebases you may want to consider splitting our linting into two separate stages: 1. fast feedback rules which operate purely based on syntax (no type-checking), 2. rules which are based on semantics (type-checking).

**[You can read more about linting with type information here](https://typescript-eslint.io/docs/linting/type-linting)**

## Supported Rules

<!-- begin base rule list -->

**Key**: :white_check_mark: = recommended, :lock: = strict, :wrench: = fixable, :thought_balloon: = requires type information

| Name                                                                                                                    | Description                                                                                                  | :white_check_mark::lock: | :wrench: | :thought_balloon: |
| ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | ------------------------ | -------- | ----------------- |
| [`@typescript-eslint/adjacent-overload-signatures`](./docs/rules/adjacent-overload-signatures.md)                       | Require that member overloads be consecutive                                                                 | :white_check_mark:       |          |                   |
| [`@typescript-eslint/array-type`](./docs/rules/array-type.md)                                                           | Require using either `T[]` or `Array<T>` for arrays                                                          | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/await-thenable`](./docs/rules/await-thenable.md)                                                   | Disallow awaiting a value that is not a Thenable                                                             | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/ban-ts-comment`](./docs/rules/ban-ts-comment.md)                                                   | Disallow `@ts-<directive>` comments or require descriptions after directive                                  | :white_check_mark:       |          |                   |
| [`@typescript-eslint/ban-tslint-comment`](./docs/rules/ban-tslint-comment.md)                                           | Disallow `// tslint:<rule-flag>` comments                                                                    | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/ban-types`](./docs/rules/ban-types.md)                                                             | Disallow certain types                                                                                       | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/class-literal-property-style`](./docs/rules/class-literal-property-style.md)                       | Enforce that literals on classes are exposed in a consistent style                                           | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-generic-constructors`](./docs/rules/consistent-generic-constructors.md)                 | Enforce specifying generic type arguments on type annotation or constructor name of a constructor call       | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-indexed-object-style`](./docs/rules/consistent-indexed-object-style.md)                 | Require or disallow the `Record` type                                                                        | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-type-assertions`](./docs/rules/consistent-type-assertions.md)                           | Enforce consistent usage of type assertions                                                                  | :lock:                   |          |                   |
| [`@typescript-eslint/consistent-type-definitions`](./docs/rules/consistent-type-definitions.md)                         | Enforce type definitions to consistently use either `interface` or `type`                                    | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/consistent-type-exports`](./docs/rules/consistent-type-exports.md)                                 | Enforce consistent usage of type exports                                                                     |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/consistent-type-imports`](./docs/rules/consistent-type-imports.md)                                 | Enforce consistent usage of type imports                                                                     |                          | :wrench: |                   |
| [`@typescript-eslint/explicit-function-return-type`](./docs/rules/explicit-function-return-type.md)                     | Require explicit return types on functions and class methods                                                 |                          |          |                   |
| [`@typescript-eslint/explicit-member-accessibility`](./docs/rules/explicit-member-accessibility.md)                     | Require explicit accessibility modifiers on class properties and methods                                     |                          | :wrench: |                   |
| [`@typescript-eslint/explicit-module-boundary-types`](./docs/rules/explicit-module-boundary-types.md)                   | Require explicit return and argument types on exported functions' and classes' public class methods          |                          |          |                   |
| [`@typescript-eslint/member-delimiter-style`](./docs/rules/member-delimiter-style.md)                                   | Require a specific member delimiter style for interfaces and type literals                                   |                          | :wrench: |                   |
| [`@typescript-eslint/member-ordering`](./docs/rules/member-ordering.md)                                                 | Require a consistent member declaration order                                                                |                          |          |                   |
| [`@typescript-eslint/method-signature-style`](./docs/rules/method-signature-style.md)                                   | Enforce using a particular method signature syntax                                                           |                          | :wrench: |                   |
| [`@typescript-eslint/naming-convention`](./docs/rules/naming-convention.md)                                             | Enforce naming conventions for everything across a codebase                                                  |                          |          | :thought_balloon: |
| [`@typescript-eslint/no-base-to-string`](./docs/rules/no-base-to-string.md)                                             | Require `.toString()` to only be called on objects which provide useful information when stringified         | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/no-confusing-non-null-assertion`](./docs/rules/no-confusing-non-null-assertion.md)                 | Disallow non-null assertion in locations that may be confusing                                               | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/no-confusing-void-expression`](./docs/rules/no-confusing-void-expression.md)                       | Require expressions of type void to appear in statement position                                             |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-duplicate-enum-values`](./docs/rules/no-duplicate-enum-values.md)                               | Disallow duplicate enum member values                                                                        | :lock:                   |          |                   |
| [`@typescript-eslint/no-dynamic-delete`](./docs/rules/no-dynamic-delete.md)                                             | Disallow using the `delete` operator on computed key expressions                                             | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/no-empty-interface`](./docs/rules/no-empty-interface.md)                                           | Disallow the declaration of empty interfaces                                                                 | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-explicit-any`](./docs/rules/no-explicit-any.md)                                                 | Disallow the `any` type                                                                                      | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-extra-non-null-assertion`](./docs/rules/no-extra-non-null-assertion.md)                         | Disallow extra non-null assertion                                                                            | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-extraneous-class`](./docs/rules/no-extraneous-class.md)                                         | Disallow classes used as namespaces                                                                          | :lock:                   |          |                   |
| [`@typescript-eslint/no-floating-promises`](./docs/rules/no-floating-promises.md)                                       | Require Promise-like statements to be handled appropriately                                                  | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-for-in-array`](./docs/rules/no-for-in-array.md)                                                 | Disallow iterating over an array with a for-in loop                                                          | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-inferrable-types`](./docs/rules/no-inferrable-types.md)                                         | Disallow explicit type declarations for variables or parameters initialized to a number, string, or boolean  | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-invalid-void-type`](./docs/rules/no-invalid-void-type.md)                                       | Disallow `void` type outside of generic or return types                                                      | :lock:                   |          |                   |
| [`@typescript-eslint/no-meaningless-void-operator`](./docs/rules/no-meaningless-void-operator.md)                       | Disallow the `void` operator except when used to discard a value                                             | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-misused-new`](./docs/rules/no-misused-new.md)                                                   | Enforce valid definition of `new` and `constructor`                                                          | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-misused-promises`](./docs/rules/no-misused-promises.md)                                         | Disallow Promises in places not designed to handle them                                                      | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-namespace`](./docs/rules/no-namespace.md)                                                       | Disallow custom TypeScript modules and namespaces                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-non-null-asserted-nullish-coalescing`](./docs/rules/no-non-null-asserted-nullish-coalescing.md) | Disallow non-null assertions in the left operand of a nullish coalescing operator                            | :lock:                   |          |                   |
| [`@typescript-eslint/no-non-null-asserted-optional-chain`](./docs/rules/no-non-null-asserted-optional-chain.md)         | Disallow non-null assertions after an optional chain expression                                              | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-non-null-assertion`](./docs/rules/no-non-null-assertion.md)                                     | Disallow non-null assertions using the `!` postfix operator                                                  | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-redundant-type-constituents`](./docs/rules/no-redundant-type-constituents.md)                   | Disallow members of unions and intersections that do nothing or override type information                    |                          |          | :thought_balloon: |
| [`@typescript-eslint/no-require-imports`](./docs/rules/no-require-imports.md)                                           | Disallow invocation of `require()`                                                                           |                          |          |                   |
| [`@typescript-eslint/no-this-alias`](./docs/rules/no-this-alias.md)                                                     | Disallow aliasing `this`                                                                                     | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-type-alias`](./docs/rules/no-type-alias.md)                                                     | Disallow type aliases                                                                                        |                          |          |                   |
| [`@typescript-eslint/no-unnecessary-boolean-literal-compare`](./docs/rules/no-unnecessary-boolean-literal-compare.md)   | Disallow unnecessary equality comparisons against boolean literals                                           | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-condition`](./docs/rules/no-unnecessary-condition.md)                               | Disallow conditionals where the type is always truthy or always falsy                                        | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-qualifier`](./docs/rules/no-unnecessary-qualifier.md)                               | Disallow unnecessary namespace qualifiers                                                                    |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-arguments`](./docs/rules/no-unnecessary-type-arguments.md)                     | Disallow type arguments that are equal to the default                                                        | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-assertion`](./docs/rules/no-unnecessary-type-assertion.md)                     | Disallow type assertions that do not change the type of an expression                                        | :white_check_mark:       | :wrench: | :thought_balloon: |
| [`@typescript-eslint/no-unnecessary-type-constraint`](./docs/rules/no-unnecessary-type-constraint.md)                   | Disallow unnecessary constraints on generic types                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-unsafe-argument`](./docs/rules/no-unsafe-argument.md)                                           | Disallow calling a function with a value with type `any`                                                     | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-assignment`](./docs/rules/no-unsafe-assignment.md)                                       | Disallow assigning a value with type `any` to variables and properties                                       | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-call`](./docs/rules/no-unsafe-call.md)                                                   | Disallow calling a value with type `any`                                                                     | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-member-access`](./docs/rules/no-unsafe-member-access.md)                                 | Disallow member access on a value with type `any`                                                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-unsafe-return`](./docs/rules/no-unsafe-return.md)                                               | Disallow returning a value with type `any` from a function                                                   | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-useless-empty-export`](./docs/rules/no-useless-empty-export.md)                                 | Disallow empty exports that don't change anything in a module file                                           |                          | :wrench: |                   |
| [`@typescript-eslint/no-var-requires`](./docs/rules/no-var-requires.md)                                                 | Disallow `require` statements except in import statements                                                    | :white_check_mark:       |          |                   |
| [`@typescript-eslint/non-nullable-type-assertion-style`](./docs/rules/non-nullable-type-assertion-style.md)             | Enforce non-null assertions over explicit type casts                                                         | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/parameter-properties`](./docs/rules/parameter-properties.md)                                       | Require or disallow parameter properties in class constructors                                               |                          |          |                   |
| [`@typescript-eslint/prefer-as-const`](./docs/rules/prefer-as-const.md)                                                 | Enforce the use of `as const` over literal type                                                              | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/prefer-enum-initializers`](./docs/rules/prefer-enum-initializers.md)                               | Require each enum member value to be explicitly initialized                                                  |                          |          |                   |
| [`@typescript-eslint/prefer-for-of`](./docs/rules/prefer-for-of.md)                                                     | Enforce the use of `for-of` loop over the standard `for` loop where possible                                 | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-function-type`](./docs/rules/prefer-function-type.md)                                       | Enforce using function types instead of interfaces with call signatures                                      | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/prefer-includes`](./docs/rules/prefer-includes.md)                                                 | Enforce `includes` method over `indexOf` method                                                              | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-literal-enum-member`](./docs/rules/prefer-literal-enum-member.md)                           | Require all enum members to be literal values                                                                | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-namespace-keyword`](./docs/rules/prefer-namespace-keyword.md)                               | Require using `namespace` keyword over `module` keyword to declare custom TypeScript modules                 | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/prefer-nullish-coalescing`](./docs/rules/prefer-nullish-coalescing.md)                             | Enforce using the nullish coalescing operator instead of logical chaining                                    | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/prefer-optional-chain`](./docs/rules/prefer-optional-chain.md)                                     | Enforce using concise optional chain expressions instead of chained logical ands                             | :lock:                   |          |                   |
| [`@typescript-eslint/prefer-readonly`](./docs/rules/prefer-readonly.md)                                                 | Require private members to be marked as `readonly` if they're never modified outside of the constructor      |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-readonly-parameter-types`](./docs/rules/prefer-readonly-parameter-types.md)                 | Require function parameters to be typed as `readonly` to prevent accidental mutation of inputs               |                          |          | :thought_balloon: |
| [`@typescript-eslint/prefer-reduce-type-parameter`](./docs/rules/prefer-reduce-type-parameter.md)                       | Enforce using type parameter when calling `Array#reduce` instead of casting                                  | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-regexp-exec`](./docs/rules/prefer-regexp-exec.md)                                           | Enforce `RegExp#exec` over `String#match` if no global flag is provided                                      |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-return-this-type`](./docs/rules/prefer-return-this-type.md)                                 | Enforce that `this` is used when only `this` type is returned                                                | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-string-starts-ends-with`](./docs/rules/prefer-string-starts-ends-with.md)                   | Enforce using `String#startsWith` and `String#endsWith` over other equivalent methods of checking substrings | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/prefer-ts-expect-error`](./docs/rules/prefer-ts-expect-error.md)                                   | Enforce using `@ts-expect-error` over `@ts-ignore`                                                           | :lock:                   | :wrench: |                   |
| [`@typescript-eslint/promise-function-async`](./docs/rules/promise-function-async.md)                                   | Require any function or method that returns a Promise to be marked async                                     |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/require-array-sort-compare`](./docs/rules/require-array-sort-compare.md)                           | Require `Array#sort` calls to always provide a `compareFunction`                                             |                          |          | :thought_balloon: |
| [`@typescript-eslint/restrict-plus-operands`](./docs/rules/restrict-plus-operands.md)                                   | Require both operands of addition to have type `number` or `string`                                          | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/restrict-template-expressions`](./docs/rules/restrict-template-expressions.md)                     | Enforce template literal expressions to be of `string` type                                                  | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/sort-type-union-intersection-members`](./docs/rules/sort-type-union-intersection-members.md)       | Enforce members of a type union/intersection to be sorted alphabetically                                     |                          | :wrench: |                   |
| [`@typescript-eslint/strict-boolean-expressions`](./docs/rules/strict-boolean-expressions.md)                           | Disallow certain types in boolean expressions                                                                |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/switch-exhaustiveness-check`](./docs/rules/switch-exhaustiveness-check.md)                         | Require switch-case statements to be exhaustive with union type                                              |                          |          | :thought_balloon: |
| [`@typescript-eslint/triple-slash-reference`](./docs/rules/triple-slash-reference.md)                                   | Disallow certain triple slash directives in favor of ES6-style import declarations                           | :white_check_mark:       |          |                   |
| [`@typescript-eslint/type-annotation-spacing`](./docs/rules/type-annotation-spacing.md)                                 | Require consistent spacing around type annotations                                                           |                          | :wrench: |                   |
| [`@typescript-eslint/typedef`](./docs/rules/typedef.md)                                                                 | Require type annotations in certain places                                                                   |                          |          |                   |
| [`@typescript-eslint/unbound-method`](./docs/rules/unbound-method.md)                                                   | Enforce unbound methods are called with their expected scope                                                 | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/unified-signatures`](./docs/rules/unified-signatures.md)                                           | Disallow two overloads that could be unified into one with a union or an optional/rest parameter             | :lock:                   |          |                   |

<!-- end base rule list -->

### Extension Rules

In some cases, ESLint provides a rule itself, but it doesn't support TypeScript syntax; either it crashes, or it ignores the syntax, or it falsely reports against it.
In these cases, we create what we call an extension rule; a rule within our plugin that has the same functionality, but also supports TypeScript.

<!-- begin extension rule list -->

**Key**: :white_check_mark: = recommended, :lock: = strict, :wrench: = fixable, :thought_balloon: = requires type information

| Name                                                                                                    | Description                                                                          | :white_check_mark::lock: | :wrench: | :thought_balloon: |
| ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | ------------------------ | -------- | ----------------- |
| [`@typescript-eslint/brace-style`](./docs/rules/brace-style.md)                                         | Enforce consistent brace style for blocks                                            |                          | :wrench: |                   |
| [`@typescript-eslint/comma-dangle`](./docs/rules/comma-dangle.md)                                       | Require or disallow trailing commas                                                  |                          | :wrench: |                   |
| [`@typescript-eslint/comma-spacing`](./docs/rules/comma-spacing.md)                                     | Enforce consistent spacing before and after commas                                   |                          | :wrench: |                   |
| [`@typescript-eslint/default-param-last`](./docs/rules/default-param-last.md)                           | Enforce default parameters to be last                                                |                          |          |                   |
| [`@typescript-eslint/dot-notation`](./docs/rules/dot-notation.md)                                       | Enforce dot notation whenever possible                                               | :lock:                   | :wrench: | :thought_balloon: |
| [`@typescript-eslint/func-call-spacing`](./docs/rules/func-call-spacing.md)                             | Require or disallow spacing between function identifiers and their invocations       |                          | :wrench: |                   |
| [`@typescript-eslint/indent`](./docs/rules/indent.md)                                                   | Enforce consistent indentation                                                       |                          | :wrench: |                   |
| [`@typescript-eslint/init-declarations`](./docs/rules/init-declarations.md)                             | Require or disallow initialization in variable declarations                          |                          |          |                   |
| [`@typescript-eslint/keyword-spacing`](./docs/rules/keyword-spacing.md)                                 | Enforce consistent spacing before and after keywords                                 |                          | :wrench: |                   |
| [`@typescript-eslint/lines-between-class-members`](./docs/rules/lines-between-class-members.md)         | Require or disallow an empty line between class members                              |                          | :wrench: |                   |
| [`@typescript-eslint/no-array-constructor`](./docs/rules/no-array-constructor.md)                       | Disallow generic `Array` constructors                                                | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-dupe-class-members`](./docs/rules/no-dupe-class-members.md)                     | Disallow duplicate class members                                                     |                          |          |                   |
| [`@typescript-eslint/no-empty-function`](./docs/rules/no-empty-function.md)                             | Disallow empty functions                                                             | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-extra-parens`](./docs/rules/no-extra-parens.md)                                 | Disallow unnecessary parentheses                                                     |                          | :wrench: |                   |
| [`@typescript-eslint/no-extra-semi`](./docs/rules/no-extra-semi.md)                                     | Disallow unnecessary semicolons                                                      | :white_check_mark:       | :wrench: |                   |
| [`@typescript-eslint/no-implied-eval`](./docs/rules/no-implied-eval.md)                                 | Disallow the use of `eval()`-like methods                                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/no-invalid-this`](./docs/rules/no-invalid-this.md)                                 | Disallow `this` keywords outside of classes or class-like objects                    |                          |          |                   |
| [`@typescript-eslint/no-loop-func`](./docs/rules/no-loop-func.md)                                       | Disallow function declarations that contain unsafe references inside loop statements |                          |          |                   |
| [`@typescript-eslint/no-loss-of-precision`](./docs/rules/no-loss-of-precision.md)                       | Disallow literal numbers that lose precision                                         | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-magic-numbers`](./docs/rules/no-magic-numbers.md)                               | Disallow magic numbers                                                               |                          |          |                   |
| [`@typescript-eslint/no-redeclare`](./docs/rules/no-redeclare.md)                                       | Disallow variable redeclaration                                                      |                          |          |                   |
| [`@typescript-eslint/no-restricted-imports`](./docs/rules/no-restricted-imports.md)                     | Disallow specified modules when loaded by `import`                                   |                          |          |                   |
| [`@typescript-eslint/no-shadow`](./docs/rules/no-shadow.md)                                             | Disallow variable declarations from shadowing variables declared in the outer scope  |                          |          |                   |
| [`@typescript-eslint/no-throw-literal`](./docs/rules/no-throw-literal.md)                               | Disallow throwing literals as exceptions                                             | :lock:                   |          | :thought_balloon: |
| [`@typescript-eslint/no-unused-expressions`](./docs/rules/no-unused-expressions.md)                     | Disallow unused expressions                                                          |                          |          |                   |
| [`@typescript-eslint/no-unused-vars`](./docs/rules/no-unused-vars.md)                                   | Disallow unused variables                                                            | :white_check_mark:       |          |                   |
| [`@typescript-eslint/no-use-before-define`](./docs/rules/no-use-before-define.md)                       | Disallow the use of variables before they are defined                                |                          |          |                   |
| [`@typescript-eslint/no-useless-constructor`](./docs/rules/no-useless-constructor.md)                   | Disallow unnecessary constructors                                                    | :lock:                   |          |                   |
| [`@typescript-eslint/object-curly-spacing`](./docs/rules/object-curly-spacing.md)                       | Enforce consistent spacing inside braces                                             |                          | :wrench: |                   |
| [`@typescript-eslint/padding-line-between-statements`](./docs/rules/padding-line-between-statements.md) | Require or disallow padding lines between statements                                 |                          | :wrench: |                   |
| [`@typescript-eslint/quotes`](./docs/rules/quotes.md)                                                   | Enforce the consistent use of either backticks, double, or single quotes             |                          | :wrench: |                   |
| [`@typescript-eslint/require-await`](./docs/rules/require-await.md)                                     | Disallow async functions which have no `await` expression                            | :white_check_mark:       |          | :thought_balloon: |
| [`@typescript-eslint/return-await`](./docs/rules/return-await.md)                                       | Enforce consistent returning of awaited values                                       |                          | :wrench: | :thought_balloon: |
| [`@typescript-eslint/semi`](./docs/rules/semi.md)                                                       | Require or disallow semicolons instead of ASI                                        |                          | :wrench: |                   |
| [`@typescript-eslint/space-before-blocks`](./docs/rules/space-before-blocks.md)                         | Enforce consistent spacing before blocks                                             |                          | :wrench: |                   |
| [`@typescript-eslint/space-before-function-paren`](./docs/rules/space-before-function-paren.md)         | Enforce consistent spacing before function parenthesis                               |                          | :wrench: |                   |
| [`@typescript-eslint/space-infix-ops`](./docs/rules/space-infix-ops.md)                                 | Require spacing around infix operators                                               |                          | :wrench: |                   |

<!-- end extension rule list -->

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md).
<h1 align="center">TypeScript-ESTree Visitor Keys</h1>

<p align="center">Visitor keys used to help traverse the TypeScript-ESTree AST</p>

<p align="center">
    <img src="https://github.com/typescript-eslint/typescript-eslint/workflows/CI/badge.svg" alt="CI" />
    <a href="https://www.npmjs.com/package/@typescript-eslint/visitor-keys"><img src="https://img.shields.io/npm/v/@typescript-eslint/visitor-keys.svg?style=flat-square" alt="NPM Version" /></a>
    <a href="https://www.npmjs.com/package/@typescript-eslint/visitor-keys"><img src="https://img.shields.io/npm/dm/@typescript-eslint/visitor-keys.svg?style=flat-square" alt="NPM Downloads" /></a>
</p>

## Contributing

[See the contributing guide here](../../CONTRIBUTING.md)
# structuredClone polyfill

[![Downloads](https://img.shields.io/npm/dm/@ungap/structured-clone.svg)](https://www.npmjs.com/package/@ungap/structured-clone) [![build status](https://github.com/ungap/structured-clone/actions/workflows/node.js.yml/badge.svg)](https://github.com/ungap/structured-clone/actions) [![Coverage Status](https://coveralls.io/repos/github/ungap/structured-clone/badge.svg?branch=main)](https://coveralls.io/github/ungap/structured-clone?branch=main)

An env agnostic serializer and deserializer with recursion ability and types beyond *JSON* from the *HTML* standard itself.

  * [Supported Types](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm#supported_types)
    * *not supported yet*: Blob, File, FileList, ImageBitmap, ImageData, and ArrayBuffer, but typed arrays are supported without major issues, but u/int8, u/int16, and u/int32 are the only safely suppored (right now).
    * *not possible to implement*: the `{transfer: []}` option can be passed but it's completely ignored.
  * [MDN Documentation](https://developer.mozilla.org/en-US/docs/Web/API/structuredClone)
  * [Serializer](https://html.spec.whatwg.org/multipage/structured-data.html#structuredserializeinternal)
  * [Deserializer](https://html.spec.whatwg.org/multipage/structured-data.html#structureddeserialize)

Serialized values can be safely stringified as *JSON* too, and deserialization resurrect all values, even recursive, or more complex than what *JSON* allows.


### Examples

Check the [100% test coverage](./test/index.js) to know even more.

```js
// as default export
import structuredClone from '@ungap/structured-clone';
const cloned = structuredClone({any: 'serializable'});

// as independent serializer/deserializer
import {serialize, deserialize} from '@ungap/structured-clone';

// the result can be stringified as JSON without issues
// even if there is recursive data, bigint values,
// typed arrays, and so on
const serialized = serialize({any: 'serializable'});

// the result will be a replica of the original object
const deserialized = deserialize(serialized);
```

#### Global Polyfill
Note: Only monkey patch the global if needed. This polyfill works just fine as an explicit import: `import structuredClone from "@ungap/structured-clone"`
```js
// Attach the polyfill as a Global function
import structuredClone from "@ungap/structured-clone";
if (!("structuredClone" in globalThis)) {
  globalThis.structuredClone = structuredClone;
}

// Or don't monkey patch
import structuredClone from "@ungap/structured-clone"
// Just use it in the file
structuredClone()
```

**Note**: Do not attach this module's default export directly to the global scope, whithout a conditional guard to detect a native implementation. In environments where there is a native global implementation of `structuredClone()` already, assignment to the global object will result in an infinite loop when `globalThis.structuredClone()` is called. See the example above for a safe way to provide the polyfill globally in your project.

### Extra Features

There is no middle-ground between the structured clone algorithm and JSON:

  * JSON is more relaxed about incompatible values: it just ignores these
  * Structured clone is inflexible regarding incompatible values, yet it makes specialized instances impossible to reconstruct, plus it doesn't offer any helper, such as `toJSON()`, to make serialization possible, or better, with specific cases

This module specialized `serialize` export offers, within the optional extra argument, a **lossy** property to avoid throwing when incompatible types are found down the road (function, symbol, ...), so that it is possible to send with less worrying about thrown errors.

```js
// as default export
import structuredClone from '@ungap/structured-clone';
const cloned = structuredClone(
  {
    method() {
      // ignored, won't be cloned
    },
    special: Symbol('also ignored')
  },
  {
    // avoid throwing
    lossy: true,
    // avoid throwing *and* looks for toJSON
    json: true
  }
);
```

The behavior is the same found in *JSON* when it comes to *Array*, so that unsupported values will result as `null` placeholders instead.

#### toJSON

If `lossy` option is not enough, `json` will actually enforce `lossy` and also check for `toJSON` method when objects are parsed.

Alternative, the `json` exports combines all features:

```js
import {stringify, parse} from '@ungap/structured-clone/json';

parse(stringify({any: 'serializable'}));
```
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).


## [4.1.0] - 2021-04-15
### Added
- Types are now exported as `yaml.types.XXX`.
- Every type now has `options` property with original arguments kept as they were
  (see `yaml.types.int.options` as an example).

### Changed
- `Schema.extend()` now keeps old type order in case of conflicts
  (e.g. Schema.extend([ a, b, c ]).extend([ b, a, d ]) is now ordered as `abcd` instead of `cbad`).


## [4.0.0] - 2021-01-03
### Changed
- Check [migration guide](migrate_v3_to_v4.md) to see details for all breaking changes.
- Breaking: "unsafe" tags `!!js/function`, `!!js/regexp`, `!!js/undefined` are
  moved to [js-yaml-js-types](https://github.com/nodeca/js-yaml-js-types) package.
- Breaking: removed `safe*` functions. Use `load`, `loadAll`, `dump`
  instead which are all now safe by default.
- `yaml.DEFAULT_SAFE_SCHEMA` and `yaml.DEFAULT_FULL_SCHEMA` are removed, use
  `yaml.DEFAULT_SCHEMA` instead.
- `yaml.Schema.create(schema, tags)` is removed, use `schema.extend(tags)` instead.
- `!!binary` now always mapped to `Uint8Array` on load.
- Reduced nesting of `/lib` folder.
- Parse numbers according to YAML 1.2 instead of YAML 1.1 (`01234` is now decimal,
  `0o1234` is octal, `1:23` is parsed as string instead of base60).
- `dump()` no longer quotes `:`, `[`, `]`, `(`, `)` except when necessary, #470, #557.
- Line and column in exceptions are now formatted as `(X:Y)` instead of
  `at line X, column Y` (also present in compact format), #332.
- Code snippet created in exceptions now contains multiple lines with line numbers.
- `dump()` now serializes `undefined` as `null` in collections and removes keys with
  `undefined` in mappings, #571.
- `dump()` with `skipInvalid=true` now serializes invalid items in collections as null.
- Custom tags starting with `!` are now dumped as `!tag` instead of `!<!tag>`, #576.
- Custom tags starting with `tag:yaml.org,2002:` are now shorthanded using `!!`, #258.

### Added
- Added `.mjs` (es modules) support.
- Added `quotingType` and `forceQuotes` options for dumper to configure
  string literal style, #290, #529.
- Added `styles: { '!!null': 'empty' }` option for dumper
  (serializes `{ foo: null }` as "`foo: `"), #570.
- Added `replacer` option (similar to option in JSON.stringify), #339.
- Custom `Tag` can now handle all tags or multiple tags with the same prefix, #385.

### Fixed
- Astral characters are no longer encoded by `dump()`, #587.
- "duplicate mapping key" exception now points at the correct column, #452.
- Extra commas in flow collections (e.g. `[foo,,bar]`) now throw an exception
  instead of producing null, #321.
- `__proto__` key no longer overrides object prototype, #164.
- Removed `bower.json`.
- Tags are now url-decoded in `load()` and url-encoded in `dump()`
  (previously usage of custom non-ascii tags may have led to invalid YAML that can't be parsed).
- Anchors now work correctly with empty nodes, #301.
- Fix incorrect parsing of invalid block mapping syntax, #418.
- Throw an error if block sequence/mapping indent contains a tab, #80.


## [3.14.1] - 2020-12-07
### Security
- Fix possible code execution in (already unsafe) `.load()` (in &anchor).


## [3.14.0] - 2020-05-22
### Changed
- Support `safe/loadAll(input, options)` variant of call.
- CI: drop outdated nodejs versions.
- Dev deps bump.

### Fixed
- Quote `=` in plain scalars #519.
- Check the node type for `!<?>` tag in case user manually specifies it.
- Verify that there are no null-bytes in input.
- Fix wrong quote position when writing condensed flow, #526.


## [3.13.1] - 2019-04-05
### Security
- Fix possible code execution in (already unsafe) `.load()`, #480.


## [3.13.0] - 2019-03-20
### Security
- Security fix: `safeLoad()` can hang when arrays with nested refs
  used as key. Now throws exception for nested arrays. #475.


## [3.12.2] - 2019-02-26
### Fixed
- Fix `noArrayIndent` option for root level, #468.


## [3.12.1] - 2019-01-05
### Added
- Added `noArrayIndent` option, #432.


## [3.12.0] - 2018-06-02
### Changed
- Support arrow functions without a block statement, #421.


## [3.11.0] - 2018-03-05
### Added
- Add arrow functions suport for `!!js/function`.

### Fixed
- Fix dump in bin/octal/hex formats for negative integers, #399.


## [3.10.0] - 2017-09-10
### Fixed
- Fix `condenseFlow` output (quote keys for sure, instead of spaces), #371, #370.
- Dump astrals as codepoints instead of surrogate pair, #368.


## [3.9.1] - 2017-07-08
### Fixed
- Ensure stack is present for custom errors in node 7.+, #351.


## [3.9.0] - 2017-07-08
### Added
- Add `condenseFlow` option (to create pretty URL query params), #346.

### Fixed
- Support array return from safeLoadAll/loadAll, #350.


## [3.8.4] - 2017-05-08
### Fixed
- Dumper: prevent space after dash for arrays that wrap, #343.


## [3.8.3] - 2017-04-05
### Fixed
- Should not allow numbers to begin and end with underscore, #335.


## [3.8.2] - 2017-03-02
### Fixed
- Fix `!!float 123` (integers) parse, #333.
- Don't allow leading zeros in floats (except 0, 0.xxx).
- Allow positive exponent without sign in floats.


## [3.8.1] - 2017-02-07
### Changed
- Maintenance: update browserified build.


## [3.8.0] - 2017-02-07
### Fixed
- Fix reported position for `duplicated mapping key` errors.
  Now points to block start instead of block end.
  (#243, thanks to @shockey).


## [3.7.0] - 2016-11-12
### Added
- Support polymorphism for tags (#300, thanks to @monken).

### Fixed
- Fix parsing of quotes followed by newlines (#304, thanks to @dplepage).


## [3.6.1] - 2016-05-11
### Fixed
- Fix output cut on a pipe, #286.


## [3.6.0] - 2016-04-16
### Fixed
- Dumper rewrite, fix multiple bugs with trailing `\n`.
  Big thanks to @aepsilon!
- Loader: fix leading/trailing newlines in block scalars, @aepsilon.


## [3.5.5] - 2016-03-17
### Fixed
- Date parse fix: don't allow dates with on digit in month and day, #268.


## [3.5.4] - 2016-03-09
### Added
- `noCompatMode` for dumper, to disable quoting YAML 1.1 values.


## [3.5.3] - 2016-02-11
### Changed
- Maintenance release.


## [3.5.2] - 2016-01-11
### Changed
- Maintenance: missed comma in bower config.


## [3.5.1] - 2016-01-11
### Changed
- Removed `inherit` dependency, #239.
- Better browserify workaround for esprima load.
- Demo rewrite.


## [3.5.0] - 2016-01-10
### Fixed
- Dumper. Fold strings only, #217.
- Dumper. `norefs` option, to clone linked objects, #229.
- Loader. Throw a warning for duplicate keys, #166.
- Improved browserify support (mark `esprima` & `Buffer` excluded).


## [3.4.6] - 2015-11-26
### Changed
- Use standalone `inherit` to keep browserified files clear.


## [3.4.5] - 2015-11-23
### Added
- Added `lineWidth` option to dumper.


## [3.4.4] - 2015-11-21
### Fixed
- Fixed floats dump (missed dot for scientific format), #220.
- Allow non-printable characters inside quoted scalars, #192.


## [3.4.3] - 2015-10-10
### Changed
- Maintenance release - deps bump (esprima, argparse).


## [3.4.2] - 2015-09-09
### Fixed
- Fixed serialization of duplicated entries in sequences, #205.
  Thanks to @vogelsgesang.


## [3.4.1] - 2015-09-05
### Fixed
- Fixed stacktrace handling in generated errors, for browsers (FF/IE).


## [3.4.0] - 2015-08-23
### Changed
- Don't throw on warnings anymore. Use `onWarning` option to catch.
- Throw error on unknown tags (was warning before).
- Reworked internals of error class.

### Fixed
- Fixed multiline keys dump, #197. Thanks to @tcr.
- Fixed heading line breaks in some scalars (regression).


## [3.3.1] - 2015-05-13
### Added
- Added `.sortKeys` dumper option, thanks to @rjmunro.

### Fixed
- Fixed astral characters support, #191.


## [3.3.0] - 2015-04-26
### Changed
- Significantly improved long strings formatting in dumper, thanks to @isaacs.
- Strip BOM if exists.


## [3.2.7] - 2015-02-19
### Changed
- Maintenance release.
- Updated dependencies.
- HISTORY.md -> CHANGELOG.md


## [3.2.6] - 2015-02-07
### Fixed
- Fixed encoding of UTF-16 surrogate pairs. (e.g. "\U0001F431" CAT FACE).
- Fixed demo dates dump (#113, thanks to @Hypercubed).


## [3.2.5] - 2014-12-28
### Fixed
- Fixed resolving of all built-in types on empty nodes.
- Fixed invalid warning on empty lines within quoted scalars and flow collections.
- Fixed bug: Tag on an empty node didn't resolve in some cases.


## [3.2.4] - 2014-12-19
### Fixed
- Fixed resolving of !!null tag on an empty node.


## [3.2.3] - 2014-11-08
### Fixed
- Implemented dumping of objects with circular and cross references.
- Partially fixed aliasing of constructed objects. (see issue #141 for details)


## [3.2.2] - 2014-09-07
### Fixed
- Fixed infinite loop on unindented block scalars.
- Rewritten base64 encode/decode in binary type, to keep code licence clear.


## [3.2.1] - 2014-08-24
### Fixed
- Nothig new. Just fix npm publish error.


## [3.2.0] - 2014-08-24
### Added
- Added input piping support to CLI.

### Fixed
- Fixed typo, that could cause hand on initial indent (#139).


## [3.1.0] - 2014-07-07
### Changed
- 1.5x-2x speed boost.
- Removed deprecated `require('xxx.yml')` support.
- Significant code cleanup and refactoring.
- Internal API changed. If you used custom types - see updated examples.
  Others are not affected.
- Even if the input string has no trailing line break character,
  it will be parsed as if it has one.
- Added benchmark scripts.
- Moved bower files to /dist folder
- Bugfixes.


## [3.0.2] - 2014-02-27
### Fixed
- Fixed bug: "constructor" string parsed as `null`.


## [3.0.1] - 2013-12-22
### Fixed
- Fixed parsing of literal scalars. (issue #108)
- Prevented adding unnecessary spaces in object dumps. (issue #68)
- Fixed dumping of objects with very long (> 1024 in length) keys.


## [3.0.0] - 2013-12-16
### Changed
- Refactored code. Changed API for custom types.
- Removed output colors in CLI, dump json by default.
- Removed big dependencies from browser version (esprima, buffer). Load `esprima` manually, if `!!js/function` needed. `!!bin` now returns Array in browser
- AMD support.
- Don't quote dumped strings because of `-` & `?` (if not first char).
- __Deprecated__ loading yaml files via `require()`, as not recommended
  behaviour for node.


## [2.1.3] - 2013-10-16
### Fixed
- Fix wrong loading of empty block scalars.


## [2.1.2] - 2013-10-07
### Fixed
- Fix unwanted line breaks in folded scalars.


## [2.1.1] - 2013-10-02
### Fixed
- Dumper now respects deprecated booleans syntax from YAML 1.0/1.1
- Fixed reader bug in JSON-like sequences/mappings.


## [2.1.0] - 2013-06-05
### Added
- Add standard YAML schemas: Failsafe (`FAILSAFE_SCHEMA`),
  JSON (`JSON_SCHEMA`) and Core (`CORE_SCHEMA`).
- Add `skipInvalid` dumper option.

### Changed
- Rename `DEFAULT_SCHEMA` to `DEFAULT_FULL_SCHEMA`
  and `SAFE_SCHEMA` to `DEFAULT_SAFE_SCHEMA`.
- Use `safeLoad` for `require` extension.

### Fixed
- Bug fix: export `NIL` constant from the public interface.


## [2.0.5] - 2013-04-26
### Security
- Close security issue in !!js/function constructor.
  Big thanks to @nealpoole for security audit.


## [2.0.4] - 2013-04-08
### Changed
- Updated .npmignore to reduce package size


## [2.0.3] - 2013-02-26
### Fixed
- Fixed dumping of empty arrays ans objects. ([] and {} instead of null)


## [2.0.2] - 2013-02-15
### Fixed
- Fixed input validation: tabs are printable characters.


## [2.0.1] - 2013-02-09
### Fixed
- Fixed error, when options not passed to function cass


## [2.0.0] - 2013-02-09
### Changed
- Full rewrite. New architecture. Fast one-stage parsing.
- Changed custom types API.
- Added YAML dumper.


## [1.0.3] - 2012-11-05
### Fixed
- Fixed utf-8 files loading.


## [1.0.2] - 2012-08-02
### Fixed
- Pull out hand-written shims. Use ES5-Shims for old browsers support. See #44.
- Fix timstamps incorectly parsed in local time when no time part specified.


## [1.0.1] - 2012-07-07
### Fixed
- Fixes `TypeError: 'undefined' is not an object` under Safari. Thanks Phuong.
- Fix timestamps incorrectly parsed in local time. Thanks @caolan. Closes #46.


## [1.0.0] - 2012-07-01
### Changed
- `y`, `yes`, `n`, `no`, `on`, `off` are not converted to Booleans anymore.
  Fixes #42.
- `require(filename)` now returns a single document and throws an Error if
  file contains more than one document.
- CLI was merged back from js-yaml.bin


## [0.3.7] - 2012-02-28
### Fixed
- Fix export of `addConstructor()`. Closes #39.


## [0.3.6] - 2012-02-22
### Changed
- Removed AMD parts - too buggy to use. Need help to rewrite from scratch

### Fixed
- Removed YUI compressor warning (renamed `double` variable). Closes #40.


## [0.3.5] - 2012-01-10
### Fixed
- Workagound for .npmignore fuckup under windows. Thanks to airportyh.


## [0.3.4] - 2011-12-24
### Fixed
- Fixes str[] for oldIEs support.
- Adds better has change support for browserified demo.
- improves compact output of Error. Closes #33.


## [0.3.3] - 2011-12-20
### Added
- adds `compact` stringification of Errors.

### Changed
- jsyaml executable moved to separate module.


## [0.3.2] - 2011-12-16
### Added
- Added jsyaml executable.
- Added !!js/function support. Closes #12.

### Fixed
- Fixes ug with block style scalars. Closes #26.
- All sources are passing JSLint now.
- Fixes bug in Safari. Closes #28.
- Fixes bug in Opers. Closes #29.
- Improves browser support. Closes #20.


## [0.3.1] - 2011-11-18
### Added
- Added AMD support for browserified version.
- Added permalinks for online demo YAML snippets. Now we have YPaste service, lol.
- Added !!js/regexp and !!js/undefined types. Partially solves #12.

### Changed
- Wrapped browserified js-yaml into closure.

### Fixed
- Fixed the resolvement of non-specific tags. Closes #17.
- Fixed !!set mapping.
- Fixed month parse in dates. Closes #19.


## [0.3.0] - 2011-11-09
### Added
- Added browserified version. Closes #13.
- Added live demo of browserified version.
- Ported some of the PyYAML tests. See #14.

### Fixed
- Removed JS.Class dependency. Closes #3.
- Fixed timestamp bug when fraction was given.


## [0.2.2] - 2011-11-06
### Fixed
- Fixed crash on docs without ---. Closes #8.
- Fixed multiline string parse
- Fixed tests/comments for using array as key


## [0.2.1] - 2011-11-02
### Fixed
- Fixed short file read (<4k). Closes #9.


## [0.2.0] - 2011-11-02
### Changed
- First public release


[4.1.0]: https://github.com/nodeca/js-yaml/compare/4.0.0...4.1.0
[4.0.0]: https://github.com/nodeca/js-yaml/compare/3.14.0...4.0.0
[3.14.0]: https://github.com/nodeca/js-yaml/compare/3.13.1...3.14.0
[3.13.1]: https://github.com/nodeca/js-yaml/compare/3.13.0...3.13.1
[3.13.0]: https://github.com/nodeca/js-yaml/compare/3.12.2...3.13.0
[3.12.2]: https://github.com/nodeca/js-yaml/compare/3.12.1...3.12.2
[3.12.1]: https://github.com/nodeca/js-yaml/compare/3.12.0...3.12.1
[3.12.0]: https://github.com/nodeca/js-yaml/compare/3.11.0...3.12.0
[3.11.0]: https://github.com/nodeca/js-yaml/compare/3.10.0...3.11.0
[3.10.0]: https://github.com/nodeca/js-yaml/compare/3.9.1...3.10.0
[3.9.1]: https://github.com/nodeca/js-yaml/compare/3.9.0...3.9.1
[3.9.0]: https://github.com/nodeca/js-yaml/compare/3.8.4...3.9.0
[3.8.4]: https://github.com/nodeca/js-yaml/compare/3.8.3...3.8.4
[3.8.3]: https://github.com/nodeca/js-yaml/compare/3.8.2...3.8.3
[3.8.2]: https://github.com/nodeca/js-yaml/compare/3.8.1...3.8.2
[3.8.1]: https://github.com/nodeca/js-yaml/compare/3.8.0...3.8.1
[3.8.0]: https://github.com/nodeca/js-yaml/compare/3.7.0...3.8.0
[3.7.0]: https://github.com/nodeca/js-yaml/compare/3.6.1...3.7.0
[3.6.1]: https://github.com/nodeca/js-yaml/compare/3.6.0...3.6.1
[3.6.0]: https://github.com/nodeca/js-yaml/compare/3.5.5...3.6.0
[3.5.5]: https://github.com/nodeca/js-yaml/compare/3.5.4...3.5.5
[3.5.4]: https://github.com/nodeca/js-yaml/compare/3.5.3...3.5.4
[3.5.3]: https://github.com/nodeca/js-yaml/compare/3.5.2...3.5.3
[3.5.2]: https://github.com/nodeca/js-yaml/compare/3.5.1...3.5.2
[3.5.1]: https://github.com/nodeca/js-yaml/compare/3.5.0...3.5.1
[3.5.0]: https://github.com/nodeca/js-yaml/compare/3.4.6...3.5.0
[3.4.6]: https://github.com/nodeca/js-yaml/compare/3.4.5...3.4.6
[3.4.5]: https://github.com/nodeca/js-yaml/compare/3.4.4...3.4.5
[3.4.4]: https://github.com/nodeca/js-yaml/compare/3.4.3...3.4.4
[3.4.3]: https://github.com/nodeca/js-yaml/compare/3.4.2...3.4.3
[3.4.2]: https://github.com/nodeca/js-yaml/compare/3.4.1...3.4.2
[3.4.1]: https://github.com/nodeca/js-yaml/compare/3.4.0...3.4.1
[3.4.0]: https://github.com/nodeca/js-yaml/compare/3.3.1...3.4.0
[3.3.1]: https://github.com/nodeca/js-yaml/compare/3.3.0...3.3.1
[3.3.0]: https://github.com/nodeca/js-yaml/compare/3.2.7...3.3.0
[3.2.7]: https://github.com/nodeca/js-yaml/compare/3.2.6...3.2.7
[3.2.6]: https://github.com/nodeca/js-yaml/compare/3.2.5...3.2.6
[3.2.5]: https://github.com/nodeca/js-yaml/compare/3.2.4...3.2.5
[3.2.4]: https://github.com/nodeca/js-yaml/compare/3.2.3...3.2.4
[3.2.3]: https://github.com/nodeca/js-yaml/compare/3.2.2...3.2.3
[3.2.2]: https://github.com/nodeca/js-yaml/compare/3.2.1...3.2.2
[3.2.1]: https://github.com/nodeca/js-yaml/compare/3.2.0...3.2.1
[3.2.0]: https://github.com/nodeca/js-yaml/compare/3.1.0...3.2.0
[3.1.0]: https://github.com/nodeca/js-yaml/compare/3.0.2...3.1.0
[3.0.2]: https://github.com/nodeca/js-yaml/compare/3.0.1...3.0.2
[3.0.1]: https://github.com/nodeca/js-yaml/compare/3.0.0...3.0.1
[3.0.0]: https://github.com/nodeca/js-yaml/compare/2.1.3...3.0.0
[2.1.3]: https://github.com/nodeca/js-yaml/compare/2.1.2...2.1.3
[2.1.2]: https://github.com/nodeca/js-yaml/compare/2.1.1...2.1.2
[2.1.1]: https://github.com/nodeca/js-yaml/compare/2.1.0...2.1.1
[2.1.0]: https://github.com/nodeca/js-yaml/compare/2.0.5...2.1.0
[2.0.5]: https://github.com/nodeca/js-yaml/compare/2.0.4...2.0.5
[2.0.4]: https://github.com/nodeca/js-yaml/compare/2.0.3...2.0.4
[2.0.3]: https://github.com/nodeca/js-yaml/compare/2.0.2...2.0.3
[2.0.2]: https://github.com/nodeca/js-yaml/compare/2.0.1...2.0.2
[2.0.1]: https://github.com/nodeca/js-yaml/compare/2.0.0...2.0.1
[2.0.0]: https://github.com/nodeca/js-yaml/compare/1.0.3...2.0.0
[1.0.3]: https://github.com/nodeca/js-yaml/compare/1.0.2...1.0.3
[1.0.2]: https://github.com/nodeca/js-yaml/compare/1.0.1...1.0.2
[1.0.1]: https://github.com/nodeca/js-yaml/compare/1.0.0...1.0.1
[1.0.0]: https://github.com/nodeca/js-yaml/compare/0.3.7...1.0.0
[0.3.7]: https://github.com/nodeca/js-yaml/compare/0.3.6...0.3.7
[0.3.6]: https://github.com/nodeca/js-yaml/compare/0.3.5...0.3.6
[0.3.5]: https://github.com/nodeca/js-yaml/compare/0.3.4...0.3.5
[0.3.4]: https://github.com/nodeca/js-yaml/compare/0.3.3...0.3.4
[0.3.3]: https://github.com/nodeca/js-yaml/compare/0.3.2...0.3.3
[0.3.2]: https://github.com/nodeca/js-yaml/compare/0.3.1...0.3.2
[0.3.1]: https://github.com/nodeca/js-yaml/compare/0.3.0...0.3.1
[0.3.0]: https://github.com/nodeca/js-yaml/compare/0.2.2...0.3.0
[0.2.2]: https://github.com/nodeca/js-yaml/compare/0.2.1...0.2.2
[0.2.1]: https://github.com/nodeca/js-yaml/compare/0.2.0...0.2.1
[0.2.0]: https://github.com/nodeca/js-yaml/releases/tag/0.2.0
JS-YAML - YAML 1.2 parser / writer for JavaScript
=================================================

[![CI](https://github.com/nodeca/js-yaml/workflows/CI/badge.svg?branch=master)](https://github.com/nodeca/js-yaml/actions)
[![NPM version](https://img.shields.io/npm/v/js-yaml.svg)](https://www.npmjs.org/package/js-yaml)

__[Online Demo](http://nodeca.github.com/js-yaml/)__


This is an implementation of [YAML](http://yaml.org/), a human-friendly data
serialization language. Started as [PyYAML](http://pyyaml.org/) port, it was
completely rewritten from scratch. Now it's very fast, and supports 1.2 spec.


Installation
------------

### YAML module for node.js

```
npm install js-yaml
```


### CLI executable

If you want to inspect your YAML files from CLI, install js-yaml globally:

```
npm install -g js-yaml
```

#### Usage

```
usage: js-yaml [-h] [-v] [-c] [-t] file

Positional arguments:
  file           File with YAML document(s)

Optional arguments:
  -h, --help     Show this help message and exit.
  -v, --version  Show program's version number and exit.
  -c, --compact  Display errors in compact mode
  -t, --trace    Show stack trace on error
```


API
---

Here we cover the most 'useful' methods. If you need advanced details (creating
your own tags), see [examples](https://github.com/nodeca/js-yaml/tree/master/examples)
for more info.

``` javascript
const yaml = require('js-yaml');
const fs   = require('fs');

// Get document, or throw exception on error
try {
  const doc = yaml.load(fs.readFileSync('/home/ixti/example.yml', 'utf8'));
  console.log(doc);
} catch (e) {
  console.log(e);
}
```


### load (string [ , options ])

Parses `string` as single YAML document. Returns either a
plain object, a string, a number, `null` or `undefined`, or throws `YAMLException` on error. By default, does
not support regexps, functions and undefined.

options:

- `filename` _(default: null)_ - string to be used as a file path in
  error/warning messages.
- `onWarning` _(default: null)_ - function to call on warning messages.
  Loader will call this function with an instance of `YAMLException` for each warning.
- `schema` _(default: `DEFAULT_SCHEMA`)_ - specifies a schema to use.
  - `FAILSAFE_SCHEMA` - only strings, arrays and plain objects:
    http://www.yaml.org/spec/1.2/spec.html#id2802346
  - `JSON_SCHEMA` - all JSON-supported types:
    http://www.yaml.org/spec/1.2/spec.html#id2803231
  - `CORE_SCHEMA` - same as `JSON_SCHEMA`:
    http://www.yaml.org/spec/1.2/spec.html#id2804923
  - `DEFAULT_SCHEMA` - all supported YAML types.
- `json` _(default: false)_ - compatibility with JSON.parse behaviour. If true, then duplicate keys in a mapping will override values rather than throwing an error.

NOTE: This function **does not** understand multi-document sources, it throws
exception on those.

NOTE: JS-YAML **does not** support schema-specific tag resolution restrictions.
So, the JSON schema is not as strictly defined in the YAML specification.
It allows numbers in any notation, use `Null` and `NULL` as `null`, etc.
The core schema also has no such restrictions. It allows binary notation for integers.


### loadAll (string [, iterator] [, options ])

Same as `load()`, but understands multi-document sources. Applies
`iterator` to each document if specified, or returns array of documents.

``` javascript
const yaml = require('js-yaml');

yaml.loadAll(data, function (doc) {
  console.log(doc);
});
```


### dump (object [ , options ])

Serializes `object` as a YAML document. Uses `DEFAULT_SCHEMA`, so it will
throw an exception if you try to dump regexps or functions. However, you can
disable exceptions by setting the `skipInvalid` option to `true`.

options:

- `indent` _(default: 2)_ - indentation width to use (in spaces).
- `noArrayIndent` _(default: false)_ - when true, will not add an indentation level to array elements
- `skipInvalid` _(default: false)_ - do not throw on invalid types (like function
  in the safe schema) and skip pairs and single values with such types.
- `flowLevel` _(default: -1)_ - specifies level of nesting, when to switch from
  block to flow style for collections. -1 means block style everwhere
- `styles` - "tag" => "style" map. Each tag may have own set of styles.
- `schema` _(default: `DEFAULT_SCHEMA`)_ specifies a schema to use.
- `sortKeys` _(default: `false`)_ - if `true`, sort keys when dumping YAML. If a
  function, use the function to sort the keys.
- `lineWidth` _(default: `80`)_ - set max line width. Set `-1` for unlimited width.
- `noRefs` _(default: `false`)_ - if `true`, don't convert duplicate objects into references
- `noCompatMode` _(default: `false`)_ - if `true` don't try to be compatible with older
  yaml versions. Currently: don't quote "yes", "no" and so on, as required for YAML 1.1
- `condenseFlow` _(default: `false`)_ - if `true` flow sequences will be condensed, omitting the space between `a, b`. Eg. `'[a,b]'`, and omitting the space between `key: value` and quoting the key. Eg. `'{"a":b}'` Can be useful when using yaml for pretty URL query params as spaces are %-encoded.
- `quotingType` _(`'` or `"`, default: `'`)_ - strings will be quoted using this quoting style. If you specify single quotes, double quotes will still be used for non-printable characters.
- `forceQuotes` _(default: `false`)_ - if `true`, all non-key strings will be quoted even if they normally don't need to.
- `replacer` - callback `function (key, value)` called recursively on each key/value in source object (see `replacer` docs for `JSON.stringify`).

The following table show availlable styles (e.g. "canonical",
"binary"...) available for each tag (.e.g. !!null, !!int ...). Yaml
output is shown on the right side after `=>` (default setting) or `->`:

``` none
!!null
  "canonical"   -> "~"
  "lowercase"   => "null"
  "uppercase"   -> "NULL"
  "camelcase"   -> "Null"

!!int
  "binary"      -> "0b1", "0b101010", "0b1110001111010"
  "octal"       -> "0o1", "0o52", "0o16172"
  "decimal"     => "1", "42", "7290"
  "hexadecimal" -> "0x1", "0x2A", "0x1C7A"

!!bool
  "lowercase"   => "true", "false"
  "uppercase"   -> "TRUE", "FALSE"
  "camelcase"   -> "True", "False"

!!float
  "lowercase"   => ".nan", '.inf'
  "uppercase"   -> ".NAN", '.INF'
  "camelcase"   -> ".NaN", '.Inf'
```

Example:

``` javascript
dump(object, {
  'styles': {
    '!!null': 'canonical' // dump null as ~
  },
  'sortKeys': true        // sort object keys
});
```

Supported YAML types
--------------------

The list of standard YAML tags and corresponding JavaScript types. See also
[YAML tag discussion](http://pyyaml.org/wiki/YAMLTagDiscussion) and
[YAML types repository](http://yaml.org/type/).

```
!!null ''                   # null
!!bool 'yes'                # bool
!!int '3...'                # number
!!float '3.14...'           # number
!!binary '...base64...'     # buffer
!!timestamp 'YYYY-...'      # date
!!omap [ ... ]              # array of key-value pairs
!!pairs [ ... ]             # array or array pairs
!!set { ... }               # array of objects with given keys and null values
!!str '...'                 # string
!!seq [ ... ]               # array
!!map { ... }               # object
```

**JavaScript-specific tags**

See [js-yaml-js-types](https://github.com/nodeca/js-yaml-js-types) for
extra types.


Caveats
-------

Note, that you use arrays or objects as key in JS-YAML. JS does not allow objects
or arrays as keys, and stringifies (by calling `toString()` method) them at the
moment of adding them.

``` yaml
---
? [ foo, bar ]
: - baz
? { foo: bar }
: - baz
  - baz
```

``` javascript
{ "foo,bar": ["baz"], "[object Object]": ["baz", "baz"] }
```

Also, reading of properties on implicit block mapping keys is not supported yet.
So, the following YAML document cannot be loaded.

``` yaml
&anchor foo:
  foo: bar
  *anchor: duplicate key
  baz: bat
  *anchor: duplicate key
```


js-yaml for enterprise
----------------------

Available as part of the Tidelift Subscription

The maintainers of js-yaml and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-js-yaml?utm_source=npm-js-yaml&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)
# eslint-visitor-keys

[![npm version](https://img.shields.io/npm/v/eslint-visitor-keys.svg)](https://www.npmjs.com/package/eslint-visitor-keys)
[![Downloads/month](https://img.shields.io/npm/dm/eslint-visitor-keys.svg)](http://www.npmtrends.com/eslint-visitor-keys)
[![Build Status](https://github.com/eslint/eslint-visitor-keys/workflows/CI/badge.svg)](https://github.com/eslint/eslint-visitor-keys/actions)

Constants and utilities about visitor keys to traverse AST.

## 💿 Installation

Use [npm] to install.

```bash
$ npm install eslint-visitor-keys
```

### Requirements

- [Node.js] `^12.22.0`, `^14.17.0`, or `>=16.0.0`


## 📖 Usage

To use in an ESM file:

```js
import * as evk from "eslint-visitor-keys"
```

To use in a CommonJS file:

```js
const evk = require("eslint-visitor-keys")
```

### evk.KEYS

> type: `{ [type: string]: string[] | undefined }`

Visitor keys. This keys are frozen.

This is an object. Keys are the type of [ESTree] nodes. Their values are an array of property names which have child nodes.

For example:

```
console.log(evk.KEYS.AssignmentExpression) // → ["left", "right"]
```

### evk.getKeys(node)

> type: `(node: object) => string[]`

Get the visitor keys of a given AST node.

This is similar to `Object.keys(node)` of ES Standard, but some keys are excluded: `parent`, `leadingComments`, `trailingComments`, and names which start with `_`.

This will be used to traverse unknown nodes.

For example:

```js
const node = {
    type: "AssignmentExpression",
    left: { type: "Identifier", name: "foo" },
    right: { type: "Literal", value: 0 }
}
console.log(evk.getKeys(node)) // → ["type", "left", "right"]
```

### evk.unionWith(additionalKeys)

> type: `(additionalKeys: object) => { [type: string]: string[] | undefined }`

Make the union set with `evk.KEYS` and the given keys.

- The order of keys is, `additionalKeys` is at first, then `evk.KEYS` is concatenated after that.
- It removes duplicated keys as keeping the first one.

For example:

```js
console.log(evk.unionWith({
    MethodDefinition: ["decorators"]
})) // → { ..., MethodDefinition: ["decorators", "key", "value"], ... }
```

## 📰 Change log

See [GitHub releases](https://github.com/eslint/eslint-visitor-keys/releases).

## 🍻 Contributing

Welcome. See [ESLint contribution guidelines](https://eslint.org/docs/developer-guide/contributing/).

### Development commands

- `npm test` runs tests and measures code coverage.
- `npm run lint` checks source codes with ESLint.
- `npm run test:open-coverage` opens the code coverage report of the previous test with your default browser.


[npm]: https://www.npmjs.com/
[Node.js]: https://nodejs.org/
[ESTree]: https://github.com/estree/estree
# W3C keyname

Tiny library that exports a function `keyName` that takes a keyboard event and
returns a
[`KeyboardEvent.key`](https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent/key)-style
string. Will use the actual `key` property of the event if available,
and fall back to a value synthesized from the `keyCode` otherwise.

Probably often wrong on non-US keyboards, since the correspondence
between a key code and the character it produces when shift is held is
predicted based on a hard-coded table. Meant as a fallback for
`KeyboardEvent.key`, not a replacement.

The lookup tables from key codes (`event.keyCode`) to names are
exported as `base` (when Shift isn't held) and `shift` (when Shift is
held).

License: MIT
# parent-module [![Build Status](https://travis-ci.org/sindresorhus/parent-module.svg?branch=master)](https://travis-ci.org/sindresorhus/parent-module)

> Get the path of the parent module

Node.js exposes `module.parent`, but it only gives you the first cached parent, which is not necessarily the actual parent.


## Install

```
$ npm install parent-module
```


## Usage

```js
// bar.js
const parentModule = require('parent-module');

module.exports = () => {
	console.log(parentModule());
	//=> '/Users/sindresorhus/dev/unicorn/foo.js'
};
```

```js
// foo.js
const bar = require('./bar');

bar();
```


## API

### parentModule([filepath])

By default, it will return the path of the immediate parent.

#### filepath

Type: `string`<br>
Default: [`__filename`](https://nodejs.org/api/globals.html#globals_filename)

Filepath of the module of which to get the parent path.

Useful if you want it to work [multiple module levels down](https://github.com/sindresorhus/parent-module/tree/master/fixtures/filepath).


## Tip

Combine it with [`read-pkg-up`](https://github.com/sindresorhus/read-pkg-up) to read the package.json of the parent module.

```js
const path = require('path');
const readPkgUp = require('read-pkg-up');
const parentModule = require('parent-module');

console.log(readPkgUp.sync({cwd: path.dirname(parentModule())}).pkg);
//=> {name: 'chalk', version: '1.0.0', …}
```


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# Config Array

by [Nicholas C. Zakas](https://humanwhocodes.com)

If you find this useful, please consider supporting my work with a [donation](https://humanwhocodes.com/donate).

## Description

A config array is a way of managing configurations that are based on glob pattern matching of filenames. Each config array contains the information needed to determine the correct configuration for any file based on the filename. 

## Background

In 2019, I submitted an [ESLint RFC](https://github.com/eslint/rfcs/pull/9) proposing a new way of configuring ESLint. The goal was to streamline what had become an increasingly complicated configuration process. Over several iterations, this proposal was eventually born.

The basic idea is that all configuration, including overrides, can be represented by a single array where each item in the array is a config object. Config objects appearing later in the array override config objects appearing earlier in the array. You can calculate a config for a given file by traversing all config objects in the array to find the ones that match the filename. Matching is done by specifying glob patterns in `files` and `ignores` properties on each config object. Here's an example:

```js
export default [

    // match all JSON files
    {
        name: "JSON Handler",
        files: ["**/*.json"],
        handler: jsonHandler
    },

    // match only package.json
    {
        name: "package.json Handler",
        files: ["package.json"],
        handler: packageJsonHandler
    }
];
```

In this example, there are two config objects: the first matches all JSON files in all directories and the second matches just `package.json` in the base path directory (all the globs are evaluated as relative to a base path that can be specified). When you retrieve a configuration for `foo.json`, only the first config object matches so `handler` is equal to `jsonHandler`; when you retrieve a configuration for `package.json`, `handler` is equal to `packageJsonHandler` (because both config objects match, the second one wins).

## Installation

You can install the package using npm or Yarn:

```bash
npm install @humanwhocodes/config-array --save

# or

yarn add @humanwhocodes/config-array
```

## Usage

First, import the `ConfigArray` constructor:

```js
import { ConfigArray } from "@humanwhocodes/config-array";

// or using CommonJS

const { ConfigArray } = require("@humanwhocodes/config-array");
```

When you create a new instance of `ConfigArray`, you must pass in two arguments: an array of configs and an options object. The array of configs is most likely read in from a configuration file, so here's a typical example:

```js
const configFilename = path.resolve(process.cwd(), "my.config.js");
const { default: rawConfigs } = await import(configFilename);
const configs = new ConfigArray(rawConfigs, {
    
    // the path to match filenames from
    basePath: process.cwd(),

    // additional items in each config
    schema: mySchema
});
```

This example reads in an object or array from `my.config.js` and passes it into the `ConfigArray` constructor as the first argument. The second argument is an object specifying the `basePath` (the directory in which `my.config.js` is found) and a `schema` to define the additional properties of a config object beyond `files`, `ignores`, and `name`.

### Specifying a Schema

The `schema` option is required for you to use additional properties in config objects. The schema is an object that follows the format of an [`ObjectSchema`](https://npmjs.com/package/@humanwhocodes/object-schema). The schema specifies both validation and merge rules that the `ConfigArray` instance needs to combine configs when there are multiple matches. Here's an example:

```js
const configFilename = path.resolve(process.cwd(), "my.config.js");
const { default: rawConfigs } = await import(configFilename);

const mySchema = {

    // define the handler key in configs
    handler: {
        required: true,
        merge(a, b) {
            if (!b) return a;
            if (!a) return b;
        },
        validate(value) {
            if (typeof value !== "function") {
                throw new TypeError("Function expected.");
            }
        }
    }
};

const configs = new ConfigArray(rawConfigs, {
    
    // the path to match filenames from
    basePath: process.cwd(),

    // additional item schemas in each config
    schema: mySchema,

    // additional config types supported (default: [])
    extraConfigTypes: ["array", "function"];
});
```

### Config Arrays

Config arrays can be multidimensional, so it's possible for a config array to contain another config array when `extraConfigTypes` contains `"array"`, such as:

```js
export default [
    
    // JS config
    {
        files: ["**/*.js"],
        handler: jsHandler
    },

    // JSON configs
    [

        // match all JSON files
        {
            name: "JSON Handler",
            files: ["**/*.json"],
            handler: jsonHandler
        },

        // match only package.json
        {
            name: "package.json Handler",
            files: ["package.json"],
            handler: packageJsonHandler
        }
    ],

    // filename must match function
    {
        files: [ filePath => filePath.endsWith(".md") ],
        handler: markdownHandler
    },

    // filename must match all patterns in subarray
    {
        files: [ ["*.test.*", "*.js"] ],
        handler: jsTestHandler
    },

    // filename must not match patterns beginning with !
    {
        name: "Non-JS files",
        files: ["!*.js"],
        settings: {
            js: false
        }
    }
];
```

In this example, the array contains both config objects and a config array. When a config array is normalized (see details below), it is flattened so only config objects remain. However, the order of evaluation remains the same.

If the `files` array contains a function, then that function is called with the absolute path of the file and is expected to return `true` if there is a match and `false` if not. (The `ignores` array can also contain functions.)

If the `files` array contains an item that is an array of strings and functions, then all patterns must match in order for the config to match. In the preceding examples, both `*.test.*` and `*.js` must match in order for the config object to be used.

If a pattern in the files array begins with `!` then it excludes that pattern. In the preceding example, any filename that doesn't end with `.js` will automatically get a `settings.js` property set to `false`.

You can also specify an `ignores` key that will force files matching those patterns to not be included. If the `ignores` key is in a config object without any other keys, then those ignores will always be applied; otherwise those ignores act as exclusions. Here's an example:

```js
export default [
    
    // Always ignored
    {
        ignores: ["**/.git/**", "**/node_modules/**"]
    },

    // .eslintrc.js file is ignored only when .js file matches
    {
        files: ["**/*.js"],
        ignores: [".eslintrc.js"]
        handler: jsHandler
    }
];
```

You can use negated patterns in `ignores` to exclude a file that was already ignored, such as:

```js
export default [
    
    // Ignore all JSON files except tsconfig.json
    {
        files: ["**/*"],
        ignores: ["**/*.json", "!tsconfig.json"]
    },

];
```

### Config Functions

Config arrays can also include config functions when `extraConfigTypes` contains `"function"`. A config function accepts a single parameter, `context` (defined by you), and must return either a config object or a config array (it cannot return another function). Config functions allow end users to execute code in the creation of appropriate config objects. Here's an example:

```js
export default [
    
    // JS config
    {
        files: ["**/*.js"],
        handler: jsHandler
    },

    // JSON configs
    function (context) {
        return [

            // match all JSON files
            {
                name: context.name + " JSON Handler",
                files: ["**/*.json"],
                handler: jsonHandler
            },

            // match only package.json
            {
                name: context.name + " package.json Handler",
                files: ["package.json"],
                handler: packageJsonHandler
            }
        ];
    }
];
```

When a config array is normalized, each function is executed and replaced in the config array with the return value.

**Note:** Config functions can also be async.

### Normalizing Config Arrays

Once a config array has been created and loaded with all of the raw config data, it must be normalized before it can be used. The normalization process goes through and flattens the config array as well as executing all config functions to get their final values.

To normalize a config array, call the `normalize()` method and pass in a context object:

```js
await configs.normalize({
    name: "MyApp"
});
```

The `normalize()` method returns a promise, so be sure to use the `await` operator. The config array instance is normalized in-place, so you don't need to create a new variable.

If you want to disallow async config functions, you can call `normalizeSync()` instead. This method is completely synchronous and does not require using the `await` operator as it does not return a promise:

```js
await configs.normalizeSync({
    name: "MyApp"
});
```

**Important:** Once a `ConfigArray` is normalized, it cannot be changed further. You can, however, create a new `ConfigArray` and pass in the normalized instance to create an unnormalized copy.

### Getting Config for a File

To get the config for a file, use the `getConfig()` method on a normalized config array and pass in the filename to get a config for:

```js
// pass in absolute filename
const fileConfig = configs.getConfig(path.resolve(process.cwd(), "package.json"));
```

The config array always returns an object, even if there are no configs matching the given filename. You can then inspect the returned config object to determine how to proceed.

A few things to keep in mind:

* You must pass in the absolute filename to get a config for.
* The returned config object never has `files`, `ignores`, or `name` properties; the only properties on the object will be the other configuration options specified.
* The config array caches configs, so subsequent calls to `getConfig()` with the same filename will return in a fast lookup rather than another calculation.
* A config will only be generated if the filename matches an entry in a `files` key. A config will not be generated without matching a `files` key (configs without a `files` key are only applied when another config with a `files` key is applied; configs without `files` are never applied on their own). Any config with a `files` key entry ending with `/**` or `/*` will only be applied if another entry in the same `files` key matches or another config matches.

## Determining Ignored Paths

You can determine if a file is ignored by using the `isFileIgnored()` method and passing in the absolute path of any file, as in this example:

```js
const ignored = configs.isFileIgnored('/foo/bar/baz.txt');
```

A file is considered ignored if any of the following is true:

* **It's parent directory is ignored.** For example, if `foo` is in `ignores`, then `foo/a.js` is considered ignored.
* **It has an ancestor directory that is ignored.** For example, if `foo` is in `ignores`, then `foo/baz/a.js` is considered ignored.
* **It matches an ignored file pattern.** For example, if `**/a.js` is in `ignores`, then `foo/a.js` and `foo/baz/a.js` are considered ignored.
* **If it matches an entry in `files` and also in `ignores`.** For example, if `**/*.js` is in `files` and `**/a.js` is in `ignores`, then `foo/a.js` and `foo/baz/a.js` are considered ignored.
* **The file is outside the `basePath`.** If the `basePath` is `/usr/me`, then `/foo/a.js` is considered ignored.

For directories, use the `isDirectoryIgnored()` method and pass in the absolute path of any directory, as in this example:

```js
const ignored = configs.isDirectoryIgnored('/foo/bar/');
```

A directory is considered ignored if any of the following is true:

* **It's parent directory is ignored.** For example, if `foo` is in `ignores`, then `foo/baz` is considered ignored.
* **It has an ancestor directory that is ignored.** For example, if `foo` is in `ignores`, then `foo/bar/baz/a.js` is considered ignored.
* **It matches and ignored file pattern.** For example, if `**/a.js` is in `ignores`, then `foo/a.js` and `foo/baz/a.js` are considered ignored.
* **If it matches an entry in `files` and also in `ignores`.** For example, if `**/*.js` is in `files` and `**/a.js` is in `ignores`, then `foo/a.js` and `foo/baz/a.js` are considered ignored.
* **The file is outside the `basePath`.** If the `basePath` is `/usr/me`, then `/foo/a.js` is considered ignored.

**Important:** A pattern such as `foo/**` means that `foo` and `foo/` are *not* ignored whereas `foo/bar` is ignored. If you want to ignore `foo` and all of its subdirectories, use the pattern `foo` or `foo/` in `ignores`.

## Caching Mechanisms

Each `ConfigArray` aggressively caches configuration objects to avoid unnecessary work. This caching occurs in two ways:

1. **File-based Caching.** For each filename that is passed into a method, the resulting config is cached against that filename so you're always guaranteed to get the same object returned from `getConfig()` whenever you pass the same filename in.
2. **Index-based Caching.** Whenever a config is calculated, the config elements that were used to create the config are also cached. So if a given filename matches elements 1, 5, and 7, the resulting config is cached with a key of `1,5,7`. That way, if another file is passed that matches the same config elements, the result is already known and doesn't have to be recalculated. That means two files that match all the same elements will return the same config from `getConfig()`.

## Acknowledgements

The design of this project was influenced by feedback on the ESLint RFC, and incorporates ideas from:

* Teddy Katz (@not-an-aardvark)
* Toru Nagashima (@mysticatea)
* Kai Cataldo (@kaicataldo)

## License

Apache 2.0
# Changelog

## [1.0.1](https://github.com/humanwhocodes/module-importer/compare/v1.0.0...v1.0.1) (2022-08-18)


### Bug Fixes

* Ensure CommonJS mode works correctly. ([cf54a0b](https://github.com/humanwhocodes/module-importer/commit/cf54a0b998085066fbe1776dd0b4cacd808cc192)), closes [#6](https://github.com/humanwhocodes/module-importer/issues/6)

## 1.0.0 (2022-08-17)


### Features

* Implement ModuleImporter ([3ce4e82](https://www.github.com/humanwhocodes/module-importer/commit/3ce4e820c30c114e787bfed00a0966ac4772f563))
# ModuleImporter

by [Nicholas C. Zakas](https://humanwhocodes.com)

If you find this useful, please consider supporting my work with a [donation](https://humanwhocodes.com/donate).

## Description

A utility for seamlessly importing modules in Node.js regardless if they are CommonJS or ESM format. Under the hood, this uses `import()` and relies on Node.js's CommonJS compatibility to work correctly. This ensures that the correct locations and formats are used for CommonJS so you can call one method and not worry about any compatibility issues.

The problem with the default `import()` is that it always resolves relative to the file location in which it is called. If you want to resolve from a different location, you need to jump through a few hoops to achieve that. This package makes it easy to both resolve and import modules from any directory.

## Usage

### Node.js

Install using [npm][npm] or [yarn][yarn]:

```
npm install @humanwhocodes/module-importer

# or

yarn add @humanwhocodes/module-importer
```

Import into your Node.js project:

```js
// CommonJS
const { ModuleImporter } = require("@humanwhocodes/module-importer");

// ESM
import { ModuleImporter } from "@humanwhocodes/module-importer";
```

### Bun

Install using this command:

```
bun add @humanwhocodes/module-importer
```

Import into your Bun project:

```js
import { ModuleImporter } from "@humanwhocodes/module-importer";
```

## API

After importing, create a new instance of `ModuleImporter` to start emitting events:

```js
// cwd can be omitted to use process.cwd()
const importer = new ModuleImporter(cwd);

// you can resolve the location of any package
const location = importer.resolve("./some-file.cjs");

// you can also import directly
const module = importer.import("./some-file.cjs");
```

For both `resolve()` and `import()`, you can pass in package names and filenames.

## Developer Setup

1. Fork the repository
2. Clone your fork
3. Run `npm install` to setup dependencies
4. Run `npm test` to run tests

## License

Apache 2.0

[npm]: https://npmjs.com/
[yarn]: https://yarnpkg.com/
# Changelog

## [2.0.3](https://github.com/humanwhocodes/object-schema/compare/v2.0.2...v2.0.3) (2024-04-01)


### Bug Fixes

* Ensure test files are not including in package ([6eeb32c](https://github.com/humanwhocodes/object-schema/commit/6eeb32cc76a3e37d76b2990bd603d72061c816e0)), closes [#19](https://github.com/humanwhocodes/object-schema/issues/19)

## [2.0.2](https://github.com/humanwhocodes/object-schema/compare/v2.0.1...v2.0.2) (2024-01-10)


### Bug Fixes

* WrapperError should be an actual error ([2523f01](https://github.com/humanwhocodes/object-schema/commit/2523f014168167e5a40bb63e0cc03231b2c0f1bf))

## [2.0.1](https://github.com/humanwhocodes/object-schema/compare/v2.0.0...v2.0.1) (2023-10-20)


### Bug Fixes

* Custom properties should be available on thrown errors ([6ca80b0](https://github.com/humanwhocodes/object-schema/commit/6ca80b001a4ffb678b9b5544fc53322117374376))

## [2.0.0](https://github.com/humanwhocodes/object-schema/compare/v1.2.1...v2.0.0) (2023-10-18)


### ⚠ BREAKING CHANGES

* Throw custom errors instead of generics.

### Features

* Throw custom errors instead of generics. ([c6c01d7](https://github.com/humanwhocodes/object-schema/commit/c6c01d71eb354bf7b1fb3e883c40f7bd9b61647c))

### [1.2.1](https://www.github.com/humanwhocodes/object-schema/compare/v1.2.0...v1.2.1) (2021-11-02)


### Bug Fixes

* Never return original object from individual config ([5463c5c](https://www.github.com/humanwhocodes/object-schema/commit/5463c5c6d2cb35a7b7948dffc37c899a41d1775f))
# JavaScript ObjectSchema Package

by [Nicholas C. Zakas](https://humanwhocodes.com)

If you find this useful, please consider supporting my work with a [donation](https://humanwhocodes.com/donate).

## Overview

A JavaScript object merge/validation utility where you can define a different merge and validation strategy for each key. This is helpful when you need to validate complex data structures and then merge them in a way that is more complex than `Object.assign()`.

## Installation

You can install using either npm:

```
npm install @humanwhocodes/object-schema
```

Or Yarn:

```
yarn add @humanwhocodes/object-schema
```

## Usage

Use CommonJS to get access to the `ObjectSchema` constructor:

```js
const { ObjectSchema } = require("@humanwhocodes/object-schema");

const schema = new ObjectSchema({

    // define a definition for the "downloads" key
    downloads: {
        required: true,
        merge(value1, value2) {
            return value1 + value2;
        },
        validate(value) {
            if (typeof value !== "number") {
                throw new Error("Expected downloads to be a number.");
            }
        }
    },

    // define a strategy for the "versions" key
    version: {
        required: true,
        merge(value1, value2) {
            return value1.concat(value2);
        },
        validate(value) {
            if (!Array.isArray(value)) {
                throw new Error("Expected versions to be an array.");
            }
        }
    }
});

const record1 = {
    downloads: 25,
    versions: [
        "v1.0.0",
        "v1.1.0",
        "v1.2.0"
    ]
};

const record2 = {
    downloads: 125,
    versions: [
        "v2.0.0",
        "v2.1.0",
        "v3.0.0"
    ]
};

// make sure the records are valid
schema.validate(record1);
schema.validate(record2);

// merge together (schema.merge() accepts any number of objects)
const result = schema.merge(record1, record2);

// result looks like this:

const result = {
    downloads: 75,
    versions: [
        "v1.0.0",
        "v1.1.0",
        "v1.2.0",
        "v2.0.0",
        "v2.1.0",
        "v3.0.0"
    ]
};
```

## Tips and Tricks

### Named merge strategies

Instead of specifying a `merge()` method, you can specify one of the following strings to use a default merge strategy:

* `"assign"` - use `Object.assign()` to merge the two values into one object.
* `"overwrite"` - the second value always replaces the first.
* `"replace"` - the second value replaces the first if the second is not `undefined`.

For example:

```js
const schema = new ObjectSchema({
    name: {
        merge: "replace",
        validate() {}
    }
});
```

### Named validation strategies

Instead of specifying a `validate()` method, you can specify one of the following strings to use a default validation strategy:

* `"array"` - value must be an array.
* `"boolean"` - value must be a boolean.
* `"number"` - value must be a number.
* `"object"` - value must be an object.
* `"object?"` - value must be an object or null.
* `"string"` - value must be a string.
* `"string!"` - value must be a non-empty string.

For example:

```js
const schema = new ObjectSchema({
    name: {
        merge: "replace",
        validate: "string"
    }
});
```

### Subschemas

If you are defining a key that is, itself, an object, you can simplify the process by using a subschema. Instead of defining `merge()` and `validate()`, assign a `schema` key that contains a schema definition, like this:

```js
const schema = new ObjectSchema({
    name: {
        schema: {
            first: {
                merge: "replace",
                validate: "string"
            },
            last: {
                merge: "replace",
                validate: "string"
            }
        }
    }
});

schema.validate({
    name: {
        first: "n",
        last: "z"
    }
});
```

### Remove Keys During Merge

If the merge strategy for a key returns `undefined`, then the key will not appear in the final object. For example:

```js
const schema = new ObjectSchema({
    date: {
        merge() {
            return undefined;
        },
        validate(value) {
            Date.parse(value);  // throws an error when invalid
        }
    }
});

const object1 = { date: "5/5/2005" };
const object2 = { date: "6/6/2006" };

const result = schema.merge(object1, object2);

console.log("date" in result);  // false
```

### Requiring Another Key Be Present

If you'd like the presence of one key to require the presence of another key, you can use the `requires` property to specify an array of other properties that any key requires. For example:

```js
const schema = new ObjectSchema();

const schema = new ObjectSchema({
    date: {
        merge() {
            return undefined;
        },
        validate(value) {
            Date.parse(value);  // throws an error when invalid
        }
    },
    time: {
        requires: ["date"],
        merge(first, second) {
            return second;
        },
        validate(value) {
            // ...
        }
    }
});

// throws error: Key "time" requires keys "date"
schema.validate({
    time: "13:45"
});
```

In this example, even though `date` is an optional key, it is required to be present whenever `time` is present.

## License

BSD 3-Clause
# is-path-inside

> Check if a path is inside another path


## Install

```
$ npm install is-path-inside
```


## Usage

```js
const isPathInside = require('is-path-inside');

isPathInside('a/b/c', 'a/b');
//=> true

isPathInside('a/b/c', 'x/y');
//=> false

isPathInside('a/b/c', 'a/b/c');
//=> false

isPathInside('/Users/sindresorhus/dev/unicorn', '/Users/sindresorhus');
//=> true
```


## API

### isPathInside(childPath, parentPath)

Note that relative paths are resolved against `process.cwd()` to make them absolute.

**Important:** This package is meant for use with path manipulation. It does not check if the paths exist nor does it resolve symlinks. You should not use this as a security mechanism to guard against access to certain places on the file system.

#### childPath

Type: `string`

The path that should be inside `parentPath`.

#### parentPath

Type: `string`

The path that should contain `childPath`.


---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-is-path-inside?utm_source=npm-is-path-inside&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# run-parallel [![travis][travis-image]][travis-url] [![npm][npm-image]][npm-url] [![downloads][downloads-image]][downloads-url] [![javascript style guide][standard-image]][standard-url]

[travis-image]: https://img.shields.io/travis/feross/run-parallel/master.svg
[travis-url]: https://travis-ci.org/feross/run-parallel
[npm-image]: https://img.shields.io/npm/v/run-parallel.svg
[npm-url]: https://npmjs.org/package/run-parallel
[downloads-image]: https://img.shields.io/npm/dm/run-parallel.svg
[downloads-url]: https://npmjs.org/package/run-parallel
[standard-image]: https://img.shields.io/badge/code_style-standard-brightgreen.svg
[standard-url]: https://standardjs.com

### Run an array of functions in parallel

![parallel](https://raw.githubusercontent.com/feross/run-parallel/master/img.png) [![Sauce Test Status](https://saucelabs.com/browser-matrix/run-parallel.svg)](https://saucelabs.com/u/run-parallel)

### install

```
npm install run-parallel
```

### usage

#### parallel(tasks, [callback])

Run the `tasks` array of functions in parallel, without waiting until the previous
function has completed. If any of the functions pass an error to its callback, the main
`callback` is immediately called with the value of the error. Once the `tasks` have
completed, the results are passed to the final `callback` as an array.

It is also possible to use an object instead of an array. Each property will be run as a
function and the results will be passed to the final `callback` as an object instead of
an array. This can be a more readable way of handling the results.

##### arguments

- `tasks` - An array or object containing functions to run. Each function is passed a
`callback(err, result)` which it must call on completion with an error `err` (which can
be `null`) and an optional `result` value.
- `callback(err, results)` - An optional callback to run once all the functions have
completed. This function gets a results array (or object) containing all the result
arguments passed to the task callbacks.

##### example

```js
var parallel = require('run-parallel')

parallel([
  function (callback) {
    setTimeout(function () {
      callback(null, 'one')
    }, 200)
  },
  function (callback) {
    setTimeout(function () {
      callback(null, 'two')
    }, 100)
  }
],
// optional callback
function (err, results) {
  // the results array will equal ['one','two'] even though
  // the second function had a shorter timeout.
})
```

This module is basically equavalent to
[`async.parallel`](https://github.com/caolan/async#paralleltasks-callback), but it's
handy to just have the one function you need instead of the kitchen sink. Modularity!
Especially handy if you're serving to the browser and need to reduce your javascript
bundle size.

Works great in the browser with [browserify](http://browserify.org/)!

### see also

- [run-auto](https://github.com/feross/run-auto)
- [run-parallel-limit](https://github.com/feross/run-parallel-limit)
- [run-series](https://github.com/feross/run-series)
- [run-waterfall](https://github.com/feross/run-waterfall)

### license

MIT. Copyright (c) [Feross Aboukhadijeh](http://feross.org).
# p-limit

> Run multiple promise-returning & async functions with limited concurrency

## Install

```
$ npm install p-limit
```

## Usage

```js
const pLimit = require('p-limit');

const limit = pLimit(1);

const input = [
	limit(() => fetchSomething('foo')),
	limit(() => fetchSomething('bar')),
	limit(() => doSomething())
];

(async () => {
	// Only one promise is run at once
	const result = await Promise.all(input);
	console.log(result);
})();
```

## API

### pLimit(concurrency)

Returns a `limit` function.

#### concurrency

Type: `number`\
Minimum: `1`\
Default: `Infinity`

Concurrency limit.

### limit(fn, ...args)

Returns the promise returned by calling `fn(...args)`.

#### fn

Type: `Function`

Promise-returning/async function.

#### args

Any arguments to pass through to `fn`.

Support for passing arguments on to the `fn` is provided in order to be able to avoid creating unnecessary closures. You probably don't need this optimization unless you're pushing a *lot* of functions.

### limit.activeCount

The number of promises that are currently running.

### limit.pendingCount

The number of promises that are waiting to run (i.e. their internal `fn` was not called yet).

### limit.clearQueue()

Discard pending promises that are waiting to run.

This might be useful if you want to teardown the queue at the end of your program's lifecycle or discard any function calls referencing an intermediary state of your app.

Note: This does not cancel promises that are already running.

## FAQ

### How is this different from the [`p-queue`](https://github.com/sindresorhus/p-queue) package?

This package is only about limiting the number of concurrent executions, while `p-queue` is a fully featured queue implementation with lots of different options, introspection, and ability to pause the queue.

## Related

- [p-queue](https://github.com/sindresorhus/p-queue) - Promise queue with concurrency control
- [p-throttle](https://github.com/sindresorhus/p-throttle) - Throttle promise-returning & async functions
- [p-debounce](https://github.com/sindresorhus/p-debounce) - Debounce promise-returning & async functions
- [p-all](https://github.com/sindresorhus/p-all) - Run promise-returning & async functions concurrently with optional limited concurrency
- [More…](https://github.com/sindresorhus/promise-fun)

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-p-limit?utm_source=npm-p-limit&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# json-schema-traverse
Traverse JSON Schema passing each schema object to callback

[![Build Status](https://travis-ci.org/epoberezkin/json-schema-traverse.svg?branch=master)](https://travis-ci.org/epoberezkin/json-schema-traverse)
[![npm version](https://badge.fury.io/js/json-schema-traverse.svg)](https://www.npmjs.com/package/json-schema-traverse)
[![Coverage Status](https://coveralls.io/repos/github/epoberezkin/json-schema-traverse/badge.svg?branch=master)](https://coveralls.io/github/epoberezkin/json-schema-traverse?branch=master)


## Install

```
npm install json-schema-traverse
```


## Usage

```javascript
const traverse = require('json-schema-traverse');
const schema = {
  properties: {
    foo: {type: 'string'},
    bar: {type: 'integer'}
  }
};

traverse(schema, {cb});
// cb is called 3 times with:
// 1. root schema
// 2. {type: 'string'}
// 3. {type: 'integer'}

// Or:

traverse(schema, {cb: {pre, post}});
// pre is called 3 times with:
// 1. root schema
// 2. {type: 'string'}
// 3. {type: 'integer'}
//
// post is called 3 times with:
// 1. {type: 'string'}
// 2. {type: 'integer'}
// 3. root schema

```

Callback function `cb` is called for each schema object (not including draft-06 boolean schemas), including the root schema, in pre-order traversal. Schema references ($ref) are not resolved, they are passed as is.  Alternatively, you can pass a `{pre, post}` object as `cb`, and then `pre` will be called before traversing child elements, and `post` will be called after all child elements have been traversed.

Callback is passed these parameters:

- _schema_: the current schema object
- _JSON pointer_: from the root schema to the current schema object
- _root schema_: the schema passed to `traverse` object
- _parent JSON pointer_: from the root schema to the parent schema object (see below)
- _parent keyword_: the keyword inside which this schema appears (e.g. `properties`, `anyOf`, etc.)
- _parent schema_: not necessarily parent object/array; in the example above the parent schema for `{type: 'string'}` is the root schema
- _index/property_: index or property name in the array/object containing multiple schemas; in the example above for `{type: 'string'}` the property name is `'foo'`


## Traverse objects in all unknown keywords

```javascript
const traverse = require('json-schema-traverse');
const schema = {
  mySchema: {
    minimum: 1,
    maximum: 2
  }
};

traverse(schema, {allKeys: true, cb});
// cb is called 2 times with:
// 1. root schema
// 2. mySchema
```

Without option `allKeys: true` callback will be called only with root schema.


## License

[MIT](https://github.com/epoberezkin/json-schema-traverse/blob/master/LICENSE)

[Build]:    http://img.shields.io/travis/litejs/natural-compare-lite.png
[Coverage]: http://img.shields.io/coveralls/litejs/natural-compare-lite.png
[1]: https://travis-ci.org/litejs/natural-compare-lite
[2]: https://coveralls.io/r/litejs/natural-compare-lite
[npm package]: https://npmjs.org/package/natural-compare-lite
[GitHub repo]: https://github.com/litejs/natural-compare-lite



    @version    1.4.0
    @date       2015-10-26
    @stability  3 - Stable


Natural Compare &ndash; [![Build][]][1] [![Coverage][]][2]
===============

Compare strings containing a mix of letters and numbers
in the way a human being would in sort order.
This is described as a "natural ordering".

```text
Standard sorting:   Natural order sorting:
    img1.png            img1.png
    img10.png           img2.png
    img12.png           img10.png
    img2.png            img12.png
```

String.naturalCompare returns a number indicating
whether a reference string comes before or after or is the same
as the given string in sort order.
Use it with builtin sort() function.



### Installation

- In browser

```html
<script src=min.natural-compare.js></script>
```

- In node.js: `npm install natural-compare-lite`

```javascript
require("natural-compare-lite")
```

### Usage

```javascript
// Simple case sensitive example
var a = ["z1.doc", "z10.doc", "z17.doc", "z2.doc", "z23.doc", "z3.doc"];
a.sort(String.naturalCompare);
// ["z1.doc", "z2.doc", "z3.doc", "z10.doc", "z17.doc", "z23.doc"]

// Use wrapper function for case insensitivity
a.sort(function(a, b){
  return String.naturalCompare(a.toLowerCase(), b.toLowerCase());
})

// In most cases we want to sort an array of objects
var a = [ {"street":"350 5th Ave", "room":"A-1021"}
        , {"street":"350 5th Ave", "room":"A-21046-b"} ];

// sort by street, then by room
a.sort(function(a, b){
  return String.naturalCompare(a.street, b.street) || String.naturalCompare(a.room, b.room);
})

// When text transformation is needed (eg toLowerCase()),
// it is best for performance to keep
// transformed key in that object.
// There are no need to do text transformation
// on each comparision when sorting.
var a = [ {"make":"Audi", "model":"A6"}
        , {"make":"Kia",  "model":"Rio"} ];

// sort by make, then by model
a.map(function(car){
  car.sort_key = (car.make + " " + car.model).toLowerCase();
})
a.sort(function(a, b){
  return String.naturalCompare(a.sort_key, b.sort_key);
})
```

- Works well with dates in ISO format eg "Rev 2012-07-26.doc".


### Custom alphabet

It is possible to configure a custom alphabet
to achieve a desired order.

```javascript
// Estonian alphabet
String.alphabet = "ABDEFGHIJKLMNOPRSŠZŽTUVÕÄÖÜXYabdefghijklmnoprsšzžtuvõäöüxy"
["t", "z", "x", "õ"].sort(String.naturalCompare)
// ["z", "t", "õ", "x"]

// Russian alphabet
String.alphabet = "АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя"
["Ё", "А", "Б"].sort(String.naturalCompare)
// ["А", "Б", "Ё"]
```


External links
--------------

-   [GitHub repo][https://github.com/litejs/natural-compare-lite]
-   [jsperf test](http://jsperf.com/natural-sort-2/12)


Licence
-------

Copyright (c) 2012-2015 Lauri Rooden &lt;lauri@rooden.ee&gt;  
[The MIT License](http://lauri.rooden.ee/mit-license.txt)


## 6.4.1 (2024-02-19)

### Bug fixes

Fix an issue that caused widgets at the end of a mark decoration to be rendered in their own separate mark DOM element.

## 6.4.0 (2023-12-28)

### Bug fixes

When multiple ranges in a single range set overlap, put the smaller ones inside the bigger ones, so that overlapping decorations don't break up each other's elements when coming from the same source.

### New features

Selection and selection range `eq` methods now support an optional argument that makes them also compare by cursor associativity.

The `RangeSet.join` function can be used to join multiple range sets together.

## 6.3.3 (2023-12-06)

### Bug fixes

Fix an issue where `Text.slice` and `Text.replace` could return objects with incorrect `length` when the given `from`/`to` values were out of range for the text.

## 6.3.2 (2023-11-27)

### Bug fixes

Make sure transactions cannot add multiple selections when `allowMultipleSelections` is false.

Fix a bug that caused `Text.iterLines` to not return empty lines at the end of the iterated ranges.

## 6.3.1 (2023-10-18)

### Bug fixes

Give the tag property on `FacetReader` the type of the output type parameter to force TypeScript to infer the proper type when converting from `Facet` to `FacetReader`.

## 6.3.0 (2023-10-12)

### New features

The new `FacetReader` type provides a way to export a read-only handle to a `Facet`.

## 6.2.1 (2023-05-23)

### Bug fixes

Fix an issue that could cause `RangeSet.compare` to miss changes in the set of active ranges around a point range.

## 6.2.0 (2022-12-26)

### New features

`EditorSelection.range` now accepts an optional 4th argument to specify the bidi level of the range's head position.

## 6.1.4 (2022-11-15)

### Bug fixes

Fix a bug that caused the `openStart` value passed to span iterators to be incorrect around widgets in some circumstances.

## 6.1.3 (2022-11-10)

### Bug fixes

Avoid unnecessary calls to computed facet getters when a state is reconfigured but no dependencies of the computed facet change.

Fix an infinite loop in `RangeSet.eq` when the `to` parameter isn't given.

## 6.1.2 (2022-09-21)

### Bug fixes

Fix an issue where, when multiple transaction extenders took effect, only the highest-precedence one was actually included in the transaction.

## 6.1.1 (2022-08-03)

### Bug fixes

Fix a bug in range set span iteration that would cause decorations to be inappropriately split in some situations.

## 6.1.0 (2022-06-30)

### Bug fixes

Refine change mapping to preserve insertions made by concurrent changes.

### New features

The `enables` option to `Facet.define` may now take a function, which will be called with the facet value to create the extensions.

## 6.0.1 (2022-06-17)

### Bug fixes

Fix a problem that caused effects' `map` methods to be called with an incorrect change set when filtering changes.

## 6.0.0 (2022-06-08)

### Breaking changes

Update dependencies to 6.0.0

## 0.20.1 (2022-06-02)

### New features

`EditorView.phrase` now accepts additional arguments, which it will interpolate into the phrase in the place of `$` markers.

## 0.20.0 (2022-04-20)

### Breaking changes

The deprecated precedence names `fallback`, `extend`, and `override` were removed from the library.

### Bug fixes

Fix a bug where, if an extension value occurs multiple times, its lowest, rather than highest precedence is used.

Fix an issue where facets with computed inputs would unneccesarily have their outputs recreated on state reconfiguration.

Fix a bug in the order in which new values for state fields and facets were computed, which could cause dynamic facets to hold the wrong value in some situations.

### New features

The exports from @codemirror/rangeset now live in this package.

The exports from @codemirror/text now live in this package.

## 0.19.9 (2022-02-16)

### Bug fixes

Mapping a non-empty selection range now always puts any newly inserted text on the sides of the range outside of the mapped version.

## 0.19.8 (2022-02-15)

### Bug fixes

Fix a bug where facet values with computed inputs could incorrectly retain their old value on reconfiguration.

## 0.19.7 (2022-02-11)

### Bug fixes

Avoid recomputing facets on state reconfiguration if that facet's inputs stayed precisely the same.

Selection ranges created with `EditorSelection.range` will now have an assoc pointing at their anchor, when non-empty.

## 0.19.6 (2021-11-19)

### Bug fixes

Fix a bug that caused facet compare functions to be called with an invalid value in some situations.

Fix a bug that caused dynamic facet values to be incorrectly kept unchanged when reconfiguration changed one of their dependencies.

## 0.19.5 (2021-11-10)

### Bug fixes

Fix a bug that would cause dynamic facet values influenced by a state reconfiguration to not properly recompute.

## 0.19.4 (2021-11-05)

### Bug fixes

When reconfiguring a state, effects from the reconfiguring transaction can now be seen by newly added state fields.

## 0.19.3 (2021-11-03)

### New features

The precedence levels (under `Prec`) now have more generic names, because their 'meaningful' names were entirely inappropriate in many situations.

## 0.19.2 (2021-09-13)

### New features

The editor state now has a `readOnly` property with a matching facet to control its value.

## 0.19.1 (2021-08-15)

### Bug fixes

Fix a bug where `wordAt` never returned a useful result.

## 0.19.0 (2021-08-11)

### Breaking changes

User event strings now work differently—the events emitted by the core packages follow a different system, and hierarchical event tags can be created by separating the words with dots.

### New features

`languageDataAt` now takes an optional `side` argument to specificy which side of the position you're interested in.

It is now possible to add a user event annotation with a direct `userEvent` property on a transaction spec.

Transactions now have an `isUserEvent` method that can be used to check if it is (a subtype of) some user event type.

## 0.18.7 (2021-05-04)

### Bug fixes

Fix an issue where state fields might be initialized with a state that they aren't actually part of during reconfiguration.

## 0.18.6 (2021-04-12)

### New features

The new `EditorState.wordAt` method finds the word at a given position.

## 0.18.5 (2021-04-08)

### Bug fixes

Fix an issue in the compiled output that would break the code when minified with terser.

## 0.18.4 (2021-04-06)

### New features

The new `Transaction.remote` annotation can be used to mark and recognize transactions created by other actors.

## 0.18.3 (2021-03-23)

### New features

The `ChangeDesc` class now has `toJSON` and `fromJSON` methods.

## 0.18.2 (2021-03-14)

### Bug fixes

Fix unintended ES2020 output (the package contains ES6 code again).

## 0.18.1 (2021-03-10)

### New features

The new `Compartment.get` method can be used to get the content of a compartment in a given state.

## 0.18.0 (2021-03-03)

### Breaking changes

`tagExtension` and the `reconfigure` transaction spec property have been replaced with the concept of configuration compartments and reconfiguration effects (see `Compartment`, `StateEffect.reconfigure`, and `StateEffect.appendConfig`).

## 0.17.2 (2021-02-19)

### New features

`EditorSelection.map` and `SelectionRange.map` now take an optional second argument to indicate which direction to map to.

## 0.17.1 (2021-01-06)

### New features

The package now also exports a CommonJS module.

## 0.17.0 (2020-12-29)

### Breaking changes

First numbered release.

# @codemirror/state [![NPM version](https://img.shields.io/npm/v/@codemirror/state.svg)](https://www.npmjs.org/package/@codemirror/state)

[ [**WEBSITE**](https://codemirror.net/) | [**DOCS**](https://codemirror.net/docs/ref/#state) | [**ISSUES**](https://github.com/codemirror/dev/issues) | [**FORUM**](https://discuss.codemirror.net/c/next/) | [**CHANGELOG**](https://github.com/codemirror/state/blob/main/CHANGELOG.md) ]

This package implements the editor state data structures for the
[CodeMirror](https://codemirror.net/) code editor.

The [project page](https://codemirror.net/) has more information, a
number of [examples](https://codemirror.net/examples/) and the
[documentation](https://codemirror.net/docs/).

This code is released under an
[MIT license](https://github.com/codemirror/state/tree/main/LICENSE).

We aim to be an inclusive, welcoming community. To make that explicit,
we have a [code of
conduct](http://contributor-covenant.org/version/1/1/0/) that applies
to communication around the project.
## 6.26.3 (2024-04-12)

### Bug fixes

Fix an issue where dispatching an update to an editor before it measured itself for the first time could cause the scroll position to incorrectly move.

Fix a crash when multiple tooltips with arrows are shown.

## 6.26.2 (2024-04-09)

### Bug fixes

Improve behavior of `scrollPastEnd` in a scaled editor.

When available, use `Selection.getComposedRanges` on Safari to find the selection inside a shadow DOM.

Remove the workaround that avoided inappropriate styling on composed text after a decoration again, since it breaks the stock Android virtual keyboard.

## 6.26.1 (2024-03-28)

### Bug fixes

Fix the editor getting stuck in composition when Safari fails to fire a compositionend event for a dead key composition.

Fix an issue where, with IME systems that kept the cursor at the start of the composed text, the editor misidentified the target node and disrupted composition.

Fix a bug where in a line-wrapped editor, with some content, the initial scroll position would be off from the top of the document.

## 6.26.0 (2024-03-14)

### Bug fixes

Avoid the editor getting confused when iOS autocorrects on pressing Enter and does the correction and the break insertion in two different events.

Fix the pasting of copied URIs in iOS.

Fix a bug where a scaled editor could keep performing unnecessary updates due to tiny differences in geometry values returned by the browser.

Fix a bug where, on iOS with a physical keyboard, the modifiers for some keys weren't being passed to the keymaps.

Work around the fact that Mobile Safari makes DOM changes before firing a key event when typing ctrl-d on an external keyboard.

Fix an issue where some commands didn't properly scroll the cursor into view on Mobile Safari.

Re-measure the document when print settings are changed on Chrome.

### New features

The `EditorView.scrollHandler` facet can be used to override or extend the behavior of the editor when things are scrolled into view.

## 6.25.1 (2024-03-06)

### Bug fixes

Fix accidental non-optional field in layer config objects.

## 6.25.0 (2024-03-04)

### Bug fixes

Properly recognize Android GBoard enter presses that strip a space at the end of the line as enter.

Fix a bug that caused the gutter to have the wrong height when the editor was scaled after construction.

When starting a composition after a non-inclusive mark decoration, temporarily insert a widget that prevents the composed text from inheriting that mark's styles.

Make sure the selection is repositioned when a transaction changes decorations without changing the document.

### New features

View plugins can now provide a `docViewUpdate` method that is called whenever the document view is updated.

Layers now take a `updateOnDocUpdate` option that controls whether they are automatically updated when the document view changes.

## 6.24.1 (2024-02-19)

### Bug fixes

Fix a crash that happens when hover tooltips are active during changes, introduced in 6.24.0.

## 6.24.0 (2024-02-09)

### Bug fixes

Fix an issue that broke context-menu select-all on Chrome when the viewport didn't cover the whole document.

Make sure tooltips are ordered by extension precedence in the DOM.

### New features

Hover tooltip sources may now return multiple tooltips.

## 6.23.1 (2024-01-24)

### Bug fixes

Fix a bug that caused `Tooltip.above` to not take effect for tooltips that were already present when the tooltip plugin is initialized.

Automatically reposition tooltips when their size changes.

## 6.23.0 (2023-12-28)

### Bug fixes

Work around odd iOS Safari behavior when doing select all.

Fix a composition interruption when an widget is inserted next to the cursor.

Fix a crash in bidirectional cursor motion.

Simplify visual motion through bidirectional text, fix several corner cases where it would work badly.

Fix a bug that broke some bidi isolates not on the first line of the document.

### New features

`EditorView.bidiIsolatedRanges` now supports automatically determining the direction of the range if not provided by the decoration.

`EditorView.visualLineSide` can be used to find the visual end or start of a line with bidirectional text.

The new `EditorView.outerDecorations` facet can be used to provide decorations that should always be at the bottom of the precedence stack.

## 6.22.3 (2023-12-13)

### Bug fixes

Fix a bug that could cause tooltips to be unnecessarily be positioned absolutely.

Make sure that, when an editor creates tooltips immediately on initialization, the editor is attached to the document when their `mount` callback is called.

## 6.22.2 (2023-12-08)

### Bug fixes

Fix an issue in the bidirectional motion that could cause the cursor to get stuck in a loop when a zero-width non-joiner char was placed on a direction boundary.

Fix a bug that corrupts the editor's internal view tree data structure on some types of edits, putting the editor in a broken state.

## 6.22.1 (2023-11-27)

### Bug fixes

Call widget `destroy` methods when the entire editor is destroyed or reset.

Work around an issue on Safari on macOS Sonoma that made the native cursor visible even when `drawSelection` is enabled.

Fix an issue where, on some browsers, the screenreader announced text ended up in the printed document.

Fix a bug where a hover tooltip could stick around even though the pointer was no longer on the editor when it was moved out over the tooltip.

Fix an issue where hover tooltips could close when moving the mouse onto them due to mouse position rounding issues.

## 6.22.0 (2023-11-03)

### Bug fixes

Exceptions raised by update listeners are now routed to the configured exception sink, if any.

Fix an issue where passing large scroll margins to `scrollIntoView` would cause the measure loop to fail to terminate.

Widgets that are draggable (and allow drag events through in their `ignoreEvent` implementation) can now use the editor's built-in drag/drop behavior.

### New features

The new `scrollTo` option to `EditorView` allows an initial scroll position to be provided.

The new `EditorView.scrollSnapshot` method returns an effect that can be used to reset to a previous scroll position.

## 6.21.4 (2023-10-24)

### Bug fixes

Support the `offset`, `getCoords`, `overlap`, and `resize` properties on hover tooltips, as long as they aren't given conflicting values when there are multiple active hover tooltips.

Fix a bug that caused tooltips in the default configuration to be positioned incorrectly on Chrome when the editor was transformed.

## 6.21.3 (2023-10-06)

### Bug fixes

Fix an issue that caused `coordsForChar` to return the wrong rectangle for characters after a line wrap in Safari.

Make the context menu work when clicking below the content in a fixed-height editor.

Tooltips that have been put below/above their target position because there is no room on their default side now stay there on further updates.

## 6.21.2 (2023-10-02)

### Bug fixes

Fix a regression that broke dragging text from inside the editor.

## 6.21.1 (2023-10-02)

### Bug fixes

Fix a bug that could corrupt the DOM view for specific changes involving newlines and mark decorations.

## 6.21.0 (2023-09-29)

### Bug fixes

Fix a bug that could cause zero-length widgets at the start of a line to be left in the view even after they were removed.

### New features

`RectangleMarker`'s dimension properties are now public.

## 6.20.2 (2023-09-25)

### Bug fixes

Fix an issue in the way the DOM selection is being read that could break backspacing of widgets on Android.

Fix a bug where the editor could incorrectly computate its transform scale when it was small.

## 6.20.1 (2023-09-22)

### Bug fixes

Fix a crash in plugin event handlers after dynamic reconfiguration.

Fix an issue where, on Chrome, tooltips would no longer use fixed positioning.

## 6.20.0 (2023-09-20)

### Bug fixes

Fix an issue that caused `repositionTooltips` to crash when it was called on an editor without tooltips.

Fix an issue that caused the tooltip system to leave empty nodes in the DOM when an editor using the `parent` option to `tooltips` is destroyed.

Fix a bug that regression mouse interaction with the area of a fixed-size editor that isn't covered by the content.

Fix some issues with the way `moveVertically` behaved for positions on line wrap points.

Fix a bug that could cause the document DOM to be incorrectly updated on some types of viewport changes.

### New features

The new `getDrawSelectionConfig` function returns the `drawSelection` configuration for a given state.

## 6.19.0 (2023-09-14)

### Bug fixes

Make sure the drop cursor is properly cleaned up even when another extension handles the drop event.

Fix a crash related to non-inclusive replacing block decorations.

### New features

The new `EditorView.domEventObservers` (and the corresponding option to view plugins) allows you to register functions that are always called for an event, regardless of whether other handlers handled it.

## 6.18.1 (2023-09-11)

### Bug fixes

Fix an issue where the editor duplicated text when the browser moved content into the focused text node on composition.

Make sure `widgetMarker` is called for gutters on lines covered by a block replace decoration.

Fix an issue where the cursor could be shown in a position that doesn't allow a cursor when the selection is in a block widget.

## 6.18.0 (2023-09-05)

### New features

The new `EditorView.scaleX` and `scaleY` properties return the CSS-transformed scale of the editor (or 1 when not scaled).

The editor now supports being scaled with CSS.

## 6.17.1 (2023-08-31)

### Bug fixes

Don't close the hover tooltip when the pointer moves over empty space caused by line breaks within the hovered range.

Fix a bug where on Chrome Android, if a virtual keyboard was slow to apply a change, the editor could end up dropping it.

Work around an issue where line-wise copy/cut didn't work in Firefox because the browser wasn't firing those events when nothing was selected.

Fix a crash triggered by the way some Android IME systems update the DOM.

Fix a bug that caused replacing a word by an emoji on Chrome Android to be treated as a backspace press.

## 6.17.0 (2023-08-28)

### Bug fixes

Fix a bug that broke hover tooltips when hovering over a widget.

### New features

The new `EditorView.cspNonce` facet can be used to provide a Content Security Policy nonce for the library's generated CSS.

The new `EditorView.bidiIsolatedRanges` can be used to inform the editor about ranges styled as Unicode bidirection isolates, so that it can compute the character order correctly.

`EditorView.dispatch` now also accepts an array of transactions to be applied together in a single view update.

The new `dispatchTransactions` option to `new EditorView` now replaces the old (deprecated but still supported) `dispatch` option in a way that allows multiple transactions to be applied in one update.

Input handlers are now passed an additional argument that they can use to retrieve the default transaction that would be applied for the insertion.

## 6.16.0 (2023-07-31)

### Bug fixes

Fix an issue that made the gutter not stick in place when the editor was in a right-to-left context.

### New features

The new `EditorView.coordsForChar` method returns the client rectangle for a given character in the editor.

## 6.15.3 (2023-07-18)

### Bug fixes

Fix another crash regression for compositions before line breaks.

## 6.15.2 (2023-07-18)

### Bug fixes

Fix the check that made sure compositions are dropped when the selection is moved.

## 6.15.1 (2023-07-18)

### Bug fixes

Fix a regression that could cause the composition content to be drawn incorrectly.

## 6.15.0 (2023-07-17)

### Bug fixes

Fix dragging a selection from inside the current selection on macOS.

Fix an issue that could cause the scroll position to jump wildly

Don't try to scroll fixed-positioned elements into view by scrolling their parent elements.

Fix a bug that caused the cursor to be hidden when showing a placeholder that consisted of the empty string.

Resolve some issues where composition could incorrectly affect nearby replaced content.

### New features

Key bindings can now set a `stopPropagation` field to cause the view to stop the key event propagation when it considers the event handled.

## 6.14.1 (2023-07-06)

### Bug fixes

Fix an issue where scrolling up through line-wrapped text would sometimes cause the scroll position to pop down.

Fix an issue where clicking wouldn't focus the editor on Firefox when it was in an iframe and already the active element of the frame.

Fix a bug that could cause compositions to be disrupted because their surrounding DOM was repurposed for some other piece of content.

Fix a bug where adding content to the editor could inappropriately move the scroll position.

Extend detection of Enter presses on Android to `beforeInput` events with an `"insertLineBreak"` type.

## 6.14.0 (2023-06-23)

### Bug fixes

When dragging text inside the editor, look at the state of Ctrl (or Alt on macOS) at the time of the drop, not the start of drag, to determine whether to move or copy the text.

Fix an issue where having a bunch of padding on lines could cause vertical cursor motion and `posAtCoords` to jump over lines.

### New features

Block widget decorations can now be given an `inlineOrder` option to make them appear in the same ordering as surrounding inline widgets.

## 6.13.2 (2023-06-13)

### Bug fixes

Fix an issue in scroll position stabilization for changes above the visible, where Chrome already does this natively and we ended up compensating twice.

## 6.13.1 (2023-06-12)

### Bug fixes

Fix a bug where the cursor would in some circumstances be drawn on the wrong side of an inline widget.

Fix an issue where `scrollPastEnd` could cause the scroll position of editors that weren't in view to be changed unnecessarily.

## 6.13.0 (2023-06-05)

### Bug fixes

Forbid widget decoration side values bigger than 10000, to prevent them from breaking range ordering invariants.

Fix a bug where differences between widgets' estimated and actual heights could cause the editor to inappropriately move the scroll position.

Avoid another situation in which composition that inserts line breaks could corrupt the editor DOM.

### New features

Inline widgets may now introduce line breaks, if they report this through the `WidgetType.lineBreaks` property.

## 6.12.0 (2023-05-18)

### Bug fixes

Remove an accidentally included `console.log`.

### New features

`EditorViewConfig.dispatch` is now passed the view object as a second argument.

## 6.11.3 (2023-05-17)

### Bug fixes

Make sure pointer selection respects `EditorView.atomicRanges`.

Preserve DOM widgets when their decoration type changes but they otherwise stay in the same place.

Fix a bug in `drawSelection` that could lead to invisible or incorrect selections for a blank line below a block widget.

## 6.11.2 (2023-05-13)

### Bug fixes

Fix a bug where the `crosshairCursor` extension could, when non-native key events were fired, trigger disruptive and needless view updates.

Fix an Android issue where backspacing at the front of a line with widget decorations could replace those decorations with their text content.

Respect scroll margins when scrolling the target of drag-selection into view.

Validate selection offsets reported by the browser, to work around Safari giving us invalid values in some cases.

## 6.11.1 (2023-05-09)

### Bug fixes

Don't preserve the DOM around a composition that spans multiple lines.
## 6.11.0 (2023-05-03)

### New features

Gutters now support a `widgetMarker` option that can be used to add markers next to block widgets.

## 6.10.1 (2023-05-01)

### Bug fixes

Limit cursor height in front of custom placeholder DOM elements.

## 6.10.0 (2023-04-25)

### Bug fixes

Fix a crash in `drawSelection` when a measured position falls on a position that doesn't have corresponding screen coordinates.

Work around unhelpful interaction observer behavior that could cause the editor to not notice it was visible.

Give the cursor next to a line-wrapped placeholder a single-line height.

Make sure drop events below the editable element in a fixed-height editor get handled properly.

### New features

Widget decorations can now define custom `coordsAtPos` methods to control the way the editor computes screen positions at or in the widget.

## 6.9.6 (2023-04-21)

### Bug fixes

Fix an issue where, when escape was pressed followed by a key that the editor handled, followed by tab, the tab would still move focus.

Fix an issue where, in some circumstances, the editor would ignore text changes at the end of a composition.

Allow inline widgets to be updated to a different length via `updateDOM`.

## 6.9.5 (2023-04-17)

### Bug fixes

Avoid disrupting the composition in specific cases where Safari invasively changes the DOM structure in the middle of a composition.

Fix a bug that prevented `destroy` being called on hover tooltips.

Fix a bug where the editor could take focus when content changes required it to restore the DOM selection.

Fix height layout corruption caused by a division by zero.

Make sure styles targeting the editor's focus status are specific enough to not cause them to apply to editors nested inside another focused editor. This will require themes to adjust their selection background styles to match the new specificity.

## 6.9.4 (2023-04-11)

### Bug fixes

Make the editor scroll while dragging a selection near its sides, even if the cursor isn't outside the scrollable element.

Fix a bug that interrupted composition after widgets in some circumstances on Firefox.

Make sure the last change in a composition has its user event set to `input.type.compose`, even if the `compositionend` event fires before the changes are applied.

Make it possible to remove additional selection ranges by clicking on them with ctrl/cmd held, even if they aren't cursors.

Keep widget buffers between widgets and compositions, since removing them confuses IME on macOS Firefox.

Fix a bug where, for DOM changes that put the selection in the middle of the changed range, the editor incorrectly set its selection state.

Fix a bug where `coordsAtPos` could return a coordinates before the line break when querying a line-wrapped position with a positive `side`.

## 6.9.3 (2023-03-21)

### Bug fixes

Work around a Firefox issue that caused `coordsAtPos` to return rectangles with the full line height on empty lines.

Opening a context menu by clicking below the content element but inside the editor now properly shows the browser's menu for editable elements.

Fix an issue that broke composition (especially of Chinese IME) after widget decorations.

Fix an issue that would cause the cursor to jump around during compositions inside nested mark decorations.

## 6.9.2 (2023-03-08)

### Bug fixes

Work around a Firefox CSS bug that caused cursors to stop blinking in a scrolled editor.

Fix an issue in `drawSelection` where the selection extended into the editor's padding.

Fix pasting of links copied from iOS share sheet.

## 6.9.1 (2023-02-17)

### Bug fixes

Improve the way `posAtCoords` picks the side of a widget to return by comparing the coordinates the center of the widget.

Fix an issue where transactions created for the `focusChangeEffect` facet were sometimes not dispatched.

## 6.9.0 (2023-02-15)

### Bug fixes

Fix an issue where inaccurate estimated vertical positions could cause the viewport to not converge in line-wrapped editors.

Don't suppress double-space to period conversion when autocorrect is enabled.

Make sure the measuring code notices when the scaling of the editor is changed, and does a full measure in that case.

### New features

The new `EditorView.focusChangeEffect` facet can be used to dispatch a state effect when the editor is focused or blurred.

## 6.8.1 (2023-02-08)

### Bug fixes

Fix an issue where tooltips that have their height reduced have their height flicker when scrolling or otherwise interacting with the editor.

## 6.8.0 (2023-02-07)

### Bug fixes

Fix a regression that caused clicking on the scrollbar to move the selection.

Fix an issue where focus or blur event handlers that dispatched editor transactions could corrupt the mouse selection state.

Fix a CSS regression that prevented the drop cursor from being positioned properly.

### New features

`WidgetType.updateDOM` is now passed the editor view object.

## 6.7.3 (2023-01-12)

### Bug fixes

Fix a bug in `posAtCoords` that could cause incorrect results for positions to the left of a wrapped line.

## 6.7.2 (2023-01-04)

### Bug fixes

Fix a regression where the cursor didn't restart its blink cycle when moving it with the pointer.

Even without a `key` property, measure request objects that are already scheduled will not be scheduled again by `requestMeasure`.

Fix an issue where keymaps incorrectly interpreted key events that used Ctrl+Alt modifiers to simulate AltGr on Windows.

Fix a bug where line decorations with a different `class` property would be treated as equal.

Fix a bug that caused `drawSelection` to not notice when it was reconfigured.

Fix a crash in the gutter extension caused by sharing of mutable arrays.

Fix a regression that caused touch selection on mobile platforms to not work in an uneditable editor.

Fix a bug where DOM events on the boundary between lines could get assigned to the wrong line.

## 6.7.1 (2022-12-12)

### Bug fixes

Make the editor properly scroll when moving the pointer out of it during drag selection.

Fix a regression where clicking below the content element in an editor with its own height didn't focus the editor.

## 6.7.0 (2022-12-07)

### Bug fixes

Make the editor notice widget height changes to automatically adjust its height information.

Fix an issue where widget buffers could be incorrectly omitted after empty lines.

Fix an issue in content redrawing that could cause `coordsAtPos` to return incorrect results.

### New features

The static `RectangleMarker.forRange` method exposes the logic used by the editor to draw rectangles covering a selection range.

Layers can now provide a `destroy` function to be called when the layer is removed.

The new `highlightWhitespace` extension makes spaces and tabs in the editor visible.

The `highlightTrailingWhitespace` extension can be used to make trailing whitespace stand out.

## 6.6.0 (2022-11-24)

### New features

The `layer` function can now be used to define extensions that draw DOM elements over or below the document text.

Tooltips that are bigger than the available vertical space for them will now have their height set so that they don't stick out of the window. The new `resize` property on `TooltipView` can be used to opt out of this behavior.

## 6.5.1 (2022-11-15)

### Bug fixes

Fix a bug that caused marked unnecessary splitting of mark decoration DOM elements in some cases.

## 6.5.0 (2022-11-14)

### Bug fixes

Fix an issue where key bindings were activated for the wrong key in some situations with non-US keyboards.

### New features

A tooltip's `positioned` callback is now passed the available space for tooltips.

## 6.4.2 (2022-11-10)

### Bug fixes

Typing into a read-only editor no longer moves the cursor.

Fix an issue where hover tooltips were closed when the mouse was moved over them if they had a custom parent element.

Fix an issue where the editor could end up displaying incorrect height measurements (typically after initializing).

## 6.4.1 (2022-11-07)

### Bug fixes

Fix an issue where coordinates next to replaced widgets were returned incorrectly, causing the cursor to be drawn in the wrong place.

Update the `crosshairCursor` state on every mousemove event.

Avoid an issue in the way that the editor enforces cursor associativity that could cause the cursor to get stuck on single-character wrapped lines.

## 6.4.0 (2022-10-18)

### Bug fixes

Avoid an issue where `scrollPastEnd` makes a single-line editor have a vertical scrollbar.

Work around a Chrome bug where it inserts a newline when you press space at the start of a wrapped line.

Align `rectangularSelection`'s behavior with other popular editors by making it create cursors at the end of lines that are too short to touch the rectangle.

Fix an issue where coordinates on mark decoration boundaries were sometimes taken from the wrong side of the position.

Prevent scrolling artifacts caused by attempts to scroll stuff into view when the editor isn't being displayed.

### New features

`TooltipView` objects can now provide a `destroy` method to be called when the tooltip is removed.

## 6.3.1 (2022-10-10)

### Bug fixes

Fix a crash when trying to scroll something into view in an editor that wasn't in the visible DOM.

Fix an issue where `coordsAtPos` returned the coordinates on the wrong side of a widget decoration wrapped in a mark decoration.

Fix an issue where content on long wrapped lines could fail to properly scroll into view.

Fix an issue where DOM change reading on Chrome Android could get confused when a transaction came in right after a beforeinput event for backspace, enter, or delete.

## 6.3.0 (2022-09-28)

### Bug fixes

Reduce the amount of wrap-point jittering when scrolling through a very long wrapped line.

Fix an issue where scrolling to content that wasn't currently drawn due to being on a very long line would often fail to scroll to the right position.

Suppress double-space-adds-period behavior on Chrome Mac when it behaves weirdly next to widget.

### New features

Key binding objects with an `any` property will now add handlers that are called for any key, within the ordering of the keybindings.

## 6.2.5 (2022-09-24)

### Bug fixes

Don't override double/triple tap behavior on touch screen devices, so that the mobile selection menu pops up properly.

Fix an issue where updating the selection could crash on Safari when the editor was hidden.

## 6.2.4 (2022-09-16)

### Bug fixes

Highlight the active line even when there is a selection. Prevent the active line background from obscuring the selection backdrop.

Fix an issue where elements with negative margins would confuse the editor's scrolling-into-view logic.

Fix scrolling to a specific position in an editor that has not been in view yet.

## 6.2.3 (2022-09-08)

### Bug fixes

Fix a bug where cursor motion, when starting from a non-empty selection range, could get stuck on atomic ranges in some circumstances.

Avoid triggering Chrome Android's text-duplication issue when a period is typed in the middle of a word.

## 6.2.2 (2022-08-31)

### Bug fixes

Don't reset the selection for selection change events that were suppressed by a node view.

## 6.2.1 (2022-08-25)

### Bug fixes

Don't use the global `document` variable to track focus, since that doesn't work in another window/frame.

Fix an issue where key handlers that didn't return true were sometimes called twice for the same keypress.

Avoid editing glitches when using deletion keys like ctrl-d on iOS.

Properly treat characters from the 'Arabic Presentation Forms-A' Unicode block as right-to-left.

Work around a Firefox bug that inserts text at the wrong point for specific cross-line selections.

## 6.2.0 (2022-08-05)

### Bug fixes

Fix a bug where `posAtCoords` would return the wrong results for positions to the right of wrapped lines.

### New features

The new `EditorView.setRoot` method can be used when an editor view is moved to a new document or shadow root.

## 6.1.4 (2022-08-04)

### Bug fixes

Make selection-restoration on focus more reliable.

## 6.1.3 (2022-08-03)

### Bug fixes

Fix a bug where a document that contains only non-printing characters would lead to bogus text measurements (and, from those, to crashing).

Make sure differences between estimated and actual block heights don't cause visible scroll glitches.

## 6.1.2 (2022-07-27)

### Bug fixes

Fix an issue where double tapping enter to confirm IME input and insert a newline on iOS would sometimes insert two newlines.

Fix an issue on iOS where a composition could get aborted if the editor scrolled on backspace.

## 6.1.1 (2022-07-25)

### Bug fixes

Make `highlightSpecialChars` replace directional isolate characters by default.

The editor will now try to suppress browsers' native behavior of resetting the selection in the editable content when the editable element is focused (programmatically, with tab, etc).

Fix a CSS issue that made it possible, when the gutters were wide enough, for them to overlap with the content.

## 6.1.0 (2022-07-19)

### New features

`MatchDecorator` now supports a `decorate` option that can be used to customize the way decorations are added for each match.

## 6.0.3 (2022-07-08)

### Bug fixes

Fix a problem where `posAtCoords` could incorrectly return the start of the next line when querying positions between lines.

Fix an issue where registering a high-precedence keymap made keymap handling take precedence over other keydown event handlers.

Ctrl/Cmd-clicking can now remove ranges from a multi-range selection.

## 6.0.2 (2022-06-23)

### Bug fixes

Fix a CSS issue that broke horizontal scroll width stabilization.

Fix a bug where `defaultLineHeight` could get an incorrect value in very narrow editors.

## 6.0.1 (2022-06-17)

### Bug fixes

Avoid DOM selection corruption when the editor doesn't have focus but has selection and updates its content.

Fall back to dispatching by key code when a key event produces a non-ASCII character (so that Cyrillic and Arabic keyboards can still use bindings specified with Latin characters).

## 6.0.0 (2022-06-08)

### New features

The new static `EditorView.findFromDOM` method can be used to retrieve an editor instance from its DOM structure.

Instead of passing a constructed state to the `EditorView` constructor, it is now also possible to inline the configuration options to the state in the view config object.

## 0.20.7 (2022-05-30)

### Bug fixes

Fix an issue on Chrome Android where the DOM could fail to display the actual document after backspace.

Avoid an issue on Chrome Android where DOM changes were sometimes inappropriately replace by a backspace key effect due to spurious beforeinput events.

Fix a problem where the content element's width didn't cover the width of the actual content.

Work around a bug in Chrome 102 which caused wheel scrolling of the editor to be interrupted every few lines.

## 0.20.6 (2022-05-20)

### Bug fixes

Make sure the editor re-measures itself when its attributes are updated.

## 0.20.5 (2022-05-18)

### Bug fixes

Fix an issue where gutter elements without any markers in them would not get the `cm-gutterElement` class assigned.

Fix an issue where DOM event handlers registered by plugins were retained indefinitely, even after the editor was reconfigured.

## 0.20.4 (2022-05-03)

### Bug fixes

Prevent Mac-style behavior of inserting a period when the user inserts two spaces.

Fix an issue where the editor would sometimes not restore the DOM selection when refocused with a selection identical to the one it held when it lost focus.

## 0.20.3 (2022-04-27)

### Bug fixes

Fix a bug where the input handling could crash on repeated (or held) backspace presses on Chrome Android.

## 0.20.2 (2022-04-22)

### New features

The new `hideOn` option to `hoverTooltip` allows more fine-grained control over when the tooltip should hide.

## 0.20.1 (2022-04-20)

### Bug fixes

Remove debug statements that accidentally made it into 0.20.0.

Fix a regression in `moveVertically`.

## 0.20.0 (2022-04-20)

### Breaking changes

The deprecated interfaces `blockAtHeight`, `visualLineAtHeight`, `viewportLines`, `visualLineAt`, `scrollPosIntoView`, `scrollTo`, and `centerOn` were removed from the library.

All decorations are now provided through `EditorView.decorations`, and are part of a single precedence ordering. Decoration sources that need access to the view are provided as functions.

Atomic ranges are now specified through a facet (`EditorView.atomicRanges`).

Scroll margins are now specified through a facet (`EditorView.scrollMargins`).

Plugin fields no longer exist in the library (and are replaced by facets holding function values).

This package no longer re-exports the Range type from @codemirror/state.

### Bug fixes

Fix a bug where zero-length block widgets could cause `viewportLineBlocks` to contain overlapping ranges.

### New features

The new `perLineTextDirection` facet configures whether the editor reads text direction per line, or uses a single direction for the entire editor. `EditorView.textDirectionAt` returns the direction around a given position.

`rectangularSelection` and `crosshairCursor` from @codemirror/rectangular-selection were merged into this package.

This package now exports the tooltip functionality that used to live in @codemirror/tooltip.

The exports from the old @codemirror/panel package are now available from this package.

The exports from the old @codemirror/gutter package are now available from this package.

## 0.19.48 (2022-03-30)

### Bug fixes

Fix an issue where DOM syncing could crash when a DOM node was moved from a parent to a child node (via widgets reusing existing nodes).

To avoid interfering with things like a vim mode too much, the editor will now only activate the tab-to-move-focus escape hatch after an escape press that wasn't handled by an event handler.

Make sure the view measures itself before the page is printed.

Tweak types of view plugin defining functions to avoid TypeScript errors when the plugin value doesn't have any of the interface's properties.

## 0.19.47 (2022-03-08)

### Bug fixes

Fix an issue where block widgets at the start of the viewport could break height computations.

## 0.19.46 (2022-03-03)

### Bug fixes

Fix a bug where block widgets on the edges of viewports could cause the positioning of content to misalign with the gutter and height computations.

Improve cursor height next to widgets.

Fix a bug where mapping positions to screen coordinates could return incorred coordinates during composition.

## 0.19.45 (2022-02-23)

### Bug fixes

Fix an issue where the library failed to call `WidgetType.destroy` on the old widget when replacing a widget with a different widget of the same type.

Fix an issue where the editor would compute DOM positions inside composition contexts incorrectly in some cases, causing the selection to be put in the wrong place and needlessly interrupting compositions.

Fix leaking of resize event handlers.

## 0.19.44 (2022-02-17)

### Bug fixes

Fix a crash that occasionally occurred when drag-selecting in a way that scrolled the editor.

### New features

The new `EditorView.compositionStarted` property indicates whether a composition is starting.

## 0.19.43 (2022-02-16)

### Bug fixes

Fix several issues where editing or composition went wrong due to our zero-width space kludge characters ending up in unexpected places.

Make sure the editor re-measures its dimensions whenever its theme changes.

Fix an issue where some keys on Android phones could leave the editor DOM unsynced with the actual document.

## 0.19.42 (2022-02-05)

### Bug fixes

Fix a regression in cursor position determination after making an edit next to a widget.

## 0.19.41 (2022-02-04)

### Bug fixes

Fix an issue where the editor's view of its content height could go out of sync with the DOM when a line-wrapping editor had its width changed, causing wrapping to change.

Fix a bug that caused the editor to draw way too much content when scrolling to a position in an editor (much) taller than the window.

Report an error when a replace decoration from a plugin crosses a line break, rather than silently ignoring it.

Fix an issue where reading DOM changes was broken when `lineSeparator` contained more than one character.

Make ordering of replace and mark decorations with the same extent and inclusivness more predictable by giving replace decorations precedence.

Fix a bug where, on Chrome, replacement across line boundaries and next to widgets could cause bogus zero-width characters to appear in the content.

## 0.19.40 (2022-01-19)

### Bug fixes

Make composition input properly appear at secondary cursors (except when those are in the DOM node with the composition, in which case the browser won't allow us to intervene without aborting the composition).

Fix a bug that cause the editor to get confused about which content was visible after scrolling something into view.

Fix a bug where the dummy elements rendered around widgets could end up in a separate set of wrapping marks, and thus become visible.

`EditorView.moveVertically` now preserves the `assoc` property of the input range.

Get rid of gaps between selection elements drawn by `drawSelection`.

Fix an issue where replacing text next to a widget might leak bogus zero-width spaces into the document.

Avoid browser selection mishandling when a focused view has `setState` called by eagerly refocusing it.

## 0.19.39 (2022-01-06)

### Bug fixes

Make sure the editor signals a `geometryChanged` update when its width changes.

### New features

`EditorView.darkTheme` can now be queried to figure out whether the editor is using a dark theme.

## 0.19.38 (2022-01-05)

### Bug fixes

Fix a bug that caused line decorations with a `class` property to suppress all other line decorations for that line.

Fix a bug that caused scroll effects to be corrupted when further updates came in before they were applied.

Fix an issue where, depending on which way a floating point rounding error fell, `posAtCoords` (and thus vertical cursor motion) for positions outside of the vertical range of the document might or might not return the start/end of the document.

## 0.19.37 (2021-12-22)

### Bug fixes

Fix regression where plugin replacing decorations that span to the end of the line are ignored.

## 0.19.36 (2021-12-22)

### Bug fixes

Fix a crash in `posAtCoords` when the position lies in a block widget that is rendered but scrolled out of view.

Adding block decorations from a plugin now raises an error. Replacing decorations that cross lines are ignored, when provided by a plugin.

Fix inverted interpretation of the `precise` argument to `posAtCoords`.

## 0.19.35 (2021-12-20)

### Bug fixes

The editor will now handle double-taps as if they are double-clicks, rather than letting the browser's native behavior happen (because the latter often does the wrong thing).

Fix an issue where backspacing out a selection on Chrome Android would sometimes only delete the last character due to event order issues.

`posAtCoords`, without second argument, will no longer return null for positions below or above the document.

## 0.19.34 (2021-12-17)

### Bug fixes

Fix a bug where content line elements would in some cases lose their `cm-line` class.

## 0.19.33 (2021-12-16)

### Breaking changes

`EditorView.scrollTo` and `EditorView.centerOn` are deprecated in favor of `EditorView.scrollIntoView`, and will be removed in the next breaking release.

### Bug fixes

Fix an issue that could cause the editor to unnecessarily interfere with composition (especially visible on macOS Chrome).

A composition started with multiple lines selected will no longer be interruptd by the editor.

### New features

The new `EditorView.scrollIntoView` function allows you to do more fine-grained scrolling.

## 0.19.32 (2021-12-15)

### Bug fixes

Fix a bug where CodeMirror's own event handers would run even after a user-supplied handler called `preventDefault` on an event.

Properly draw selections when negative text-indent is used for soft wrapping.

Fix an issue where `viewportLineBlocks` could hold inaccurate height information when the vertical scaling changed.

Fixes drop cursor positioning when the document is scrolled. Force a content measure when the editor comes into view

Fix a bug that could cause the editor to not measure its layout the first time it came into view.

## 0.19.31 (2021-12-13)

### New features

The package now exports a `dropCursor` extension that draws a cursor at the current drop position when dragging content over the editor.

## 0.19.30 (2021-12-13)

### Bug fixes

Refine Android key event handling to work properly in a GBoard corner case where pressing Enter fires a bunch of spurious deleteContentBackward events.

Fix a crash in `drawSelection` for some kinds of selections.

Prevent a possibility where some content updates causes duplicate text to remain in DOM.

### New features

Support a `maxLength` option to `MatchDecorator` that allows user code to control how far it scans into hidden parts of viewport lines.

## 0.19.29 (2021-12-09)

### Bug fixes

Fix a bug that could cause out-of-view editors to get a nonsensical viewport and fail to scroll into view when asked to.

Fix a bug where  would return 0 when clicking below the content if the last line was replaced with a block widget decoration.

Fix an issue where clicking at the position of the previous cursor in a blurred editor would cause the selection to reset to the start of the document.

Fix an issue where composition could be interrupted if the browser created a new node inside a mark decoration node.

## 0.19.28 (2021-12-08)

### Bug fixes

Fix an issue where pressing Enter on Chrome Android during composition did not fire key handlers for Enter.

Avoid a Chrome bug where the virtual keyboard closes when pressing backspace after a widget.

Fix an issue where the editor could show a horizontal scroll bar even after all lines that caused it had been deleted or changed.

## 0.19.27 (2021-12-06)

### Bug fixes

Fix a bug that could cause `EditorView.plugin` to inappropriately return `null` during plugin initialization.

Fix a bug where a block widget without `estimatedHeight` at the end of the document could fail to be drawn

## 0.19.26 (2021-12-03)

### New features

Widgets can now define a `destroy` method that is called when they are removed from the view.

## 0.19.25 (2021-12-02)

### Bug fixes

Widgets around replaced ranges are now visible when their side does not point towards the replaced range.

A replaced line with a line decoration no longer creates an extra empty line block in the editor.

The `scrollPastEnd` extension will now over-reserve space at the bottom of the editor on startup, to prevent restored scroll positions from being clipped.

### New features

`EditorView.editorAttributes` and `contentAttributes` may now hold functions that produce the attributes.

## 0.19.24 (2021-12-01)

### Bug fixes

Fix a bug where `lineBlockAt`, for queries inside the viewport, would always return the first line in the viewport.

## 0.19.23 (2021-11-30)

### Bug fixes

Fix an issue where after some kinds of changes, `EditorView.viewportLineBlocks` held an out-of-date set of blocks.

### New features

Export `EditorView.documentPadding`, with information about the vertical padding of the document.

## 0.19.22 (2021-11-30)

### Bug fixes

Fix an issue where editors with large vertical padding (for example via `scrollPastEnd`) could sometimes lose their scroll position on Chrome.

Avoid some unnecessary DOM measuring work by more carefully checking whether it is needed.

### New features

The new `elementAtHeight`, `lineBlockAtHeight`, and `lineBlockAt` methods provide a simpler and more efficient replacement for the (now deprecated) `blockAtHeight`, `visualLineAtHeight`, and `visualLineAt` methods.

The editor view now exports a `documentTop` getter that gives you the vertical position of the top of the document. All height info is queried and reported relative to this top.

The editor view's new `viewportLineBlocks` property provides an array of in-viewport line blocks, and replaces the (now deprecated) `viewportLines` method.

## 0.19.21 (2021-11-26)

### Bug fixes

Fix a problem where the DOM update would unnecessarily trigger browser relayouts.

## 0.19.20 (2021-11-19)

### Bug fixes

Run a measure cycle when the editor's size spontaneously changes.

## 0.19.19 (2021-11-17)

### Bug fixes

Fix a bug that caused the precedence of `editorAttributes` and `contentAttributes` to be inverted, making lower-precedence extensions override higher-precedence ones.

## 0.19.18 (2021-11-16)

### Bug fixes

Fix an issue where the editor wasn't aware it was line-wrapping with its own `lineWrapping` extension enabled.

## 0.19.17 (2021-11-16)

### Bug fixes

Avoid an issue where stretches of whitespace on line wrap points could cause the cursor to be placed outside of the content.

## 0.19.16 (2021-11-11)

### Breaking changes

Block replacement decorations now default to inclusive, because non-inclusive block decorations are rarely what you need.

### Bug fixes

Fix an issue that caused block widgets to always have a large side value, making it impossible to show them between to replacement decorations.

Fix a crash that could happen after some types of viewport changes, due to a bug in the block widget view data structure.

## 0.19.15 (2021-11-09)

### Bug fixes

Fix a bug where the editor would think it was invisible when the document body was given screen height and scroll behavior.

Fix selection reading inside a shadow root on iOS.

## 0.19.14 (2021-11-07)

### Bug fixes

Fix an issue where typing into a read-only editor would move the selection.

Fix slowness when backspace is held down on iOS.

## 0.19.13 (2021-11-06)

### Bug fixes

Fix a bug where backspace, enter, and delete would get applied twice on iOS.

## 0.19.12 (2021-11-04)

### Bug fixes

Make sure the workaround for the lost virtual keyboard on Chrome Android also works on slower phones. Slight style change in beforeinput handler

Avoid failure cases in viewport-based rendering of very long lines.

## 0.19.11 (2021-11-03)

### Breaking changes

`EditorView.scrollPosIntoView` has been deprecated. Use the `EditorView.scrollTo` effect instead.

### New features

The new `EditorView.centerOn` effect can be used to scroll a given range to the center of the view.

## 0.19.10 (2021-11-02)

### Bug fixes

Don't crash when `IntersectionObserver` fires its callback without any records. Try to handle some backspace issues on Chrome Android

Using backspace near uneditable widgets on Chrome Android should now be more reliable.

Work around a number of browser bugs by always rendering zero-width spaces around in-content widgets, so that browsers will treat the positions near them as valid cursor positions and not try to run composition across widget boundaries.

Work around bogus composition changes created by Chrome Android after handled backspace presses.

Work around an issue where tapping on an uneditable node in the editor would sometimes fail to show the virtual keyboard on Chrome Android.

Prevent translation services from translating the editor content. Show direction override characters as special chars by default

`specialChars` will now, by default, replace direction override chars, to mitigate https://trojansource.codes/ attacks.

### New features

The editor view will, if `parent` is given but `root` is not, derive the root from the parent element.

Line decorations now accept a `class` property to directly add DOM classes to the line.

## 0.19.9 (2021-10-01)

### Bug fixes

Fix an issue where some kinds of reflows in the surrounding document could move unrendered parts of the editor into view without the editor noticing and updating its viewport.

Fix an occasional crash in the selection drawing extension.

## 0.19.8 (2021-09-26)

### Bug fixes

Fix a bug that could, on DOM changes near block widgets, insert superfluous line breaks.

Make interacting with a destroyed editor view do nothing, rather than crash, to avoid tripping people up with pending timeouts and such.

Make sure `ViewUpdate.viewportChanged` is true whenever `visibleRanges` changes, so that plugins acting only on visible ranges can use it to check when to update.

Fix line-wise cut on empty lines.

## 0.19.7 (2021-09-13)

### Bug fixes

The view is now aware of the new `EditorState.readOnly` property, and suppresses events that modify the document when it is true.

## 0.19.6 (2021-09-10)

### Bug fixes

Remove a `console.log` that slipped into the previous release.

## 0.19.5 (2021-09-09)

### New features

The new `EditorView.scrollTo` effect can be used to scroll a given range into view.

## 0.19.4 (2021-09-01)

### Bug fixes

Fix an issue where lines containing just a widget decoration wrapped in a mark decoration could be displayed with 0 height.

## 0.19.3 (2021-08-25)

### Bug fixes

Fix a view corruption that could happen in situations involving overlapping mark decorations.

## 0.19.2 (2021-08-23)

### New features

The package now exports a `scrollPastEnd` function, which returns an extension that adds space below the document to allow the last line to be scrolled to the top of the editor.

## 0.19.1 (2021-08-11)

### Breaking changes

The view now emits new-style user event annotations for the transactions it generates.

### Bug fixes

Fix a bug where `coordsAtPos` would allow the passed `side` argument to override widget sides, producing incorrect cursor positions.

Fix a bug that could cause content lines to be misaligned in certain situations involving widgets at the end of lines.

Fix an issue where, if the browser decided to modify DOM attributes in the content in response to some editing action, the view failed to reset those again.

## 0.18.19 (2021-07-12)

### Bug fixes

Fix a regression where `EditorView.editable.of(false)` didn't disable editing on Webkit-based browsers.

## 0.18.18 (2021-07-06)

### Bug fixes

Fix a bug that caused `EditorView.moveVertically` to only move by one line, even when given a custom distance, in some cases.

Hide Safari's native bold/italic/underline controls for the content.

Fix a CSS problem that prevented Safari from breaking words longer than the line in line-wrapping mode.

Avoid a problem where composition would be inappropriately abored on Safari.

Fix drag-selection that scrolls the content by dragging past the visible viewport.

### New features

`posAtCoords` now has an imprecise mode where it'll return an approximate position even for parts of the document that aren't currently rendered.

## 0.18.17 (2021-06-14)

### Bug fixes

Make `drawSelection` behave properly when lines are split by block widgets.

Make sure drawn selections that span a single line break don't leave a gap between the lines.

## 0.18.16 (2021-06-03)

### Bug fixes

Fix a crash that could occur when the document changed during mouse selection.

Fix a bug where composition inside styled content would sometimes be inappropriately aborted by editor DOM updates.

### New features

`MouseSelectionStyle.update` may now return true to indicate it should be queried for a new selection after the update.

## 0.18.15 (2021-06-01)

### Bug fixes

Fix a bug that would, in very specific circumstances, cause `posAtCoords` to go into an infinite loop in Safari.

Fix a bug where some types of IME input on Mobile Safari would drop text.

## 0.18.14 (2021-05-28)

### Bug fixes

Fix an issue where the DOM selection was sometimes not properly updated when next to a widget.

Invert the order in which overlapping decorations are drawn so that higher-precedence decorations are nested inside lower-precedence ones (and thus override their styling).

Fix a but in `posAtCoords` where it would in some situations return -1 instead of `null`.

### New features

A new plugin field, `PluginField.atomicRanges`, can be used to cause cursor motion to skip past some ranges of the document.

## 0.18.13 (2021-05-20)

### Bug fixes

Fix a bug that would cause the content DOM update to crash in specific circumstances.

Work around an issue where, after some types of changes, Mobile Safari would ignore Enter presses.

Make iOS enter and backspace handling more robust, so that platform bugs are less likely to break those keys in the editor.

Fix a regression where Esc + Tab no longer allowed the user to exit the editor.

### New features

You can now drop text files into the editor.

## 0.18.12 (2021-05-10)

### Bug fixes

Work around a Mobile Safari bug where, after backspacing out the last character on a line, Enter didn't work anymore.

Work around a problem in Mobile Safari where you couldn't tap to put the cursor at the end of a line that ended in a widget.

## 0.18.11 (2021-04-30)

### Bug fixes

Add an attribute to prevent the Grammarly browser extension from messing with the editor content.

Fix more issues around selection handling a Shadow DOM in Safari.

## 0.18.10 (2021-04-27)

### Bug fixes

Fix a bug where some types of updates wouldn't properly cause marks around the changes to be joined in the DOM.

Fix an issue where the content and gutters in a fixed-height editor could be smaller than the editor height.

Fix a crash on Safari when initializing an editor in an unfocused window.

Fix a bug where the editor would incorrectly conclude it was out of view in some types of absolutely positioned parent elements.

## 0.18.9 (2021-04-23)

### Bug fixes

Fix a crash that occurred when determining DOM coordinates in some specific situations.

Fix a crash when a DOM change that ended at a zero-width view element (widget) removed that element from the DOM.

Disable autocorrect and autocapitalize by default, since in most code-editor contexts they get in the way. You can use `EditorView.contentAttributes` to override this.

Fix a bug that interfered with native touch selection handling on Android.

Fix an unnecessary DOM update after composition that would disrupt touch selection on Android.

Add a workaround for Safari's broken selection reporting when the editor is in a shadow DOM tree.

Fix select-all from the context menu on Safari.

## 0.18.8 (2021-04-19)

### Bug fixes

Handle selection replacements where the inserted text matches the start/end of the replaced text better.

Fix an issue where the editor would miss scroll events when it was placed in a DOM component slot.

## 0.18.7 (2021-04-13)

### Bug fixes

Fix a crash when drag-selecting out of the editor with editable turned off.

Backspace and delete now largely work in an editor without a keymap.

Pressing backspace on iOS should now properly update the virtual keyboard's capitalize and autocorrect state.

Prevent random line-wrapping in (non-wrapping) editors on Mobile Safari.
## 0.18.6 (2021-04-08)

### Bug fixes

Fix an issue in the compiled output that would break the code when minified with terser.

## 0.18.5 (2021-04-07)

### Bug fixes

Improve handling of bidi text with brackets (conforming to Unicode 13's bidi algorithm).

Fix the position where `drawSelection` displays the cursor on bidi boundaries.

## 0.18.4 (2021-04-07)

### Bug fixes

Fix an issue where the default focus ring gets obscured by the gutters and active line.

Fix an issue where the editor believed Chrome Android didn't support the CSS `tab-size` style.

Don't style active lines when there are non-empty selection ranges, so that the active line background doesn't obscure the selection.

Make iOS autocapitalize update properly when you press Enter.

## 0.18.3 (2021-03-19)

### Breaking changes

The outer DOM element now has class `cm-editor` instead of `cm-wrap` (`cm-wrap` will be present as well until 0.19).

### Bug fixes

Improve behavior of `posAtCoords` when the position is near text but not in any character's actual box.

## 0.18.2 (2021-03-19)

### Bug fixes

Triple-clicking now selects the line break after the clicked line (if any).

Fix an issue where the `drawSelection` plugin would fail to draw the top line of the selection when it started in an empty line.

Fix an issue where, at the end of a specific type of composition on iOS, the editor read the DOM before the browser was done updating it.

## 0.18.1 (2021-03-05)

### Bug fixes

Fix an issue where, on iOS, some types of IME would cause the composed content to be deleted when confirming a composition.

## 0.18.0 (2021-03-03)

### Breaking changes

The `themeClass` function and ``-style selectors in themes are no longer supported (prefixing with `cm-` should be done manually now).

Themes must now use `&` (instead of an extra `$`) to target the editor wrapper element.

The editor no longer adds `cm-light` or `cm-dark` classes. Targeting light or dark configurations in base themes should now be done by using a `&light` or `&dark` top-level selector.

## 0.17.13 (2021-03-03)

### Bug fixes

Work around a Firefox bug where it won't draw the cursor when it is between uneditable elements.

Fix a bug that broke built-in mouse event handling.

## 0.17.12 (2021-03-02)

### Bug fixes

Avoid interfering with touch events, to allow native selection behavior.

Fix a bug that broke sub-selectors with multiple `&` placeholders in themes.

## 0.17.11 (2021-02-25)

### Bug fixes

Fix vertical cursor motion on Safari with a larger line-height.

Fix incorrect selection drawing (with `drawSelection`) when the selection spans to just after a soft wrap point.

Fix an issue where compositions on Safari were inappropriately aborted in some circumstances.

The view will now redraw when the `EditorView.phrases` facet changes, to make sure translated text is properly updated.

## 0.17.10 (2021-02-22)

### Bug fixes

Long words without spaces, when line-wrapping is enabled, are now properly broken.

Fix the horizontal position of selections drawn by `drawSelection` in right-to-left editors with a scrollbar.

## 0.17.9 (2021-02-18)

### Bug fixes

Fix an issue where pasting linewise at the start of a line left the cursor before the inserted content.

## 0.17.8 (2021-02-16)

### Bug fixes

Fix a problem where the DOM selection and the editor state could get out of sync in non-editable mode.

Fix a crash when the editor was hidden on Safari, due to `getClientRects` returning an empty list.

Prevent Firefox from making the scrollable element keyboard-focusable.

## 0.17.7 (2021-01-25)

### New features

Add an `EditorView.announce` state effect that can be used to conveniently provide screen reader announcements.

## 0.17.6 (2021-01-22)

### Bug fixes

Avoid creating very high scroll containers for large documents so that we don't overflow the DOM's fixed-precision numbers.

## 0.17.5 (2021-01-15)

### Bug fixes

Fix a bug that would create space-filling placeholders with incorrect height when document is very large.

## 0.17.4 (2021-01-14)

### Bug fixes

The `drawSelection` extension will now reuse cursor DOM nodes when the number of cursors stays the same, allowing some degree of cursor transition animation.

Makes highlighted special characters styleable (``) and fix their default look in dark themes to have appropriate contrast.

### New features

Adds a new `MatchDecorator` helper class which can be used to easily maintain decorations on content that matches a regular expression.

## 0.17.3 (2021-01-06)

### New features

The package now also exports a CommonJS module.

## 0.17.2 (2021-01-04)

### Bug fixes

Work around Chrome problem where the native shift-enter behavior inserts two line breaks.

Make bracket closing and bracket pair removing more reliable on Android.

Fix bad cursor position and superfluous change transactions after pressing enter when in a composition on Android.

Fix issue where the wrong character was deleted when backspacing out a character before an identical copy of that character on Android.

## 0.17.1 (2020-12-30)

### Bug fixes

Fix a bug that prevented `ViewUpdate.focusChanged` from ever being true.

## 0.17.0 (2020-12-29)

### Breaking changes

First numbered release.

# @codemirror/view [![NPM version](https://img.shields.io/npm/v/@codemirror/view.svg)](https://www.npmjs.org/package/@codemirror/view)

[ [**WEBSITE**](https://codemirror.net/) | [**DOCS**](https://codemirror.net/docs/ref/#view) | [**ISSUES**](https://github.com/codemirror/dev/issues) | [**FORUM**](https://discuss.codemirror.net/c/next/) | [**CHANGELOG**](https://github.com/codemirror/view/blob/main/CHANGELOG.md) ]

This package implements the DOM view component for the
[CodeMirror](https://codemirror.net/) code editor.

The [project page](https://codemirror.net/) has more information, a
number of [examples](https://codemirror.net/examples/) and the
[documentation](https://codemirror.net/docs/).

This code is released under an
[MIT license](https://github.com/codemirror/view/tree/main/LICENSE).

We aim to be an inclusive, welcoming community. To make that explicit,
we have a [code of
conduct](http://contributor-covenant.org/version/1/1/0/) that applies
to communication around the project.
### esutils [![Build Status](https://secure.travis-ci.org/estools/esutils.svg)](http://travis-ci.org/estools/esutils)
esutils ([esutils](http://github.com/estools/esutils)) is
utility box for ECMAScript language tools.

### API

### ast

#### ast.isExpression(node)

Returns true if `node` is an Expression as defined in ECMA262 edition 5.1 section
[11](https://es5.github.io/#x11).

#### ast.isStatement(node)

Returns true if `node` is a Statement as defined in ECMA262 edition 5.1 section
[12](https://es5.github.io/#x12).

#### ast.isIterationStatement(node)

Returns true if `node` is an IterationStatement as defined in ECMA262 edition
5.1 section [12.6](https://es5.github.io/#x12.6).

#### ast.isSourceElement(node)

Returns true if `node` is a SourceElement as defined in ECMA262 edition 5.1
section [14](https://es5.github.io/#x14).

#### ast.trailingStatement(node)

Returns `Statement?` if `node` has trailing `Statement`.
```js
if (cond)
    consequent;
```
When taking this `IfStatement`, returns `consequent;` statement.

#### ast.isProblematicIfStatement(node)

Returns true if `node` is a problematic IfStatement. If `node` is a problematic `IfStatement`, `node` cannot be represented as an one on one JavaScript code.
```js
{
    type: 'IfStatement',
    consequent: {
        type: 'WithStatement',
        body: {
            type: 'IfStatement',
            consequent: {type: 'EmptyStatement'}
        }
    },
    alternate: {type: 'EmptyStatement'}
}
```
The above node cannot be represented as a JavaScript code, since the top level `else` alternate belongs to an inner `IfStatement`.


### code

#### code.isDecimalDigit(code)

Return true if provided code is decimal digit.

#### code.isHexDigit(code)

Return true if provided code is hexadecimal digit.

#### code.isOctalDigit(code)

Return true if provided code is octal digit.

#### code.isWhiteSpace(code)

Return true if provided code is white space. White space characters are formally defined in ECMA262.

#### code.isLineTerminator(code)

Return true if provided code is line terminator. Line terminator characters are formally defined in ECMA262.

#### code.isIdentifierStart(code)

Return true if provided code can be the first character of ECMA262 Identifier. They are formally defined in ECMA262.

#### code.isIdentifierPart(code)

Return true if provided code can be the trailing character of ECMA262 Identifier. They are formally defined in ECMA262.

### keyword

#### keyword.isKeywordES5(id, strict)

Returns `true` if provided identifier string is a Keyword or Future Reserved Word
in ECMA262 edition 5.1. They are formally defined in ECMA262 sections
[7.6.1.1](http://es5.github.io/#x7.6.1.1) and [7.6.1.2](http://es5.github.io/#x7.6.1.2),
respectively. If the `strict` flag is truthy, this function additionally checks whether
`id` is a Keyword or Future Reserved Word under strict mode.

#### keyword.isKeywordES6(id, strict)

Returns `true` if provided identifier string is a Keyword or Future Reserved Word
in ECMA262 edition 6. They are formally defined in ECMA262 sections
[11.6.2.1](http://ecma-international.org/ecma-262/6.0/#sec-keywords) and
[11.6.2.2](http://ecma-international.org/ecma-262/6.0/#sec-future-reserved-words),
respectively. If the `strict` flag is truthy, this function additionally checks whether
`id` is a Keyword or Future Reserved Word under strict mode.

#### keyword.isReservedWordES5(id, strict)

Returns `true` if provided identifier string is a Reserved Word in ECMA262 edition 5.1.
They are formally defined in ECMA262 section [7.6.1](http://es5.github.io/#x7.6.1).
If the `strict` flag is truthy, this function additionally checks whether `id`
is a Reserved Word under strict mode.

#### keyword.isReservedWordES6(id, strict)

Returns `true` if provided identifier string is a Reserved Word in ECMA262 edition 6.
They are formally defined in ECMA262 section [11.6.2](http://ecma-international.org/ecma-262/6.0/#sec-reserved-words).
If the `strict` flag is truthy, this function additionally checks whether `id`
is a Reserved Word under strict mode.

#### keyword.isRestrictedWord(id)

Returns `true` if provided identifier string is one of `eval` or `arguments`.
They are restricted in strict mode code throughout ECMA262 edition 5.1 and
in ECMA262 edition 6 section [12.1.1](http://ecma-international.org/ecma-262/6.0/#sec-identifiers-static-semantics-early-errors).

#### keyword.isIdentifierNameES5(id)

Return true if provided identifier string is an IdentifierName as specified in
ECMA262 edition 5.1 section [7.6](https://es5.github.io/#x7.6).

#### keyword.isIdentifierNameES6(id)

Return true if provided identifier string is an IdentifierName as specified in
ECMA262 edition 6 section [11.6](http://ecma-international.org/ecma-262/6.0/#sec-names-and-keywords).

#### keyword.isIdentifierES5(id, strict)

Return true if provided identifier string is an Identifier as specified in
ECMA262 edition 5.1 section [7.6](https://es5.github.io/#x7.6). If the `strict`
flag is truthy, this function additionally checks whether `id` is an Identifier
under strict mode.

#### keyword.isIdentifierES6(id, strict)

Return true if provided identifier string is an Identifier as specified in
ECMA262 edition 6 section [12.1](http://ecma-international.org/ecma-262/6.0/#sec-identifiers).
If the `strict` flag is truthy, this function additionally checks whether `id`
is an Identifier under strict mode.

### License

Copyright (C) 2013 [Yusuke Suzuki](http://github.com/Constellation)
 (twitter: [@Constellation](http://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# find-up [![Build Status](https://travis-ci.com/sindresorhus/find-up.svg?branch=master)](https://travis-ci.com/github/sindresorhus/find-up)

> Find a file or directory by walking up parent directories

## Install

```
$ npm install find-up
```

## Usage

```
/
└── Users
    └── sindresorhus
        ├── unicorn.png
        └── foo
            └── bar
                ├── baz
                └── example.js
```

`example.js`

```js
const path = require('path');
const findUp = require('find-up');

(async () => {
	console.log(await findUp('unicorn.png'));
	//=> '/Users/sindresorhus/unicorn.png'

	console.log(await findUp(['rainbow.png', 'unicorn.png']));
	//=> '/Users/sindresorhus/unicorn.png'

	console.log(await findUp(async directory => {
		const hasUnicorns = await findUp.exists(path.join(directory, 'unicorn.png'));
		return hasUnicorns && directory;
	}, {type: 'directory'}));
	//=> '/Users/sindresorhus'
})();
```

## API

### findUp(name, options?)
### findUp(matcher, options?)

Returns a `Promise` for either the path or `undefined` if it couldn't be found.

### findUp([...name], options?)

Returns a `Promise` for either the first path found (by respecting the order of the array) or `undefined` if none could be found.

### findUp.sync(name, options?)
### findUp.sync(matcher, options?)

Returns a path or `undefined` if it couldn't be found.

### findUp.sync([...name], options?)

Returns the first path found (by respecting the order of the array) or `undefined` if none could be found.

#### name

Type: `string`

Name of the file or directory to find.

#### matcher

Type: `Function`

A function that will be called with each directory until it returns a `string` with the path, which stops the search, or the root directory has been reached and nothing was found. Useful if you want to match files with certain patterns, set of permissions, or other advanced use-cases.

When using async mode, the `matcher` may optionally be an async or promise-returning function that returns the path.

#### options

Type: `object`

##### cwd

Type: `string`\
Default: `process.cwd()`

Directory to start from.

##### type

Type: `string`\
Default: `'file'`\
Values: `'file'` `'directory'`

The type of paths that can match.

##### allowSymlinks

Type: `boolean`\
Default: `true`

Allow symbolic links to match if they point to the chosen path type.

### findUp.exists(path)

Returns a `Promise<boolean>` of whether the path exists.

### findUp.sync.exists(path)

Returns a `boolean` of whether the path exists.

#### path

Type: `string`

Path to a file or directory.

### findUp.stop

A [`Symbol`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol) that can be returned by a `matcher` function to stop the search and cause `findUp` to immediately return `undefined`. Useful as a performance optimization in case the current working directory is deeply nested in the filesystem.

```js
const path = require('path');
const findUp = require('find-up');

(async () => {
	await findUp(directory => {
		return path.basename(directory) === 'work' ? findUp.stop : 'logo.png';
	});
})();
```

## Related

- [find-up-cli](https://github.com/sindresorhus/find-up-cli) - CLI for this module
- [pkg-up](https://github.com/sindresorhus/pkg-up) - Find the closest package.json file
- [pkg-dir](https://github.com/sindresorhus/pkg-dir) - Find the root directory of an npm package
- [resolve-from](https://github.com/sindresorhus/resolve-from) - Resolve the path of a module like `require.resolve()` but from a given path

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-find-up?utm_source=npm-find-up&utm_medium=referral&utm_campaign=readme">Get professional support for 'find-up' with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
<h1 align="center">
	<br>
	<br>
	<img width="320" src="media/logo.svg" alt="Chalk">
	<br>
	<br>
	<br>
</h1>

> Terminal string styling done right

[![Build Status](https://travis-ci.org/chalk/chalk.svg?branch=master)](https://travis-ci.org/chalk/chalk) [![Coverage Status](https://coveralls.io/repos/github/chalk/chalk/badge.svg?branch=master)](https://coveralls.io/github/chalk/chalk?branch=master) [![npm dependents](https://badgen.net/npm/dependents/chalk)](https://www.npmjs.com/package/chalk?activeTab=dependents) [![Downloads](https://badgen.net/npm/dt/chalk)](https://www.npmjs.com/package/chalk) [![](https://img.shields.io/badge/unicorn-approved-ff69b4.svg)](https://www.youtube.com/watch?v=9auOCbH5Ns4) [![XO code style](https://img.shields.io/badge/code_style-XO-5ed9c7.svg)](https://github.com/xojs/xo) ![TypeScript-ready](https://img.shields.io/npm/types/chalk.svg) [![run on repl.it](https://repl.it/badge/github/chalk/chalk)](https://repl.it/github/chalk/chalk)

<img src="https://cdn.jsdelivr.net/gh/chalk/ansi-styles@8261697c95bf34b6c7767e2cbe9941a851d59385/screenshot.svg" width="900">

<br>

---

<div align="center">
	<p>
		<p>
			<sup>
				Sindre Sorhus' open source work is supported by the community on <a href="https://github.com/sponsors/sindresorhus">GitHub Sponsors</a> and <a href="https://stakes.social/0x44d871aebF0126Bf646753E2C976Aa7e68A66c15">Dev</a>
			</sup>
		</p>
		<sup>Special thanks to:</sup>
		<br>
		<br>
		<a href="https://standardresume.co/tech">
			<img src="https://sindresorhus.com/assets/thanks/standard-resume-logo.svg" width="160"/>
		</a>
		<br>
		<br>
		<a href="https://retool.com/?utm_campaign=sindresorhus">
			<img src="https://sindresorhus.com/assets/thanks/retool-logo.svg" width="230"/>
		</a>
		<br>
		<br>
		<a href="https://doppler.com/?utm_campaign=github_repo&utm_medium=referral&utm_content=chalk&utm_source=github">
			<div>
				<img src="https://dashboard.doppler.com/imgs/logo-long.svg" width="240" alt="Doppler">
			</div>
			<b>All your environment variables, in one place</b>
			<div>
				<span>Stop struggling with scattered API keys, hacking together home-brewed tools,</span>
				<br>
				<span>and avoiding access controls. Keep your team and servers in sync with Doppler.</span>
			</div>
		</a>
		<br>
		<a href="https://uibakery.io/?utm_source=chalk&utm_medium=sponsor&utm_campaign=github">
			<div>
				<img src="https://sindresorhus.com/assets/thanks/uibakery-logo.jpg" width="270" alt="UI Bakery">
			</div>
		</a>
	</p>
</div>

---

<br>

## Highlights

- Expressive API
- Highly performant
- Ability to nest styles
- [256/Truecolor color support](#256-and-truecolor-color-support)
- Auto-detects color support
- Doesn't extend `String.prototype`
- Clean and focused
- Actively maintained
- [Used by ~50,000 packages](https://www.npmjs.com/browse/depended/chalk) as of January 1, 2020

## Install

```console
$ npm install chalk
```

## Usage

```js
const chalk = require('chalk');

console.log(chalk.blue('Hello world!'));
```

Chalk comes with an easy to use composable API where you just chain and nest the styles you want.

```js
const chalk = require('chalk');
const log = console.log;

// Combine styled and normal strings
log(chalk.blue('Hello') + ' World' + chalk.red('!'));

// Compose multiple styles using the chainable API
log(chalk.blue.bgRed.bold('Hello world!'));

// Pass in multiple arguments
log(chalk.blue('Hello', 'World!', 'Foo', 'bar', 'biz', 'baz'));

// Nest styles
log(chalk.red('Hello', chalk.underline.bgBlue('world') + '!'));

// Nest styles of the same type even (color, underline, background)
log(chalk.green(
	'I am a green line ' +
	chalk.blue.underline.bold('with a blue substring') +
	' that becomes green again!'
));

// ES2015 template literal
log(`
CPU: ${chalk.red('90%')}
RAM: ${chalk.green('40%')}
DISK: ${chalk.yellow('70%')}
`);

// ES2015 tagged template literal
log(chalk`
CPU: {red ${cpu.totalPercent}%}
RAM: {green ${ram.used / ram.total * 100}%}
DISK: {rgb(255,131,0) ${disk.used / disk.total * 100}%}
`);

// Use RGB colors in terminal emulators that support it.
log(chalk.keyword('orange')('Yay for orange colored text!'));
log(chalk.rgb(123, 45, 67).underline('Underlined reddish color'));
log(chalk.hex('#DEADED').bold('Bold gray!'));
```

Easily define your own themes:

```js
const chalk = require('chalk');

const error = chalk.bold.red;
const warning = chalk.keyword('orange');

console.log(error('Error!'));
console.log(warning('Warning!'));
```

Take advantage of console.log [string substitution](https://nodejs.org/docs/latest/api/console.html#console_console_log_data_args):

```js
const name = 'Sindre';
console.log(chalk.green('Hello %s'), name);
//=> 'Hello Sindre'
```

## API

### chalk.`<style>[.<style>...](string, [string...])`

Example: `chalk.red.bold.underline('Hello', 'world');`

Chain [styles](#styles) and call the last one as a method with a string argument. Order doesn't matter, and later styles take precedent in case of a conflict. This simply means that `chalk.red.yellow.green` is equivalent to `chalk.green`.

Multiple arguments will be separated by space.

### chalk.level

Specifies the level of color support.

Color support is automatically detected, but you can override it by setting the `level` property. You should however only do this in your own code as it applies globally to all Chalk consumers.

If you need to change this in a reusable module, create a new instance:

```js
const ctx = new chalk.Instance({level: 0});
```

| Level | Description |
| :---: | :--- |
| `0` | All colors disabled |
| `1` | Basic color support (16 colors) |
| `2` | 256 color support |
| `3` | Truecolor support (16 million colors) |

### chalk.supportsColor

Detect whether the terminal [supports color](https://github.com/chalk/supports-color). Used internally and handled for you, but exposed for convenience.

Can be overridden by the user with the flags `--color` and `--no-color`. For situations where using `--color` is not possible, use the environment variable `FORCE_COLOR=1` (level 1), `FORCE_COLOR=2` (level 2), or `FORCE_COLOR=3` (level 3) to forcefully enable color, or `FORCE_COLOR=0` to forcefully disable. The use of `FORCE_COLOR` overrides all other color support checks.

Explicit 256/Truecolor mode can be enabled using the `--color=256` and `--color=16m` flags, respectively.

### chalk.stderr and chalk.stderr.supportsColor

`chalk.stderr` contains a separate instance configured with color support detected for `stderr` stream instead of `stdout`. Override rules from `chalk.supportsColor` apply to this too. `chalk.stderr.supportsColor` is exposed for convenience.

## Styles

### Modifiers

- `reset` - Resets the current color chain.
- `bold` - Make text bold.
- `dim` - Emitting only a small amount of light.
- `italic` - Make text italic. *(Not widely supported)*
- `underline` - Make text underline. *(Not widely supported)*
- `inverse`- Inverse background and foreground colors.
- `hidden` - Prints the text, but makes it invisible.
- `strikethrough` - Puts a horizontal line through the center of the text. *(Not widely supported)*
- `visible`- Prints the text only when Chalk has a color level > 0. Can be useful for things that are purely cosmetic.

### Colors

- `black`
- `red`
- `green`
- `yellow`
- `blue`
- `magenta`
- `cyan`
- `white`
- `blackBright` (alias: `gray`, `grey`)
- `redBright`
- `greenBright`
- `yellowBright`
- `blueBright`
- `magentaBright`
- `cyanBright`
- `whiteBright`

### Background colors

- `bgBlack`
- `bgRed`
- `bgGreen`
- `bgYellow`
- `bgBlue`
- `bgMagenta`
- `bgCyan`
- `bgWhite`
- `bgBlackBright` (alias: `bgGray`, `bgGrey`)
- `bgRedBright`
- `bgGreenBright`
- `bgYellowBright`
- `bgBlueBright`
- `bgMagentaBright`
- `bgCyanBright`
- `bgWhiteBright`

## Tagged template literal

Chalk can be used as a [tagged template literal](https://exploringjs.com/es6/ch_template-literals.html#_tagged-template-literals).

```js
const chalk = require('chalk');

const miles = 18;
const calculateFeet = miles => miles * 5280;

console.log(chalk`
	There are {bold 5280 feet} in a mile.
	In {bold ${miles} miles}, there are {green.bold ${calculateFeet(miles)} feet}.
`);
```

Blocks are delimited by an opening curly brace (`{`), a style, some content, and a closing curly brace (`}`).

Template styles are chained exactly like normal Chalk styles. The following three statements are equivalent:

```js
console.log(chalk.bold.rgb(10, 100, 200)('Hello!'));
console.log(chalk.bold.rgb(10, 100, 200)`Hello!`);
console.log(chalk`{bold.rgb(10,100,200) Hello!}`);
```

Note that function styles (`rgb()`, `hsl()`, `keyword()`, etc.) may not contain spaces between parameters.

All interpolated values (`` chalk`${foo}` ``) are converted to strings via the `.toString()` method. All curly braces (`{` and `}`) in interpolated value strings are escaped.

## 256 and Truecolor color support

Chalk supports 256 colors and [Truecolor](https://gist.github.com/XVilka/8346728) (16 million colors) on supported terminal apps.

Colors are downsampled from 16 million RGB values to an ANSI color format that is supported by the terminal emulator (or by specifying `{level: n}` as a Chalk option). For example, Chalk configured to run at level 1 (basic color support) will downsample an RGB value of #FF0000 (red) to 31 (ANSI escape for red).

Examples:

- `chalk.hex('#DEADED').underline('Hello, world!')`
- `chalk.keyword('orange')('Some orange text')`
- `chalk.rgb(15, 100, 204).inverse('Hello!')`

Background versions of these models are prefixed with `bg` and the first level of the module capitalized (e.g. `keyword` for foreground colors and `bgKeyword` for background colors).

- `chalk.bgHex('#DEADED').underline('Hello, world!')`
- `chalk.bgKeyword('orange')('Some orange text')`
- `chalk.bgRgb(15, 100, 204).inverse('Hello!')`

The following color models can be used:

- [`rgb`](https://en.wikipedia.org/wiki/RGB_color_model) - Example: `chalk.rgb(255, 136, 0).bold('Orange!')`
- [`hex`](https://en.wikipedia.org/wiki/Web_colors#Hex_triplet) - Example: `chalk.hex('#FF8800').bold('Orange!')`
- [`keyword`](https://www.w3.org/wiki/CSS/Properties/color/keywords) (CSS keywords) - Example: `chalk.keyword('orange').bold('Orange!')`
- [`hsl`](https://en.wikipedia.org/wiki/HSL_and_HSV) - Example: `chalk.hsl(32, 100, 50).bold('Orange!')`
- [`hsv`](https://en.wikipedia.org/wiki/HSL_and_HSV) - Example: `chalk.hsv(32, 100, 100).bold('Orange!')`
- [`hwb`](https://en.wikipedia.org/wiki/HWB_color_model) - Example: `chalk.hwb(32, 0, 50).bold('Orange!')`
- [`ansi`](https://en.wikipedia.org/wiki/ANSI_escape_code#3/4_bit) - Example: `chalk.ansi(31).bgAnsi(93)('red on yellowBright')`
- [`ansi256`](https://en.wikipedia.org/wiki/ANSI_escape_code#8-bit) - Example: `chalk.bgAnsi256(194)('Honeydew, more or less')`

## Windows

If you're on Windows, do yourself a favor and use [Windows Terminal](https://github.com/microsoft/terminal) instead of `cmd.exe`.

## Origin story

[colors.js](https://github.com/Marak/colors.js) used to be the most popular string styling module, but it has serious deficiencies like extending `String.prototype` which causes all kinds of [problems](https://github.com/yeoman/yo/issues/68) and the package is unmaintained. Although there are other packages, they either do too much or not enough. Chalk is a clean and focused alternative.

## chalk for enterprise

Available as part of the Tidelift Subscription.

The maintainers of chalk and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-chalk?utm_source=npm-chalk&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)

## Related

- [chalk-cli](https://github.com/chalk/chalk-cli) - CLI for this module
- [ansi-styles](https://github.com/chalk/ansi-styles) - ANSI escape codes for styling strings in the terminal
- [supports-color](https://github.com/chalk/supports-color) - Detect whether a terminal supports color
- [strip-ansi](https://github.com/chalk/strip-ansi) - Strip ANSI escape codes
- [strip-ansi-stream](https://github.com/chalk/strip-ansi-stream) - Strip ANSI escape codes from a stream
- [has-ansi](https://github.com/chalk/has-ansi) - Check if a string has ANSI escape codes
- [ansi-regex](https://github.com/chalk/ansi-regex) - Regular expression for matching ANSI escape codes
- [wrap-ansi](https://github.com/chalk/wrap-ansi) - Wordwrap a string with ANSI escape codes
- [slice-ansi](https://github.com/chalk/slice-ansi) - Slice a string with ANSI escape codes
- [color-convert](https://github.com/qix-/color-convert) - Converts colors between different models
- [chalk-animation](https://github.com/bokub/chalk-animation) - Animate strings in the terminal
- [gradient-string](https://github.com/bokub/gradient-string) - Apply color gradients to strings
- [chalk-pipe](https://github.com/LitoMore/chalk-pipe) - Create chalk style schemes with simpler style strings
- [terminal-link](https://github.com/sindresorhus/terminal-link) - Create clickable links in the terminal

## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Josh Junon](https://github.com/qix-)
# ansi-regex

> Regular expression for matching [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code)


## Install

```
$ npm install ansi-regex
```


## Usage

```js
const ansiRegex = require('ansi-regex');

ansiRegex().test('\u001B[4mcake\u001B[0m');
//=> true

ansiRegex().test('cake');
//=> false

'\u001B[4mcake\u001B[0m'.match(ansiRegex());
//=> ['\u001B[4m', '\u001B[0m']

'\u001B[4mcake\u001B[0m'.match(ansiRegex({onlyFirst: true}));
//=> ['\u001B[4m']

'\u001B]8;;https://github.com\u0007click\u001B]8;;\u0007'.match(ansiRegex());
//=> ['\u001B]8;;https://github.com\u0007', '\u001B]8;;\u0007']
```


## API

### ansiRegex(options?)

Returns a regex for matching ANSI escape codes.

#### options

Type: `object`

##### onlyFirst

Type: `boolean`<br>
Default: `false` *(Matches any ANSI escape codes in a string)*

Match only the first ANSI escape.


## FAQ

### Why do you test for codes not in the ECMA 48 standard?

Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them.

On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of "interrupts" that can mean different things on certain brands of processors, most of which have been phased out.


## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Josh Junon](https://github.com/qix-)


---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-ansi-regex?utm_source=npm-ansi-regex&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# has-flag [![Build Status](https://travis-ci.org/sindresorhus/has-flag.svg?branch=master)](https://travis-ci.org/sindresorhus/has-flag)

> Check if [`argv`](https://nodejs.org/docs/latest/api/process.html#process_process_argv) has a specific flag

Correctly stops looking after an `--` argument terminator.

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-has-flag?utm_source=npm-has-flag&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>

---


## Install

```
$ npm install has-flag
```


## Usage

```js
// foo.js
const hasFlag = require('has-flag');

hasFlag('unicorn');
//=> true

hasFlag('--unicorn');
//=> true

hasFlag('f');
//=> true

hasFlag('-f');
//=> true

hasFlag('foo=bar');
//=> true

hasFlag('foo');
//=> false

hasFlag('rainbow');
//=> false
```

```
$ node foo.js -f --unicorn --foo=bar -- --rainbow
```


## API

### hasFlag(flag, [argv])

Returns a boolean for whether the flag exists.

#### flag

Type: `string`

CLI flag to look for. The `--` prefix is optional.

#### argv

Type: `string[]`<br>
Default: `process.argv`

CLI arguments.


## Security

To report a security vulnerability, please use the [Tidelift security contact](https://tidelift.com/security). Tidelift will coordinate the fix and disclosure.


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# supports-color [![Build Status](https://travis-ci.org/chalk/supports-color.svg?branch=master)](https://travis-ci.org/chalk/supports-color)

> Detect whether a terminal supports color


## Install

```
$ npm install supports-color
```


## Usage

```js
const supportsColor = require('supports-color');

if (supportsColor.stdout) {
	console.log('Terminal stdout supports color');
}

if (supportsColor.stdout.has256) {
	console.log('Terminal stdout supports 256 colors');
}

if (supportsColor.stderr.has16m) {
	console.log('Terminal stderr supports 16 million colors (truecolor)');
}
```


## API

Returns an `Object` with a `stdout` and `stderr` property for testing either streams. Each property is an `Object`, or `false` if color is not supported.

The `stdout`/`stderr` objects specifies a level of support for color through a `.level` property and a corresponding flag:

- `.level = 1` and `.hasBasic = true`: Basic color support (16 colors)
- `.level = 2` and `.has256 = true`: 256 color support
- `.level = 3` and `.has16m = true`: Truecolor support (16 million colors)


## Info

It obeys the `--color` and `--no-color` CLI flags.

For situations where using `--color` is not possible, use the environment variable `FORCE_COLOR=1` (level 1), `FORCE_COLOR=2` (level 2), or `FORCE_COLOR=3` (level 3) to forcefully enable color, or `FORCE_COLOR=0` to forcefully disable. The use of `FORCE_COLOR` overrides all other color support checks.

Explicit 256/Truecolor mode can be enabled using the `--color=256` and `--color=16m` flags, respectively.


## Related

- [supports-color-cli](https://github.com/chalk/supports-color-cli) - CLI for this module
- [chalk](https://github.com/chalk/chalk) - Terminal string styling done right


## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Josh Junon](https://github.com/qix-)


---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-supports-color?utm_source=npm-supports-color&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>

---
# 1.0.0 - 2016-01-07

- Removed: unused speed test
- Added: Automatic routing between previously unsupported conversions
([#27](https://github.com/Qix-/color-convert/pull/27))
- Removed: `xxx2xxx()` and `xxx2xxxRaw()` functions
([#27](https://github.com/Qix-/color-convert/pull/27))
- Removed: `convert()` class
([#27](https://github.com/Qix-/color-convert/pull/27))
- Changed: all functions to lookup dictionary
([#27](https://github.com/Qix-/color-convert/pull/27))
- Changed: `ansi` to `ansi256`
([#27](https://github.com/Qix-/color-convert/pull/27))
- Fixed: argument grouping for functions requiring only one argument
([#27](https://github.com/Qix-/color-convert/pull/27))

# 0.6.0 - 2015-07-23

- Added: methods to handle
[ANSI](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors) 16/256 colors:
  - rgb2ansi16
  - rgb2ansi
  - hsl2ansi16
  - hsl2ansi
  - hsv2ansi16
  - hsv2ansi
  - hwb2ansi16
  - hwb2ansi
  - cmyk2ansi16
  - cmyk2ansi
  - keyword2ansi16
  - keyword2ansi
  - ansi162rgb
  - ansi162hsl
  - ansi162hsv
  - ansi162hwb
  - ansi162cmyk
  - ansi162keyword
  - ansi2rgb
  - ansi2hsl
  - ansi2hsv
  - ansi2hwb
  - ansi2cmyk
  - ansi2keyword
([#18](https://github.com/harthur/color-convert/pull/18))

# 0.5.3 - 2015-06-02

- Fixed: hsl2hsv does not return `NaN` anymore when using `[0,0,0]`
([#15](https://github.com/harthur/color-convert/issues/15))

---

Check out commit logs for older releases
# color-convert

[![Build Status](https://travis-ci.org/Qix-/color-convert.svg?branch=master)](https://travis-ci.org/Qix-/color-convert)

Color-convert is a color conversion library for JavaScript and node.
It converts all ways between `rgb`, `hsl`, `hsv`, `hwb`, `cmyk`, `ansi`, `ansi16`, `hex` strings, and CSS `keyword`s (will round to closest):

```js
var convert = require('color-convert');

convert.rgb.hsl(140, 200, 100);             // [96, 48, 59]
convert.keyword.rgb('blue');                // [0, 0, 255]

var rgbChannels = convert.rgb.channels;     // 3
var cmykChannels = convert.cmyk.channels;   // 4
var ansiChannels = convert.ansi16.channels; // 1
```

# Install

```console
$ npm install color-convert
```

# API

Simply get the property of the _from_ and _to_ conversion that you're looking for.

All functions have a rounded and unrounded variant. By default, return values are rounded. To get the unrounded (raw) results, simply tack on `.raw` to the function.

All 'from' functions have a hidden property called `.channels` that indicates the number of channels the function expects (not including alpha).

```js
var convert = require('color-convert');

// Hex to LAB
convert.hex.lab('DEADBF');         // [ 76, 21, -2 ]
convert.hex.lab.raw('DEADBF');     // [ 75.56213190997677, 20.653827952644754, -2.290532499330533 ]

// RGB to CMYK
convert.rgb.cmyk(167, 255, 4);     // [ 35, 0, 98, 0 ]
convert.rgb.cmyk.raw(167, 255, 4); // [ 34.509803921568626, 0, 98.43137254901961, 0 ]
```

### Arrays
All functions that accept multiple arguments also support passing an array.

Note that this does **not** apply to functions that convert from a color that only requires one value (e.g. `keyword`, `ansi256`, `hex`, etc.)

```js
var convert = require('color-convert');

convert.rgb.hex(123, 45, 67);      // '7B2D43'
convert.rgb.hex([123, 45, 67]);    // '7B2D43'
```

## Routing

Conversions that don't have an _explicitly_ defined conversion (in [conversions.js](conversions.js)), but can be converted by means of sub-conversions (e.g. XYZ -> **RGB** -> CMYK), are automatically routed together. This allows just about any color model supported by `color-convert` to be converted to any other model, so long as a sub-conversion path exists. This is also true for conversions requiring more than one step in between (e.g. LCH -> **LAB** -> **XYZ** -> **RGB** -> Hex).

Keep in mind that extensive conversions _may_ result in a loss of precision, and exist only to be complete. For a list of "direct" (single-step) conversions, see [conversions.js](conversions.js).

# Contribute

If there is a new model you would like to support, or want to add a direct conversion between two existing models, please send us a pull request.

# License
Copyright &copy; 2011-2016, Heather Arthur and Josh Junon. Licensed under the [MIT License](LICENSE).
# path-key [![Build Status](https://travis-ci.org/sindresorhus/path-key.svg?branch=master)](https://travis-ci.org/sindresorhus/path-key)

> Get the [PATH](https://en.wikipedia.org/wiki/PATH_(variable)) environment variable key cross-platform

It's usually `PATH`, but on Windows it can be any casing like `Path`...


## Install

```
$ npm install path-key
```


## Usage

```js
const pathKey = require('path-key');

const key = pathKey();
//=> 'PATH'

const PATH = process.env[key];
//=> '/usr/local/bin:/usr/bin:/bin'
```


## API

### pathKey(options?)

#### options

Type: `object`

##### env

Type: `object`<br>
Default: [`process.env`](https://nodejs.org/api/process.html#process_process_env)

Use a custom environment variables object.

#### platform

Type: `string`<br>
Default: [`process.platform`](https://nodejs.org/api/process.html#process_process_platform)

Get the PATH key for a specific platform.


---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-path-key?utm_source=npm-path-key&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
<!-- To edit this file, edit /src/README.md, not /README.md -->

# style-mod

Minimal CSS module shim for generating CSS rules for sets of style
-declarations and attaching such a set to a document or shadow root.

Using it would look something like this:

```javascript
const {StyleModule} = require("style-mod")
const myModule = new StyleModule({
  "#main": {
    fontFamily: "Georgia, 'Nimbus Roman No9 L'",
    margin: "0"
  },
  ".callout": {
    color: "red",
    fontWeight: "bold",
    "&:hover": {color: "orange"}
  }
})
StyleModule.mount(document, myModule)
```

This code is open source, released under an MIT license.
    
## Documentation

### class StyleModule

Style modules encapsulate a set of CSS rules defined from
JavaScript. Their definitions are only available in a given DOM
root after it has been _mounted_ there with `StyleModule.mount`.

Style modules should be created once and stored somewhere, as
opposed to re-creating them every time you need them. The amount of
CSS rules generated for a given DOM root is bounded by the amount
of style modules that were used. So to avoid leaking rules, don't
create these dynamically, but treat them as one-time allocations.

 * `new `**`StyleModule`**`(spec: Object< Style >, options: ?{finish: ?fn(string) → string})`\
   Create a style module from the given spec.

   When `finish` is given, it is called on regular (non-`@`)
   selectors (after `&` expansion) to compute the final selector.

 * **`getRules`**`() → string`\
   Returns a string containing the module's CSS rules.

 * `static `**`newName`**`() → string`\
   Generate a new unique CSS class name.

 * `static `**`mount`**`(root: Document | ShadowRoot, modules: [StyleModule] | StyleModule, options: ?{nonce: ?string})`\
   Mount the given set of modules in the given DOM root, which ensures
   that the CSS rules defined by the module are available in that
   context.

   Rules are only added to the document once per root.

   Rule order will follow the order of the modules, so that rules from
   modules later in the array take precedence of those from earlier
   modules. If you call this function multiple times for the same root
   in a way that changes the order of already mounted modules, the old
   order will be changed.

   If a Content Security Policy nonce is provided, it is added to
   the `<style>` tag generated by the library.


Where the `Style` type is defined as:

 * **`Style`**`: Object< Style | string >`\
   A style is an object that, in the simple case, maps CSS property
   names to strings holding their values, as in `{color: "red",
   fontWeight: "bold"}`. The property names can be given in
   camel-case—the library will insert a dash before capital letters
   when converting them to CSS.

   If you include an underscore in a property name, it and everything
   after it will be removed from the output, which can be useful when
   providing a property multiple times, for browser compatibility
   reasons.

   A property in a style object can also be a sub-selector, which
   extends the current context to add a pseudo-selector or a child
   selector. Such a property should contain a `&` character, which
   will be replaced by the current selector. For example `{"&:before":
   {content: '"hi"'}}`. Sub-selectors and regular properties can
   freely be mixed in a given object. Any property containing a `&` is
   assumed to be a sub-selector.

   Finally, a property can specify an @-block to be wrapped around the
   styles defined inside the object that's the property's value. For
   example to create a media query you can do `{"@media screen and
   (min-width: 400px)": {...}}`.


<!-- To edit this file, edit /src/README.md, not /README.md -->

# style-mod

Minimal CSS module shim for generating CSS rules for sets of style
-declarations and attaching such a set to a document or shadow root.

Using it would look something like this:

```javascript
const {StyleModule} = require("style-mod")
const myModule = new StyleModule({
  "#main": {
    fontFamily: "Georgia, 'Nimbus Roman No9 L'",
    margin: "0"
  },
  ".callout": {
    color: "red",
    fontWeight: "bold",
    "&:hover": {color: "orange"}
  }
})
StyleModule.mount(document, myModule)
```

This code is open source, released under an MIT license.
    
## Documentation

@StyleModule

Where the `Style` type is defined as:

@Style
# brace-expansion

[Brace expansion](https://www.gnu.org/software/bash/manual/html_node/Brace-Expansion.html), 
as known from sh/bash, in JavaScript.

[![build status](https://secure.travis-ci.org/juliangruber/brace-expansion.svg)](http://travis-ci.org/juliangruber/brace-expansion)
[![downloads](https://img.shields.io/npm/dm/brace-expansion.svg)](https://www.npmjs.org/package/brace-expansion)
[![Greenkeeper badge](https://badges.greenkeeper.io/juliangruber/brace-expansion.svg)](https://greenkeeper.io/)

[![testling badge](https://ci.testling.com/juliangruber/brace-expansion.png)](https://ci.testling.com/juliangruber/brace-expansion)

## Example

```js
var expand = require('brace-expansion');

expand('file-{a,b,c}.jpg')
// => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg']

expand('-v{,,}')
// => ['-v', '-v', '-v']

expand('file{0..2}.jpg')
// => ['file0.jpg', 'file1.jpg', 'file2.jpg']

expand('file-{a..c}.jpg')
// => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg']

expand('file{2..0}.jpg')
// => ['file2.jpg', 'file1.jpg', 'file0.jpg']

expand('file{0..4..2}.jpg')
// => ['file0.jpg', 'file2.jpg', 'file4.jpg']

expand('file-{a..e..2}.jpg')
// => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg']

expand('file{00..10..5}.jpg')
// => ['file00.jpg', 'file05.jpg', 'file10.jpg']

expand('{{A..C},{a..c}}')
// => ['A', 'B', 'C', 'a', 'b', 'c']

expand('ppp{,config,oe{,conf}}')
// => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf']
```

## API

```js
var expand = require('brace-expansion');
```

### var expanded = expand(str)

Return an array of all possible and valid expansions of `str`. If none are
found, `[str]` is returned.

Valid expansions are:

```js
/^(.*,)+(.+)?$/
// {a,b,...}
```

A comma separated list of options, like `{a,b}` or `{a,{b,c}}` or `{,a,}`.

```js
/^-?\d+\.\.-?\d+(\.\.-?\d+)?$/
// {x..y[..incr]}
```

A numeric sequence from `x` to `y` inclusive, with optional increment.
If `x` or `y` start with a leading `0`, all the numbers will be padded
to have equal length. Negative numbers and backwards iteration work too.

```js
/^-?\d+\.\.-?\d+(\.\.-?\d+)?$/
// {x..y[..incr]}
```

An alphabetic sequence from `x` to `y` inclusive, with optional increment.
`x` and `y` must be exactly one character, and if given, `incr` must be a
number.

For compatibility reasons, the string `${` is not eligible for brace expansion.

## Installation

With [npm](https://npmjs.org) do:

```bash
npm install brace-expansion
```

## Contributors

- [Julian Gruber](https://github.com/juliangruber)
- [Isaac Z. Schlueter](https://github.com/isaacs)

## Sponsors

This module is proudly supported by my [Sponsors](https://github.com/juliangruber/sponsors)!

Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my [Patreon](https://www.patreon.com/juliangruber). Not sure how much of my modules you're using? Try [feross/thanks](https://github.com/feross/thanks)!

## License

(MIT)

Copyright (c) 2013 Julian Gruber &lt;julian@juliangruber.com&gt;

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
# fill-range [![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=W8YFZ425KND68) [![NPM version](https://img.shields.io/npm/v/fill-range.svg?style=flat)](https://www.npmjs.com/package/fill-range) [![NPM monthly downloads](https://img.shields.io/npm/dm/fill-range.svg?style=flat)](https://npmjs.org/package/fill-range) [![NPM total downloads](https://img.shields.io/npm/dt/fill-range.svg?style=flat)](https://npmjs.org/package/fill-range) [![Linux Build Status](https://img.shields.io/travis/jonschlinkert/fill-range.svg?style=flat&label=Travis)](https://travis-ci.org/jonschlinkert/fill-range)

> Fill in a range of numbers or letters, optionally passing an increment or `step` to use, or create a regex-compatible range with `options.toRegex`

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save fill-range
```

## Usage

Expands numbers and letters, optionally using a `step` as the last argument. _(Numbers may be defined as JavaScript numbers or strings)_.

```js
const fill = require('fill-range');
// fill(from, to[, step, options]);

console.log(fill('1', '10')); //=> ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
console.log(fill('1', '10', { toRegex: true })); //=> [1-9]|10
```

**Params**

* `from`: **{String|Number}** the number or letter to start with
* `to`: **{String|Number}** the number or letter to end with
* `step`: **{String|Number|Object|Function}** Optionally pass a [step](#optionsstep) to use.
* `options`: **{Object|Function}**: See all available [options](#options)

## Examples

By default, an array of values is returned.

**Alphabetical ranges**

```js
console.log(fill('a', 'e')); //=> ['a', 'b', 'c', 'd', 'e']
console.log(fill('A', 'E')); //=> [ 'A', 'B', 'C', 'D', 'E' ]
```

**Numerical ranges**

Numbers can be defined as actual numbers or strings.

```js
console.log(fill(1, 5));     //=> [ 1, 2, 3, 4, 5 ]
console.log(fill('1', '5')); //=> [ 1, 2, 3, 4, 5 ]
```

**Negative ranges**

Numbers can be defined as actual numbers or strings.

```js
console.log(fill('-5', '-1')); //=> [ '-5', '-4', '-3', '-2', '-1' ]
console.log(fill('-5', '5')); //=> [ '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5' ]
```

**Steps (increments)**

```js
// numerical ranges with increments
console.log(fill('0', '25', 4)); //=> [ '0', '4', '8', '12', '16', '20', '24' ]
console.log(fill('0', '25', 5)); //=> [ '0', '5', '10', '15', '20', '25' ]
console.log(fill('0', '25', 6)); //=> [ '0', '6', '12', '18', '24' ]

// alphabetical ranges with increments
console.log(fill('a', 'z', 4)); //=> [ 'a', 'e', 'i', 'm', 'q', 'u', 'y' ]
console.log(fill('a', 'z', 5)); //=> [ 'a', 'f', 'k', 'p', 'u', 'z' ]
console.log(fill('a', 'z', 6)); //=> [ 'a', 'g', 'm', 's', 'y' ]
```

## Options

### options.step

**Type**: `number` (formatted as a string or number)

**Default**: `undefined`

**Description**: The increment to use for the range. Can be used with letters or numbers.

**Example(s)**

```js
// numbers
console.log(fill('1', '10', 2)); //=> [ '1', '3', '5', '7', '9' ]
console.log(fill('1', '10', 3)); //=> [ '1', '4', '7', '10' ]
console.log(fill('1', '10', 4)); //=> [ '1', '5', '9' ]

// letters
console.log(fill('a', 'z', 5)); //=> [ 'a', 'f', 'k', 'p', 'u', 'z' ]
console.log(fill('a', 'z', 7)); //=> [ 'a', 'h', 'o', 'v' ]
console.log(fill('a', 'z', 9)); //=> [ 'a', 'j', 's' ]
```

### options.strictRanges

**Type**: `boolean`

**Default**: `false`

**Description**: By default, `null` is returned when an invalid range is passed. Enable this option to throw a `RangeError` on invalid ranges.

**Example(s)**

The following are all invalid:

```js
fill('1.1', '2');   // decimals not supported in ranges
fill('a', '2');     // incompatible range values
fill(1, 10, 'foo'); // invalid "step" argument
```

### options.stringify

**Type**: `boolean`

**Default**: `undefined`

**Description**: Cast all returned values to strings. By default, integers are returned as numbers.

**Example(s)**

```js
console.log(fill(1, 5));                    //=> [ 1, 2, 3, 4, 5 ]
console.log(fill(1, 5, { stringify: true })); //=> [ '1', '2', '3', '4', '5' ]
```

### options.toRegex

**Type**: `boolean`

**Default**: `undefined`

**Description**: Create a regex-compatible source string, instead of expanding values to an array.

**Example(s)**

```js
// alphabetical range
console.log(fill('a', 'e', { toRegex: true })); //=> '[a-e]'
// alphabetical with step
console.log(fill('a', 'z', 3, { toRegex: true })); //=> 'a|d|g|j|m|p|s|v|y'
// numerical range
console.log(fill('1', '100', { toRegex: true })); //=> '[1-9]|[1-9][0-9]|100'
// numerical range with zero padding
console.log(fill('000001', '100000', { toRegex: true }));
//=> '0{5}[1-9]|0{4}[1-9][0-9]|0{3}[1-9][0-9]{2}|0{2}[1-9][0-9]{3}|0[1-9][0-9]{4}|100000'
```

### options.transform

**Type**: `function`

**Default**: `undefined`

**Description**: Customize each value in the returned array (or [string](#optionstoRegex)). _(you can also pass this function as the last argument to `fill()`)_.

**Example(s)**

```js
// add zero padding
console.log(fill(1, 5, value => String(value).padStart(4, '0')));
//=> ['0001', '0002', '0003', '0004', '0005']
```

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Contributors

| **Commits** | **Contributor** |  
| --- | --- |  
| 116 | [jonschlinkert](https://github.com/jonschlinkert) |  
| 4   | [paulmillr](https://github.com/paulmillr) |  
| 2   | [realityking](https://github.com/realityking) |  
| 2   | [bluelovers](https://github.com/bluelovers) |  
| 1   | [edorivai](https://github.com/edorivai) |  
| 1   | [wtgtybhertgeghgtwtg](https://github.com/wtgtybhertgeghgtwtg) |  

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

Please consider supporting me on Patreon, or [start your own Patreon page](https://patreon.com/invite/bxpbvm)!

<a href="https://www.patreon.com/jonschlinkert">
<img src="https://c5.patreon.com/external/logo/become_a_patron_button@2x.png" height="50">
</a>

### License

Copyright © 2019, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.8.0, on April 08, 2019._# json-buffer

JSON functions that can convert buffers!

[![build status](https://secure.travis-ci.org/dominictarr/json-buffer.png)](http://travis-ci.org/dominictarr/json-buffer)

[![testling badge](https://ci.testling.com/dominictarr/json-buffer.png)](https://ci.testling.com/dominictarr/json-buffer)

JSON mangles buffers by converting to an array...
which isn't helpful. json-buffers converts to base64 instead,
and deconverts base64 to a buffer.

``` js
var JSONB = require('json-buffer')
var Buffer = require('buffer').Buffer

var str = JSONB.stringify(Buffer.from('hello there!'))

console.log(JSONB.parse(str)) //GET a BUFFER back
```

## License

MIT
# slash [![Build Status](https://travis-ci.org/sindresorhus/slash.svg?branch=master)](https://travis-ci.org/sindresorhus/slash)

> Convert Windows backslash paths to slash paths: `foo\\bar` ➔ `foo/bar`

[Forward-slash paths can be used in Windows](http://superuser.com/a/176395/6877) as long as they're not extended-length paths and don't contain any non-ascii characters.

This was created since the `path` methods in Node.js outputs `\\` paths on Windows.


## Install

```
$ npm install slash
```


## Usage

```js
const path = require('path');
const slash = require('slash');

const string = path.join('foo', 'bar');
// Unix    => foo/bar
// Windows => foo\\bar

slash(string);
// Unix    => foo/bar
// Windows => foo/bar
```


## API

### slash(path)

Type: `string`

Accepts a Windows backslash path and returns a path with forward slashes.


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
v3.0.0 - November 9, 2018

* 0b5a8c7 Breaking: drop support for Node < 6 (#223) (Kai Cataldo)
* a05e9f2 Upgrade: eslint-release@1.0.0 (#220) (Teddy Katz)
* 36ed027 Chore: upgrade coveralls to ^3.0.1 (#213) (Teddy Katz)
* 8667e34 Upgrade: eslint-release@^0.11.1 (#210) (Kevin Partington)

v2.1.0 - January 6, 2018

* 827f314 Update: support node ranges (fixes #89) (#190) (Teddy Katz)

v2.0.2 - November 25, 2017

* 5049ee3 Fix: Remove redundant LICENSE/README names from files (#203) (Kevin Partington)

v2.0.1 - November 10, 2017

* 009f33d Fix: Making sure union type stringification respects compact flag (#199) (Mitermayer Reis)
* 19da935 Use native String.prototype.trim instead of a custom implementation. (#201) (Rouven Weßling)
* e3a011b chore: add mocha.opts to restore custom mocha config (Jason Kurian)
* d888200 chore: adds nyc and a newer version of mocha to accurately report coverage (Jason Kurian)
* 6b210a8 fix: support type expression for @this tag (fixes #181) (#182) (Frédéric Junod)
* 1c4a4c7 fix: Allow array indexes in names (#193) (Tom MacWright)
* 9aed54d Fix incorrect behavior when arrow functions are used as default values (#189) (Gaurab Paul)
* 9efb6ca Upgrade: Use Array.isArray instead of isarray package (#195) (medanat)

v2.0.0 - November 15, 2016

* 7d7c5f1 Breaking: Re-license to Apache 2 (fixes #176) (#178) (Nicholas C. Zakas)
* 5496132 Docs: Update license copyright (Nicholas C. Zakas)

v1.5.0 - October 13, 2016

* e33c6bb Update: Add support for BooleanLiteralType (#173) (Erik Arvidsson)

v1.4.0 - September 13, 2016

* d7426e5 Update: add ability to parse optional properties in typedefs (refs #5) (#174) (ikokostya)

v1.3.0 - August 22, 2016

* 12c7ad9 Update: Add support for numeric and string literal types (fixes #156) (#172) (Andrew Walter)

v1.2.3 - August 16, 2016

* b96a884 Build: Add CI release script (Nicholas C. Zakas)
* 8d9b3c7 Upgrade: Upgrade esutils to v2.0.2 (fixes #170) (#171) (Emeegeemee)

v1.2.2 - May 19, 2016

* ebe0b08 Fix: Support case insensitive tags (fixes #163) (#164) (alberto)
* 8e6d81e Chore: Remove copyright and license from headers (Nicholas C. Zakas)
* 79035c6 Chore: Include jQuery Foundation copyright (Nicholas C. Zakas)
* 06910a7 Fix: Preserve whitespace in default param string values (fixes #157) (Kai Cataldo)

v1.2.1 - March 29, 2016

* 1f54014 Fix: allow hyphens in names (fixes #116) (Kai Cataldo)
* bbee469 Docs: Add issue template (Nicholas C. Zakas)

v1.2.0 - February 19, 2016

* 18136c5 Build: Cleanup build system (Nicholas C. Zakas)
* b082f85 Update: Add support for slash in namepaths (fixes #100) (Ryan Duffy)
* def53a2 Docs: Fix typo in option lineNumbers (Daniel Tschinder)
* e2cbbc5 Update: Bump isarray to v1.0.0 (Shinnosuke Watanabe)
* ae07aa8 Fix: Allow whitespace in optional param with default value (fixes #141) (chris)

v1.1.0 - January 6, 2016

* Build: Switch to Makefile.js (Nicholas C. Zakas)
* New: support name expression for @this tag (fixes #143) (Tim Schaub)
* Build: Update ESLint settings (Nicholas C. Zakas)

v1.0.0 - December 21, 2015

* New: parse caption tags in examples into separate property. (fixes #131) (Tom MacWright)

v0.7.2 - November 27, 2015

* Fix: Line numbers for some tags (fixes #138) Fixing issue where input was not consumed via advance() but was skipped when parsing tags resulting in sometimes incorrect reported lineNumber. (TEHEK)
* Build: Add missing linefix package (Nicholas C. Zakas)

v0.7.1 - November 13, 2015

* Update: Begin switch to Makefile.js (Nicholas C. Zakas)
* Fix: permit return tag without type (fixes #136) (Tom MacWright)
* Fix: package.json homepage field (Bogdan Chadkin)
* Fix: Parse array default syntax. Fixes #133 (Tom MacWright)
* Fix: Last tag always has \n in the description (fixes #87) (Burak Yigit Kaya)
* Docs: Add changelog (Nicholas C. Zakas)

v0.7.0 - September 21, 2015

* Docs: Update README with new info (fixes #127) (Nicholas C. Zakas)
* Fix: Parsing fix for param with arrays and properties (fixes #111) (Gyandeep Singh)
* Build: Add travis build (fixes #123) (Gyandeep Singh)
* Fix: Parsing of parameter name without a type (fixes #120) (Gyandeep Singh)
* New: added preserveWhitespace option (Aleks Totic)
* New: Add "files" entry to only deploy select files (Rob Loach)
* New: Add support and tests for typedefs. Refs #5 (Tom MacWright)
[![NPM version][npm-image]][npm-url]
[![build status][travis-image]][travis-url]
[![Test coverage][coveralls-image]][coveralls-url]
[![Downloads][downloads-image]][downloads-url]
[![Join the chat at https://gitter.im/eslint/doctrine](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/eslint/doctrine?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

# Doctrine

Doctrine is a [JSDoc](http://usejsdoc.org) parser that parses documentation comments from JavaScript (you need to pass in the comment, not a whole JavaScript file).

## Installation

You can install Doctrine using [npm](https://npmjs.com):

```
$ npm install doctrine --save-dev
```

Doctrine can also be used in web browsers using [Browserify](http://browserify.org).

## Usage

Require doctrine inside of your JavaScript:

```js
var doctrine = require("doctrine");
```

### parse()

The primary method is `parse()`, which accepts two arguments: the JSDoc comment to parse and an optional options object. The available options are:

* `unwrap` - set to `true` to delete the leading `/**`, any `*` that begins a line, and the trailing `*/` from the source text. Default: `false`.
* `tags` - an array of tags to return. When specified, Doctrine returns only tags in this array. For example, if `tags` is `["param"]`, then only `@param` tags will be returned. Default: `null`.
* `recoverable` - set to `true` to keep parsing even when syntax errors occur. Default: `false`.
* `sloppy` - set to `true` to allow optional parameters to be specified in brackets (`@param {string} [foo]`). Default: `false`.
* `lineNumbers` - set to `true` to add `lineNumber` to each node, specifying the line on which the node is found in the source. Default: `false`.
* `range` - set to `true` to add `range` to each node, specifying the start and end index of the node in the original comment. Default: `false`.

Here's a simple example:

```js
var ast = doctrine.parse(
    [
        "/**",
        " * This function comment is parsed by doctrine",
        " * @param {{ok:String}} userName",
        "*/"
    ].join('\n'), { unwrap: true });
```

This example returns the following AST:

    {
        "description": "This function comment is parsed by doctrine",
        "tags": [
            {
                "title": "param",
                "description": null,
                "type": {
                    "type": "RecordType",
                    "fields": [
                        {
                            "type": "FieldType",
                            "key": "ok",
                            "value": {
                                "type": "NameExpression",
                                "name": "String"
                            }
                        }
                    ]
                },
                "name": "userName"
            }
        ]
    }

See the [demo page](http://eslint.org/doctrine/demo/) more detail.

## Team

These folks keep the project moving and are resources for help:

* Nicholas C. Zakas ([@nzakas](https://github.com/nzakas)) - project lead
* Yusuke Suzuki ([@constellation](https://github.com/constellation)) - reviewer

## Contributing

Issues and pull requests will be triaged and responded to as quickly as possible. We operate under the [ESLint Contributor Guidelines](http://eslint.org/docs/developer-guide/contributing), so please be sure to read them before contributing. If you're not sure where to dig in, check out the [issues](https://github.com/eslint/doctrine/issues).

## Frequently Asked Questions

### Can I pass a whole JavaScript file to Doctrine?

No. Doctrine can only parse JSDoc comments, so you'll need to pass just the JSDoc comment to Doctrine in order to work.


### License

#### doctrine

Copyright JS Foundation and other contributors, https://js.foundation

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

#### esprima

some of functions is derived from esprima

Copyright (C) 2012, 2011 [Ariya Hidayat](http://ariya.ofilabs.com/about)
 (twitter: [@ariyahidayat](http://twitter.com/ariyahidayat)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


#### closure-compiler

some of extensions is derived from closure-compiler

Apache License
Version 2.0, January 2004
http://www.apache.org/licenses/


### Where to ask for help?

Join our [Chatroom](https://gitter.im/eslint/doctrine)

[npm-image]: https://img.shields.io/npm/v/doctrine.svg?style=flat-square
[npm-url]: https://www.npmjs.com/package/doctrine
[travis-image]: https://img.shields.io/travis/eslint/doctrine/master.svg?style=flat-square
[travis-url]: https://travis-ci.org/eslint/doctrine
[coveralls-image]: https://img.shields.io/coveralls/eslint/doctrine/master.svg?style=flat-square
[coveralls-url]: https://coveralls.io/r/eslint/doctrine?branch=master
[downloads-image]: http://img.shields.io/npm/dm/doctrine.svg?style=flat-square
[downloads-url]: https://www.npmjs.com/package/doctrine
semver(1) -- The semantic versioner for npm
===========================================

## Install

```bash
npm install semver
````

## Usage

As a node module:

```js
const semver = require('semver')

semver.valid('1.2.3') // '1.2.3'
semver.valid('a.b.c') // null
semver.clean('  =v1.2.3   ') // '1.2.3'
semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true
semver.gt('1.2.3', '9.8.7') // false
semver.lt('1.2.3', '9.8.7') // true
semver.minVersion('>=1.0.0') // '1.0.0'
semver.valid(semver.coerce('v2')) // '2.0.0'
semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7'
```

You can also just load the module for the function that you care about, if
you'd like to minimize your footprint.

```js
// load the whole API at once in a single object
const semver = require('semver')

// or just load the bits you need
// all of them listed here, just pick and choose what you want

// classes
const SemVer = require('semver/classes/semver')
const Comparator = require('semver/classes/comparator')
const Range = require('semver/classes/range')

// functions for working with versions
const semverParse = require('semver/functions/parse')
const semverValid = require('semver/functions/valid')
const semverClean = require('semver/functions/clean')
const semverInc = require('semver/functions/inc')
const semverDiff = require('semver/functions/diff')
const semverMajor = require('semver/functions/major')
const semverMinor = require('semver/functions/minor')
const semverPatch = require('semver/functions/patch')
const semverPrerelease = require('semver/functions/prerelease')
const semverCompare = require('semver/functions/compare')
const semverRcompare = require('semver/functions/rcompare')
const semverCompareLoose = require('semver/functions/compare-loose')
const semverCompareBuild = require('semver/functions/compare-build')
const semverSort = require('semver/functions/sort')
const semverRsort = require('semver/functions/rsort')

// low-level comparators between versions
const semverGt = require('semver/functions/gt')
const semverLt = require('semver/functions/lt')
const semverEq = require('semver/functions/eq')
const semverNeq = require('semver/functions/neq')
const semverGte = require('semver/functions/gte')
const semverLte = require('semver/functions/lte')
const semverCmp = require('semver/functions/cmp')
const semverCoerce = require('semver/functions/coerce')

// working with ranges
const semverSatisfies = require('semver/functions/satisfies')
const semverMaxSatisfying = require('semver/ranges/max-satisfying')
const semverMinSatisfying = require('semver/ranges/min-satisfying')
const semverToComparators = require('semver/ranges/to-comparators')
const semverMinVersion = require('semver/ranges/min-version')
const semverValidRange = require('semver/ranges/valid')
const semverOutside = require('semver/ranges/outside')
const semverGtr = require('semver/ranges/gtr')
const semverLtr = require('semver/ranges/ltr')
const semverIntersects = require('semver/ranges/intersects')
const simplifyRange = require('semver/ranges/simplify')
const rangeSubset = require('semver/ranges/subset')
```

As a command-line utility:

```
$ semver -h

A JavaScript implementation of the https://semver.org/ specification
Copyright Isaac Z. Schlueter

Usage: semver [options] <version> [<version> [...]]
Prints valid versions sorted by SemVer precedence

Options:
-r --range <range>
        Print versions that match the specified range.

-i --increment [<level>]
        Increment a version by the specified level.  Level can
        be one of: major, minor, patch, premajor, preminor,
        prepatch, or prerelease.  Default level is 'patch'.
        Only one version may be specified.

--preid <identifier>
        Identifier to be used to prefix premajor, preminor,
        prepatch or prerelease version increments.

-l --loose
        Interpret versions and ranges loosely

-n <0|1>
        This is the base to be used for the prerelease identifier.

-p --include-prerelease
        Always include prerelease versions in range matching

-c --coerce
        Coerce a string into SemVer if possible
        (does not imply --loose)

--rtl
        Coerce version strings right to left

--ltr
        Coerce version strings left to right (default)

Program exits successfully if any valid version satisfies
all supplied ranges, and prints all satisfying versions.

If no satisfying versions are found, then exits failure.

Versions are printed in ascending order, so supplying
multiple versions to the utility will just sort them.
```

## Versions

A "version" is described by the `v2.0.0` specification found at
<https://semver.org/>.

A leading `"="` or `"v"` character is stripped off and ignored.

## Ranges

A `version range` is a set of `comparators` which specify versions
that satisfy the range.

A `comparator` is composed of an `operator` and a `version`.  The set
of primitive `operators` is:

* `<` Less than
* `<=` Less than or equal to
* `>` Greater than
* `>=` Greater than or equal to
* `=` Equal.  If no operator is specified, then equality is assumed,
  so this operator is optional, but MAY be included.

For example, the comparator `>=1.2.7` would match the versions
`1.2.7`, `1.2.8`, `2.5.3`, and `1.3.9`, but not the versions `1.2.6`
or `1.1.0`. The comparator `>1` is equivalent to `>=2.0.0` and
would match the versions `2.0.0` and `3.1.0`, but not the versions
`1.0.1` or `1.1.0`.

Comparators can be joined by whitespace to form a `comparator set`,
which is satisfied by the **intersection** of all of the comparators
it includes.

A range is composed of one or more comparator sets, joined by `||`.  A
version matches a range if and only if every comparator in at least
one of the `||`-separated comparator sets is satisfied by the version.

For example, the range `>=1.2.7 <1.3.0` would match the versions
`1.2.7`, `1.2.8`, and `1.2.99`, but not the versions `1.2.6`, `1.3.0`,
or `1.1.0`.

The range `1.2.7 || >=1.2.9 <2.0.0` would match the versions `1.2.7`,
`1.2.9`, and `1.4.6`, but not the versions `1.2.8` or `2.0.0`.

### Prerelease Tags

If a version has a prerelease tag (for example, `1.2.3-alpha.3`) then
it will only be allowed to satisfy comparator sets if at least one
comparator with the same `[major, minor, patch]` tuple also has a
prerelease tag.

For example, the range `>1.2.3-alpha.3` would be allowed to match the
version `1.2.3-alpha.7`, but it would *not* be satisfied by
`3.4.5-alpha.9`, even though `3.4.5-alpha.9` is technically "greater
than" `1.2.3-alpha.3` according to the SemVer sort rules.  The version
range only accepts prerelease tags on the `1.2.3` version.  The
version `3.4.5` *would* satisfy the range, because it does not have a
prerelease flag, and `3.4.5` is greater than `1.2.3-alpha.7`.

The purpose for this behavior is twofold.  First, prerelease versions
frequently are updated very quickly, and contain many breaking changes
that are (by the author's design) not yet fit for public consumption.
Therefore, by default, they are excluded from range matching
semantics.

Second, a user who has opted into using a prerelease version has
clearly indicated the intent to use *that specific* set of
alpha/beta/rc versions.  By including a prerelease tag in the range,
the user is indicating that they are aware of the risk.  However, it
is still not appropriate to assume that they have opted into taking a
similar risk on the *next* set of prerelease versions.

Note that this behavior can be suppressed (treating all prerelease
versions as if they were normal versions, for the purpose of range
matching) by setting the `includePrerelease` flag on the options
object to any
[functions](https://github.com/npm/node-semver#functions) that do
range matching.

#### Prerelease Identifiers

The method `.inc` takes an additional `identifier` string argument that
will append the value of the string as a prerelease identifier:

```javascript
semver.inc('1.2.3', 'prerelease', 'beta')
// '1.2.4-beta.0'
```

command-line example:

```bash
$ semver 1.2.3 -i prerelease --preid beta
1.2.4-beta.0
```

Which then can be used to increment further:

```bash
$ semver 1.2.4-beta.0 -i prerelease
1.2.4-beta.1
```

#### Prerelease Identifier Base

The method `.inc` takes an optional parameter 'identifierBase' string
that will let you let your prerelease number as zero-based or one-based.
Set to `false` to omit the prerelease number altogether.
If you do not specify this parameter, it will default to zero-based.

```javascript
semver.inc('1.2.3', 'prerelease', 'beta', '1')
// '1.2.4-beta.1'
```

```javascript
semver.inc('1.2.3', 'prerelease', 'beta', false)
// '1.2.4-beta'
```

command-line example:

```bash
$ semver 1.2.3 -i prerelease --preid beta -n 1
1.2.4-beta.1
```

```bash
$ semver 1.2.3 -i prerelease --preid beta -n false
1.2.4-beta
```

### Advanced Range Syntax

Advanced range syntax desugars to primitive comparators in
deterministic ways.

Advanced ranges may be combined in the same way as primitive
comparators using white space or `||`.

#### Hyphen Ranges `X.Y.Z - A.B.C`

Specifies an inclusive set.

* `1.2.3 - 2.3.4` := `>=1.2.3 <=2.3.4`

If a partial version is provided as the first version in the inclusive
range, then the missing pieces are replaced with zeroes.

* `1.2 - 2.3.4` := `>=1.2.0 <=2.3.4`

If a partial version is provided as the second version in the
inclusive range, then all versions that start with the supplied parts
of the tuple are accepted, but nothing that would be greater than the
provided tuple parts.

* `1.2.3 - 2.3` := `>=1.2.3 <2.4.0-0`
* `1.2.3 - 2` := `>=1.2.3 <3.0.0-0`

#### X-Ranges `1.2.x` `1.X` `1.2.*` `*`

Any of `X`, `x`, or `*` may be used to "stand in" for one of the
numeric values in the `[major, minor, patch]` tuple.

* `*` := `>=0.0.0` (Any non-prerelease version satisfies, unless
  `includePrerelease` is specified, in which case any version at all
  satisfies)
* `1.x` := `>=1.0.0 <2.0.0-0` (Matching major version)
* `1.2.x` := `>=1.2.0 <1.3.0-0` (Matching major and minor versions)

A partial version range is treated as an X-Range, so the special
character is in fact optional.

* `""` (empty string) := `*` := `>=0.0.0`
* `1` := `1.x.x` := `>=1.0.0 <2.0.0-0`
* `1.2` := `1.2.x` := `>=1.2.0 <1.3.0-0`

#### Tilde Ranges `~1.2.3` `~1.2` `~1`

Allows patch-level changes if a minor version is specified on the
comparator.  Allows minor-level changes if not.

* `~1.2.3` := `>=1.2.3 <1.(2+1).0` := `>=1.2.3 <1.3.0-0`
* `~1.2` := `>=1.2.0 <1.(2+1).0` := `>=1.2.0 <1.3.0-0` (Same as `1.2.x`)
* `~1` := `>=1.0.0 <(1+1).0.0` := `>=1.0.0 <2.0.0-0` (Same as `1.x`)
* `~0.2.3` := `>=0.2.3 <0.(2+1).0` := `>=0.2.3 <0.3.0-0`
* `~0.2` := `>=0.2.0 <0.(2+1).0` := `>=0.2.0 <0.3.0-0` (Same as `0.2.x`)
* `~0` := `>=0.0.0 <(0+1).0.0` := `>=0.0.0 <1.0.0-0` (Same as `0.x`)
* `~1.2.3-beta.2` := `>=1.2.3-beta.2 <1.3.0-0` Note that prereleases in
  the `1.2.3` version will be allowed, if they are greater than or
  equal to `beta.2`.  So, `1.2.3-beta.4` would be allowed, but
  `1.2.4-beta.2` would not, because it is a prerelease of a
  different `[major, minor, patch]` tuple.

#### Caret Ranges `^1.2.3` `^0.2.5` `^0.0.4`

Allows changes that do not modify the left-most non-zero element in the
`[major, minor, patch]` tuple.  In other words, this allows patch and
minor updates for versions `1.0.0` and above, patch updates for
versions `0.X >=0.1.0`, and *no* updates for versions `0.0.X`.

Many authors treat a `0.x` version as if the `x` were the major
"breaking-change" indicator.

Caret ranges are ideal when an author may make breaking changes
between `0.2.4` and `0.3.0` releases, which is a common practice.
However, it presumes that there will *not* be breaking changes between
`0.2.4` and `0.2.5`.  It allows for changes that are presumed to be
additive (but non-breaking), according to commonly observed practices.

* `^1.2.3` := `>=1.2.3 <2.0.0-0`
* `^0.2.3` := `>=0.2.3 <0.3.0-0`
* `^0.0.3` := `>=0.0.3 <0.0.4-0`
* `^1.2.3-beta.2` := `>=1.2.3-beta.2 <2.0.0-0` Note that prereleases in
  the `1.2.3` version will be allowed, if they are greater than or
  equal to `beta.2`.  So, `1.2.3-beta.4` would be allowed, but
  `1.2.4-beta.2` would not, because it is a prerelease of a
  different `[major, minor, patch]` tuple.
* `^0.0.3-beta` := `>=0.0.3-beta <0.0.4-0`  Note that prereleases in the
  `0.0.3` version *only* will be allowed, if they are greater than or
  equal to `beta`.  So, `0.0.3-pr.2` would be allowed.

When parsing caret ranges, a missing `patch` value desugars to the
number `0`, but will allow flexibility within that value, even if the
major and minor versions are both `0`.

* `^1.2.x` := `>=1.2.0 <2.0.0-0`
* `^0.0.x` := `>=0.0.0 <0.1.0-0`
* `^0.0` := `>=0.0.0 <0.1.0-0`

A missing `minor` and `patch` values will desugar to zero, but also
allow flexibility within those values, even if the major version is
zero.

* `^1.x` := `>=1.0.0 <2.0.0-0`
* `^0.x` := `>=0.0.0 <1.0.0-0`

### Range Grammar

Putting all this together, here is a Backus-Naur grammar for ranges,
for the benefit of parser authors:

```bnf
range-set  ::= range ( logical-or range ) *
logical-or ::= ( ' ' ) * '||' ( ' ' ) *
range      ::= hyphen | simple ( ' ' simple ) * | ''
hyphen     ::= partial ' - ' partial
simple     ::= primitive | partial | tilde | caret
primitive  ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial
partial    ::= xr ( '.' xr ( '.' xr qualifier ? )? )?
xr         ::= 'x' | 'X' | '*' | nr
nr         ::= '0' | ['1'-'9'] ( ['0'-'9'] ) *
tilde      ::= '~' partial
caret      ::= '^' partial
qualifier  ::= ( '-' pre )? ( '+' build )?
pre        ::= parts
build      ::= parts
parts      ::= part ( '.' part ) *
part       ::= nr | [-0-9A-Za-z]+
```

## Functions

All methods and classes take a final `options` object argument.  All
options in this object are `false` by default.  The options supported
are:

- `loose`  Be more forgiving about not-quite-valid semver strings.
  (Any resulting output will always be 100% strict compliant, of
  course.)  For backwards compatibility reasons, if the `options`
  argument is a boolean value instead of an object, it is interpreted
  to be the `loose` param.
- `includePrerelease`  Set to suppress the [default
  behavior](https://github.com/npm/node-semver#prerelease-tags) of
  excluding prerelease tagged versions from ranges unless they are
  explicitly opted into.

Strict-mode Comparators and Ranges will be strict about the SemVer
strings that they parse.

* `valid(v)`: Return the parsed version, or null if it's not valid.
* `inc(v, release)`: Return the version incremented by the release
  type (`major`,   `premajor`, `minor`, `preminor`, `patch`,
  `prepatch`, or `prerelease`), or null if it's not valid
  * `premajor` in one call will bump the version up to the next major
    version and down to a prerelease of that major version.
    `preminor`, and `prepatch` work the same way.
  * If called from a non-prerelease version, the `prerelease` will work the
    same as `prepatch`. It increments the patch version, then makes a
    prerelease. If the input version is already a prerelease it simply
    increments it.
* `prerelease(v)`: Returns an array of prerelease components, or null
  if none exist. Example: `prerelease('1.2.3-alpha.1') -> ['alpha', 1]`
* `major(v)`: Return the major version number.
* `minor(v)`: Return the minor version number.
* `patch(v)`: Return the patch version number.
* `intersects(r1, r2, loose)`: Return true if the two supplied ranges
  or comparators intersect.
* `parse(v)`: Attempt to parse a string as a semantic version, returning either
  a `SemVer` object or `null`.

### Comparison

* `gt(v1, v2)`: `v1 > v2`
* `gte(v1, v2)`: `v1 >= v2`
* `lt(v1, v2)`: `v1 < v2`
* `lte(v1, v2)`: `v1 <= v2`
* `eq(v1, v2)`: `v1 == v2` This is true if they're logically equivalent,
  even if they're not the exact same string.  You already know how to
  compare strings.
* `neq(v1, v2)`: `v1 != v2` The opposite of `eq`.
* `cmp(v1, comparator, v2)`: Pass in a comparison string, and it'll call
  the corresponding function above.  `"==="` and `"!=="` do simple
  string comparison, but are included for completeness.  Throws if an
  invalid comparison string is provided.
* `compare(v1, v2)`: Return `0` if `v1 == v2`, or `1` if `v1` is greater, or `-1` if
  `v2` is greater.  Sorts in ascending order if passed to `Array.sort()`.
* `rcompare(v1, v2)`: The reverse of compare.  Sorts an array of versions
  in descending order when passed to `Array.sort()`.
* `compareBuild(v1, v2)`: The same as `compare` but considers `build` when two versions
  are equal.  Sorts in ascending order if passed to `Array.sort()`.
  `v2` is greater.  Sorts in ascending order if passed to `Array.sort()`.
* `diff(v1, v2)`: Returns difference between two versions by the release type
  (`major`, `premajor`, `minor`, `preminor`, `patch`, `prepatch`, or `prerelease`),
  or null if the versions are the same.

### Comparators

* `intersects(comparator)`: Return true if the comparators intersect

### Ranges

* `validRange(range)`: Return the valid range or null if it's not valid
* `satisfies(version, range)`: Return true if the version satisfies the
  range.
* `maxSatisfying(versions, range)`: Return the highest version in the list
  that satisfies the range, or `null` if none of them do.
* `minSatisfying(versions, range)`: Return the lowest version in the list
  that satisfies the range, or `null` if none of them do.
* `minVersion(range)`: Return the lowest version that can possibly match
  the given range.
* `gtr(version, range)`: Return `true` if version is greater than all the
  versions possible in the range.
* `ltr(version, range)`: Return `true` if version is less than all the
  versions possible in the range.
* `outside(version, range, hilo)`: Return true if the version is outside
  the bounds of the range in either the high or low direction.  The
  `hilo` argument must be either the string `'>'` or `'<'`.  (This is
  the function called by `gtr` and `ltr`.)
* `intersects(range)`: Return true if any of the ranges comparators intersect
* `simplifyRange(versions, range)`: Return a "simplified" range that
  matches the same items in `versions` list as the range specified.  Note
  that it does *not* guarantee that it would match the same versions in all
  cases, only for the set of versions provided.  This is useful when
  generating ranges by joining together multiple versions with `||`
  programmatically, to provide the user with something a bit more
  ergonomic.  If the provided range is shorter in string-length than the
  generated range, then that is returned.
* `subset(subRange, superRange)`: Return `true` if the `subRange` range is
  entirely contained by the `superRange` range.

Note that, since ranges may be non-contiguous, a version might not be
greater than a range, less than a range, *or* satisfy a range!  For
example, the range `1.2 <1.2.9 || >2.0.0` would have a hole from `1.2.9`
until `2.0.0`, so the version `1.2.10` would not be greater than the
range (because `2.0.1` satisfies, which is higher), nor less than the
range (since `1.2.8` satisfies, which is lower), and it also does not
satisfy the range.

If you want to know if a version satisfies or does not satisfy a
range, use the `satisfies(version, range)` function.

### Coercion

* `coerce(version, options)`: Coerces a string to semver if possible

This aims to provide a very forgiving translation of a non-semver string to
semver. It looks for the first digit in a string, and consumes all
remaining characters which satisfy at least a partial semver (e.g., `1`,
`1.2`, `1.2.3`) up to the max permitted length (256 characters).  Longer
versions are simply truncated (`4.6.3.9.2-alpha2` becomes `4.6.3`).  All
surrounding text is simply ignored (`v3.4 replaces v3.3.1` becomes
`3.4.0`).  Only text which lacks digits will fail coercion (`version one`
is not valid).  The maximum  length for any semver component considered for
coercion is 16 characters; longer components will be ignored
(`10000000000000000.4.7.4` becomes `4.7.4`).  The maximum value for any
semver component is `Number.MAX_SAFE_INTEGER || (2**53 - 1)`; higher value
components are invalid (`9999999999999999.4.7.4` is likely invalid).

If the `options.rtl` flag is set, then `coerce` will return the right-most
coercible tuple that does not share an ending index with a longer coercible
tuple.  For example, `1.2.3.4` will return `2.3.4` in rtl mode, not
`4.0.0`.  `1.2.3/4` will return `4.0.0`, because the `4` is not a part of
any other overlapping SemVer tuple.

If the `options.includePrerelease` flag is set, then the `coerce` result will contain
prerelease and build parts of a version.  For example, `1.2.3.4-rc.1+rev.2`
will preserve prerelease `rc.1` and build `rev.2` in the result.

### Clean

* `clean(version)`: Clean a string to be a valid semver if possible

This will return a cleaned and trimmed semver version. If the provided
version is not valid a null will be returned. This does not work for
ranges.

ex.
* `s.clean(' = v 2.1.5foo')`: `null`
* `s.clean(' = v 2.1.5foo', { loose: true })`: `'2.1.5-foo'`
* `s.clean(' = v 2.1.5-foo')`: `null`
* `s.clean(' = v 2.1.5-foo', { loose: true })`: `'2.1.5-foo'`
* `s.clean('=v2.1.5')`: `'2.1.5'`
* `s.clean('  =v2.1.5')`: `'2.1.5'`
* `s.clean('      2.1.5   ')`: `'2.1.5'`
* `s.clean('~1.0.0')`: `null`

## Constants

As a convenience, helper constants are exported to provide information about what `node-semver` supports:

### `RELEASE_TYPES`

- major
- premajor
- minor
- preminor
- patch
- prepatch
- prerelease

```
const semver = require('semver');

if (semver.RELEASE_TYPES.includes(arbitraryUserInput)) {
  console.log('This is a valid release type!');
} else {
  console.warn('This is NOT a valid release type!');
}
```

### `SEMVER_SPEC_VERSION`

2.0.0

```
const semver = require('semver');

console.log('We are currently using the semver specification version:', semver.SEMVER_SPEC_VERSION);
```

## Exported Modules

<!--
TODO: Make sure that all of these items are documented (classes aren't,
eg), and then pull the module name into the documentation for that specific
thing.
-->

You may pull in just the part of this semver utility that you need, if you
are sensitive to packing and tree-shaking concerns.  The main
`require('semver')` export uses getter functions to lazily load the parts
of the API that are used.

The following modules are available:

* `require('semver')`
* `require('semver/classes')`
* `require('semver/classes/comparator')`
* `require('semver/classes/range')`
* `require('semver/classes/semver')`
* `require('semver/functions/clean')`
* `require('semver/functions/cmp')`
* `require('semver/functions/coerce')`
* `require('semver/functions/compare')`
* `require('semver/functions/compare-build')`
* `require('semver/functions/compare-loose')`
* `require('semver/functions/diff')`
* `require('semver/functions/eq')`
* `require('semver/functions/gt')`
* `require('semver/functions/gte')`
* `require('semver/functions/inc')`
* `require('semver/functions/lt')`
* `require('semver/functions/lte')`
* `require('semver/functions/major')`
* `require('semver/functions/minor')`
* `require('semver/functions/neq')`
* `require('semver/functions/parse')`
* `require('semver/functions/patch')`
* `require('semver/functions/prerelease')`
* `require('semver/functions/rcompare')`
* `require('semver/functions/rsort')`
* `require('semver/functions/satisfies')`
* `require('semver/functions/sort')`
* `require('semver/functions/valid')`
* `require('semver/ranges/gtr')`
* `require('semver/ranges/intersects')`
* `require('semver/ranges/ltr')`
* `require('semver/ranges/max-satisfying')`
* `require('semver/ranges/min-satisfying')`
* `require('semver/ranges/min-version')`
* `require('semver/ranges/outside')`
* `require('semver/ranges/to-comparators')`
* `require('semver/ranges/valid')`

# minimatch

A minimal matching utility.

[![Build Status](https://travis-ci.org/isaacs/minimatch.svg?branch=master)](http://travis-ci.org/isaacs/minimatch)


This is the matching library used internally by npm.

It works by converting glob expressions into JavaScript `RegExp`
objects.

## Usage

```javascript
var minimatch = require("minimatch")

minimatch("bar.foo", "*.foo") // true!
minimatch("bar.foo", "*.bar") // false!
minimatch("bar.foo", "*.+(bar|foo)", { debug: true }) // true, and noisy!
```

## Features

Supports these glob features:

* Brace Expansion
* Extended glob matching
* "Globstar" `**` matching

See:

* `man sh`
* `man bash`
* `man 3 fnmatch`
* `man 5 gitignore`

## Minimatch Class

Create a minimatch object by instantiating the `minimatch.Minimatch` class.

```javascript
var Minimatch = require("minimatch").Minimatch
var mm = new Minimatch(pattern, options)
```

### Properties

* `pattern` The original pattern the minimatch object represents.
* `options` The options supplied to the constructor.
* `set` A 2-dimensional array of regexp or string expressions.
  Each row in the
  array corresponds to a brace-expanded pattern.  Each item in the row
  corresponds to a single path-part.  For example, the pattern
  `{a,b/c}/d` would expand to a set of patterns like:

        [ [ a, d ]
        , [ b, c, d ] ]

    If a portion of the pattern doesn't have any "magic" in it
    (that is, it's something like `"foo"` rather than `fo*o?`), then it
    will be left as a string rather than converted to a regular
    expression.

* `regexp` Created by the `makeRe` method.  A single regular expression
  expressing the entire pattern.  This is useful in cases where you wish
  to use the pattern somewhat like `fnmatch(3)` with `FNM_PATH` enabled.
* `negate` True if the pattern is negated.
* `comment` True if the pattern is a comment.
* `empty` True if the pattern is `""`.

### Methods

* `makeRe` Generate the `regexp` member if necessary, and return it.
  Will return `false` if the pattern is invalid.
* `match(fname)` Return true if the filename matches the pattern, or
  false otherwise.
* `matchOne(fileArray, patternArray, partial)` Take a `/`-split
  filename, and match it against a single row in the `regExpSet`.  This
  method is mainly for internal use, but is exposed so that it can be
  used by a glob-walker that needs to avoid excessive filesystem calls.

All other methods are internal, and will be called as necessary.

### minimatch(path, pattern, options)

Main export.  Tests a path against the pattern using the options.

```javascript
var isJS = minimatch(file, "*.js", { matchBase: true })
```

### minimatch.filter(pattern, options)

Returns a function that tests its
supplied argument, suitable for use with `Array.filter`.  Example:

```javascript
var javascripts = fileList.filter(minimatch.filter("*.js", {matchBase: true}))
```

### minimatch.match(list, pattern, options)

Match against the list of
files, in the style of fnmatch or glob.  If nothing is matched, and
options.nonull is set, then return a list containing the pattern itself.

```javascript
var javascripts = minimatch.match(fileList, "*.js", {matchBase: true}))
```

### minimatch.makeRe(pattern, options)

Make a regular expression object from the pattern.

## Options

All options are `false` by default.

### debug

Dump a ton of stuff to stderr.

### nobrace

Do not expand `{a,b}` and `{1..3}` brace sets.

### noglobstar

Disable `**` matching against multiple folder names.

### dot

Allow patterns to match filenames starting with a period, even if
the pattern does not explicitly have a period in that spot.

Note that by default, `a/**/b` will **not** match `a/.d/b`, unless `dot`
is set.

### noext

Disable "extglob" style patterns like `+(a|b)`.

### nocase

Perform a case-insensitive match.

### nonull

When a match is not found by `minimatch.match`, return a list containing
the pattern itself if this option is set.  When not set, an empty list
is returned if there are no matches.

### matchBase

If set, then patterns without slashes will be matched
against the basename of the path if it contains slashes.  For example,
`a?b` would match the path `/xyz/123/acb`, but not `/xyz/acb/123`.

### nocomment

Suppress the behavior of treating `#` at the start of a pattern as a
comment.

### nonegate

Suppress the behavior of treating a leading `!` character as negation.

### flipNegate

Returns from negate expressions the same as if they were not negated.
(Ie, true on a hit, false on a miss.)

### partial

Compare a partial path to a pattern.  As long as the parts of the path that
are present are not contradicted by the pattern, it will be treated as a
match.  This is useful in applications where you're walking through a
folder structure, and don't yet have the full path, but want to ensure that
you do not walk down paths that can never be a match.

For example,

```js
minimatch('/a/b', '/a/*/c/d', { partial: true })  // true, might be /a/b/c/d
minimatch('/a/b', '/**/d', { partial: true })     // true, might be /a/b/.../d
minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a
```

### allowWindowsEscape

Windows path separator `\` is by default converted to `/`, which
prohibits the usage of `\` as a escape character. This flag skips that
behavior and allows using the escape character.

## Comparisons to other fnmatch/glob implementations

While strict compliance with the existing standards is a worthwhile
goal, some discrepancies exist between minimatch and other
implementations, and are intentional.

If the pattern starts with a `!` character, then it is negated.  Set the
`nonegate` flag to suppress this behavior, and treat leading `!`
characters normally.  This is perhaps relevant if you wish to start the
pattern with a negative extglob pattern like `!(a|B)`.  Multiple `!`
characters at the start of a pattern will negate the pattern multiple
times.

If a pattern starts with `#`, then it is treated as a comment, and
will not match anything.  Use `\#` to match a literal `#` at the
start of a line, or set the `nocomment` flag to suppress this behavior.

The double-star character `**` is supported by default, unless the
`noglobstar` flag is set.  This is supported in the manner of bsdglob
and bash 4.1, where `**` only has special significance if it is the only
thing in a path part.  That is, `a/**/b` will match `a/x/y/b`, but
`a/**b` will not.

If an escaped pattern has no matches, and the `nonull` flag is set,
then minimatch.match returns the pattern as-provided, rather than
interpreting the character escapes.  For example,
`minimatch.match([], "\\*a\\?")` will return `"\\*a\\?"` rather than
`"*a?"`.  This is akin to setting the `nullglob` option in bash, except
that it does not resolve escaped pattern characters.

If brace expansion is not disabled, then it is performed before any
other interpretation of the glob pattern.  Thus, a pattern like
`+(a|{b),c)}`, which would not be valid in bash or zsh, is expanded
**first** into the set of `+(a|b)` and `+(a|c)`, and those patterns are
checked for validity.  Since those two are valid, matching proceeds.
### Estraverse [![Build Status](https://secure.travis-ci.org/estools/estraverse.svg)](http://travis-ci.org/estools/estraverse)

Estraverse ([estraverse](http://github.com/estools/estraverse)) is
[ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm)
traversal functions from [esmangle project](http://github.com/estools/esmangle).

### Documentation

You can find usage docs at [wiki page](https://github.com/estools/estraverse/wiki/Usage).

### Example Usage

The following code will output all variables declared at the root of a file.

```javascript
estraverse.traverse(ast, {
    enter: function (node, parent) {
        if (node.type == 'FunctionExpression' || node.type == 'FunctionDeclaration')
            return estraverse.VisitorOption.Skip;
    },
    leave: function (node, parent) {
        if (node.type == 'VariableDeclarator')
          console.log(node.id.name);
    }
});
```

We can use `this.skip`, `this.remove` and `this.break` functions instead of using Skip, Remove and Break.

```javascript
estraverse.traverse(ast, {
    enter: function (node) {
        this.break();
    }
});
```

And estraverse provides `estraverse.replace` function. When returning node from `enter`/`leave`, current node is replaced with it.

```javascript
result = estraverse.replace(tree, {
    enter: function (node) {
        // Replace it with replaced.
        if (node.type === 'Literal')
            return replaced;
    }
});
```

By passing `visitor.keys` mapping, we can extend estraverse traversing functionality.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Extending the existing traversing rules.
    keys: {
        // TargetNodeName: [ 'keys', 'containing', 'the', 'other', '**node**' ]
        TestExpression: ['argument']
    }
});
```

By passing `visitor.fallback` option, we can control the behavior when encountering unknown nodes.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Iterating the child **nodes** of unknown nodes.
    fallback: 'iteration'
});
```

When `visitor.fallback` is a function, we can determine which keys to visit on each node.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Skip the `argument` property of each node
    fallback: function(node) {
        return Object.keys(node).filter(function(key) {
            return key !== 'argument';
        });
    }
});
```

### License

Copyright (C) 2012-2016 [Yusuke Suzuki](http://github.com/Constellation)
 (twitter: [@Constellation](http://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# ansi-styles [![Build Status](https://travis-ci.org/chalk/ansi-styles.svg?branch=master)](https://travis-ci.org/chalk/ansi-styles)

> [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors_and_Styles) for styling strings in the terminal

You probably want the higher-level [chalk](https://github.com/chalk/chalk) module for styling your strings.

<img src="screenshot.svg" width="900">

## Install

```
$ npm install ansi-styles
```

## Usage

```js
const style = require('ansi-styles');

console.log(`${style.green.open}Hello world!${style.green.close}`);


// Color conversion between 16/256/truecolor
// NOTE: If conversion goes to 16 colors or 256 colors, the original color
//       may be degraded to fit that color palette. This means terminals
//       that do not support 16 million colors will best-match the
//       original color.
console.log(style.bgColor.ansi.hsl(120, 80, 72) + 'Hello world!' + style.bgColor.close);
console.log(style.color.ansi256.rgb(199, 20, 250) + 'Hello world!' + style.color.close);
console.log(style.color.ansi16m.hex('#abcdef') + 'Hello world!' + style.color.close);
```

## API

Each style has an `open` and `close` property.

## Styles

### Modifiers

- `reset`
- `bold`
- `dim`
- `italic` *(Not widely supported)*
- `underline`
- `inverse`
- `hidden`
- `strikethrough` *(Not widely supported)*

### Colors

- `black`
- `red`
- `green`
- `yellow`
- `blue`
- `magenta`
- `cyan`
- `white`
- `blackBright` (alias: `gray`, `grey`)
- `redBright`
- `greenBright`
- `yellowBright`
- `blueBright`
- `magentaBright`
- `cyanBright`
- `whiteBright`

### Background colors

- `bgBlack`
- `bgRed`
- `bgGreen`
- `bgYellow`
- `bgBlue`
- `bgMagenta`
- `bgCyan`
- `bgWhite`
- `bgBlackBright` (alias: `bgGray`, `bgGrey`)
- `bgRedBright`
- `bgGreenBright`
- `bgYellowBright`
- `bgBlueBright`
- `bgMagentaBright`
- `bgCyanBright`
- `bgWhiteBright`

## Advanced usage

By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module.

- `style.modifier`
- `style.color`
- `style.bgColor`

###### Example

```js
console.log(style.color.green.open);
```

Raw escape codes (i.e. without the CSI escape prefix `\u001B[` and render mode postfix `m`) are available under `style.codes`, which returns a `Map` with the open codes as keys and close codes as values.

###### Example

```js
console.log(style.codes.get(36));
//=> 39
```

## [256 / 16 million (TrueColor) support](https://gist.github.com/XVilka/8346728)

`ansi-styles` uses the [`color-convert`](https://github.com/Qix-/color-convert) package to allow for converting between various colors and ANSI escapes, with support for 256 and 16 million colors.

The following color spaces from `color-convert` are supported:

- `rgb`
- `hex`
- `keyword`
- `hsl`
- `hsv`
- `hwb`
- `ansi`
- `ansi256`

To use these, call the associated conversion function with the intended output, for example:

```js
style.color.ansi.rgb(100, 200, 15); // RGB to 16 color ansi foreground code
style.bgColor.ansi.rgb(100, 200, 15); // RGB to 16 color ansi background code

style.color.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code
style.bgColor.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code

style.color.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color foreground code
style.bgColor.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color background code
```

## Related

- [ansi-escapes](https://github.com/sindresorhus/ansi-escapes) - ANSI escape codes for manipulating the terminal

## Maintainers

- [Sindre Sorhus](https://github.com/sindresorhus)
- [Josh Junon](https://github.com/qix-)

## For enterprise

Available as part of the Tidelift Subscription.

The maintainers of `ansi-styles` and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-ansi-styles?utm_source=npm-ansi-styles&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.3.0] - 2021-12-13

### Added

- Updated to include support for Unicode 14

## [1.2.0] - 2021-01-29

### Updated

- Refactored to increase speed

## [1.1.0] - 2020-09-14

### Added

- Updated to include support for Unicode 13

## [1.0.0] - 2020-09-13

- Forked from work by @JLHwung on original `Grapheme-Splitter` library: https://github.com/JLHwung/grapheme-splitter/tree/next
- Converted to Typescript
- Added development and build tooling
# Graphemer: Unicode Character Splitter 🪓

## Introduction

This library continues the work of [Grapheme Splitter](https://github.com/orling/grapheme-splitter) and supports the following unicode versions:

- Unicode 15 and below `[v1.4.0]`
- Unicode 14 and below `[v1.3.0]`
- Unicode 13 and below `[v1.1.0]`
- Unicode 11 and below `[v1.0.0]` (Unicode 10 supported by `grapheme-splitter`)

In JavaScript there is not always a one-to-one relationship between string characters and what a user would call a separate visual "letter". Some symbols are represented by several characters. This can cause issues when splitting strings and inadvertently cutting a multi-char letter in half, or when you need the actual number of letters in a string.

For example, emoji characters like "🌷","🎁","💩","😜" and "👍" are represented by two JavaScript characters each (high surrogate and low surrogate). That is,

```javascript
'🌷'.length == 2;
```

The combined emoji are even longer:

```javascript
'🏳️‍🌈'.length == 6;
```

What's more, some languages often include combining marks - characters that are used to modify the letters before them. Common examples are the German letter ü and the Spanish letter ñ. Sometimes they can be represented alternatively both as a single character and as a letter + combining mark, with both forms equally valid:

```javascript
var two = 'ñ'; // unnormalized two-char n+◌̃, i.e. "\u006E\u0303";
var one = 'ñ'; // normalized single-char, i.e. "\u00F1"

console.log(one != two); // prints 'true'
```

Unicode normalization, as performed by the popular punycode.js library or ECMAScript 6's String.normalize, can **sometimes** fix those differences and turn two-char sequences into single characters. But it is **not** enough in all cases. Some languages like Hindi make extensive use of combining marks on their letters, that have no dedicated single-codepoint Unicode sequences, due to the sheer number of possible combinations.
For example, the Hindi word "अनुच्छेद" is comprised of 5 letters and 3 combining marks:

अ + न + ु + च + ् + छ + े + द

which is in fact just 5 user-perceived letters:

अ + नु + च् + छे + द

and which Unicode normalization would not combine properly.
There are also the unusual letter+combining mark combinations which have no dedicated Unicode codepoint. The string Z͑ͫ̓ͪ̂ͫ̽͏̴̙̤̞͉͚̯̞̠͍A̴̵̜̰͔ͫ͗͢L̠ͨͧͩ͘G̴̻͈͍͔̹̑͗̎̅͛́Ǫ̵̹̻̝̳͂̌̌͘ obviously has 5 separate letters, but is in fact comprised of 58 JavaScript characters, most of which are combining marks.

Enter the `graphemer` library. It can be used to properly split JavaScript strings into what a human user would call separate letters (or "extended grapheme clusters" in Unicode terminology), no matter what their internal representation is. It is an implementation on the [Default Grapheme Cluster Boundary](http://unicode.org/reports/tr29/#Default_Grapheme_Cluster_Table) of [UAX #29](http://www.unicode.org/reports/tr29/).

## Installation

Install `graphemer` using the NPM command below:

```
$ npm i graphemer
```

## Usage

If you're using [Typescript](https://www.typescriptlang.org/) or a compiler like [Babel](https://babeljs.io/) (or something like Create React App) things are pretty simple; just import, initialize and use!

```javascript
import Graphemer from 'graphemer';

const splitter = new Graphemer();

// split the string to an array of grapheme clusters (one string each)
const graphemes = splitter.splitGraphemes(string);

// iterate the string to an iterable iterator of grapheme clusters (one string each)
const graphemeIterator = splitter.iterateGraphemes(string);

// or do this if you just need their number
const graphemeCount = splitter.countGraphemes(string);
```

If you're using vanilla Node you can use the `require()` method.

```javascript
const Graphemer = require('graphemer').default;

const splitter = new Graphemer();

const graphemes = splitter.splitGraphemes(string);
```

## Examples

```javascript
import Graphemer from 'graphemer';

const splitter = new Graphemer();

// plain latin alphabet - nothing spectacular
splitter.splitGraphemes('abcd'); // returns ["a", "b", "c", "d"]

// two-char emojis and six-char combined emoji
splitter.splitGraphemes('🌷🎁💩😜👍🏳️‍🌈'); // returns ["🌷","🎁","💩","😜","👍","🏳️‍🌈"]

// diacritics as combining marks, 10 JavaScript chars
splitter.splitGraphemes('Ĺo͂řȩm̅'); // returns ["Ĺ","o͂","ř","ȩ","m̅"]

// individual Korean characters (Jamo), 4 JavaScript chars
splitter.splitGraphemes('뎌쉐'); // returns ["뎌","쉐"]

// Hindi text with combining marks, 8 JavaScript chars
splitter.splitGraphemes('अनुच्छेद'); // returns ["अ","नु","च्","छे","द"]

// demonic multiple combining marks, 75 JavaScript chars
splitter.splitGraphemes('Z͑ͫ̓ͪ̂ͫ̽͏̴̙̤̞͉͚̯̞̠͍A̴̵̜̰͔ͫ͗͢L̠ͨͧͩ͘G̴̻͈͍͔̹̑͗̎̅͛́Ǫ̵̹̻̝̳͂̌̌͘!͖̬̰̙̗̿̋ͥͥ̂ͣ̐́́͜͞'); // returns ["Z͑ͫ̓ͪ̂ͫ̽͏̴̙̤̞͉͚̯̞̠͍","A̴̵̜̰͔ͫ͗͢","L̠ͨͧͩ͘","G̴̻͈͍͔̹̑͗̎̅͛́","Ǫ̵̹̻̝̳͂̌̌͘","!͖̬̰̙̗̿̋ͥͥ̂ͣ̐́́͜͞"]
```

## TypeScript

Graphemer is built with TypeScript and, of course, includes type declarations.

```javascript
import Graphemer from 'graphemer';

const splitter = new Graphemer();

const split: string[] = splitter.splitGraphemes('Z͑ͫ̓ͪ̂ͫ̽͏̴̙̤̞͉͚̯̞̠͍A̴̵̜̰͔ͫ͗͢L̠ͨͧͩ͘G̴̻͈͍͔̹̑͗̎̅͛́Ǫ̵̹̻̝̳͂̌̌͘!͖̬̰̙̗̿̋ͥͥ̂ͣ̐́́͜͞');
```

## Contributing

See [Contribution Guide](./CONTRIBUTING.md).

## Acknowledgements

This library is a fork of the incredible work done by Orlin Georgiev and Huáng Jùnliàng at https://github.com/orling/grapheme-splitter.

The original library was heavily influenced by Devon Govett's excellent [grapheme-breaker](https://github.com/devongovett/grapheme-breaker) CoffeeScript library.
# Acorn-JSX

[![Build Status](https://travis-ci.org/acornjs/acorn-jsx.svg?branch=master)](https://travis-ci.org/acornjs/acorn-jsx)
[![NPM version](https://img.shields.io/npm/v/acorn-jsx.svg)](https://www.npmjs.org/package/acorn-jsx)

This is plugin for [Acorn](http://marijnhaverbeke.nl/acorn/) - a tiny, fast JavaScript parser, written completely in JavaScript.

It was created as an experimental alternative, faster [React.js JSX](http://facebook.github.io/react/docs/jsx-in-depth.html) parser. Later, it replaced the [official parser](https://github.com/facebookarchive/esprima) and these days is used by many prominent development tools.

## Transpiler

Please note that this tool only parses source code to JSX AST, which is useful for various language tools and services. If you want to transpile your code to regular ES5-compliant JavaScript with source map, check out [Babel](https://babeljs.io/) and [Buble](https://buble.surge.sh/) transpilers which use `acorn-jsx` under the hood.

## Usage

Requiring this module provides you with an Acorn plugin that you can use like this:

```javascript
var acorn = require("acorn");
var jsx = require("acorn-jsx");
acorn.Parser.extend(jsx()).parse("my(<jsx/>, 'code');");
```

Note that official spec doesn't support mix of XML namespaces and object-style access in tag names (#27) like in `<namespace:Object.Property />`, so it was deprecated in `acorn-jsx@3.0`. If you still want to opt-in to support of such constructions, you can pass the following option:

```javascript
acorn.Parser.extend(jsx({ allowNamespacedObjects: true }))
```

Also, since most apps use pure React transformer, a new option was introduced that allows to prohibit namespaces completely:

```javascript
acorn.Parser.extend(jsx({ allowNamespaces: false }))
```

Note that by default `allowNamespaces` is enabled for spec compliancy.

## License

This plugin is issued under the [MIT license](./LICENSE).
# builtin-modules

> List of the Node.js builtin modules

The list is just a [JSON file](builtin-modules.json) and can be used anywhere.

## Install

```
$ npm install builtin-modules
```

## Usage

```js
const builtinModules = require('builtin-modules');

console.log(builtinModules);
//=> ['assert', 'buffer', ...]
```

## API

Returns an array of builtin modules fetched from the running Node.js version.

### Static list

This module also comes bundled with a static array of builtin modules generated from the latest Node.js version. You can get it with `require('builtin-modules/static');`

## Related

- [is-builtin-module](https://github.com/sindresorhus/is-builtin-module) - Check if a string matches the name of a Node.js builtin module

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-builtin-modules?utm_source=npm-builtin-modules&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# is-number [![NPM version](https://img.shields.io/npm/v/is-number.svg?style=flat)](https://www.npmjs.com/package/is-number) [![NPM monthly downloads](https://img.shields.io/npm/dm/is-number.svg?style=flat)](https://npmjs.org/package/is-number) [![NPM total downloads](https://img.shields.io/npm/dt/is-number.svg?style=flat)](https://npmjs.org/package/is-number) [![Linux Build Status](https://img.shields.io/travis/jonschlinkert/is-number.svg?style=flat&label=Travis)](https://travis-ci.org/jonschlinkert/is-number)

> Returns true if the value is a finite number.

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save is-number
```

## Why is this needed?

In JavaScript, it's not always as straightforward as it should be to reliably check if a value is a number. It's common for devs to use `+`, `-`, or `Number()` to cast a string value to a number (for example, when values are returned from user input, regex matches, parsers, etc). But there are many non-intuitive edge cases that yield unexpected results:

```js
console.log(+[]); //=> 0
console.log(+''); //=> 0
console.log(+'   '); //=> 0
console.log(typeof NaN); //=> 'number'
```

This library offers a performant way to smooth out edge cases like these.

## Usage

```js
const isNumber = require('is-number');
```

See the [tests](./test.js) for more examples.

### true

```js
isNumber(5e3);               // true
isNumber(0xff);              // true
isNumber(-1.1);              // true
isNumber(0);                 // true
isNumber(1);                 // true
isNumber(1.1);               // true
isNumber(10);                // true
isNumber(10.10);             // true
isNumber(100);               // true
isNumber('-1.1');            // true
isNumber('0');               // true
isNumber('012');             // true
isNumber('0xff');            // true
isNumber('1');               // true
isNumber('1.1');             // true
isNumber('10');              // true
isNumber('10.10');           // true
isNumber('100');             // true
isNumber('5e3');             // true
isNumber(parseInt('012'));   // true
isNumber(parseFloat('012')); // true
```

### False

Everything else is false, as you would expect:

```js
isNumber(Infinity);          // false
isNumber(NaN);               // false
isNumber(null);              // false
isNumber(undefined);         // false
isNumber('');                // false
isNumber('   ');             // false
isNumber('foo');             // false
isNumber([1]);               // false
isNumber([]);                // false
isNumber(function () {});    // false
isNumber({});                // false
```

## Release history

### 7.0.0

* Refactor. Now uses `.isFinite` if it exists.
* Performance is about the same as v6.0 when the value is a string or number. But it's now 3x-4x faster when the value is not a string or number.

### 6.0.0

* Optimizations, thanks to @benaadams.

### 5.0.0

**Breaking changes**

* removed support for `instanceof Number` and `instanceof String`

## Benchmarks

As with all benchmarks, take these with a grain of salt. See the [benchmarks](./benchmark/index.js) for more detail.

```
# all
v7.0 x 413,222 ops/sec ±2.02% (86 runs sampled)
v6.0 x 111,061 ops/sec ±1.29% (85 runs sampled)
parseFloat x 317,596 ops/sec ±1.36% (86 runs sampled)
fastest is 'v7.0'

# string
v7.0 x 3,054,496 ops/sec ±1.05% (89 runs sampled)
v6.0 x 2,957,781 ops/sec ±0.98% (88 runs sampled)
parseFloat x 3,071,060 ops/sec ±1.13% (88 runs sampled)
fastest is 'parseFloat,v7.0'

# number
v7.0 x 3,146,895 ops/sec ±0.89% (89 runs sampled)
v6.0 x 3,214,038 ops/sec ±1.07% (89 runs sampled)
parseFloat x 3,077,588 ops/sec ±1.07% (87 runs sampled)
fastest is 'v6.0'
```

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Related projects

You might also be interested in these projects:

* [is-plain-object](https://www.npmjs.com/package/is-plain-object): Returns true if an object was created by the `Object` constructor. | [homepage](https://github.com/jonschlinkert/is-plain-object "Returns true if an object was created by the `Object` constructor.")
* [is-primitive](https://www.npmjs.com/package/is-primitive): Returns `true` if the value is a primitive.  | [homepage](https://github.com/jonschlinkert/is-primitive "Returns `true` if the value is a primitive. ")
* [isobject](https://www.npmjs.com/package/isobject): Returns true if the value is an object and not an array or null. | [homepage](https://github.com/jonschlinkert/isobject "Returns true if the value is an object and not an array or null.")
* [kind-of](https://www.npmjs.com/package/kind-of): Get the native type of a value. | [homepage](https://github.com/jonschlinkert/kind-of "Get the native type of a value.")

### Contributors

| **Commits** | **Contributor** | 
| --- | --- |
| 49 | [jonschlinkert](https://github.com/jonschlinkert) |
| 5 | [charlike-old](https://github.com/charlike-old) |
| 1 | [benaadams](https://github.com/benaadams) |
| 1 | [realityking](https://github.com/realityking) |

### Author

**Jon Schlinkert**

* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)
* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)

### License

Copyright © 2018, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.6.0, on June 15, 2018._# fs.realpath

A backwards-compatible fs.realpath for Node v6 and above

In Node v6, the JavaScript implementation of fs.realpath was replaced
with a faster (but less resilient) native implementation.  That raises
new and platform-specific errors and cannot handle long or excessively
symlink-looping paths.

This module handles those cases by detecting the new errors and
falling back to the JavaScript implementation.  On versions of Node
prior to v6, it has no effect.

## USAGE

```js
var rp = require('fs.realpath')

// async version
rp.realpath(someLongAndLoopingPath, function (er, real) {
  // the ELOOP was handled, but it was a bit slower
})

// sync version
var real = rp.realpathSync(someLongAndLoopingPath)

// monkeypatch at your own risk!
// This replaces the fs.realpath/fs.realpathSync builtins
rp.monkeypatch()

// un-do the monkeypatching
rp.unmonkeypatch()
```
# levn [![Build Status](https://travis-ci.org/gkz/levn.png)](https://travis-ci.org/gkz/levn) <a name="levn" />
__Light ECMAScript (JavaScript) Value Notation__
Levn is a library which allows you to parse a string into a JavaScript value based on an expected type. It is meant for short amounts of human entered data (eg. config files, command line arguments).

Levn aims to concisely describe JavaScript values in text, and allow for the extraction and validation of those values. Levn uses [type-check](https://github.com/gkz/type-check) for its type format, and to validate the results. MIT license. Version 0.4.1.

__How is this different than JSON?__ levn is meant to be written by humans only, is (due to the previous point) much more concise, can be validated against supplied types, has regex and date literals, and can easily be extended with custom types. On the other hand, it is probably slower and thus less efficient at transporting large amounts of data, which is fine since this is not its purpose.

    npm install levn

For updates on levn, [follow me on twitter](https://twitter.com/gkzahariev).


## Quick Examples

```js
var parse = require('levn').parse;
parse('Number', '2');      // 2
parse('String', '2');      // '2'
parse('String', 'levn');   // 'levn'
parse('String', 'a b');    // 'a b'
parse('Boolean', 'true');  // true

parse('Date', '#2011-11-11#'); // (Date object)
parse('Date', '2011-11-11');   // (Date object)
parse('RegExp', '/[a-z]/gi');  // /[a-z]/gi
parse('RegExp', 're');         // /re/
parse('Int', '2');             // 2

parse('Number | String', 'str'); // 'str'
parse('Number | String', '2');   // 2

parse('[Number]', '[1,2,3]');                      // [1,2,3]
parse('(String, Boolean)', '(hi, false)');         // ['hi', false]
parse('{a: String, b: Number}', '{a: str, b: 2}'); // {a: 'str', b: 2}

// at the top level, you can ommit surrounding delimiters
parse('[Number]', '1,2,3');                      // [1,2,3]
parse('(String, Boolean)', 'hi, false');         // ['hi', false]
parse('{a: String, b: Number}', 'a: str, b: 2'); // {a: 'str', b: 2}

// wildcard - auto choose type
parse('*', '[hi,(null,[42]),{k: true}]'); // ['hi', [null, [42]], {k: true}]
```
## Usage

`require('levn');` returns an object that exposes three properties. `VERSION` is the current version of the library as a string. `parse` and `parsedTypeParse` are functions.

```js
// parse(type, input, options);
parse('[Number]', '1,2,3'); // [1, 2, 3]

// parsedTypeParse(parsedType, input, options);
var parsedType = require('type-check').parseType('[Number]');
parsedTypeParse(parsedType, '1,2,3'); // [1, 2, 3]
```

### parse(type, input, options)

`parse` casts the string `input` into a JavaScript value according to the specified `type` in the [type format](https://github.com/gkz/type-check#type-format) (and taking account the optional `options`) and returns the resulting JavaScript value.

##### arguments
* type - `String` - the type written in the [type format](https://github.com/gkz/type-check#type-format) which to check against
* input - `String` - the value written in the [levn format](#levn-format)
* options - `Maybe Object` - an optional parameter specifying additional [options](#options)

##### returns
`*` - the resulting JavaScript value

##### example
```js
parse('[Number]', '1,2,3'); // [1, 2, 3]
```

### parsedTypeParse(parsedType, input, options)

`parsedTypeParse` casts the string `input` into a JavaScript value according to the specified `type` which has already been parsed (and taking account the optional `options`) and returns the resulting JavaScript value. You can parse a type using the [type-check](https://github.com/gkz/type-check) library's `parseType` function.

##### arguments
* type - `Object` - the type in the parsed type format which to check against
* input - `String` - the value written in the [levn format](#levn-format)
* options - `Maybe Object` - an optional parameter specifying additional [options](#options)

##### returns
`*` - the resulting JavaScript value

##### example
```js
var parsedType = require('type-check').parseType('[Number]');
parsedTypeParse(parsedType, '1,2,3'); // [1, 2, 3]
```

## Levn Format

Levn can use the type information you provide to choose the appropriate value to produce from the input. For the same input, it will choose a different output value depending on the type provided. For example, `parse('Number', '2')` will produce the number `2`, but `parse('String', '2')` will produce the string `"2"`.

If you do not provide type information, and simply use `*`, levn will parse the input according the unambiguous "explicit" mode, which we will now detail - you can also set the `explicit` option to true manually in the [options](#options).

* `"string"`, `'string'` are parsed as a String, eg. `"a msg"` is `"a msg"`
* `#date#` is parsed as a Date, eg. `#2011-11-11#` is `new Date('2011-11-11')`
* `/regexp/flags` is parsed as a RegExp, eg. `/re/gi` is `/re/gi`
* `undefined`, `null`, `NaN`, `true`, and `false` are all their JavaScript equivalents
* `[element1, element2, etc]` is an Array, and the casting procedure is recursively applied to each element. Eg. `[1,2,3]` is `[1,2,3]`.
* `(element1, element2, etc)` is an tuple, and the casting procedure is recursively applied to each element. Eg. `(1, a)` is `(1, a)` (is `[1, 'a']`).
* `{key1: val1, key2: val2, ...}` is an Object, and the casting procedure is recursively applied to each property. Eg. `{a: 1, b: 2}` is `{a: 1, b: 2}`.
* Any test which does not fall under the above, and which does not contain special characters (`[``]``(``)``{``}``:``,`) is a string, eg. `$12- blah` is `"$12- blah"`.

If you do provide type information, you can make your input more concise as the program already has some information about what it expects. Please see the [type format](https://github.com/gkz/type-check#type-format) section of [type-check](https://github.com/gkz/type-check) for more information about how to specify types. There are some rules about what levn can do with the information:

* If a String is expected, and only a String, all characters of the input (including any special ones) will become part of the output. Eg. `[({})]` is `"[({})]"`, and `"hi"` is `'"hi"'`.
* If a Date is expected, the surrounding `#` can be omitted from date literals. Eg. `2011-11-11` is `new Date('2011-11-11')`.
* If a RegExp is expected, no flags need to be specified, and the regex is not using any of the special characters,the opening and closing `/` can be omitted - this will have the affect of setting the source of the regex to the input. Eg. `regex` is `/regex/`.
* If an Array is expected, and it is the root node (at the top level), the opening `[` and closing `]` can be omitted. Eg. `1,2,3` is `[1,2,3]`.
* If a tuple is expected, and it is the root node (at the top level), the opening `(` and closing `)` can be omitted. Eg. `1, a` is `(1, a)` (is `[1, 'a']`).
* If an Object is expected, and it is the root node (at the top level), the opening `{` and closing `}` can be omitted. Eg `a: 1, b: 2` is `{a: 1, b: 2}`.

If you list multiple types (eg. `Number | String`), it will first attempt to cast to the first type and then validate - if the validation fails it will move on to the next type and so forth, left to right. You must be careful as some types will succeed with any input, such as String. Thus put String at the end of your list. In non-explicit mode, Date and RegExp will succeed with a large variety of input - also be careful with these and list them near the end if not last in your list.

Whitespace between special characters and elements is inconsequential.

## Options

Options is an object. It is an optional parameter to the `parse` and `parsedTypeParse` functions.

### Explicit

A `Boolean`. By default it is `false`.

__Example:__

```js
parse('RegExp', 're', {explicit: false});          // /re/
parse('RegExp', 're', {explicit: true});           // Error: ... does not type check...
parse('RegExp | String', 're', {explicit: true});  // 're'
```

`explicit` sets whether to be in explicit mode or not. Using `*` automatically activates explicit mode. For more information, read the [levn format](#levn-format) section.

### customTypes

An `Object`. Empty `{}` by default.

__Example:__

```js
var options = {
  customTypes: {
    Even: {
      typeOf: 'Number',
      validate: function (x) {
        return x % 2 === 0;
      },
      cast: function (x) {
        return {type: 'Just', value: parseInt(x)};
      }
    }
  }
}
parse('Even', '2', options); // 2
parse('Even', '3', options); // Error: Value: "3" does not type check...
```

__Another Example:__
```js
function Person(name, age){
  this.name = name;
  this.age = age;
}
var options = {
  customTypes: {
    Person: {
      typeOf: 'Object',
      validate: function (x) {
        x instanceof Person;
      },
      cast: function (value, options, typesCast) {
        var name, age;
        if ({}.toString.call(value).slice(8, -1) !== 'Object') {
          return {type: 'Nothing'};
        }
        name = typesCast(value.name, [{type: 'String'}], options);
        age = typesCast(value.age, [{type: 'Numger'}], options);
        return {type: 'Just', value: new Person(name, age)};
    }
  }
}
parse('Person', '{name: Laura, age: 25}', options); // Person {name: 'Laura', age: 25}
```

`customTypes` is an object whose keys are the name of the types, and whose values are an object with three properties, `typeOf`, `validate`, and `cast`. For more information about `typeOf` and `validate`, please see the [custom types](https://github.com/gkz/type-check#custom-types) section of type-check.

`cast` is a function which receives three arguments, the value under question, options, and the typesCast function. In `cast`, attempt to cast the value into the specified type. If you are successful, return an object in the format `{type: 'Just', value: CAST-VALUE}`, if you know it won't work, return `{type: 'Nothing'}`.  You can use the `typesCast` function to cast any child values. Remember to pass `options` to it. In your function you can also check for `options.explicit` and act accordingly.

## Technical About

`levn` is written in [LiveScript](http://livescript.net/) - a language that compiles to JavaScript. It uses [type-check](https://github.com/gkz/type-check) to both parse types and validate values. It also uses the [prelude.ls](http://preludels.com/) library.
# yocto-queue [![](https://badgen.net/bundlephobia/minzip/yocto-queue)](https://bundlephobia.com/result?p=yocto-queue)

> Tiny queue data structure

You should use this package instead of an array if you do a lot of `Array#push()` and `Array#shift()` on large arrays, since `Array#shift()` has [linear time complexity](https://medium.com/@ariel.salem1989/an-easy-to-use-guide-to-big-o-time-complexity-5dcf4be8a444#:~:text=O(N)%E2%80%94Linear%20Time) *O(n)* while `Queue#dequeue()` has [constant time complexity](https://medium.com/@ariel.salem1989/an-easy-to-use-guide-to-big-o-time-complexity-5dcf4be8a444#:~:text=O(1)%20%E2%80%94%20Constant%20Time) *O(1)*. That makes a huge difference for large arrays.

> A [queue](https://en.wikipedia.org/wiki/Queue_(abstract_data_type)) is an ordered list of elements where an element is inserted at the end of the queue and is removed from the front of the queue. A queue works based on the first-in, first-out ([FIFO](https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics))) principle.

## Install

```
$ npm install yocto-queue
```

## Usage

```js
const Queue = require('yocto-queue');

const queue = new Queue();

queue.enqueue('🦄');
queue.enqueue('🌈');

console.log(queue.size);
//=> 2

console.log(...queue);
//=> '🦄 🌈'

console.log(queue.dequeue());
//=> '🦄'

console.log(queue.dequeue());
//=> '🌈'
```

## API

### `queue = new Queue()`

The instance is an [`Iterable`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols), which means you can iterate over the queue front to back with a “for…of” loop, or use spreading to convert the queue to an array. Don't do this unless you really need to though, since it's slow.

#### `.enqueue(value)`

Add a value to the queue.

#### `.dequeue()`

Remove the next value in the queue.

Returns the removed value or `undefined` if the queue is empty.

#### `.clear()`

Clear the queue.

#### `.size`

The size of the queue.

## Related

- [quick-lru](https://github.com/sindresorhus/quick-lru) - Simple “Least Recently Used” (LRU) cache
# lodash.merge v4.6.2

The [Lodash](https://lodash.com/) method `_.merge` exported as a [Node.js](https://nodejs.org/) module.

## Installation

Using npm:
```bash
$ {sudo -H} npm i -g npm
$ npm i --save lodash.merge
```

In Node.js:
```js
var merge = require('lodash.merge');
```

See the [documentation](https://lodash.com/docs#merge) or [package source](https://github.com/lodash/lodash/blob/4.6.2-npm-packages/lodash.merge) for more details.
# 3.21.0

**Features:**

* added `getWellKnownSymbolPropertyOfType` to reliably get symbol named properties due to changes in typescript@4.3
* `getPropertyNameOfWellKnownSymbol` is now deprecated

# 3.20.0

**Features:**

* `findImports` and `findImportLikeNodes` take an additional parameter `ignoreFileName`. The default value for this paramter is `true` to remain backwards compatible. When set to `false`, it matches the behavior of TypeScript, i.e. only looks for `require` in JavaScript files.

**Bugfixes:**

* `getJsDoc` for `EndOfFileToken` now returns `JSDoc` comments whose contents are usable with the type checker

# 3.19.1

**Bugfixes:**

* `getSymbolOfClassLikeDeclaration` no longer crashes on anonymous mixin classes

# 3.19.0

**Features:**

* `getSymbolOfClassLikeDeclaration` to retrieve the symbol of class declarations and expressions regardless whether they have a name or not
* `getBaseOfClassLikeDeclaration` to conventiently get the expression after `extends`
* `getBaseClassMemberOfClassElement` to look up the declaration of a class member in the base class

**Bugfixes:**

* `getConstructorTypeOfClassLikeDeclaration` now really returns the constructor type (the static side of the class), previously it returned the instance type
* `hasExhaustiveCaseClauses` allows additional case clauses with `null`, `undefined` and `never`

# 3.18.0

**Features:**

* Source maps for easier debugging
* JSDoc is preserved in declaration files
* Comments are presered in transpiled code
* Everything you need to handle the control flow changes of TypeScript@3.7
  * `callExpressionAffectsControlFlow` to determine whether a CallExpression affects control flow by returning `never` or `asserts`
  * `hasExhaustiveCaseClauses` to determine whether a SwitchStatement's CaseClauses handle every possible value
  * `endsControlFlow` and `getControlFlowEnd` take an optional `checker` parameter to recognize exhaustive SwitchStatements and control flow effects of CallExpressions
* `formatPseudoBigInt` converts TypeScript's representation of a BigInt to its literal representation as you would write it in your source code
* `getAstNodeAtPosition` similar to `getTokenAtPosition`, but only operates on AST Nodes
* `removeOptionalChainingUndefinedMarkerType` and `isOptionalChainingUndefinedMarkerType` to handle types originating in an optional chain
* `findImports` and `findImportLikeNodes`: prepare for import assertions
* `getTsCheckDirective` as new name for `getCheckJsDirective`
* `getCheckJsDirective` is now deprecated

**Bugfixes:**

* `getUsageDomain`: handles NamespaceExport and NamedTupleMember
* `getPropertyName`: handles parentheses and negative numeric literals, excludes RegExp literals and private identifiers
* `getSingleLateBoundPropertyNameOfPropertyName` and `getLateBoundPropertyNamesOfPropertyName`: handles private identifiers
* `hasAccessModifier`: handles JSDoc access modifier
* `hasSideEffects`: correctly determines side effects of (static) property initializers
* `isExpressionValueUsed`: handle nullish coalescing and conditional assignment operators
* `canHaveJsDoc`: aligned with upstream changes in TypeScript
* `isCompilerOptionEnabled`:
  * `noUncheckedIndexedAccess` requires `strictNullChecks`
  * `checkJs` implies `allowJs`
  * `emitDeclarationOnly` requires `declaration`
* `isInConstContext`: handle template string interpolations
* excluded unnecessary files from npm package

# 3.17.1

**Bugfixes:**

* `isValidJsxIdentifier`, `isValidPropertyAccess`, `isValidPropertyName`: fix unicode character width handling

# 3.17.0

**Features:**

* `isValidJsxIdentifier` added an optional parameter to specify the target ECMAScript version

**Bugfixes:**

* `isValidJsxIdentifier` now handles astral plane characters

# 3.16.0

**Features:**

* added `getIteratorYieldResultFromIteratorResult` to extract the `yield`ed type from `IteratorResult<TYield, TReturn, TNext>`

# 3.15.0

**Features:**

* `isValidIdentifier`, `isValidPropertyName`, `isValidPropertyAccess`, `isValidNumericLiteral` added an optional parameter to specify the target ECMAScript version

**Bugfixes:**

* `isValidPropertyName`, `isValidPropertyAccess` now handle astral plane characters

# 3.14.1

**Bugfixes:**

* `findImports`: fixed crash on nested namespaces

# 3.14.0

**Features:**

* added `getInstanceTypeOfClassLikeDeclaration` and `getConstructorTypeOfClassLikeDeclaration`
* added `AccessKind.Delete` to `getAccessKind`: `getAccessKind(node) & AccessKind.Modification` can now be used to restore the old behavior of `isReassignmentTarget(node)`

# 3.13.0

**Features:**

* `getAccessKind` determines whether an expression is read from, written to or both
* optimized `getPropertyOfType` for unambiguous property names to partially work around https://github.com/microsoft/TypeScript/issues/31565

**Bugfixes:**

* `isReassignmentTarget` no longer returns `true` for `DeleteExpression` as it doesn't **assign** a value to the operand

# 3.12.0

**Features:**

* `getLateBoundPropertyNamesOfPropertyName` returns all statically analyzable names of a property, method, ...
* `getSingleLateBoundPropertyNameOfPropertyName` returns the literal name of a property, method, ... if statically analyzable

**Bugfixes:**

* fixed circular import

# 3.11.0

**Features:**

* typeguards: `isNumericOrStringLikeLiteral`, `isTupleTypeReference`
* `intersectionTypeParts` as counterpart to `unionTypeParts`
* `someTypePart` to execute a callback for each union or intersection constituent until the callback returns true
* `getPropertyOfType` looks up a property by its escaped name
* `isPropertyReadonlyInType` determines whether a property in a given type cannot be written to
* `symbolHasReadonlyDeclaration` determines if a Symbol has any readonly or constant declaration
* `isNumericPropertyName` determines whether a property name would match an index signature
* `isBindableObjectDefinePropertyCall` returns true for statically analyzable forms of `Object.defineProperty(o, 'p', {value, writable})`
* `isReadonlyAssignmentDeclaration` determines whether an `Object.defineProperty` call is known to result in a readonly property
* `getLateBoundPropertyNames` returns all known property names of an expression
* `getPropertyNameFromType` extracts the property name of literal types
* `isWellKnownSymbolLiterally` to recognize expressions in the form of `Symbol.<name>`
* `getPropertyNameOfWellKnownSymbol` returns the escaped name for a well known symbol literal
* `unwrapParentheses` returns the first child expression that is not a `ParenthesizedExpression`

# 3.10.0

**Features:**

* `isCompilerOptionEnabled`: `incremental` is implicitly enabled by `composite`

**Bugfixes:**

* `collectVariableUsage`/`getUsageDomain`: no longer treat `as const` as type usage

# 3.9.1

**Bugfixes:**

* reverted invalid deprecation of `canHaveJsdoc`
* fixed condition in `parseJsdocOfNode`

# 3.9.0

**Features:**

* added typeguards: `isNullLiteral` and `isBooleanLiteral`

# 3.8.0

**Features:**

* exposes typeguards for typescript@3.2 by default
* added utilities: `isConstAssertion` and `isInConstContext`

# 3.7.0

**Features:**

* added `isBlockScopedDeclarationStatement`
* added `isInSingleStatementContext`

# 3.6.0

**Features:**

* added `getCheckJsDirective` utility to parse `// @ts-check` and `// @ts-nocheck` pragmas

# 3.5.2

**Bugfixes:**

* Published declaration files no longer contain `const enum`. They are now declared as regular enums instead.

# 3.5.1

**Bugfixes:**

* `isThenableType` allows `Node` instead of `Expression` as parameter
* `isBlockScopeBoundary` and `isScopeBoundary` consider `WithStatement` as scope boundary

# 3.5.0

**Features:**

* correctly handle BigInt literals
  * added typeguard `isBigIntLiteral`
  * `isLiteralType` recognises BigInt
  * `getPropertyName` adds special handling for BigInt

# 3.4.0

**Features:**

* added utility `commentText` to get the actual text content of a comment excluding the characters needed to start and end the comment

# 3.3.1

**Bugfixes:**

* `findImports`: fixed handling of ImportEqualsDeclaration

# 3.3.0

**Features:**

* `isCompilerOptionEnabled`: recognizes `strictBindCallApply`
* `getTokenAtPosition`: optionally includes JSDoc during lookup

**Bugfixes:**

* `isCompilerOptionEnabled`: correctly implements logic for `allowSyntheticDefaultImports`
* `findImportLikeNodes`: correctly finds imports in namespaces
* `findImportLikeNodes` / `findImports`: finds import types in JSDoc of JS files

# 3.2.0

**Features:**

* added utility `findImportLikeNodes` that works similar to `findImports` but returns the import statement or expression instead of the module specifier and doesn't filter non-string module specifiers

# 3.1.0

**Features:**

* added utilities: `isKeywordKind` and `isValidJsxIdentifier`
* exposes typeguards for typescript@3.0 by default

# 3.0.0

:warning: **Breaking Changes:**

* Dropped support for `typescript@<2.8.0`
* Dropped support for Node.js 4
* Removed deprecated APIs:
  * `getIdentifierText`, `isJsxFramgment`, `ImportOptions`
  * deprected overloads of `isModifierFlagSet`, `findImports` and `getControlFlowEnd`
* control flow related symbols can no longer be imported from `'tsutils/util/util'`, import directly from `'tsutils/util/control-flow'` or `'tsutils/util'`
* `isFunctionScopeBoundary` and `isBlockScopeBoundary` now return a enum member of `ScopeBoundary` instead of a boolean
* `isFunctionScopeBoundary` no longer returns a truthy value for `InterfaceDeclaration`, `TypeAliasDeclaration`

**Features:**

* added utility `isTypeScopeBoundary` returning `ScopeBoundary.Type` or `ScopeBoundary.ConditionalType`
* added enum `ScopeBoundarySelector` whose members can be used to determine if a declaration belongs to a given `ScopeBoundary` by using bitwise AND

**Bugfixes:**

* `collectVariableUsage` now correctly handles `infer T` nested inside function signatures or mapped types
* `isCompilerOptionEnabled` correctly handles `skipDefaultLibCHeck` and `suppressImplicitAnyIndexErrors`

# 2.29.0

**Features:**

* added utility `isCompilerOptionEnabled`

# 2.28.0

Typeguards are now split into multiple submodules for each version of TypeScript (starting with 2.8.0).
That means you can now import directly from `"tsutils/typeguard/2.8"` to get compatible declaraton files for TypeScript@2.8.
For more information please read the relevant section in [README.md](README.md).

**Features:**

* added typeguards: `isTupleType`, `isOptionalTypeNode`, `isRestTypeNode`, `isSyntheticExpression` (currently available from `"tsutils/typeguard/3.0"`)
* added utility `isStrictCompilerOptionEnabled`

# 2.27.2

Avoid crash caused by removed function in `typescript@3.0.0`.

# 2.27.1

Added support for TypeScript@3.0.0 nightly builds.

# 2.27.0

**Features:**

* added `getIIFE` utility

# 2.26.2

**Bugfixes:**

* `forEachComment` and `forEachTokenWithTrivia` no longer duplicate comments around missing nodes

# 2.26.1

**Bugfixes:**

* fixed crash in `hasSideEffects` with tagged template literal without substitution: ``tag`template` ``

# 2.26.0

**Features:**

* added typeguard `isLiteralTypeNode`
* added support for type imports (`type T = import('foo')`) to `findImports` via `ImportKind.ImportType`

# 2.25.1

**Bugfixes:**

* `collectVariableUsage`: fixed name lookup in function signatures to match runtime behavior. Note that this is not completely fixed in TypeScript, yet. See: [Microsoft/TypeScript#22825](https://github.com/Microsoft/TypeScript/issues/22825) and [Microsoft/TypeScript#22769](https://github.com/Microsoft/TypeScript/issues/22769)

# 2.25.0

**Features:**

* added utilities: `isStatementInAmbientContext` and `isAmbientModuleBlock`

# 2.24.0

**Features:**

* added typeguards for typescript@2.8: `isConditionalTypeNode`, `isInferTypeNode`, `isConditionalType`, `isInstantiableType`, `isSubstitutionType`

# 2.23.0

**Features:**

* added typeguard `isForInOrOfStatement`

**Bugfixes:**

* correctly handle comments in generic JSX elements: `<MyComponent<string>/*comment*/></MyComponent>`
* fixed a bug with false positive trailing comments at the end of JSX self closing element: `<div><br/>/*no comment*/</div>`

# 2.22.2

**Bugfixes:**

* `collectVariableUsage`: handle ConditionalTypes and `infer T`, which will be introduced in TypeScript@2.8.0 and are already available in nightly builds
* `isLiteralType` no longer returns true for `ts.TypeFlags.BooleanLiteral` as this is not a `ts.LiteralType`

# 2.22.1

**Bugfixes:**

* `endsControlFlow`:
  * handle loops that might not even run a single iteration
  * handle constant boolean conditions in loops and if

# 2.22.0

**Features:**

* added `isFalsyType` utility

# 2.21.2

**Bugfixes:**

* fixed compile error with `typescript@2.8.0-dev`

# 2.21.1

**Bugfixes:**

* `isReassignmentTarget`: handle type assertions and non-null assertion

# 2.21.0

**Bugfixes:**

* `forEachDeclaredVariable` uses a more precise type for the callback parameter to make it useable again with typescript@2.7.1

**Features:**

* added `isUniqueESSymbolType` typeguard

# 2.20.0

**Features:**

* added `isThenableType` utility
* added `unionTypeParts` utility

# 2.19.1

**Bugfixes:**

* `forEachComment`, `getCommentAtPosition` and `isPositionInComment`: skip shebang (`#! something`) to not miss following comments at the start of the file

# 2.19.0

**Features:**

* added `WrappedAst` interface that models the type of a wrapped SourceFile more accurate
* added `getWrappedNodeAtPosition` utiltiy that takes a `NodeWrap` and returns the most deeply nested NodeWrap that contains the given position

# 2.18.0

**Features:**

* `getControlFlowEnd` accepts BlockLike as argument

**Bugfixes:**

* `getControlFlowEnd` and `endsControlFlow`: correctly handle nested LabeledStatements
* `endsControlFlow` removed erroneous special case when an IterationStatement is passed as argument whose parent is a LabeledStatement.
  * if you want labels of an IterationStatement (or SwitchStatement) to be handled, you need to pass the LabeledStatement as argument.
  * :warning: this fix may change the returned value if you relied on the buggy behavior

**Deprecations:**

* deprecated overload of `getControlFlowEnd` that contains the `label` parameter. This parameter is no longer used and should no longer be passed to the function.

# 2.17.1

**Bugfixes:**

* `getControlFlowEnd` and `endsControlFlow` (#22)
  * ThrowStatements inside `try` are filtered out if there is a `catch` clause
  * TryStatements with `catch` only end control flow if `try` AND `catch` definitely end control flow

# 2.17.0

**Features:**

* added `kind` property to `NodeWrap`
* added `getControlFlowEnd` to public API

# 2.16.0

**Features:**

* added `isDecorator` and `isCallLikeExpression` typeguards

# 2.15.0

**Features:**

* added `convertAst` utility to produce a flattened and wrapped version of the AST

# 2.14.0

**Features:**

* added `isDeleteExpression`
* added `getLineBreakStyle`

# 2.13.1

**Bugfixes:**

* fixed name of `isJsxFragment`

# 2.13.0

**Features:**

* added support for `JsxFragment` introduced in typescript@2.6.2
* added corresponding typeguard functions

# 2.12.2

**Bugfixes:**

* `endsControlFlow`
  * added missing logic for labeled statement, iteration statements and try-catch
  * added missing logic for `break` and `continue` with labels
  * take all jump statements into account, not only the last statement
* `isValidIdentifier` and `isValidNumericLiteral` handle irregular whitespace
* `findImports` searches in ambient modules inside regular `.ts` files (not only `.d.ts`)
* `canHaveJsDoc` is now a typeguard

# 2.12.1

**Bugfixes:**

* `forEachTokenWithTrivia`
  * handles irregular whitespace and no longer visits some tokens twice
  * correctly calculates the range of JsxText

# 2.12.0

**API-Changes:**

* deprecated `ImportOptions` if favor of the new `ImportKind` enum

# 2.11.2

**Bugfixes:**

* `parseJsDocOfNode`: set correct `pos`, `end` and `parent` properties. Also affects `getJsDoc` of `EndOfFileToken`

# 2.11.1

**Bugfixes:**

* `collectVariableUsage`: correctly consider catch binding as block scoped declaration inside catch block

# 2.11.0

**Bugfixes:**

* `getJsDoc` now correctly returns JsDoc for `EndOfFileToken`

**Features:**

* added utility `parseJsDocOfNode`

# 2.10.0

**Features:**

* added utility `findImports` to find all kinds of imports in a source file

# 2.9.0

**Features:**

* added typeguard `isMappedTypeNode`
* added utilities `canHaveJsDoc` and `getJsDoc`

# 2.8.2

**Bugfixes:**

* `collectVariableUsage`: handle global augmentation like other module augmentations

# 2.8.1

**Bugfixes:**

* Support `typescript@2.5.1` with optional catch binding
* `collectVariableUsage` fixed a bug where method decorator had method's parameters in scope

# 2.8.0

* Compatibility with the latest typescript nightly
* Added `getIdentifierText` to unescape identifiers across typescript versions

# 2.7.1

**Bugfixes:**

* `isReassignmentTarget` don't return `true` for right side of assignment

# 2.7.0

**Features:**

* Added `isReassignmentTarget` utility

# 2.6.1

**Bugfixes:**

* `getDeclarationDomain` now returns `undefined` for Parameter in IndexSignature
* `collectVariableUsage` ignores Parameter in IndexSignature

# 2.6.0

**Bugfixes:**

* `collectVariableUsage`:
  * don't merge imports with global declarations
  * treat everything in a declaration file as exported if there is no explicit `export {};`
* `isExpressionValueUsed`: handle destructuring in `for...of`

**Features:**

* Added `getModifier` utility
* Added `DeclarationDomain.Import` to distinguish imports from other declarations

# 2.5.1

**Bugfixes:**

* `collectVariableUsage` ignore jump labels as in `break label;`

# 2.5.0

**Bugfixes:**

* `isFunctionWithBody` handles constructor overload correctly.

**Features:**

* Implemented `isExpressionValueUsed` to check whether the result of an expression is actually used.
* Implemented `getDeclarationDomain` to determine if a given declaration introduces a new symbol in the value or type domain.

**`collectVariableUses` is now usable**

* no longer ignores signatures and its parameters
* don't merge declarations and uses across domains
* no longer marks exceptions in catch clause or parameter properties as exported
* fixed exports of namespaces
* fixed scoping of ClassExpression name
* correcly handle ambient namespaces and module augmentations
* fixed how `: typeof foo` is handled for parameters and function return type
* **still WIP**: `export {Foo as Bar}` inside ambient namespaces and modules

# 2.4.0

**Bugfixes:**

* `getLineRanges`: `contentLength` now contains the correct line length when there are multiple consecutive line break characters
* `getTokenAtPosition`: don't match tokens that end at the specified position (because that's already outside of their range)
* deprecated the misnamed `isModfierFlagSet`, use the new `isModifierFlagSet` instead

**Features:**

* Added typeguard: `isJsDoc`
* Added experimental scope and usage analysis (`getUsageDomain` and `collectVariableUsage`)

# 2.3.0

**Bugfixes:**

* `forEachComment` no longer omits some comments when callback returns a truthy value
* `isPositionInComment` fixed false positive inside JSXText

**Features:**

* Added utility: `getCommentAtPosition`

# 2.2.0

**Bugfixes:**

* Fixed bit value of `SideEffectOptions.JsxElement` to be a power of 2

**Features:**

* Added utilities: `getTokenAtPosition` and `isPositionInComment`

# 2.1.0

**Features:**

* Added typeguard `isExpression`
* Added utilities: `hasSideEffects`, `getDeclarationOfBindingElement`

# 2.0.0

**Breaking Changes:**

* Dropped compatibility with `typescript@<2.1.0`
* Removed misnamed `isNumericliteral`, use `isNumericLiteral` instead (notice the uppercase L)
* Removed `isEnumLiteralType` which will cause compile errors with typescript@2.4.0
* Refactored directory structure: all imports that referenced subdirectories (e.g. `require('tsutils/src/typeguard')` will be broken

**Features:**

* New directory structure allows imports of typeguards or utils independently, e.g. (`require('tsutils/typeguard')`)

# 1.9.1

**Bugfixes:**

* `isObjectFlagSet` now uses the correct `objectFlags` property

# 1.9.0

**Bugfixes:**

* `getNextToken` no longer omits `EndOfFileToken` when there is no trivia before EOF. That means the only inputs where `getNextToken` returns `undefined` are `SourceFile` and `EndOfFileToken`

**Features**:

* Added typeguards for types
* Added utilities for flag checking: `isNodeFlagSet`, `isTypeFlagSet`, `isSymbolFlagSet`,`isObjectFlagSet`, `isModifierFlagSet`

# 1.8.0

**Features:**

* Support peer dependency of typescript nightlies of 2.4.0
* Added typeguards: `isJsxAttributes`, `isIntersectionTypeNode`, `isTypeOperatorNode`, `isTypePredicateNode`, `isTypeQueryNode`, `isUnionTypeNode`

# 1.7.0

**Bugfixes:**

* `isFunctionScopeBoundary` now handles Interfaces, TypeAliases, FunctionSignatures, etc

**Features:**

* Added utilities: `isThisParameter`, `isSameLine` and `isFunctionWithBody`

# 1.6.0

**Features:**

* Add `isValidPropertyAccess`, `isValidNumericLiteral` and `isValidPropertyName`

# 1.5.0

**Features:**

* Add `isValidIdentifier`

# 1.4.0

**Features:**

* Add `contentLength` property to the result of `getLineRanges`

# 1.3.0

**Bugfixes:**

* `canHaveLeadingTrivia`:
  * Fix property access on undefined parent reference
  * Fixes: [palantir/tslint#2330](https://github.com/palantir/tslint/issues/2330)
* `hasOwnThisReference`: now includes accessors on object literals

**Features:**

* Typeguards:
  * isTypeParameterDeclaration
  * isEnitityName

# 1.2.2

**Bugfixes:**

* `hasOwnThisReference`:
  * exclude overload signatures of function declarations
  * add method declarations on object literals

# 1.2.1

**Bugfixes:**

* Fix name of `isNumericLiteral`

# 1.2.0

**Features:**

* Typeguards:
  * isEnumMember
  * isExpressionWithTypeArguments
  * isImportSpecifier
* Utilities:
  * isJsDocKind, isTypeNodeKind
* Allow typescript@next in peerDependencies

# 1.1.0

**Bugfixes:**

* Fix isBlockScopeBoundary: Remove WithStatement, IfStatment, DoStatement and WhileStatement because they are no scope boundary whitout a block.

**Features:**

* Added more typeguards:
  * isAssertionExpression
  * isEmptyStatement
  * isJsxAttributeLike
  * isJsxOpeningLikeElement
  * isNonNullExpression
  * isSyntaxList
* Utilities:
  * getNextToken, getPreviousToken
  * hasOwnThisReference
  * getLineRanges

# 1.0.0

**Features:**

* Initial implementation of typeguards
* Utilities:
  * getChildOfKind
  * isNodeKind, isAssignmentKind
  * hasModifier, isParameterProperty, hasAccessModifier
  * getPreviousStatement, getNextStatement
  * getPropertyName
  * forEachDestructuringIdentifier, forEachDeclaredVariable
  * getVariableDeclarationKind, isBlockScopedVariableDeclarationList, isBlockScopedVariableDeclaration
  * isScopeBoundary, isFunctionScopeBoundary, isBlockScopeBoundary
  * forEachToken, forEachTokenWithTrivia, forEachComment
  * endsControlFlow
# tslib

This is a runtime library for [TypeScript](http://www.typescriptlang.org/) that contains all of the TypeScript helper functions.

This library is primarily used by the `--importHelpers` flag in TypeScript.
When using `--importHelpers`, a module that uses helper functions like `__extends` and `__assign` in the following emitted file:

```ts
var __assign = (this && this.__assign) || Object.assign || function(t) {
    for (var s, i = 1, n = arguments.length; i < n; i++) {
        s = arguments[i];
        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
            t[p] = s[p];
    }
    return t;
};
exports.x = {};
exports.y = __assign({}, exports.x);

```

will instead be emitted as something like the following:

```ts
var tslib_1 = require("tslib");
exports.x = {};
exports.y = tslib_1.__assign({}, exports.x);
```

Because this can avoid duplicate declarations of things like `__extends`, `__assign`, etc., this means delivering users smaller files on average, as well as less runtime overhead.
For optimized bundles with TypeScript, you should absolutely consider using `tslib` and `--importHelpers`.

# Installing

For the latest stable version, run:

## npm

```sh
# TypeScript 2.3.3 or later
npm install tslib

# TypeScript 2.3.2 or earlier
npm install tslib@1.6.1
```

## yarn

```sh
# TypeScript 2.3.3 or later
yarn add tslib

# TypeScript 2.3.2 or earlier
yarn add tslib@1.6.1
```

## bower

```sh
# TypeScript 2.3.3 or later
bower install tslib

# TypeScript 2.3.2 or earlier
bower install tslib@1.6.1
```

## JSPM

```sh
# TypeScript 2.3.3 or later
jspm install tslib

# TypeScript 2.3.2 or earlier
jspm install tslib@1.6.1
```

# Usage

Set the `importHelpers` compiler option on the command line:

```
tsc --importHelpers file.ts
```

or in your tsconfig.json:

```json
{
    "compilerOptions": {
        "importHelpers": true
    }
}
```

#### For bower and JSPM users

You will need to add a `paths` mapping for `tslib`, e.g. For Bower users:

```json
{
    "compilerOptions": {
        "module": "amd",
        "importHelpers": true,
        "baseUrl": "./",
        "paths": {
            "tslib" : ["bower_components/tslib/tslib.d.ts"]
        }
    }
}
```

For JSPM users:

```json
{
    "compilerOptions": {
        "module": "system",
        "importHelpers": true,
        "baseUrl": "./",
        "paths": {
            "tslib" : ["jspm_packages/npm/tslib@1.[version].0/tslib.d.ts"]
        }
    }
}
```


# Contribute

There are many ways to [contribute](https://github.com/Microsoft/TypeScript/blob/master/CONTRIBUTING.md) to TypeScript.

* [Submit bugs](https://github.com/Microsoft/TypeScript/issues) and help us verify fixes as they are checked in.
* Review the [source code changes](https://github.com/Microsoft/TypeScript/pulls).
* Engage with other TypeScript users and developers on [StackOverflow](http://stackoverflow.com/questions/tagged/typescript).
* Join the [#typescript](http://twitter.com/#!/search/realtime/%23typescript) discussion on Twitter.
* [Contribute bug fixes](https://github.com/Microsoft/TypeScript/blob/master/CONTRIBUTING.md).

# Documentation

* [Quick tutorial](http://www.typescriptlang.org/Tutorial)
* [Programming handbook](http://www.typescriptlang.org/Handbook)
* [Homepage](http://www.typescriptlang.org/)
# Utility functions for working with typescript's AST

[![Greenkeeper badge](https://badges.greenkeeper.io/ajafff/tsutils.svg)](https://greenkeeper.io/)

## Usage

This package consists of two major parts: utilities and typeguard functions.
By importing the project you will get both of them.
```js
import * as utils from "tsutils";
utils.isIdentifier(node); // typeguard
utils.getLineRanges(sourceFile); // utilities
```

If you don't need everything offered by this package, you can select what should be imported. The parts that are not imported are never read from disk and may save some startup time and reduce memory consumtion.

If you only need typeguards you can explicitly import them:
```js
import { isIdentifier } from "tsutils/typeguard";
// You can even distiguish between typeguards for nodes and types
import { isUnionTypeNode } from "tsutils/typeguard/node";
import { isUnionType } from "tsutils/typeguard/type";
```

If you only need the utilities you can also explicitly import them:
```js
import { forEachComment, forEachToken } from "tsutils/util";
```

### Typescript version dependency

This package is backwards compatible with typescript 2.8.0 at runtime although compiling might need a newer version of typescript installed.

Using `typescript@next` might work, but it's not officially supported. If you encounter any bugs, please open an issue.

For compatibility with older versions of TypeScript typeguard functions are separated by TypeScript version. If you are stuck on `typescript@2.8`, you should import directly from the submodule for that version:

```js
// all typeguards compatible with typescript@2.8
import { isIdentifier } from "tsutils/typeguard/2.8";
// you can even use nested submodules
import { isIdentifier } from "tsutils/typeguard/2.8/node";

// all typeguards compatible with typescript@2.9 (includes those of 2.8)
import { isIdentifier } from "tsutils/typeguard/2.9";

// always points to the latest stable version (2.9 as of writing this)
import { isIdentifier } from "tsutils/typeguard";
import { isIdentifier } from "tsutils";

// always points to the typeguards for the next TypeScript version (3.0 as of writing this)
import { isIdentifier } from "tsutils/typeguard/next";
```

Note that if you are also using utility functions, you should prefer the relevant submodule:

```js
// importing directly from 'tsutils' would pull in the latest typeguards
import { forEachToken } from 'tsutils/util';
import { isIdentifier } from 'tsutils/typeguard/2.8';
```
# 0.9.0
- update dependencies, in particular `levn` and `type-check` - this could affect behaviour of argument parsing

# 0.8.3
- changes dependency from `wordwrap` to `word-wrap` due to license issue
- update dependencies

# 0.8.2
- fix bug #18 - detect missing value when flag is last item
- update dependencies

# 0.8.1
- update `fast-levenshtein` dependency

# 0.8.0
- update `levn` dependency - supplying a float value to an option with type `Int` now throws an error, instead of silently converting to an `Int`

# 0.7.1
- fix bug with use of `defaults` and `concatRepeatedArrays` or `mergeRepeatedObjects`

# 0.7.0
- added `concatrepeatedarrays` option: `oneValuePerFlag`, only allows one array value per flag
- added `typeAliases` option
- added `parseArgv` which takes an array and parses with the first two items sliced off
- changed enum help style
- bug fixes (#12)
- use of `concatRepeatedArrays` and `mergeRepeatedObjects` at the top level is deprecated, use it as either a per-option option, or set them in the `defaults` object to set them for all objects

# 0.6.0
- added `defaults` lib-option flag, allowing one to set default properties for all options
- added `concatRepeatedArrays` and `mergeRepeatedObjects` as option level properties, allowing you to turn this feature on for specific options only

# 0.5.0
- `Boolean` flags with `default: 'true'`, and no short aliases, will by default show the `--no` version in help

# 0.4.0
- add `mergeRepeatedObjects` setting

# 0.3.0
- add `concatRepeatedArrays` setting
- add `overrideRequired` option setting
- use just Levenshtein string compare algo rather than Levenshtein Damerau to due dependency license issue

# 0.2.2
- bug fixes

# 0.2.1
- improved interpolation
- added changelog

# 0.2.0
- add dependency checks to options - added `dependsOn` as an option property
- add interpolation for `prepend` and `append` text with new `generateHelp` option, `interpolate`

# 0.1.1
- update dependencies

# 0.1.0
- initial release
# Optionator
<a name="optionator" />

Optionator is a JavaScript/Node.js option parsing and help generation library used by [eslint](http://eslint.org), [Grasp](http://graspjs.com), [LiveScript](http://livescript.net), [esmangle](https://github.com/estools/esmangle), [escodegen](https://github.com/estools/escodegen), and [many more](https://www.npmjs.com/browse/depended/optionator).

For an online demo, check out the [Grasp online demo](http://www.graspjs.com/#demo).

[About](#about) &middot; [Usage](#usage) &middot; [Settings Format](#settings-format) &middot; [Argument Format](#argument-format)

## Why?
The  problem with other option parsers, such as `yargs` or `minimist`, is they just accept all input, valid or not.
With Optionator, if you mistype an option, it will give you an error (with a suggestion for what you meant).
If you give the wrong type of argument for an option, it will give you an error rather than supplying the wrong input to your application.

    $ cmd --halp
    Invalid option '--halp' - perhaps you meant '--help'?

    $ cmd --count str
    Invalid value for option 'count' - expected type Int, received value: str.

Other helpful features include reformatting the help text based on the size of the console, so that it fits even if the console is narrow, and accepting not just an array (eg. process.argv), but a string or object as well, making things like testing much easier.

## About
Optionator uses [type-check](https://github.com/gkz/type-check) and [levn](https://github.com/gkz/levn) behind the scenes to cast and verify input according the specified types.

MIT license. Version 0.9.3

    npm install optionator

For updates on Optionator, [follow me on twitter](https://twitter.com/gkzahariev).

Optionator is a Node.js module, but can be used in the browser as well if packed with webpack/browserify.

## Usage
`require('optionator');` returns a function. It has one property, `VERSION`, the current version of the library as a string. This function is called with an object specifying your options and other information, see the [settings format section](#settings-format). This in turn returns an object with three properties, `parse`, `parseArgv`, `generateHelp`, and `generateHelpForOption`, which are all functions.

```js
var optionator = require('optionator')({
    prepend: 'Usage: cmd [options]',
    append: 'Version 1.0.0',
    options: [{
        option: 'help',
        alias: 'h',
        type: 'Boolean',
        description: 'displays help'
    }, {
        option: 'count',
        alias: 'c',
        type: 'Int',
        description: 'number of things',
        example: 'cmd --count 2'
    }]
});

var options = optionator.parseArgv(process.argv);
if (options.help) {
    console.log(optionator.generateHelp());
}
...
```

### parse(input, parseOptions)
`parse` processes the `input` according to your settings, and returns an object with the results.

##### arguments
* input - `[String] | Object | String` - the input you wish to parse
* parseOptions - `{slice: Int}` - all options optional
    - `slice` specifies how much to slice away from the beginning if the input is an array or string - by default `0` for string, `2` for array (works with `process.argv`)

##### returns
`Object` - the parsed options, each key is a camelCase version of the option name (specified in dash-case), and each value is the processed value for that option. Positional values are in an array under the `_` key.

##### example
```js
parse(['node', 't.js', '--count', '2', 'positional']); // {count: 2, _: ['positional']}
parse('--count 2 positional');                         // {count: 2, _: ['positional']}
parse({count: 2, _:['positional']});                   // {count: 2, _: ['positional']}
```

### parseArgv(input)
`parseArgv` works exactly like `parse`, but only for array input and it slices off the first two elements.

##### arguments
* input - `[String]` - the input you wish to parse

##### returns
See "returns" section in "parse"

##### example
```js
parseArgv(process.argv);
```

### generateHelp(helpOptions)
`generateHelp` produces help text based on your settings.

##### arguments
* helpOptions - `{showHidden: Boolean, interpolate: Object}` - all options optional
    - `showHidden` specifies whether to show options with `hidden: true` specified, by default it is `false`
    - `interpolate` specify data to be interpolated in `prepend` and `append` text, `{{key}}` is the format - eg. `generateHelp({interpolate:{version: '0.4.2'}})`, will change this `append` text: `Version {{version}}` to `Version 0.4.2`

##### returns
`String` - the generated help text

##### example
```js
generateHelp(); /*
"Usage: cmd [options] positional

  -h, --help       displays help
  -c, --count Int  number of things

Version  1.0.0
"*/
```

### generateHelpForOption(optionName)
`generateHelpForOption` produces expanded help text for the specified with `optionName` option. If an `example` was specified for the option, it will be displayed,  and if a `longDescription` was specified, it will display that instead of the `description`.

##### arguments
* optionName - `String` - the name of the option to display

##### returns
`String` - the generated help text for the option

##### example
```js
generateHelpForOption('count'); /*
"-c, --count Int
description: number of things
example: cmd --count 2
"*/
```

## Settings Format
When your `require('optionator')`, you get a function that takes in a settings object. This object has the type:

    {
      prepend: String,
      append: String,
      options: [{heading: String} | {
        option: String,
        alias: [String] | String,
        type: String,
        enum: [String],
        default: String,
        restPositional: Boolean,
        required: Boolean,
        overrideRequired: Boolean,
        dependsOn: [String] | String,
        concatRepeatedArrays: Boolean | (Boolean, Object),
        mergeRepeatedObjects: Boolean,
        description: String,
        longDescription: String,
        example: [String] | String
      }],
      helpStyle: {
        aliasSeparator: String,
        typeSeparator: String,
        descriptionSeparator: String,
        initialIndent: Int,
        secondaryIndent: Int,
        maxPadFactor: Number
      },
      mutuallyExclusive: [[String | [String]]],
      concatRepeatedArrays: Boolean | (Boolean, Object), // deprecated, set in defaults object
      mergeRepeatedObjects: Boolean, // deprecated, set in defaults object
      positionalAnywhere: Boolean,
      typeAliases: Object,
      defaults: Object
    }

All of the properties are optional (the `Maybe` has been excluded for brevities sake), except for having either `heading: String` or `option: String` in each object in the `options` array.

### Top Level Properties
* `prepend` is an optional string to be placed before the options in the help text
* `append` is an optional string to be placed after the options in the help text
* `options` is a required array specifying your options and headings, the options and headings will be displayed in the order specified
* `helpStyle` is an optional object which enables you to change the default appearance of some aspects of the help text
* `mutuallyExclusive` is an optional array of arrays of either strings or arrays of strings. The top level array is a list of rules, each rule is a list of elements - each element can be either a string (the name of an option), or a list of strings (a group of option names) - there will be an error if more than one element is present
* `concatRepeatedArrays` see description under the "Option Properties" heading - use at the top level is deprecated, if you want to set this for all options, use the `defaults` property
* `mergeRepeatedObjects` see description under the "Option Properties" heading - use at the top level is deprecated, if you want to set this for all options, use the `defaults` property
* `positionalAnywhere` is an optional boolean (defaults to `true`) - when `true` it allows positional arguments anywhere, when `false`, all arguments after the first positional one are taken to be positional as well, even if they look like a flag. For example, with `positionalAnywhere: false`, the arguments `--flag --boom 12 --crack` would have two positional arguments: `12` and `--crack`
* `typeAliases` is an optional object, it allows you to set aliases for types, eg. `{Path: 'String'}` would allow you to use the type `Path` as an alias for the type `String`
* `defaults` is an optional object following the option properties format, which specifies default values for all options. A default will be overridden if manually set. For example, you can do `default: { type: "String" }` to set the default type of all options to `String`, and then override that default in an individual option by setting the `type` property

#### Heading Properties
* `heading` a required string, the name of the heading

#### Option Properties
* `option` the required name of the option - use dash-case, without the leading dashes
* `alias` is an optional string or array of strings which specify any aliases for the option
* `type` is a required string in the [type check](https://github.com/gkz/type-check) [format](https://github.com/gkz/type-check#type-format), this will be used to cast the inputted value and validate it
* `enum` is an optional array of strings, each string will be parsed by [levn](https://github.com/gkz/levn) - the argument value must be one of the resulting values - each potential value must validate against the specified `type`
* `default` is a optional string, which will be parsed by [levn](https://github.com/gkz/levn) and used as the default value if none is set - the value must validate against the specified `type`
* `restPositional` is an optional boolean - if set to `true`, everything after the option will be taken to be a positional argument, even if it looks like a named argument
* `required` is an optional boolean - if set to `true`, the option parsing will fail if the option is not defined
* `overrideRequired` is a optional boolean - if set to `true` and the option is used, and there is another option which is required but not set, it will override the need for the required option and there will be no error - this is useful if you have required options and want to use `--help` or `--version` flags
* `concatRepeatedArrays` is an optional boolean or tuple with boolean and options object (defaults to `false`) - when set to `true` and an option contains an array value and is repeated, the subsequent values for the flag will be appended rather than overwriting the original value - eg. option `g` of type `[String]`: `-g a -g b -g c,d` will result in `['a','b','c','d']`

 You can supply an options object by giving the following value: `[true, options]`. The one currently supported option is `oneValuePerFlag`, this only allows one array value per flag. This is useful if your potential values contain a comma.
* `mergeRepeatedObjects` is an optional boolean (defaults to `false`) - when set to `true` and an option contains an object value and is repeated, the subsequent values for the flag will be merged rather than overwriting the original value - eg. option `g` of type `Object`: `-g a:1 -g b:2 -g c:3,d:4` will result in `{a: 1, b: 2, c: 3, d: 4}`
* `dependsOn` is an optional string or array of strings - if simply a string (the name of another option), it will make sure that that other option is set, if an array of strings, depending on whether `'and'` or `'or'` is first, it will either check whether all (`['and', 'option-a', 'option-b']`), or at least one (`['or', 'option-a', 'option-b']`) other options are set
* `description` is an optional string, which will be displayed next to the option in the help text
* `longDescription` is an optional string, it will be displayed instead of the `description` when `generateHelpForOption` is used
* `example` is an optional string or array of strings with example(s) for the option - these will be displayed when `generateHelpForOption` is used

#### Help Style Properties
* `aliasSeparator` is an optional string, separates multiple names from each other - default: ' ,'
* `typeSeparator` is an optional string, separates the type from the names - default: ' '
* `descriptionSeparator` is an optional string , separates the description from the padded name and type - default: '  '
* `initialIndent` is an optional int - the amount of indent for options - default: 2
* `secondaryIndent` is an optional int - the amount of indent if wrapped fully (in addition to the initial indent) - default: 4
* `maxPadFactor` is an optional number - affects the default level of padding for the names/type, it is multiplied by the average of the length of the names/type - default: 1.5

## Argument Format
At the highest level there are two types of arguments: named, and positional.

Name arguments of any length are prefixed with `--` (eg. `--go`), and those of one character may be prefixed with either `--` or `-` (eg. `-g`).

There are two types of named arguments: boolean flags (eg. `--problemo`, `-p`) which take no value and result in a `true` if they are present, the falsey `undefined` if they are not present, or `false` if present and explicitly prefixed with `no` (eg. `--no-problemo`). Named arguments with values (eg. `--tseries 800`, `-t 800`) are the other type. If the option has a type `Boolean` it will automatically be made into a boolean flag. Any other type results in a named argument that takes a value.

For more information about how to properly set types to get the value you want, take a look at the [type check](https://github.com/gkz/type-check) and [levn](https://github.com/gkz/levn) pages.

You can group single character arguments that use a single `-`, however all except the last must be boolean flags (which take no value). The last may be a boolean flag, or an argument which takes a value - eg. `-ba 2` is equivalent to `-b -a 2`.

Positional arguments are all those values which do not fall under the above - they can be anywhere, not just at the end. For example, in `cmd -b one -a 2 two` where `b` is a boolean flag, and `a` has the type `Number`, there are two positional arguments, `one` and `two`.

Everything after an `--` is positional, even if it looks like a named argument.

You may optionally use `=` to separate option names from values, for example: `--count=2`.

If you specify the option `NUM`, then any argument using a single `-` followed by a number will be valid and will set the value of `NUM`. Eg. `-2` will be parsed into `NUM: 2`.

If duplicate named arguments are present, the last one will be taken.

## Technical About
`optionator` is written in [LiveScript](http://livescript.net/) - a language that compiles to JavaScript. It uses [levn](https://github.com/gkz/levn) to cast arguments to their specified type, and uses [type-check](https://github.com/gkz/type-check) to validate values. It also uses the [prelude.ls](http://preludels.com/) library.
# URI.js

URI.js is an [RFC 3986](http://www.ietf.org/rfc/rfc3986.txt) compliant, scheme extendable URI parsing/validating/resolving library for all JavaScript environments (browsers, Node.js, etc).
It is also compliant with the IRI ([RFC 3987](http://www.ietf.org/rfc/rfc3987.txt)), IDNA ([RFC 5890](http://www.ietf.org/rfc/rfc5890.txt)), IPv6 Address ([RFC 5952](http://www.ietf.org/rfc/rfc5952.txt)), IPv6 Zone Identifier ([RFC 6874](http://www.ietf.org/rfc/rfc6874.txt)) specifications.

URI.js has an extensive test suite, and works in all (Node.js, web) environments. It weighs in at 6.4kb (gzipped, 17kb deflated).

## API

### Parsing

	URI.parse("uri://user:pass@example.com:123/one/two.three?q1=a1&q2=a2#body");
	//returns:
	//{
	//  scheme : "uri",
	//  userinfo : "user:pass",
	//  host : "example.com",
	//  port : 123,
	//  path : "/one/two.three",
	//  query : "q1=a1&q2=a2",
	//  fragment : "body"
	//}

### Serializing

	URI.serialize({scheme : "http", host : "example.com", fragment : "footer"}) === "http://example.com/#footer"

### Resolving

	URI.resolve("uri://a/b/c/d?q", "../../g") === "uri://a/g"

### Normalizing

	URI.normalize("HTTP://ABC.com:80/%7Esmith/home.html") === "http://abc.com/~smith/home.html"

### Comparison

	URI.equal("example://a/b/c/%7Bfoo%7D", "eXAMPLE://a/./b/../b/%63/%7bfoo%7d") === true

### IP Support

	//IPv4 normalization
	URI.normalize("//192.068.001.000") === "//192.68.1.0"

	//IPv6 normalization
	URI.normalize("//[2001:0:0DB8::0:0001]") === "//[2001:0:db8::1]"

	//IPv6 zone identifier support
	URI.parse("//[2001:db8::7%25en1]");
	//returns:
	//{
	//  host : "2001:db8::7%en1"
	//}

### IRI Support

	//convert IRI to URI
	URI.serialize(URI.parse("http://examplé.org/rosé")) === "http://xn--exampl-gva.org/ros%C3%A9"
	//convert URI to IRI
	URI.serialize(URI.parse("http://xn--exampl-gva.org/ros%C3%A9"), {iri:true}) === "http://examplé.org/rosé"

### Options

All of the above functions can accept an additional options argument that is an object that can contain one or more of the following properties:

*	`scheme` (string)

	Indicates the scheme that the URI should be treated as, overriding the URI's normal scheme parsing behavior.

*	`reference` (string)

	If set to `"suffix"`, it indicates that the URI is in the suffix format, and the validator will use the option's `scheme` property to determine the URI's scheme.

*	`tolerant` (boolean, false)

	If set to `true`, the parser will relax URI resolving rules.

*	`absolutePath` (boolean, false)

	If set to `true`, the serializer will not resolve a relative `path` component.

*	`iri` (boolean, false)

	If set to `true`, the serializer will unescape non-ASCII characters as per [RFC 3987](http://www.ietf.org/rfc/rfc3987.txt).

*	`unicodeSupport` (boolean, false)

	If set to `true`, the parser will unescape non-ASCII characters in the parsed output as per [RFC 3987](http://www.ietf.org/rfc/rfc3987.txt).

*	`domainHost` (boolean, false)

	If set to `true`, the library will treat the `host` component as a domain name, and convert IDNs (International Domain Names) as per [RFC 5891](http://www.ietf.org/rfc/rfc5891.txt).

## Scheme Extendable

URI.js supports inserting custom [scheme](http://en.wikipedia.org/wiki/URI_scheme) dependent processing rules. Currently, URI.js has built in support for the following schemes:

*	http \[[RFC 2616](http://www.ietf.org/rfc/rfc2616.txt)\]
*	https \[[RFC 2818](http://www.ietf.org/rfc/rfc2818.txt)\]
*	ws \[[RFC 6455](http://www.ietf.org/rfc/rfc6455.txt)\]
*	wss \[[RFC 6455](http://www.ietf.org/rfc/rfc6455.txt)\]
*	mailto \[[RFC 6068](http://www.ietf.org/rfc/rfc6068.txt)\]
*	urn \[[RFC 2141](http://www.ietf.org/rfc/rfc2141.txt)\]
*	urn:uuid \[[RFC 4122](http://www.ietf.org/rfc/rfc4122.txt)\]

### HTTP/HTTPS Support

	URI.equal("HTTP://ABC.COM:80", "http://abc.com/") === true
	URI.equal("https://abc.com", "HTTPS://ABC.COM:443/") === true

### WS/WSS Support

	URI.parse("wss://example.com/foo?bar=baz");
	//returns:
	//{
	//	scheme : "wss",
	//	host: "example.com",
	//	resourceName: "/foo?bar=baz",
	//	secure: true,
	//}

	URI.equal("WS://ABC.COM:80/chat#one", "ws://abc.com/chat") === true

### Mailto Support

	URI.parse("mailto:alpha@example.com,bravo@example.com?subject=SUBSCRIBE&body=Sign%20me%20up!");
	//returns:
	//{
	//	scheme : "mailto",
	//	to : ["alpha@example.com", "bravo@example.com"],
	//	subject : "SUBSCRIBE",
	//	body : "Sign me up!"
	//}

	URI.serialize({
		scheme : "mailto",
		to : ["alpha@example.com"],
		subject : "REMOVE",
		body : "Please remove me",
		headers : {
			cc : "charlie@example.com"
		}
	}) === "mailto:alpha@example.com?cc=charlie@example.com&subject=REMOVE&body=Please%20remove%20me"

### URN Support

	URI.parse("urn:example:foo");
	//returns:
	//{
	//	scheme : "urn",
	//	nid : "example",
	//	nss : "foo",
	//}

#### URN UUID Support

	URI.parse("urn:uuid:f81d4fae-7dec-11d0-a765-00a0c91e6bf6");
	//returns:
	//{
	//	scheme : "urn",
	//	nid : "uuid",
	//	uuid : "f81d4fae-7dec-11d0-a765-00a0c91e6bf6",
	//}

## Usage

To load in a browser, use the following tag:

	<script type="text/javascript" src="uri-js/dist/es5/uri.all.min.js"></script>

To load in a CommonJS/Module environment, first install with npm/yarn by running on the command line:

	npm install uri-js
	# OR
	yarn add uri-js

Then, in your code, load it using:

	const URI = require("uri-js");

If you are writing your code in ES6+ (ESNEXT) or TypeScript, you would load it using:

	import * as URI from "uri-js";

Or you can load just what you need using named exports:

	import { parse, serialize, resolve, resolveComponents, normalize, equal, removeDotSegments, pctEncChar, pctDecChars, escapeComponent, unescapeComponent } from "uri-js";

## Breaking changes

### Breaking changes from 3.x

URN parsing has been completely changed to better align with the specification. Scheme is now always `urn`, but has two new properties: `nid` which contains the Namspace Identifier, and `nss` which contains the Namespace Specific String. The `nss` property will be removed by higher order scheme handlers, such as the UUID URN scheme handler.

The UUID of a URN can now be found in the `uuid` property.

### Breaking changes from 2.x

URI validation has been removed as it was slow, exposed a vulnerabilty, and was generally not useful.

### Breaking changes from 1.x

The `errors` array on parsed components is now an `error` string.
# Changelog

All notable changes to this project will be documented in this file. See [standard-version](https://github.com/conventional-changelog/standard-version) for commit guidelines.

### [7.0.3](https://github.com/moxystudio/node-cross-spawn/compare/v7.0.2...v7.0.3) (2020-05-25)


### Bug Fixes

* detect path key based on correct environment ([#133](https://github.com/moxystudio/node-cross-spawn/issues/133)) ([159e7e9](https://github.com/moxystudio/node-cross-spawn/commit/159e7e9785e57451cba034ae51719f97135074ae))

### [7.0.2](https://github.com/moxystudio/node-cross-spawn/compare/v7.0.1...v7.0.2) (2020-04-04)


### Bug Fixes

* fix worker threads in Node >=11.10.0 ([#132](https://github.com/moxystudio/node-cross-spawn/issues/132)) ([6c5b4f0](https://github.com/moxystudio/node-cross-spawn/commit/6c5b4f015814a6c4f6b33230dfd1a860aedc0aaf))

### [7.0.1](https://github.com/moxystudio/node-cross-spawn/compare/v7.0.0...v7.0.1) (2019-10-07)


### Bug Fixes

* **core:** support worker threads ([#127](https://github.com/moxystudio/node-cross-spawn/issues/127)) ([cfd49c9](https://github.com/moxystudio/node-cross-spawn/commit/cfd49c9))

## [7.0.0](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.5...v7.0.0) (2019-09-03)


### ⚠ BREAKING CHANGES

* drop support for Node.js < 8

* drop support for versions below Node.js 8 ([#125](https://github.com/moxystudio/node-cross-spawn/issues/125)) ([16feb53](https://github.com/moxystudio/node-cross-spawn/commit/16feb53))

<a name="6.0.5"></a>
## [6.0.5](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.4...v6.0.5) (2018-03-02)


### Bug Fixes

* avoid using deprecated Buffer constructor ([#94](https://github.com/moxystudio/node-cross-spawn/issues/94)) ([d5770df](https://github.com/moxystudio/node-cross-spawn/commit/d5770df)), closes [/nodejs.org/api/deprecations.html#deprecations_dep0005](https://github.com//nodejs.org/api/deprecations.html/issues/deprecations_dep0005)



<a name="6.0.4"></a>
## [6.0.4](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.3...v6.0.4) (2018-01-31)


### Bug Fixes

* fix paths being incorrectly normalized on unix ([06ee3c6](https://github.com/moxystudio/node-cross-spawn/commit/06ee3c6)), closes [#90](https://github.com/moxystudio/node-cross-spawn/issues/90)



<a name="6.0.3"></a>
## [6.0.3](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.2...v6.0.3) (2018-01-23)



<a name="6.0.2"></a>
## [6.0.2](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.1...v6.0.2) (2018-01-23)



<a name="6.0.1"></a>
## [6.0.1](https://github.com/moxystudio/node-cross-spawn/compare/v6.0.0...v6.0.1) (2018-01-23)



<a name="6.0.0"></a>
# [6.0.0](https://github.com/moxystudio/node-cross-spawn/compare/5.1.0...6.0.0) (2018-01-23)


### Bug Fixes

* fix certain arguments not being correctly escaped or causing batch syntax error ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10)), closes [#82](https://github.com/moxystudio/node-cross-spawn/issues/82) [#51](https://github.com/moxystudio/node-cross-spawn/issues/51)
* fix commands as posix relatixe paths not working correctly, e.g.: `./my-command` ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10))
* fix `options` argument being mutated ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10))
* fix commands resolution when PATH was actually Path ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10))


### Features

* improve compliance with node's ENOENT errors ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10))
* improve detection of node's shell option support ([900cf10](https://github.com/moxystudio/node-cross-spawn/commit/900cf10))


### Chores

* upgrade tooling
* upgrate project to es6 (node v4)


### BREAKING CHANGES

* remove support for older nodejs versions, only `node >= 4` is supported


<a name="5.1.0"></a>
## [5.1.0](https://github.com/moxystudio/node-cross-spawn/compare/5.0.1...5.1.0) (2017-02-26)


### Bug Fixes

* fix `options.shell` support for NodeJS [v4.8](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V4.md#4.8.0)


<a name="5.0.1"></a>
## [5.0.1](https://github.com/moxystudio/node-cross-spawn/compare/5.0.0...5.0.1) (2016-11-04)


### Bug Fixes

* fix `options.shell` support for NodeJS v7


<a name="5.0.0"></a>
# [5.0.0](https://github.com/moxystudio/node-cross-spawn/compare/4.0.2...5.0.0) (2016-10-30)


## Features

* add support for `options.shell`
* improve parsing of shebangs by using [`shebang-command`](https://github.com/kevva/shebang-command) module


## Chores

* refactor some code to make it more clear
* update README caveats
# cross-spawn

[![NPM version][npm-image]][npm-url] [![Downloads][downloads-image]][npm-url] [![Build Status][travis-image]][travis-url] [![Build status][appveyor-image]][appveyor-url] [![Coverage Status][codecov-image]][codecov-url] [![Dependency status][david-dm-image]][david-dm-url] [![Dev Dependency status][david-dm-dev-image]][david-dm-dev-url]

[npm-url]:https://npmjs.org/package/cross-spawn
[downloads-image]:https://img.shields.io/npm/dm/cross-spawn.svg
[npm-image]:https://img.shields.io/npm/v/cross-spawn.svg
[travis-url]:https://travis-ci.org/moxystudio/node-cross-spawn
[travis-image]:https://img.shields.io/travis/moxystudio/node-cross-spawn/master.svg
[appveyor-url]:https://ci.appveyor.com/project/satazor/node-cross-spawn
[appveyor-image]:https://img.shields.io/appveyor/ci/satazor/node-cross-spawn/master.svg
[codecov-url]:https://codecov.io/gh/moxystudio/node-cross-spawn
[codecov-image]:https://img.shields.io/codecov/c/github/moxystudio/node-cross-spawn/master.svg
[david-dm-url]:https://david-dm.org/moxystudio/node-cross-spawn
[david-dm-image]:https://img.shields.io/david/moxystudio/node-cross-spawn.svg
[david-dm-dev-url]:https://david-dm.org/moxystudio/node-cross-spawn?type=dev
[david-dm-dev-image]:https://img.shields.io/david/dev/moxystudio/node-cross-spawn.svg

A cross platform solution to node's spawn and spawnSync.


## Installation

Node.js version 8 and up:
`$ npm install cross-spawn`

Node.js version 7 and under:
`$ npm install cross-spawn@6`

## Why

Node has issues when using spawn on Windows:

- It ignores [PATHEXT](https://github.com/joyent/node/issues/2318)
- It does not support [shebangs](https://en.wikipedia.org/wiki/Shebang_(Unix))
- Has problems running commands with [spaces](https://github.com/nodejs/node/issues/7367)
- Has problems running commands with posix relative paths (e.g.: `./my-folder/my-executable`)
- Has an [issue](https://github.com/moxystudio/node-cross-spawn/issues/82) with command shims (files in `node_modules/.bin/`), where arguments with quotes and parenthesis would result in [invalid syntax error](https://github.com/moxystudio/node-cross-spawn/blob/e77b8f22a416db46b6196767bcd35601d7e11d54/test/index.test.js#L149)
- No `options.shell` support on node `<v4.8`

All these issues are handled correctly by `cross-spawn`.
There are some known modules, such as [win-spawn](https://github.com/ForbesLindesay/win-spawn), that try to solve this but they are either broken or provide faulty escaping of shell arguments.


## Usage

Exactly the same way as node's [`spawn`](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options) or [`spawnSync`](https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options), so it's a drop in replacement.


```js
const spawn = require('cross-spawn');

// Spawn NPM asynchronously
const child = spawn('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' });

// Spawn NPM synchronously
const result = spawn.sync('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' });
```


## Caveats

### Using `options.shell` as an alternative to `cross-spawn`

Starting from node `v4.8`, `spawn` has a `shell` option that allows you run commands from within a shell. This new option solves
the [PATHEXT](https://github.com/joyent/node/issues/2318) issue but:

- It's not supported in node `<v4.8`
- You must manually escape the command and arguments which is very error prone, specially when passing user input
- There are a lot of other unresolved issues from the [Why](#why) section that you must take into account

If you are using the `shell` option to spawn a command in a cross platform way, consider using `cross-spawn` instead. You have been warned.

### `options.shell` support

While `cross-spawn` adds support for `options.shell` in node `<v4.8`, all of its enhancements are disabled.

This mimics the Node.js behavior. More specifically, the command and its arguments will not be automatically escaped nor shebang support will be offered. This is by design because if you are using `options.shell` you are probably targeting a specific platform anyway and you don't want things to get into your way.

### Shebangs support

While `cross-spawn` handles shebangs on Windows, its support is limited. More specifically, it just supports `#!/usr/bin/env <program>` where `<program>` must not contain any arguments.   
If you would like to have the shebang support improved, feel free to contribute via a pull-request.

Remember to always test your code on Windows!


## Tests

`$ npm test`   
`$ npm test -- --watch` during development


## License

Released under the [MIT License](https://www.opensource.org/licenses/mit-license.php).
[![npm version](https://img.shields.io/npm/v/espree.svg)](https://www.npmjs.com/package/espree)
[![npm downloads](https://img.shields.io/npm/dm/espree.svg)](https://www.npmjs.com/package/espree)
[![Build Status](https://github.com/eslint/espree/workflows/CI/badge.svg)](https://github.com/eslint/espree/actions)
[![Bountysource](https://www.bountysource.com/badge/tracker?tracker_id=9348450)](https://www.bountysource.com/trackers/9348450-eslint?utm_source=9348450&utm_medium=shield&utm_campaign=TRACKER_BADGE)

# Espree

Espree started out as a fork of [Esprima](http://esprima.org) v1.2.2, the last stable published released of Esprima before work on ECMAScript 6 began. Espree is now built on top of [Acorn](https://github.com/ternjs/acorn), which has a modular architecture that allows extension of core functionality. The goal of Espree is to produce output that is similar to Esprima with a similar API so that it can be used in place of Esprima.

## Usage

Install:

```
npm i espree
```

To use in an ESM file:

```js
import * as espree from "espree";

const ast = espree.parse(code);
```

To use in a Common JS file:

```js
const espree = require("espree");

const ast = espree.parse(code);
```

## API

### `parse()`

`parse` parses the given code and returns a abstract syntax tree (AST). It takes two parameters.

- `code` [string]() - the code which needs to be parsed.
- `options (Optional)` [Object]() - read more about this [here](#options).

```js
import * as espree from "espree";

const ast = espree.parse(code);
```

**Example :**

```js
const ast = espree.parse('let foo = "bar"', { ecmaVersion: 6 });
console.log(ast);
```

<details><summary>Output</summary>
<p>

```
Node {
  type: 'Program',
  start: 0,
  end: 15,
  body: [
    Node {
      type: 'VariableDeclaration',
      start: 0,
      end: 15,
      declarations: [Array],
      kind: 'let'
    }
  ],
  sourceType: 'script'
}
```

</p>
</details>

### `tokenize()`

`tokenize` returns the tokens of a given code. It takes two parameters.

- `code` [string]() - the code which needs to be parsed.
- `options (Optional)` [Object]() - read more about this [here](#options).

Even if `options` is empty or undefined or `options.tokens` is `false`, it assigns it to `true` in order to get the `tokens` array

**Example :**

```js
import * as espree from "espree";

const tokens = espree.tokenize('let foo = "bar"', { ecmaVersion: 6 });
console.log(tokens);
```

<details><summary>Output</summary>
<p>

```
Token { type: 'Keyword', value: 'let', start: 0, end: 3 },
Token { type: 'Identifier', value: 'foo', start: 4, end: 7 },
Token { type: 'Punctuator', value: '=', start: 8, end: 9 },
Token { type: 'String', value: '"bar"', start: 10, end: 15 }
```

</p>
</details>

### `version`

Returns the current `espree` version

### `VisitorKeys`

Returns all visitor keys for traversing the AST from [eslint-visitor-keys](https://github.com/eslint/eslint-visitor-keys)

### `latestEcmaVersion`

Returns the latest ECMAScript supported by `espree`

### `supportedEcmaVersions`

Returns an array of all supported ECMAScript versions

## Options

```js
const options = {
    // attach range information to each node
    range: false,

    // attach line/column location information to each node
    loc: false,

    // create a top-level comments array containing all comments
    comment: false,

    // create a top-level tokens array containing all tokens
    tokens: false,

    // Set to 3, 5 (the default), 6, 7, 8, 9, 10, 11, 12, 13, 14 or 15 to specify the version of ECMAScript syntax you want to use.
    // You can also set to 2015 (same as 6), 2016 (same as 7), 2017 (same as 8), 2018 (same as 9), 2019 (same as 10), 2020 (same as 11), 2021 (same as 12), 2022 (same as 13), 2023 (same as 14) or 2024 (same as 15) to use the year-based naming.
    // You can also set "latest" to use the most recently supported version.
    ecmaVersion: 3,

    allowReserved: true, // only allowed when ecmaVersion is 3

    // specify which type of script you're parsing ("script", "module", or "commonjs")
    sourceType: "script",

    // specify additional language features
    ecmaFeatures: {

        // enable JSX parsing
        jsx: false,

        // enable return in global scope (set to true automatically when sourceType is "commonjs")
        globalReturn: false,

        // enable implied strict mode (if ecmaVersion >= 5)
        impliedStrict: false
    }
}
```

## Esprima Compatibility Going Forward

The primary goal is to produce the exact same AST structure and tokens as Esprima, and that takes precedence over anything else. (The AST structure being the [ESTree](https://github.com/estree/estree) API with JSX extensions.) Separate from that, Espree may deviate from what Esprima outputs in terms of where and how comments are attached, as well as what additional information is available on AST nodes. That is to say, Espree may add more things to the AST nodes than Esprima does but the overall AST structure produced will be the same.

Espree may also deviate from Esprima in the interface it exposes.

## Contributing

Issues and pull requests will be triaged and responded to as quickly as possible. We operate under the [ESLint Contributor Guidelines](http://eslint.org/docs/developer-guide/contributing), so please be sure to read them before contributing. If you're not sure where to dig in, check out the [issues](https://github.com/eslint/espree/issues).

Espree is licensed under a permissive BSD 2-clause license.

## Security Policy

We work hard to ensure that Espree is safe for everyone and that security issues are addressed quickly and responsibly. Read the full [security policy](https://github.com/eslint/.github/blob/master/SECURITY.md).

## Build Commands

* `npm test` - run all linting and tests
* `npm run lint` - run all linting

## Differences from Espree 2.x

* The `tokenize()` method does not use `ecmaFeatures`. Any string will be tokenized completely based on ECMAScript 6 semantics.
* Trailing whitespace no longer is counted as part of a node.
* `let` and `const` declarations are no longer parsed by default. You must opt-in by using an `ecmaVersion` newer than `5` or setting `sourceType` to `module`.
* The `esparse` and `esvalidate` binary scripts have been removed.
* There is no `tolerant` option. We will investigate adding this back in the future.

## Known Incompatibilities

In an effort to help those wanting to transition from other parsers to Espree, the following is a list of noteworthy incompatibilities with other parsers. These are known differences that we do not intend to change.

### Esprima 1.2.2

* Esprima counts trailing whitespace as part of each AST node while Espree does not. In Espree, the end of a node is where the last token occurs.
* Espree does not parse `let` and `const` declarations by default.
* Error messages returned for parsing errors are different.
* There are two addition properties on every node and token: `start` and `end`. These represent the same data as `range` and are used internally by Acorn.

### Esprima 2.x

* Esprima 2.x uses a different comment attachment algorithm that results in some comments being added in different places than Espree. The algorithm Espree uses is the same one used in Esprima 1.2.2.

## Frequently Asked Questions

### Why another parser

[ESLint](http://eslint.org) had been relying on Esprima as its parser from the beginning. While that was fine when the JavaScript language was evolving slowly, the pace of development increased dramatically and Esprima had fallen behind. ESLint, like many other tools reliant on Esprima, has been stuck in using new JavaScript language features until Esprima updates, and that caused our users frustration.

We decided the only way for us to move forward was to create our own parser, bringing us inline with JSHint and JSLint, and allowing us to keep implementing new features as we need them. We chose to fork Esprima instead of starting from scratch in order to move as quickly as possible with a compatible API.

With Espree 2.0.0, we are no longer a fork of Esprima but rather a translation layer between Acorn and Esprima syntax. This allows us to put work back into a community-supported parser (Acorn) that is continuing to grow and evolve while maintaining an Esprima-compatible parser for those utilities still built on Esprima.

### Have you tried working with Esprima?

Yes. Since the start of ESLint, we've regularly filed bugs and feature requests with Esprima and will continue to do so. However, there are some different philosophies around how the projects work that need to be worked through. The initial goal was to have Espree track Esprima and eventually merge the two back together, but we ultimately decided that building on top of Acorn was a better choice due to Acorn's plugin support.

### Why don't you just use Acorn?

Acorn is a great JavaScript parser that produces an AST that is compatible with Esprima. Unfortunately, ESLint relies on more than just the AST to do its job. It relies on Esprima's tokens and comment attachment features to get a complete picture of the source code. We investigated switching to Acorn, but the inconsistencies between Esprima and Acorn created too much work for a project like ESLint.

We are building on top of Acorn, however, so that we can contribute back and help make Acorn even better.

### What ECMAScript features do you support?

Espree supports all ECMAScript 2023 features and partially supports ECMAScript 2024 features.

Because ECMAScript 2024 is still under development, we are implementing features as they are finalized. Currently, Espree supports:

* [RegExp v flag with set notation + properties of strings](https://github.com/tc39/proposal-regexp-v-flag)

See [finished-proposals.md](https://github.com/tc39/proposals/blob/master/finished-proposals.md) to know what features are finalized.

### How do you determine which experimental features to support?

In general, we do not support experimental JavaScript features. We may make exceptions from time to time depending on the maturity of the features.
[![npm version](https://img.shields.io/npm/v/eslint-scope.svg)](https://www.npmjs.com/package/eslint-scope)
[![Downloads](https://img.shields.io/npm/dm/eslint-scope.svg)](https://www.npmjs.com/package/eslint-scope)
[![Build Status](https://github.com/eslint/eslint-scope/workflows/CI/badge.svg)](https://github.com/eslint/eslint-scope/actions)

# ESLint Scope

ESLint Scope is the [ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm) scope analyzer used in ESLint. It is a fork of [escope](http://github.com/estools/escope).

## Install

```
npm i eslint-scope --save
```

## 📖 Usage

To use in an ESM file:

```js
import * as eslintScope from 'eslint-scope';
```

To use in a CommonJS file:

```js
const eslintScope = require('eslint-scope');
```

Example:

```js
import * as eslintScope from 'eslint-scope';
import * as espree from 'espree';
import estraverse from 'estraverse';

const ast = espree.parse(code, { range: true });
const scopeManager = eslintScope.analyze(ast);

const currentScope = scopeManager.acquire(ast);   // global scope

estraverse.traverse(ast, {
    enter (node, parent) {
        // do stuff

        if (/Function/.test(node.type)) {
            currentScope = scopeManager.acquire(node);  // get current function scope
        }
    },
    leave(node, parent) {
        if (/Function/.test(node.type)) {
            currentScope = currentScope.upper;  // set to parent scope
        }

        // do stuff
    }
});
```

## Contributing

Issues and pull requests will be triaged and responded to as quickly as possible. We operate under the [ESLint Contributor Guidelines](http://eslint.org/docs/developer-guide/contributing), so please be sure to read them before contributing. If you're not sure where to dig in, check out the [issues](https://github.com/eslint/eslint-scope/issues).

## Build Commands

* `npm test` - run all linting and tests
* `npm run lint` - run all linting

## License

ESLint Scope is licensed under a permissive BSD 2-clause license.
### Estraverse [![Build Status](https://secure.travis-ci.org/estools/estraverse.svg)](http://travis-ci.org/estools/estraverse)

Estraverse ([estraverse](http://github.com/estools/estraverse)) is
[ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm)
traversal functions from [esmangle project](http://github.com/estools/esmangle).

### Documentation

You can find usage docs at [wiki page](https://github.com/estools/estraverse/wiki/Usage).

### Example Usage

The following code will output all variables declared at the root of a file.

```javascript
estraverse.traverse(ast, {
    enter: function (node, parent) {
        if (node.type == 'FunctionExpression' || node.type == 'FunctionDeclaration')
            return estraverse.VisitorOption.Skip;
    },
    leave: function (node, parent) {
        if (node.type == 'VariableDeclarator')
          console.log(node.id.name);
    }
});
```

We can use `this.skip`, `this.remove` and `this.break` functions instead of using Skip, Remove and Break.

```javascript
estraverse.traverse(ast, {
    enter: function (node) {
        this.break();
    }
});
```

And estraverse provides `estraverse.replace` function. When returning node from `enter`/`leave`, current node is replaced with it.

```javascript
result = estraverse.replace(tree, {
    enter: function (node) {
        // Replace it with replaced.
        if (node.type === 'Literal')
            return replaced;
    }
});
```

By passing `visitor.keys` mapping, we can extend estraverse traversing functionality.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Extending the existing traversing rules.
    keys: {
        // TargetNodeName: [ 'keys', 'containing', 'the', 'other', '**node**' ]
        TestExpression: ['argument']
    }
});
```

By passing `visitor.fallback` option, we can control the behavior when encountering unknown nodes.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Iterating the child **nodes** of unknown nodes.
    fallback: 'iteration'
});
```

When `visitor.fallback` is a function, we can determine which keys to visit on each node.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Skip the `argument` property of each node
    fallback: function(node) {
        return Object.keys(node).filter(function(key) {
            return key !== 'argument';
        });
    }
});
```

### License

Copyright (C) 2012-2016 [Yusuke Suzuki](http://github.com/Constellation)
 (twitter: [@Constellation](http://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
[![npm version](https://img.shields.io/npm/v/eslint.svg)](https://www.npmjs.com/package/eslint)
[![Downloads](https://img.shields.io/npm/dm/eslint.svg)](https://www.npmjs.com/package/eslint)
[![Build Status](https://github.com/eslint/eslint/workflows/CI/badge.svg)](https://github.com/eslint/eslint/actions)
[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Feslint%2Feslint.svg?type=shield)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Feslint%2Feslint?ref=badge_shield)
<br />
[![Open Collective Backers](https://img.shields.io/opencollective/backers/eslint)](https://opencollective.com/eslint)
[![Open Collective Sponsors](https://img.shields.io/opencollective/sponsors/eslint)](https://opencollective.com/eslint)
[![Follow us on Twitter](https://img.shields.io/twitter/follow/geteslint?label=Follow&style=social)](https://twitter.com/intent/user?screen_name=geteslint)

# ESLint

[Website](https://eslint.org) |
[Configure ESLint](https://eslint.org/docs/latest/use/configure) |
[Rules](https://eslint.org/docs/rules/) |
[Contribute to ESLint](https://eslint.org/docs/latest/contribute) |
[Report Bugs](https://eslint.org/docs/latest/contribute/report-bugs) |
[Code of Conduct](https://eslint.org/conduct) |
[Twitter](https://twitter.com/geteslint) |
[Discord](https://eslint.org/chat) |
[Mastodon](https://fosstodon.org/@eslint)

ESLint is a tool for identifying and reporting on patterns found in ECMAScript/JavaScript code. In many ways, it is similar to JSLint and JSHint with a few exceptions:

* ESLint uses [Espree](https://github.com/eslint/espree) for JavaScript parsing.
* ESLint uses an AST to evaluate patterns in code.
* ESLint is completely pluggable, every single rule is a plugin and you can add more at runtime.

## Table of Contents

1. [Installation and Usage](#installation-and-usage)
2. [Configuration](#configuration)
3. [Code of Conduct](#code-of-conduct)
4. [Filing Issues](#filing-issues)
5. [Frequently Asked Questions](#frequently-asked-questions)
6. [Releases](#releases)
7. [Security Policy](#security-policy)
8. [Semantic Versioning Policy](#semantic-versioning-policy)
9. [Stylistic Rule Updates](#stylistic-rule-updates)
10. [License](#license)
11. [Team](#team)
12. [Sponsors](#sponsors)
13. [Technology Sponsors](#technology-sponsors)

## Installation and Usage

Prerequisites: [Node.js](https://nodejs.org/) (`^12.22.0`, `^14.17.0`, or `>=16.0.0`) built with SSL support. (If you are using an official Node.js distribution, SSL is always built in.)

You can install and configure ESLint using this command:

```shell
npm init @eslint/config
```

After that, you can run ESLint on any file or directory like this:

```shell
./node_modules/.bin/eslint yourfile.js
```

## Configuration

After running `npm init @eslint/config`, you'll have an `.eslintrc` file in your directory. In it, you'll see some rules configured like this:

```json
{
    "rules": {
        "semi": ["error", "always"],
        "quotes": ["error", "double"]
    }
}
```

The names `"semi"` and `"quotes"` are the names of [rules](https://eslint.org/docs/rules) in ESLint. The first value is the error level of the rule and can be one of these values:

* `"off"` or `0` - turn the rule off
* `"warn"` or `1` - turn the rule on as a warning (doesn't affect exit code)
* `"error"` or `2` - turn the rule on as an error (exit code will be 1)

The three error levels allow you fine-grained control over how ESLint applies rules (for more configuration options and details, see the [configuration docs](https://eslint.org/docs/latest/use/configure)).

## Code of Conduct

ESLint adheres to the [JS Foundation Code of Conduct](https://eslint.org/conduct).

## Filing Issues

Before filing an issue, please be sure to read the guidelines for what you're reporting:

* [Bug Report](https://eslint.org/docs/latest/contribute/report-bugs)
* [Propose a New Rule](https://eslint.org/docs/latest/contribute/propose-new-rule)
* [Proposing a Rule Change](https://eslint.org/docs/latest/contribute/propose-rule-change)
* [Request a Change](https://eslint.org/docs/latest/contribute/request-change)

## Frequently Asked Questions

### I'm using JSCS, should I migrate to ESLint?

Yes. [JSCS has reached end of life](https://eslint.org/blog/2016/07/jscs-end-of-life) and is no longer supported.

We have prepared a [migration guide](https://eslint.org/docs/latest/use/migrating-from-jscs) to help you convert your JSCS settings to an ESLint configuration.

We are now at or near 100% compatibility with JSCS. If you try ESLint and believe we are not yet compatible with a JSCS rule/configuration, please create an issue (mentioning that it is a JSCS compatibility issue) and we will evaluate it as per our normal process.

### Does Prettier replace ESLint?

No, ESLint and Prettier have diffent jobs: ESLint is a linter (looking for problematic patterns) and Prettier is a code formatter. Using both tools is common, refer to [Prettier's documentation](https://prettier.io/docs/en/install#eslint-and-other-linters) to learn how to configure them to work well with each other.

### Why can't ESLint find my plugins?

* Make sure your plugins (and ESLint) are both in your project's `package.json` as devDependencies (or dependencies, if your project uses ESLint at runtime).
* Make sure you have run `npm install` and all your dependencies are installed.
* Make sure your plugins' peerDependencies have been installed as well. You can use `npm view eslint-plugin-myplugin peerDependencies` to see what peer dependencies `eslint-plugin-myplugin` has.

### Does ESLint support JSX?

Yes, ESLint natively supports parsing JSX syntax (this must be enabled in [configuration](https://eslint.org/docs/latest/use/configure)). Please note that supporting JSX syntax *is not* the same as supporting React. React applies specific semantics to JSX syntax that ESLint doesn't recognize. We recommend using [eslint-plugin-react](https://www.npmjs.com/package/eslint-plugin-react) if you are using React and want React semantics.

### What ECMAScript versions does ESLint support?

ESLint has full support for ECMAScript 3, 5 (default), 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, and 2023. You can set your desired ECMAScript syntax (and other settings, like global variables or your target environments) through [configuration](https://eslint.org/docs/latest/use/configure).

### What about experimental features?

ESLint's parser only officially supports the latest final ECMAScript standard. We will make changes to core rules in order to avoid crashes on stage 3 ECMAScript syntax proposals (as long as they are implemented using the correct experimental ESTree syntax). We may make changes to core rules to better work with language extensions (such as JSX, Flow, and TypeScript) on a case-by-case basis.

In other cases (including if rules need to warn on more or fewer cases due to new syntax, rather than just not crashing), we recommend you use other parsers and/or rule plugins. If you are using Babel, you can use [@babel/eslint-parser](https://www.npmjs.com/package/@babel/eslint-parser) and [@babel/eslint-plugin](https://www.npmjs.com/package/@babel/eslint-plugin) to use any option available in Babel.

Once a language feature has been adopted into the ECMAScript standard (stage 4 according to the [TC39 process](https://tc39.github.io/process-document/)), we will accept issues and pull requests related to the new feature, subject to our [contributing guidelines](https://eslint.org/docs/latest/contribute). Until then, please use the appropriate parser and plugin(s) for your experimental feature.

### Where to ask for help?

Open a [discussion](https://github.com/eslint/eslint/discussions) or stop by our [Discord server](https://eslint.org/chat).

### Why doesn't ESLint lock dependency versions?

Lock files like `package-lock.json` are helpful for deployed applications. They ensure that dependencies are consistent between environments and across deployments.

Packages like `eslint` that get published to the npm registry do not include lock files. `npm install eslint` as a user will respect version constraints in ESLint's `package.json`. ESLint and its dependencies will be included in the user's lock file if one exists, but ESLint's own lock file would not be used.

We intentionally don't lock dependency versions so that we have the latest compatible dependency versions in development and CI that our users get when installing ESLint in a project.

The Twilio blog has a [deeper dive](https://www.twilio.com/blog/lockfiles-nodejs) to learn more.

## Releases

We have scheduled releases every two weeks on Friday or Saturday. You can follow a [release issue](https://github.com/eslint/eslint/issues?q=is%3Aopen+is%3Aissue+label%3Arelease) for updates about the scheduling of any particular release.

## Security Policy

ESLint takes security seriously. We work hard to ensure that ESLint is safe for everyone and that security issues are addressed quickly and responsibly. Read the full [security policy](https://github.com/eslint/.github/blob/master/SECURITY.md).

## Semantic Versioning Policy

ESLint follows [semantic versioning](https://semver.org). However, due to the nature of ESLint as a code quality tool, it's not always clear when a minor or major version bump occurs. To help clarify this for everyone, we've defined the following semantic versioning policy for ESLint:

* Patch release (intended to not break your lint build)
    * A bug fix in a rule that results in ESLint reporting fewer linting errors.
    * A bug fix to the CLI or core (including formatters).
    * Improvements to documentation.
    * Non-user-facing changes such as refactoring code, adding, deleting, or modifying tests, and increasing test coverage.
    * Re-releasing after a failed release (i.e., publishing a release that doesn't work for anyone).
* Minor release (might break your lint build)
    * A bug fix in a rule that results in ESLint reporting more linting errors.
    * A new rule is created.
    * A new option to an existing rule that does not result in ESLint reporting more linting errors by default.
    * A new addition to an existing rule to support a newly-added language feature (within the last 12 months) that will result in ESLint reporting more linting errors by default.
    * An existing rule is deprecated.
    * A new CLI capability is created.
    * New capabilities to the public API are added (new classes, new methods, new arguments to existing methods, etc.).
    * A new formatter is created.
    * `eslint:recommended` is updated and will result in strictly fewer linting errors (e.g., rule removals).
* Major release (likely to break your lint build)
    * `eslint:recommended` is updated and may result in new linting errors (e.g., rule additions, most rule option updates).
    * A new option to an existing rule that results in ESLint reporting more linting errors by default.
    * An existing formatter is removed.
    * Part of the public API is removed or changed in an incompatible way. The public API includes:
        * Rule schemas
        * Configuration schema
        * Command-line options
        * Node.js API
        * Rule, formatter, parser, plugin APIs

According to our policy, any minor update may report more linting errors than the previous release (ex: from a bug fix). As such, we recommend using the tilde (`~`) in `package.json` e.g. `"eslint": "~3.1.0"` to guarantee the results of your builds.

## Stylistic Rule Updates

Stylistic rules are frozen according to [our policy](https://eslint.org/blog/2020/05/changes-to-rules-policies) on how we evaluate new rules and rule changes.
This means:

* **Bug fixes**: We will still fix bugs in stylistic rules.
* **New ECMAScript features**: We will also make sure stylistic rules are compatible with new ECMAScript features.
* **New options**: We will **not** add any new options to stylistic rules unless an option is the only way to fix a bug or support a newly-added ECMAScript feature.

## License

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Feslint%2Feslint.svg?type=large)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Feslint%2Feslint?ref=badge_large)

## Team

These folks keep the project moving and are resources for help.

<!-- NOTE: This section is autogenerated. Do not manually edit.-->

<!--teamstart-->

### Technical Steering Committee (TSC)

The people who manage releases, review feature requests, and meet regularly to ensure ESLint is properly maintained.

<table><tbody><tr><td align="center" valign="top" width="11%">
<a href="https://github.com/nzakas">
<img src="https://github.com/nzakas.png?s=75" width="75" height="75" alt="Nicholas C. Zakas's Avatar"><br />
Nicholas C. Zakas
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/mdjermanovic">
<img src="https://github.com/mdjermanovic.png?s=75" width="75" height="75" alt="Milos Djermanovic's Avatar"><br />
Milos Djermanovic
</a>
</td></tr></tbody></table>

### Reviewers

The people who review and implement new features.

<table><tbody><tr><td align="center" valign="top" width="11%">
<a href="https://github.com/aladdin-add">
<img src="https://github.com/aladdin-add.png?s=75" width="75" height="75" alt="唯然's Avatar"><br />
唯然
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/snitin315">
<img src="https://github.com/snitin315.png?s=75" width="75" height="75" alt="Nitin Kumar's Avatar"><br />
Nitin Kumar
</a>
</td></tr></tbody></table>

### Committers

The people who review and fix bugs and help triage issues.

<table><tbody><tr><td align="center" valign="top" width="11%">
<a href="https://github.com/bmish">
<img src="https://github.com/bmish.png?s=75" width="75" height="75" alt="Bryan Mishkin's Avatar"><br />
Bryan Mishkin
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/fasttime">
<img src="https://github.com/fasttime.png?s=75" width="75" height="75" alt="Francesco Trotta's Avatar"><br />
Francesco Trotta
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/ota-meshi">
<img src="https://github.com/ota-meshi.png?s=75" width="75" height="75" alt="Yosuke Ota's Avatar"><br />
Yosuke Ota
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/Tanujkanti4441">
<img src="https://github.com/Tanujkanti4441.png?s=75" width="75" height="75" alt="Tanuj Kanti's Avatar"><br />
Tanuj Kanti
</a>
</td></tr></tbody></table>

### Website Team

Team members who focus specifically on eslint.org

<table><tbody><tr><td align="center" valign="top" width="11%">
<a href="https://github.com/amareshsm">
<img src="https://github.com/amareshsm.png?s=75" width="75" height="75" alt="Amaresh  S M's Avatar"><br />
Amaresh  S M
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/harish-sethuraman">
<img src="https://github.com/harish-sethuraman.png?s=75" width="75" height="75" alt="Strek's Avatar"><br />
Strek
</a>
</td><td align="center" valign="top" width="11%">
<a href="https://github.com/kecrily">
<img src="https://github.com/kecrily.png?s=75" width="75" height="75" alt="Percy Ma's Avatar"><br />
Percy Ma
</a>
</td></tr></tbody></table>

<!--teamend-->

## Sponsors

The following companies, organizations, and individuals support ESLint's ongoing maintenance and development. [Become a Sponsor](https://opencollective.com/eslint) to get your logo on our README and website.

<!-- NOTE: This section is autogenerated. Do not manually edit.-->
<!--sponsorsstart-->
<h3>Platinum Sponsors</h3>
<p><a href="#"><img src="https://images.opencollective.com/2021-frameworks-fund/logo.png" alt="Chrome Frameworks Fund" height="undefined"></a> <a href="https://automattic.com"><img src="https://images.opencollective.com/automattic/d0ef3e1/logo.png" alt="Automattic" height="undefined"></a></p><h3>Gold Sponsors</h3>
<p><a href="https://engineering.salesforce.com"><img src="https://images.opencollective.com/salesforce/ca8f997/logo.png" alt="Salesforce" height="96"></a> <a href="https://www.airbnb.com/"><img src="https://images.opencollective.com/airbnb/d327d66/logo.png" alt="Airbnb" height="96"></a></p><h3>Silver Sponsors</h3>
<p><a href="https://liftoff.io/"><img src="https://images.opencollective.com/liftoff/5c4fa84/logo.png" alt="Liftoff" height="64"></a> <a href="https://americanexpress.io"><img src="https://avatars.githubusercontent.com/u/3853301?v=4" alt="American Express" height="64"></a> <a href="https://www.workleap.com"><img src="https://avatars.githubusercontent.com/u/53535748?u=d1e55d7661d724bf2281c1bfd33cb8f99fe2465f&v=4" alt="Workleap" height="64"></a></p><h3>Bronze Sponsors</h3>
<p><a href="https://themeisle.com"><img src="https://images.opencollective.com/themeisle/d5592fe/logo.png" alt="ThemeIsle" height="32"></a> <a href="https://www.crosswordsolver.org/anagram-solver/"><img src="https://images.opencollective.com/anagram-solver/2666271/logo.png" alt="Anagram Solver" height="32"></a> <a href="https://icons8.com/"><img src="https://images.opencollective.com/icons8/7fa1641/logo.png" alt="Icons8" height="32"></a> <a href="https://discord.com"><img src="https://images.opencollective.com/discordapp/f9645d9/logo.png" alt="Discord" height="32"></a> <a href="https://transloadit.com/"><img src="https://avatars.githubusercontent.com/u/125754?v=4" alt="Transloadit" height="32"></a> <a href="https://www.ignitionapp.com"><img src="https://avatars.githubusercontent.com/u/5753491?v=4" alt="Ignition" height="32"></a> <a href="https://nx.dev"><img src="https://avatars.githubusercontent.com/u/23692104?v=4" alt="Nx" height="32"></a> <a href="https://herocoders.com"><img src="https://avatars.githubusercontent.com/u/37549774?v=4" alt="HeroCoders" height="32"></a></p>
<!--sponsorsend-->

## Technology Sponsors

* Site search ([eslint.org](https://eslint.org)) is sponsored by [Algolia](https://www.algolia.com)
* Hosting for ([eslint.org](https://eslint.org)) is sponsored by [Netlify](https://www.netlify.com)
* Password management is sponsored by [1Password](https://www.1password.com)
# Glob

Match files using the patterns the shell uses, like stars and stuff.

[![Build Status](https://travis-ci.org/isaacs/node-glob.svg?branch=master)](https://travis-ci.org/isaacs/node-glob/) [![Build Status](https://ci.appveyor.com/api/projects/status/kd7f3yftf7unxlsx?svg=true)](https://ci.appveyor.com/project/isaacs/node-glob) [![Coverage Status](https://coveralls.io/repos/isaacs/node-glob/badge.svg?branch=master&service=github)](https://coveralls.io/github/isaacs/node-glob?branch=master)

This is a glob implementation in JavaScript.  It uses the `minimatch`
library to do its matching.

![a fun cartoon logo made of glob characters](logo/glob.png)

## Usage

Install with npm

```
npm i glob
```

```javascript
var glob = require("glob")

// options is optional
glob("**/*.js", options, function (er, files) {
  // files is an array of filenames.
  // If the `nonull` option is set, and nothing
  // was found, then files is ["**/*.js"]
  // er is an error object or null.
})
```

## Glob Primer

"Globs" are the patterns you type when you do stuff like `ls *.js` on
the command line, or put `build/*` in a `.gitignore` file.

Before parsing the path part patterns, braced sections are expanded
into a set.  Braced sections start with `{` and end with `}`, with any
number of comma-delimited sections within.  Braced sections may contain
slash characters, so `a{/b/c,bcd}` would expand into `a/b/c` and `abcd`.

The following characters have special magic meaning when used in a
path portion:

* `*` Matches 0 or more characters in a single path portion
* `?` Matches 1 character
* `[...]` Matches a range of characters, similar to a RegExp range.
  If the first character of the range is `!` or `^` then it matches
  any character not in the range.
* `!(pattern|pattern|pattern)` Matches anything that does not match
  any of the patterns provided.
* `?(pattern|pattern|pattern)` Matches zero or one occurrence of the
  patterns provided.
* `+(pattern|pattern|pattern)` Matches one or more occurrences of the
  patterns provided.
* `*(a|b|c)` Matches zero or more occurrences of the patterns provided
* `@(pattern|pat*|pat?erN)` Matches exactly one of the patterns
  provided
* `**` If a "globstar" is alone in a path portion, then it matches
  zero or more directories and subdirectories searching for matches.
  It does not crawl symlinked directories.

### Dots

If a file or directory path portion has a `.` as the first character,
then it will not match any glob pattern unless that pattern's
corresponding path part also has a `.` as its first character.

For example, the pattern `a/.*/c` would match the file at `a/.b/c`.
However the pattern `a/*/c` would not, because `*` does not start with
a dot character.

You can make glob treat dots as normal characters by setting
`dot:true` in the options.

### Basename Matching

If you set `matchBase:true` in the options, and the pattern has no
slashes in it, then it will seek for any file anywhere in the tree
with a matching basename.  For example, `*.js` would match
`test/simple/basic.js`.

### Empty Sets

If no matching files are found, then an empty array is returned.  This
differs from the shell, where the pattern itself is returned.  For
example:

    $ echo a*s*d*f
    a*s*d*f

To get the bash-style behavior, set the `nonull:true` in the options.

### See Also:

* `man sh`
* `man bash` (Search for "Pattern Matching")
* `man 3 fnmatch`
* `man 5 gitignore`
* [minimatch documentation](https://github.com/isaacs/minimatch)

## glob.hasMagic(pattern, [options])

Returns `true` if there are any special characters in the pattern, and
`false` otherwise.

Note that the options affect the results.  If `noext:true` is set in
the options object, then `+(a|b)` will not be considered a magic
pattern.  If the pattern has a brace expansion, like `a/{b/c,x/y}`
then that is considered magical, unless `nobrace:true` is set in the
options.

## glob(pattern, [options], cb)

* `pattern` `{String}` Pattern to be matched
* `options` `{Object}`
* `cb` `{Function}`
  * `err` `{Error | null}`
  * `matches` `{Array<String>}` filenames found matching the pattern

Perform an asynchronous glob search.

## glob.sync(pattern, [options])

* `pattern` `{String}` Pattern to be matched
* `options` `{Object}`
* return: `{Array<String>}` filenames found matching the pattern

Perform a synchronous glob search.

## Class: glob.Glob

Create a Glob object by instantiating the `glob.Glob` class.

```javascript
var Glob = require("glob").Glob
var mg = new Glob(pattern, options, cb)
```

It's an EventEmitter, and starts walking the filesystem to find matches
immediately.

### new glob.Glob(pattern, [options], [cb])

* `pattern` `{String}` pattern to search for
* `options` `{Object}`
* `cb` `{Function}` Called when an error occurs, or matches are found
  * `err` `{Error | null}`
  * `matches` `{Array<String>}` filenames found matching the pattern

Note that if the `sync` flag is set in the options, then matches will
be immediately available on the `g.found` member.

### Properties

* `minimatch` The minimatch object that the glob uses.
* `options` The options object passed in.
* `aborted` Boolean which is set to true when calling `abort()`.  There
  is no way at this time to continue a glob search after aborting, but
  you can re-use the statCache to avoid having to duplicate syscalls.
* `cache` Convenience object.  Each field has the following possible
  values:
  * `false` - Path does not exist
  * `true` - Path exists
  * `'FILE'` - Path exists, and is not a directory
  * `'DIR'` - Path exists, and is a directory
  * `[file, entries, ...]` - Path exists, is a directory, and the
    array value is the results of `fs.readdir`
* `statCache` Cache of `fs.stat` results, to prevent statting the same
  path multiple times.
* `symlinks` A record of which paths are symbolic links, which is
  relevant in resolving `**` patterns.
* `realpathCache` An optional object which is passed to `fs.realpath`
  to minimize unnecessary syscalls.  It is stored on the instantiated
  Glob object, and may be re-used.

### Events

* `end` When the matching is finished, this is emitted with all the
  matches found.  If the `nonull` option is set, and no match was found,
  then the `matches` list contains the original pattern.  The matches
  are sorted, unless the `nosort` flag is set.
* `match` Every time a match is found, this is emitted with the specific
  thing that matched. It is not deduplicated or resolved to a realpath.
* `error` Emitted when an unexpected error is encountered, or whenever
  any fs error occurs if `options.strict` is set.
* `abort` When `abort()` is called, this event is raised.

### Methods

* `pause` Temporarily stop the search
* `resume` Resume the search
* `abort` Stop the search forever

### Options

All the options that can be passed to Minimatch can also be passed to
Glob to change pattern matching behavior.  Also, some have been added,
or have glob-specific ramifications.

All options are false by default, unless otherwise noted.

All options are added to the Glob object, as well.

If you are running many `glob` operations, you can pass a Glob object
as the `options` argument to a subsequent operation to shortcut some
`stat` and `readdir` calls.  At the very least, you may pass in shared
`symlinks`, `statCache`, `realpathCache`, and `cache` options, so that
parallel glob operations will be sped up by sharing information about
the filesystem.

* `cwd` The current working directory in which to search.  Defaults
  to `process.cwd()`.
* `root` The place where patterns starting with `/` will be mounted
  onto.  Defaults to `path.resolve(options.cwd, "/")` (`/` on Unix
  systems, and `C:\` or some such on Windows.)
* `dot` Include `.dot` files in normal matches and `globstar` matches.
  Note that an explicit dot in a portion of the pattern will always
  match dot files.
* `nomount` By default, a pattern starting with a forward-slash will be
  "mounted" onto the root setting, so that a valid filesystem path is
  returned.  Set this flag to disable that behavior.
* `mark` Add a `/` character to directory matches.  Note that this
  requires additional stat calls.
* `nosort` Don't sort the results.
* `stat` Set to true to stat *all* results.  This reduces performance
  somewhat, and is completely unnecessary, unless `readdir` is presumed
  to be an untrustworthy indicator of file existence.
* `silent` When an unusual error is encountered when attempting to
  read a directory, a warning will be printed to stderr.  Set the
  `silent` option to true to suppress these warnings.
* `strict` When an unusual error is encountered when attempting to
  read a directory, the process will just continue on in search of
  other matches.  Set the `strict` option to raise an error in these
  cases.
* `cache` See `cache` property above.  Pass in a previously generated
  cache object to save some fs calls.
* `statCache` A cache of results of filesystem information, to prevent
  unnecessary stat calls.  While it should not normally be necessary
  to set this, you may pass the statCache from one glob() call to the
  options object of another, if you know that the filesystem will not
  change between calls.  (See "Race Conditions" below.)
* `symlinks` A cache of known symbolic links.  You may pass in a
  previously generated `symlinks` object to save `lstat` calls when
  resolving `**` matches.
* `sync` DEPRECATED: use `glob.sync(pattern, opts)` instead.
* `nounique` In some cases, brace-expanded patterns can result in the
  same file showing up multiple times in the result set.  By default,
  this implementation prevents duplicates in the result set.  Set this
  flag to disable that behavior.
* `nonull` Set to never return an empty set, instead returning a set
  containing the pattern itself.  This is the default in glob(3).
* `debug` Set to enable debug logging in minimatch and glob.
* `nobrace` Do not expand `{a,b}` and `{1..3}` brace sets.
* `noglobstar` Do not match `**` against multiple filenames.  (Ie,
  treat it as a normal `*` instead.)
* `noext` Do not match `+(a|b)` "extglob" patterns.
* `nocase` Perform a case-insensitive match.  Note: on
  case-insensitive filesystems, non-magic patterns will match by
  default, since `stat` and `readdir` will not raise errors.
* `matchBase` Perform a basename-only match if the pattern does not
  contain any slash characters.  That is, `*.js` would be treated as
  equivalent to `**/*.js`, matching all js files in all directories.
* `nodir` Do not match directories, only files.  (Note: to match
  *only* directories, simply put a `/` at the end of the pattern.)
* `ignore` Add a pattern or an array of glob patterns to exclude matches.
  Note: `ignore` patterns are *always* in `dot:true` mode, regardless
  of any other settings.
* `follow` Follow symlinked directories when expanding `**` patterns.
  Note that this can result in a lot of duplicate references in the
  presence of cyclic links.
* `realpath` Set to true to call `fs.realpath` on all of the results.
  In the case of a symlink that cannot be resolved, the full absolute
  path to the matched entry is returned (though it will usually be a
  broken symlink)
* `absolute` Set to true to always receive absolute paths for matched
  files.  Unlike `realpath`, this also affects the values returned in
  the `match` event.
* `fs` File-system object with Node's `fs` API. By default, the built-in
  `fs` module will be used. Set to a volume provided by a library like
  `memfs` to avoid using the "real" file-system.

## Comparisons to other fnmatch/glob implementations

While strict compliance with the existing standards is a worthwhile
goal, some discrepancies exist between node-glob and other
implementations, and are intentional.

The double-star character `**` is supported by default, unless the
`noglobstar` flag is set.  This is supported in the manner of bsdglob
and bash 4.3, where `**` only has special significance if it is the only
thing in a path part.  That is, `a/**/b` will match `a/x/y/b`, but
`a/**b` will not.

Note that symlinked directories are not crawled as part of a `**`,
though their contents may match against subsequent portions of the
pattern.  This prevents infinite loops and duplicates and the like.

If an escaped pattern has no matches, and the `nonull` flag is set,
then glob returns the pattern as-provided, rather than
interpreting the character escapes.  For example,
`glob.match([], "\\*a\\?")` will return `"\\*a\\?"` rather than
`"*a?"`.  This is akin to setting the `nullglob` option in bash, except
that it does not resolve escaped pattern characters.

If brace expansion is not disabled, then it is performed before any
other interpretation of the glob pattern.  Thus, a pattern like
`+(a|{b),c)}`, which would not be valid in bash or zsh, is expanded
**first** into the set of `+(a|b)` and `+(a|c)`, and those patterns are
checked for validity.  Since those two are valid, matching proceeds.

### Comments and Negation

Previously, this module let you mark a pattern as a "comment" if it
started with a `#` character, or a "negated" pattern if it started
with a `!` character.

These options were deprecated in version 5, and removed in version 6.

To specify things that should not match, use the `ignore` option.

## Windows

**Please only use forward-slashes in glob expressions.**

Though windows uses either `/` or `\` as its path separator, only `/`
characters are used by this glob implementation.  You must use
forward-slashes **only** in glob expressions.  Back-slashes will always
be interpreted as escape characters, not path separators.

Results from absolute patterns such as `/foo/*` are mounted onto the
root setting using `path.join`.  On windows, this will by default result
in `/foo/*` matching `C:\foo\bar.txt`.

## Race Conditions

Glob searching, by its very nature, is susceptible to race conditions,
since it relies on directory walking and such.

As a result, it is possible that a file that exists when glob looks for
it may have been deleted or modified by the time it returns the result.

As part of its internal implementation, this program caches all stat
and readdir calls that it makes, in order to cut down on system
overhead.  However, this also makes it even more susceptible to races,
especially if the cache or statCache objects are reused between glob
calls.

Users are thus advised not to use a glob result as a guarantee of
filesystem state in the face of rapid changes.  For the vast majority
of operations, this is never a problem.

## Glob Logo
Glob's logo was created by [Tanya Brassie](http://tanyabrassie.com/). Logo files can be found [here](https://github.com/isaacs/node-glob/tree/master/logo).

The logo is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).

## Contributing

Any change to behavior (including bugfixes) must come with a test.

Patches that fail tests or reduce performance will be rejected.

```
# to run tests
npm test

# to re-generate test fixtures
npm run test-regen

# to benchmark against bash/zsh
npm run bench

# to profile javascript
npm run prof
```

![](oh-my-glob.gif)
### Estraverse [![Build Status](https://secure.travis-ci.org/estools/estraverse.svg)](http://travis-ci.org/estools/estraverse)

Estraverse ([estraverse](http://github.com/estools/estraverse)) is
[ECMAScript](http://www.ecma-international.org/publications/standards/Ecma-262.htm)
traversal functions from [esmangle project](http://github.com/estools/esmangle).

### Documentation

You can find usage docs at [wiki page](https://github.com/estools/estraverse/wiki/Usage).

### Example Usage

The following code will output all variables declared at the root of a file.

```javascript
estraverse.traverse(ast, {
    enter: function (node, parent) {
        if (node.type == 'FunctionExpression' || node.type == 'FunctionDeclaration')
            return estraverse.VisitorOption.Skip;
    },
    leave: function (node, parent) {
        if (node.type == 'VariableDeclarator')
          console.log(node.id.name);
    }
});
```

We can use `this.skip`, `this.remove` and `this.break` functions instead of using Skip, Remove and Break.

```javascript
estraverse.traverse(ast, {
    enter: function (node) {
        this.break();
    }
});
```

And estraverse provides `estraverse.replace` function. When returning node from `enter`/`leave`, current node is replaced with it.

```javascript
result = estraverse.replace(tree, {
    enter: function (node) {
        // Replace it with replaced.
        if (node.type === 'Literal')
            return replaced;
    }
});
```

By passing `visitor.keys` mapping, we can extend estraverse traversing functionality.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Extending the existing traversing rules.
    keys: {
        // TargetNodeName: [ 'keys', 'containing', 'the', 'other', '**node**' ]
        TestExpression: ['argument']
    }
});
```

By passing `visitor.fallback` option, we can control the behavior when encountering unknown nodes.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Iterating the child **nodes** of unknown nodes.
    fallback: 'iteration'
});
```

When `visitor.fallback` is a function, we can determine which keys to visit on each node.

```javascript
// This tree contains a user-defined `TestExpression` node.
var tree = {
    type: 'TestExpression',

    // This 'argument' is the property containing the other **node**.
    argument: {
        type: 'Literal',
        value: 20
    },

    // This 'extended' is the property not containing the other **node**.
    extended: true
};
estraverse.traverse(tree, {
    enter: function (node) { },

    // Skip the `argument` property of each node
    fallback: function(node) {
        return Object.keys(node).filter(function(key) {
            return key !== 'argument';
        });
    }
});
```

### License

Copyright (C) 2012-2016 [Yusuke Suzuki](http://github.com/Constellation)
 (twitter: [@Constellation](http://twitter.com/Constellation)) and other contributors.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
ESQuery is a library for querying the AST output by Esprima for patterns of syntax using a CSS style selector system. Check out the demo:

[demo](https://estools.github.io/esquery/)

The following selectors are supported:
* AST node type: `ForStatement`
* [wildcard](http://dev.w3.org/csswg/selectors4/#universal-selector): `*`
* [attribute existence](http://dev.w3.org/csswg/selectors4/#attribute-selectors): `[attr]`
* [attribute value](http://dev.w3.org/csswg/selectors4/#attribute-selectors): `[attr="foo"]` or `[attr=123]`
* attribute regex: `[attr=/foo.*/]` or (with flags) `[attr=/foo.*/is]`
* attribute conditions: `[attr!="foo"]`, `[attr>2]`, `[attr<3]`, `[attr>=2]`, or `[attr<=3]`
* nested attribute: `[attr.level2="foo"]`
* field: `FunctionDeclaration > Identifier.id`
* [First](http://dev.w3.org/csswg/selectors4/#the-first-child-pseudo) or [last](http://dev.w3.org/csswg/selectors4/#the-last-child-pseudo) child: `:first-child` or `:last-child`
* [nth-child](http://dev.w3.org/csswg/selectors4/#the-nth-child-pseudo) (no ax+b support): `:nth-child(2)`
* [nth-last-child](http://dev.w3.org/csswg/selectors4/#the-nth-last-child-pseudo) (no ax+b support): `:nth-last-child(1)`
* [descendant](http://dev.w3.org/csswg/selectors4/#descendant-combinators): `ancestor descendant`
* [child](http://dev.w3.org/csswg/selectors4/#child-combinators): `parent > child`
* [following sibling](http://dev.w3.org/csswg/selectors4/#general-sibling-combinators): `node ~ sibling`
* [adjacent sibling](http://dev.w3.org/csswg/selectors4/#adjacent-sibling-combinators): `node + adjacent`
* [negation](http://dev.w3.org/csswg/selectors4/#negation-pseudo): `:not(ForStatement)`
* [has](https://drafts.csswg.org/selectors-4/#has-pseudo): `:has(ForStatement)`
* [matches-any](http://dev.w3.org/csswg/selectors4/#matches): `:matches([attr] > :first-child, :last-child)`
* [subject indicator](http://dev.w3.org/csswg/selectors4/#subject): `!IfStatement > [name="foo"]`
* class of AST node: `:statement`, `:expression`, `:declaration`, `:function`, or `:pattern`

[![Build Status](https://travis-ci.org/estools/esquery.png?branch=master)](https://travis-ci.org/estools/esquery)
# import-fresh

> Import a module while bypassing the [cache](https://nodejs.org/api/modules.html#modules_caching)

Useful for testing purposes when you need to freshly import a module.

## Install

```
$ npm install import-fresh
```

## Usage

```js
// foo.js
let i = 0;
module.exports = () => ++i;
```

```js
const importFresh = require('import-fresh');

require('./foo')();
//=> 1

require('./foo')();
//=> 2

importFresh('./foo')();
//=> 1

importFresh('./foo')();
//=> 1
```

## import-fresh for enterprise

Available as part of the Tidelift Subscription.

The maintainers of import-fresh and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-import-fresh?utm_source=npm-import-fresh&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)

## Related

- [clear-module](https://github.com/sindresorhus/clear-module) - Clear a module from the import cache
- [import-from](https://github.com/sindresorhus/import-from) - Import a module from a given path
- [import-cwd](https://github.com/sindresorhus/import-cwd) - Import a module from the current working directory
- [import-lazy](https://github.com/sindresorhus/import-lazy) - Import modules lazily
(MIT License)

Copyright (c) 2013 [Ramesh Nair](http://www.hiddentao.com/)

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use,
copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.

# fast-levenshtein - Levenshtein algorithm in Javascript

[![Build Status](https://secure.travis-ci.org/hiddentao/fast-levenshtein.png)](http://travis-ci.org/hiddentao/fast-levenshtein)
[![NPM module](https://badge.fury.io/js/fast-levenshtein.png)](https://badge.fury.io/js/fast-levenshtein)
[![NPM downloads](https://img.shields.io/npm/dm/fast-levenshtein.svg?maxAge=2592000)](https://www.npmjs.com/package/fast-levenshtein)
[![Follow on Twitter](https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Follow&maxAge=2592000)](https://twitter.com/hiddentao)

An efficient Javascript implementation of the [Levenshtein algorithm](http://en.wikipedia.org/wiki/Levenshtein_distance) with locale-specific collator support.

## Features

* Works in node.js and in the browser.
* Better performance than other implementations by not needing to store the whole matrix ([more info](http://www.codeproject.com/Articles/13525/Fast-memory-efficient-Levenshtein-algorithm)).
* Locale-sensitive string comparisions if needed.
* Comprehensive test suite and performance benchmark.
* Small: <1 KB minified and gzipped

## Installation

### node.js

Install using [npm](http://npmjs.org/):

```bash
$ npm install fast-levenshtein
```

### Browser

Using bower:

```bash
$ bower install fast-levenshtein
```

If you are not using any module loader system then the API will then be accessible via the `window.Levenshtein` object.

## Examples

**Default usage**

```javascript
var levenshtein = require('fast-levenshtein');

var distance = levenshtein.get('back', 'book');   // 2
var distance = levenshtein.get('我愛你', '我叫你');   // 1
```

**Locale-sensitive string comparisons**

It supports using [Intl.Collator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Collator) for locale-sensitive  string comparisons:

```javascript
var levenshtein = require('fast-levenshtein');

levenshtein.get('mikailovitch', 'Mikhaïlovitch', { useCollator: true});
// 1
```

## Building and Testing

To build the code and run the tests:

```bash
$ npm install -g grunt-cli
$ npm install
$ npm run build
```

## Performance

_Thanks to [Titus Wormer](https://github.com/wooorm) for [encouraging me](https://github.com/hiddentao/fast-levenshtein/issues/1) to do this._

Benchmarked against other node.js levenshtein distance modules (on Macbook Air 2012, Core i7, 8GB RAM):

```bash
Running suite Implementation comparison [benchmark/speed.js]...
>> levenshtein-edit-distance x 234 ops/sec ±3.02% (73 runs sampled)
>> levenshtein-component x 422 ops/sec ±4.38% (83 runs sampled)
>> levenshtein-deltas x 283 ops/sec ±3.83% (78 runs sampled)
>> natural x 255 ops/sec ±0.76% (88 runs sampled)
>> levenshtein x 180 ops/sec ±3.55% (86 runs sampled)
>> fast-levenshtein x 1,792 ops/sec ±2.72% (95 runs sampled)
Benchmark done.
Fastest test is fast-levenshtein at 4.2x faster than levenshtein-component
```

You can run this benchmark yourself by doing:

```bash
$ npm install
$ npm run build
$ npm run benchmark
```

## Contributing

If you wish to submit a pull request please update and/or create new tests for any changes you make and ensure the grunt build passes.

See [CONTRIBUTING.md](https://github.com/hiddentao/fast-levenshtein/blob/master/CONTRIBUTING.md) for details.

## License

MIT - see [LICENSE.md](https://github.com/hiddentao/fast-levenshtein/blob/master/LICENSE.md)
# to-regex-range [![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=W8YFZ425KND68) [![NPM version](https://img.shields.io/npm/v/to-regex-range.svg?style=flat)](https://www.npmjs.com/package/to-regex-range) [![NPM monthly downloads](https://img.shields.io/npm/dm/to-regex-range.svg?style=flat)](https://npmjs.org/package/to-regex-range) [![NPM total downloads](https://img.shields.io/npm/dt/to-regex-range.svg?style=flat)](https://npmjs.org/package/to-regex-range) [![Linux Build Status](https://img.shields.io/travis/micromatch/to-regex-range.svg?style=flat&label=Travis)](https://travis-ci.org/micromatch/to-regex-range)

> Pass two numbers, get a regex-compatible source string for matching ranges. Validated against more than 2.78 million test assertions.

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save to-regex-range
```

<details>
<summary><strong>What does this do?</strong></summary>

<br>

This libary generates the `source` string to be passed to `new RegExp()` for matching a range of numbers.

**Example**

```js
const toRegexRange = require('to-regex-range');
const regex = new RegExp(toRegexRange('15', '95'));
```

A string is returned so that you can do whatever you need with it before passing it to `new RegExp()` (like adding `^` or `$` boundaries, defining flags, or combining it another string).

<br>

</details>

<details>
<summary><strong>Why use this library?</strong></summary>

<br>

### Convenience

Creating regular expressions for matching numbers gets deceptively complicated pretty fast.

For example, let's say you need a validation regex for matching part of a user-id, postal code, social security number, tax id, etc:

* regex for matching `1` => `/1/` (easy enough)
* regex for matching `1` through `5` => `/[1-5]/` (not bad...)
* regex for matching `1` or `5` => `/(1|5)/` (still easy...)
* regex for matching `1` through `50` => `/([1-9]|[1-4][0-9]|50)/` (uh-oh...)
* regex for matching `1` through `55` => `/([1-9]|[1-4][0-9]|5[0-5])/` (no prob, I can do this...)
* regex for matching `1` through `555` => `/([1-9]|[1-9][0-9]|[1-4][0-9]{2}|5[0-4][0-9]|55[0-5])/` (maybe not...)
* regex for matching `0001` through `5555` => `/(0{3}[1-9]|0{2}[1-9][0-9]|0[1-9][0-9]{2}|[1-4][0-9]{3}|5[0-4][0-9]{2}|55[0-4][0-9]|555[0-5])/` (okay, I get the point!)

The numbers are contrived, but they're also really basic. In the real world you might need to generate a regex on-the-fly for validation.

**Learn more**

If you're interested in learning more about [character classes](http://www.regular-expressions.info/charclass.html) and other regex features, I personally have always found [regular-expressions.info](http://www.regular-expressions.info/charclass.html) to be pretty useful.

### Heavily tested

As of April 07, 2019, this library runs [>1m test assertions](./test/test.js) against generated regex-ranges to provide brute-force verification that results are correct.

Tests run in ~280ms on my MacBook Pro, 2.5 GHz Intel Core i7.

### Optimized

Generated regular expressions are optimized:

* duplicate sequences and character classes are reduced using quantifiers
* smart enough to use `?` conditionals when number(s) or range(s) can be positive or negative
* uses fragment caching to avoid processing the same exact string more than once

<br>

</details>

## Usage

Add this library to your javascript application with the following line of code

```js
const toRegexRange = require('to-regex-range');
```

The main export is a function that takes two integers: the `min` value and `max` value (formatted as strings or numbers).

```js
const source = toRegexRange('15', '95');
//=> 1[5-9]|[2-8][0-9]|9[0-5]

const regex = new RegExp(`^${source}$`);
console.log(regex.test('14')); //=> false
console.log(regex.test('50')); //=> true
console.log(regex.test('94')); //=> true
console.log(regex.test('96')); //=> false
```

## Options

### options.capture

**Type**: `boolean`

**Deafault**: `undefined`

Wrap the returned value in parentheses when there is more than one regex condition. Useful when you're dynamically generating ranges.

```js
console.log(toRegexRange('-10', '10'));
//=> -[1-9]|-?10|[0-9]

console.log(toRegexRange('-10', '10', { capture: true }));
//=> (-[1-9]|-?10|[0-9])
```

### options.shorthand

**Type**: `boolean`

**Deafault**: `undefined`

Use the regex shorthand for `[0-9]`:

```js
console.log(toRegexRange('0', '999999'));
//=> [0-9]|[1-9][0-9]{1,5}

console.log(toRegexRange('0', '999999', { shorthand: true }));
//=> \d|[1-9]\d{1,5}
```

### options.relaxZeros

**Type**: `boolean`

**Default**: `true`

This option relaxes matching for leading zeros when when ranges are zero-padded.

```js
const source = toRegexRange('-0010', '0010');
const regex = new RegExp(`^${source}$`);
console.log(regex.test('-10')); //=> true
console.log(regex.test('-010')); //=> true
console.log(regex.test('-0010')); //=> true
console.log(regex.test('10')); //=> true
console.log(regex.test('010')); //=> true
console.log(regex.test('0010')); //=> true
```

When `relaxZeros` is false, matching is strict:

```js
const source = toRegexRange('-0010', '0010', { relaxZeros: false });
const regex = new RegExp(`^${source}$`);
console.log(regex.test('-10')); //=> false
console.log(regex.test('-010')); //=> false
console.log(regex.test('-0010')); //=> true
console.log(regex.test('10')); //=> false
console.log(regex.test('010')); //=> false
console.log(regex.test('0010')); //=> true
```

## Examples

| **Range**                   | **Result**                                                                      | **Compile time** |
| ---                         | ---                                                                             | ---              |
| `toRegexRange(-10, 10)`     | `-[1-9]\|-?10\|[0-9]`                                                           | _132μs_          |
| `toRegexRange(-100, -10)`   | `-1[0-9]\|-[2-9][0-9]\|-100`                                                    | _50μs_           |
| `toRegexRange(-100, 100)`   | `-[1-9]\|-?[1-9][0-9]\|-?100\|[0-9]`                                            | _42μs_           |
| `toRegexRange(001, 100)`    | `0{0,2}[1-9]\|0?[1-9][0-9]\|100`                                                | _109μs_          |
| `toRegexRange(001, 555)`    | `0{0,2}[1-9]\|0?[1-9][0-9]\|[1-4][0-9]{2}\|5[0-4][0-9]\|55[0-5]`                | _51μs_           |
| `toRegexRange(0010, 1000)`  | `0{0,2}1[0-9]\|0{0,2}[2-9][0-9]\|0?[1-9][0-9]{2}\|1000`                         | _31μs_           |
| `toRegexRange(1, 50)`       | `[1-9]\|[1-4][0-9]\|50`                                                         | _24μs_           |
| `toRegexRange(1, 55)`       | `[1-9]\|[1-4][0-9]\|5[0-5]`                                                     | _23μs_           |
| `toRegexRange(1, 555)`      | `[1-9]\|[1-9][0-9]\|[1-4][0-9]{2}\|5[0-4][0-9]\|55[0-5]`                        | _30μs_           |
| `toRegexRange(1, 5555)`     | `[1-9]\|[1-9][0-9]{1,2}\|[1-4][0-9]{3}\|5[0-4][0-9]{2}\|55[0-4][0-9]\|555[0-5]` | _43μs_           |
| `toRegexRange(111, 555)`    | `11[1-9]\|1[2-9][0-9]\|[2-4][0-9]{2}\|5[0-4][0-9]\|55[0-5]`                     | _38μs_           |
| `toRegexRange(29, 51)`      | `29\|[34][0-9]\|5[01]`                                                          | _24μs_           |
| `toRegexRange(31, 877)`     | `3[1-9]\|[4-9][0-9]\|[1-7][0-9]{2}\|8[0-6][0-9]\|87[0-7]`                       | _32μs_           |
| `toRegexRange(5, 5)`        | `5`                                                                             | _8μs_            |
| `toRegexRange(5, 6)`        | `5\|6`                                                                          | _11μs_           |
| `toRegexRange(1, 2)`        | `1\|2`                                                                          | _6μs_            |
| `toRegexRange(1, 5)`        | `[1-5]`                                                                         | _15μs_           |
| `toRegexRange(1, 10)`       | `[1-9]\|10`                                                                     | _22μs_           |
| `toRegexRange(1, 100)`      | `[1-9]\|[1-9][0-9]\|100`                                                        | _25μs_           |
| `toRegexRange(1, 1000)`     | `[1-9]\|[1-9][0-9]{1,2}\|1000`                                                  | _31μs_           |
| `toRegexRange(1, 10000)`    | `[1-9]\|[1-9][0-9]{1,3}\|10000`                                                 | _34μs_           |
| `toRegexRange(1, 100000)`   | `[1-9]\|[1-9][0-9]{1,4}\|100000`                                                | _36μs_           |
| `toRegexRange(1, 1000000)`  | `[1-9]\|[1-9][0-9]{1,5}\|1000000`                                               | _42μs_           |
| `toRegexRange(1, 10000000)` | `[1-9]\|[1-9][0-9]{1,6}\|10000000`                                              | _42μs_           |

## Heads up!

**Order of arguments**

When the `min` is larger than the `max`, values will be flipped to create a valid range:

```js
toRegexRange('51', '29');
```

Is effectively flipped to:

```js
toRegexRange('29', '51');
//=> 29|[3-4][0-9]|5[0-1]
```

**Steps / increments**

This library does not support steps (increments). A pr to add support would be welcome.

## History

### v2.0.0 - 2017-04-21

**New features**

Adds support for zero-padding!

### v1.0.0

**Optimizations**

Repeating ranges are now grouped using quantifiers. rocessing time is roughly the same, but the generated regex is much smaller, which should result in faster matching.

## Attribution

Inspired by the python library [range-regex](https://github.com/dimka665/range-regex).

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Related projects

You might also be interested in these projects:

* [expand-range](https://www.npmjs.com/package/expand-range): Fast, bash-like range expansion. Expand a range of numbers or letters, uppercase or lowercase. Used… [more](https://github.com/jonschlinkert/expand-range) | [homepage](https://github.com/jonschlinkert/expand-range "Fast, bash-like range expansion. Expand a range of numbers or letters, uppercase or lowercase. Used by micromatch.")
* [fill-range](https://www.npmjs.com/package/fill-range): Fill in a range of numbers or letters, optionally passing an increment or `step` to… [more](https://github.com/jonschlinkert/fill-range) | [homepage](https://github.com/jonschlinkert/fill-range "Fill in a range of numbers or letters, optionally passing an increment or `step` to use, or create a regex-compatible range with `options.toRegex`")
* [micromatch](https://www.npmjs.com/package/micromatch): Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch. | [homepage](https://github.com/micromatch/micromatch "Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch.")
* [repeat-element](https://www.npmjs.com/package/repeat-element): Create an array by repeating the given value n times. | [homepage](https://github.com/jonschlinkert/repeat-element "Create an array by repeating the given value n times.")
* [repeat-string](https://www.npmjs.com/package/repeat-string): Repeat the given string n times. Fastest implementation for repeating a string. | [homepage](https://github.com/jonschlinkert/repeat-string "Repeat the given string n times. Fastest implementation for repeating a string.")

### Contributors

| **Commits** | **Contributor** |  
| --- | --- |  
| 63 | [jonschlinkert](https://github.com/jonschlinkert) |  
| 3  | [doowb](https://github.com/doowb) |  
| 2  | [realityking](https://github.com/realityking) |  

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

Please consider supporting me on Patreon, or [start your own Patreon page](https://patreon.com/invite/bxpbvm)!

<a href="https://www.patreon.com/jonschlinkert">
<img src="https://c5.patreon.com/external/logo/become_a_patron_button@2x.png" height="50">
</a>

### License

Copyright © 2019, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.8.0, on April 07, 2019._Copyright 2022 Dynalist Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.# Changelog

## v1.4.4

We've exposed our helper function for setting tooltips on elements (`setTooltip`) as well as added a new progress bar component.

The `FileManager.processFrontMatter` function now also exposes the DataWriteOptions argument to be consistent with the other `process` and `write` functions.

## v1.4.0

We've made some changes to `CachedMetadata` to support **Properties**. `FrontMatterCache` is now no longer a `CacheItem`—meaning that it doesn't have a position. Instead, is it a _Reference_.

Another big change in v.1.4 is that frontmatter now supports wikilinks. If a value in the frontmatter can be interpreted as a link, it will be cached inside `CachedMetadata.frontmatterLinks`.

## v1.1.3

- Updated the [Canvas spec](https://github.com/obsidianmd/obsidian-api/blob/master/canvas.d.ts) to indicate that colors can be stored in 1 or 2 formats:
  - as a hex string (i.e. "#FFFFFF")
  - as a number "1", "2", etc.

  If it's a number, this refers to the palette position. It can be themed via CSS variables.


### Theme Changes

There are some new CSS variables related to canvas and callouts in 1.1.3+. All the extended palette colors now have an RGB variant that is used for callouts and canvas colors. The hex values are primarily used for syntax highlighting.

```css
body {
    --callout-bug: var(--color-red-rgb);
    --callout-default: var(--color-blue-rgb);
    --callout-error: var(--color-red-rgb);
    --callout-example: var(--color-purple-rgb);
    --callout-fail: var(--color-red-rgb);
    --callout-important: var(--color-cyan-rgb);
    --callout-info: var(--color-blue-rgb);
    --callout-question: var(--color-yellow-rgb);
    --callout-success: var(--color-green-rgb);
    --callout-summary: var(--color-cyan-rgb);
    --callout-tip: var(--color-cyan-rgb);
    --callout-todo: var(--color-blue-rgb);
    --callout-warning: var(--color-orange-rgb);
    --callout-quote: 158, 158, 158;
}
.theme-light {
    --color-red-rgb: 228, 55, 75;
    --color-red: #E4374B;

    --color-orange-rgb: 217, 108, 0;
    --color-orange: #d96c00;

    --color-yellow-rgb: 189, 142, 55;
    --color-yellow: #BD8E37;

    --color-green-rgb: 12, 181, 79;
    --color-green: #0cb54f;

    --color-cyan-rgb: 45, 183, 181;
    --color-cyan: #2db7b5;

    --color-blue-rgb: 8, 109, 221;
    --color-blue: #086DDD;

    --color-purple-rgb: 135, 107, 224;
    --color-purple: #876be0;

    --color-pink-rgb: 195, 43, 116;
    --color-pink: #C32B74;
}
.theme-dark {
    --color-red-rgb: 251, 70, 76;
    --color-red: #fb464c;

    --color-orange-rgb: 233, 151, 63;
    --color-orange: #E9973F;

    --color-yellow-rgb: 224, 222, 113;
    --color-yellow: #E0DE71;

    --color-green-rgb: 68, 207, 110;
    --color-green: #44CF6E;

    --color-cyan-rgb: 83, 223, 221;
    --color-cyan: #53DFDD;

    --color-blue-rgb: 2, 122, 255;
    --color-blue: #027aff;

    --color-purple-rgb: 168, 130, 255;
    --color-purple: #a882ff;

    --color-pink-rgb: 250, 153, 205;
    --color-pink: #FA99CD;
}
```


## v1.1.1 (2022-12-8 — Insider build)

_[Changes since v1.0](https://github.com/obsidianmd/obsidian-api/compare/32fe4c3f...6161bf59)_

- [`file-open`](https://github.com/obsidianmd/obsidian-api/blob/ec589e9762a1d7e2faad01f894cb34c41b10ecaf/obsidian.d.ts#L4189) event is now fired when focusing a Canvas file card.
- Exposed the `activeEditor` on the Workspace. When a markdown view is active, this will point to the underlying `MarkdownEditView`. If a canvas view is active, this will be an EmbeddedEditor component.

With these two changes, plugins should be able to adapt to the new Canvas view quite easily. Custom
views that react the the currently focused views will automatically respond to the user clicking 
on file cards in the canvas. If a plugin is currently accessing the `Editor` using the following
approach:

```ts
let view = app.workspace.getActiveViewOfType(MarkdownView);

if (view) {
    let editor = view.editor;
    // or
    let file = view.file;
}
```

Instead you can access the `editor` or `file` by looking under the `activeEditor`:
```ts
let { activeEditor } = app.workspace;
if (activeEditor) {
    let editor = activeEditor.editor;
    let file = activeEditor.file;
}
```

## v1.1.0 (2022-12-05 — Insider build)

_[Changes since v1.0](https://github.com/obsidianmd/obsidian-api/compare/1b4f6e2...32fe4c3f)_

### New Metadata API

In anticipation of bigger improvements to metadata and frontmatter in Obsidian, we have introduced a new metadata API.
It is currently defined as follows:

```ts
interface FileManager {
/**
     * Atomically read, modify, and save the frontmatter of a note.
     * The frontmatter is passed in as a JS object, and should be mutated directly to achieve the desired result.
     * @param file - the file to be modified. Must be a markdown file.
     * @param fn - a callback function which mutates the frontMatter object synchronously.
     * @public
     */
    processFrontMatter(file: TFile, fn: (frontMatter: any) => void): Promise<void>
}
```

To use it:

```ts
app.fileManager.processFrontMatter(file, (frontmatter) => {
    frontmatter["key1"] = value;
    delete frontmatter["key2"];
});
```

All changes made within the callback block will be applied at once.


### Improved

- `setTooltip` now accepts an optional tooltip position.
- The `size?: number` parameter has been removed from `setIcon`. This is now configurable via CSS. You can add override the CSS var `--icon-size` on the parent class of your element to override the sizing (e.g. `.parent-element { --icon-size: var(--icon-xs) } `) The following icon sizes are available out-of-the-box: `--icon-xs`, `--icon-s`, `--icon-m`, and `--icon-l`.
- `editorCallback` no longer passes the active `view: MarkdownView`. Instead, it now provides either the MarkdownView or a MarkdownFileInfo object. This change allows for editor commands to work within a Canvas.
- `registerHoverLinkSource` is now available in the API to register your plugin's view with the Page preview core plugin.

### No longer broken

- Fixed `Editor.replaceSelection` not working when run immediately after closing a modal.

### Notable Changes

- Added support for an optional `fundingUrl` field the plugin manifest This is a link for users that want to donate to show appreciation and support plugin development. It's displayed when your plugin is selected in the list of community plugins.
- Added macOS calendar entitlements. This allow scripts run from within Obsidian to request calendar access.

## v1.0 (2022-10-13)

_[Changes since v0.15.9](https://github.com/obsidianmd/obsidian-api/compare/ff121cd...1b4f6e2)_

### New

- Added standard [color picker component](https://github.com/obsidianmd/obsidian-api/blob/902badd38ba907689f0917d7b193f7e33d1284fe/obsidian.d.ts#L493).

### Improved

- `getLeaf` can now be used to create a leaf in a new tab, a new tab group, or a new window. The preferred usage of `getLeaf` would be `getLeaf(Keymap.isModEvent(evt))` where `evt` is the user's KeyboardEvent. This allows for a consistent user experience when opening files while a modifier key is pressed.

### Notable Changes

- Workspace information is no longer saved to the `.obsidian/workspace` file. It is now saved to `workspace.json`.
- Added `.has-active-menu` class to file explorer item that received the right-click.
- Added `.list-bullet` class to HTML markup for unordered list items.
## Obsidian API

Type definitions for the latest [Obsidian](https://obsidian.md) API.

### Documentation

You can browse our Plugin API documentation at https://docs.obsidian.md/

For an example on how to create Obsidian plugins, use the template at https://github.com/obsidianmd/obsidian-sample-plugin 

### Plugin structure

`manifest.json`

- `id` the ID of your plugin.
- `name` the display name of your plugin.
- `author` the plugin author's name.
- `version` the version of your plugin.
- `minAppVersion` the minimum required Obsidian version for your plugin.
- `description` the long description of your plugin.
- `isDesktopOnly` whether your plugin uses NodeJS or Electron APIs.
- `authorUrl` (optional) a URL to your own website.
- `fundingUrl` (optional) a link for users to donation to show appreciation and support plugin development.

`main.js`

- This is the main entry point of your plugin.
- Import any Obsidian API using `require('obsidian')`
- Import NodeJS or Electron API using `require('fs')` or `require('electron')`
- Must export a default class which extends `Plugin`
- Must bundle all external dependencies into this file, using Rollup, Webpack, or another javascript bundler.

### App Architecture

##### The app is organized into a few major modules:

- `App`, the global object that owns everything else. You can access this via `this.app` inside your plugin. The `App` interface provides accessors for the following interfaces.
- `Vault`, the interface that lets you interact with files and folders in the vault.
- `Workspace`, the interface that lets you interact with panes on the screen.
- `MetadataCache`, the interface that contains cached metadata about each markdown file, including headings, links, embeds, tags, and blocks.

##### Additionally, by inheriting `Plugin`, you can:
- Add a ribbon icon using `this.addRibbonIcon`.
- Add a status bar (bottom) element using `this.addStatusBarItem`.
- Add a global command, optionally with a default hotkey, using `this.addCommand`.
- Add a plugin settings tab using `this.addSettingTab`.
- Register a new kind of view using `this.registerView`.
- Save and load plugin data using `this.loadData` and `this.saveData`.

##### Registering events

For registering events from any event interfaces, such as `App` and `Workspace`, please use `this.registerEvent`, which will automatically detach your event handler when your plugin unloads:
```
this.registerEvent(app.on('event-name', callback));
```

If you register DOM events for elements that persist on the page after your plugin unloads, such as `window` or `document` events, please use `this.registerDomEvent`:
```
this.registerDomEvent(element, 'click', callback);
```

If you use `setInterval`, please use `this.registerInterval`:
```
this.registerInterval(setInterval(callback, 1000));
```
---
name: API bug report
about: 'For reproducible bugs with the API only. If you have a question, you should
  instead go to our discord server under the #plugin-dev channel to ask for help.'
title: 'Bug: '

---

**Steps to reproduce:**
-
# array-union [![Build Status](https://travis-ci.org/sindresorhus/array-union.svg?branch=master)](https://travis-ci.org/sindresorhus/array-union)

> Create an array of unique values, in order, from the input arrays


## Install

```
$ npm install array-union
```


## Usage

```js
const arrayUnion = require('array-union');

arrayUnion([1, 1, 2, 3], [2, 3]);
//=> [1, 2, 3]

arrayUnion(['foo', 'foo', 'bar']);
//=> ['foo', 'bar']

arrayUnion(['🐱', '🦄', '🐻'], ['🦄', '🌈']);
//=> ['🐱', '🦄', '🐻', '🌈']

arrayUnion(['🐱', '🦄'], ['🐻', '🦄'], ['🐶', '🌈', '🌈']);
//=> ['🐱', '🦄', '🐻', '🐶', '🌈']
```


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
MIT License

Copyright (c) 2020 Evan Wallace

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
# esbuild

This is a JavaScript bundler and minifier. See https://github.com/evanw/esbuild and the [JavaScript API documentation](https://esbuild.github.io/api/) for details.
# yallist

Yet Another Linked List

There are many doubly-linked list implementations like it, but this
one is mine.

For when an array would be too big, and a Map can't be iterated in
reverse order.


[![Build Status](https://travis-ci.org/isaacs/yallist.svg?branch=master)](https://travis-ci.org/isaacs/yallist) [![Coverage Status](https://coveralls.io/repos/isaacs/yallist/badge.svg?service=github)](https://coveralls.io/github/isaacs/yallist)

## basic usage

```javascript
var yallist = require('yallist')
var myList = yallist.create([1, 2, 3])
myList.push('foo')
myList.unshift('bar')
// of course pop() and shift() are there, too
console.log(myList.toArray()) // ['bar', 1, 2, 3, 'foo']
myList.forEach(function (k) {
  // walk the list head to tail
})
myList.forEachReverse(function (k, index, list) {
  // walk the list tail to head
})
var myDoubledList = myList.map(function (k) {
  return k + k
})
// now myDoubledList contains ['barbar', 2, 4, 6, 'foofoo']
// mapReverse is also a thing
var myDoubledListReverse = myList.mapReverse(function (k) {
  return k + k
}) // ['foofoo', 6, 4, 2, 'barbar']

var reduced = myList.reduce(function (set, entry) {
  set += entry
  return set
}, 'start')
console.log(reduced) // 'startfoo123bar'
```

## api

The whole API is considered "public".

Functions with the same name as an Array method work more or less the
same way.

There's reverse versions of most things because that's the point.

### Yallist

Default export, the class that holds and manages a list.

Call it with either a forEach-able (like an array) or a set of
arguments, to initialize the list.

The Array-ish methods all act like you'd expect.  No magic length,
though, so if you change that it won't automatically prune or add
empty spots.

### Yallist.create(..)

Alias for Yallist function.  Some people like factories.

#### yallist.head

The first node in the list

#### yallist.tail

The last node in the list

#### yallist.length

The number of nodes in the list.  (Change this at your peril.  It is
not magic like Array length.)

#### yallist.toArray()

Convert the list to an array.

#### yallist.forEach(fn, [thisp])

Call a function on each item in the list.

#### yallist.forEachReverse(fn, [thisp])

Call a function on each item in the list, in reverse order.

#### yallist.get(n)

Get the data at position `n` in the list.  If you use this a lot,
probably better off just using an Array.

#### yallist.getReverse(n)

Get the data at position `n`, counting from the tail.

#### yallist.map(fn, thisp)

Create a new Yallist with the result of calling the function on each
item.

#### yallist.mapReverse(fn, thisp)

Same as `map`, but in reverse.

#### yallist.pop()

Get the data from the list tail, and remove the tail from the list.

#### yallist.push(item, ...)

Insert one or more items to the tail of the list.

#### yallist.reduce(fn, initialValue)

Like Array.reduce.

#### yallist.reduceReverse

Like Array.reduce, but in reverse.

#### yallist.reverse

Reverse the list in place.

#### yallist.shift()

Get the data from the list head, and remove the head from the list.

#### yallist.slice([from], [to])

Just like Array.slice, but returns a new Yallist.

#### yallist.sliceReverse([from], [to])

Just like yallist.slice, but the result is returned in reverse.

#### yallist.toArray()

Create an array representation of the list.

#### yallist.toArrayReverse()

Create a reversed array representation of the list.

#### yallist.unshift(item, ...)

Insert one or more items to the head of the list.

#### yallist.unshiftNode(node)

Move a Node object to the front of the list.  (That is, pull it out of
wherever it lives, and make it the new head.)

If the node belongs to a different list, then that list will remove it
first.

#### yallist.pushNode(node)

Move a Node object to the end of the list.  (That is, pull it out of
wherever it lives, and make it the new tail.)

If the node belongs to a list already, then that list will remove it
first.

#### yallist.removeNode(node)

Remove a node from the list, preserving referential integrity of head
and tail and other nodes.

Will throw an error if you try to have a list remove a node that
doesn't belong to it.

### Yallist.Node

The class that holds the data and is actually the list.

Call with `var n = new Node(value, previousNode, nextNode)`

Note that if you do direct operations on Nodes themselves, it's very
easy to get into weird states where the list is broken.  Be careful :)

#### node.next

The next node in the list.

#### node.prev

The previous node in the list.

#### node.value

The data the node contains.

#### node.list

The list to which this node belongs.  (Null if it does not belong to
any list.)
# micromatch [![NPM version](https://img.shields.io/npm/v/micromatch.svg?style=flat)](https://www.npmjs.com/package/micromatch) [![NPM monthly downloads](https://img.shields.io/npm/dm/micromatch.svg?style=flat)](https://npmjs.org/package/micromatch) [![NPM total downloads](https://img.shields.io/npm/dt/micromatch.svg?style=flat)](https://npmjs.org/package/micromatch)  [![Tests](https://github.com/micromatch/micromatch/actions/workflows/test.yml/badge.svg)](https://github.com/micromatch/micromatch/actions/workflows/test.yml)

> Glob matching for javascript/node.js. A replacement and faster alternative to minimatch and multimatch.

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Table of Contents

<details>
<summary><strong>Details</strong></summary>

- [Install](#install)
- [Quickstart](#quickstart)
- [Why use micromatch?](#why-use-micromatch)
  * [Matching features](#matching-features)
- [Switching to micromatch](#switching-to-micromatch)
  * [From minimatch](#from-minimatch)
  * [From multimatch](#from-multimatch)
- [API](#api)
- [Options](#options)
- [Options Examples](#options-examples)
  * [options.basename](#optionsbasename)
  * [options.bash](#optionsbash)
  * [options.expandRange](#optionsexpandrange)
  * [options.format](#optionsformat)
  * [options.ignore](#optionsignore)
  * [options.matchBase](#optionsmatchbase)
  * [options.noextglob](#optionsnoextglob)
  * [options.nonegate](#optionsnonegate)
  * [options.noglobstar](#optionsnoglobstar)
  * [options.nonull](#optionsnonull)
  * [options.nullglob](#optionsnullglob)
  * [options.onIgnore](#optionsonignore)
  * [options.onMatch](#optionsonmatch)
  * [options.onResult](#optionsonresult)
  * [options.posixSlashes](#optionsposixslashes)
  * [options.unescape](#optionsunescape)
- [Extended globbing](#extended-globbing)
  * [Extglobs](#extglobs)
  * [Braces](#braces)
  * [Regex character classes](#regex-character-classes)
  * [Regex groups](#regex-groups)
  * [POSIX bracket expressions](#posix-bracket-expressions)
- [Notes](#notes)
  * [Bash 4.3 parity](#bash-43-parity)
  * [Backslashes](#backslashes)
- [Benchmarks](#benchmarks)
  * [Running benchmarks](#running-benchmarks)
  * [Latest results](#latest-results)
- [Contributing](#contributing)
- [About](#about)

</details>

## Install

Install with [npm](https://www.npmjs.com/) (requires [Node.js](https://nodejs.org/en/) >=8.6):

```sh
$ npm install --save micromatch
```

## Quickstart

```js
const micromatch = require('micromatch');
// micromatch(list, patterns[, options]);
```

The [main export](#micromatch) takes a list of strings and one or more glob patterns:

```js
console.log(micromatch(['foo', 'bar', 'baz', 'qux'], ['f*', 'b*'])) //=> ['foo', 'bar', 'baz']
console.log(micromatch(['foo', 'bar', 'baz', 'qux'], ['*', '!b*'])) //=> ['foo', 'qux']
```

Use [.isMatch()](#ismatch) to for boolean matching:

```js
console.log(micromatch.isMatch('foo', 'f*')) //=> true
console.log(micromatch.isMatch('foo', ['b*', 'f*'])) //=> true
```

[Switching](#switching-to-micromatch) from minimatch and multimatch is easy!

<br>

## Why use micromatch?

> micromatch is a [replacement](#switching-to-micromatch) for minimatch and multimatch

* Supports all of the same matching features as [minimatch](https://github.com/isaacs/minimatch) and [multimatch](https://github.com/sindresorhus/multimatch)
* More complete support for the Bash 4.3 specification than minimatch and multimatch. Micromatch passes _all of the spec tests_ from bash, including some that bash still fails.
* **Fast & Performant** - Loads in about 5ms and performs [fast matches](#benchmarks).
* **Glob matching** - Using wildcards (`*` and `?`), globstars (`**`) for nested directories
* **[Advanced globbing](#extended-globbing)** - Supports [extglobs](#extglobs), [braces](#braces-1), and [POSIX brackets](#posix-bracket-expressions), and support for escaping special characters with `\` or quotes.
* **Accurate** - Covers more scenarios [than minimatch](https://github.com/yarnpkg/yarn/pull/3339)
* **Well tested** - More than 5,000 [test assertions](./test)
* **Windows support** - More reliable windows support than minimatch and multimatch.
* **[Safe](https://github.com/micromatch/braces#braces-is-safe)** - Micromatch is not subject to DoS with brace patterns like minimatch and multimatch.

### Matching features

* Support for multiple glob patterns (no need for wrappers like multimatch)
* Wildcards (`**`, `*.js`)
* Negation (`'!a/*.js'`, `'*!(b).js'`)
* [extglobs](#extglobs) (`+(x|y)`, `!(a|b)`)
* [POSIX character classes](#posix-bracket-expressions) (`[[:alpha:][:digit:]]`)
* [brace expansion](https://github.com/micromatch/braces) (`foo/{1..5}.md`, `bar/{a,b,c}.js`)
* regex character classes (`foo-[1-5].js`)
* regex logical "or" (`foo/(abc|xyz).js`)

You can mix and match these features to create whatever patterns you need!

## Switching to micromatch

_(There is one notable difference between micromatch and minimatch in regards to how backslashes are handled. See [the notes about backslashes](#backslashes) for more information.)_

### From minimatch

Use [micromatch.isMatch()](#ismatch) instead of `minimatch()`:

```js
console.log(micromatch.isMatch('foo', 'b*')); //=> false
```

Use [micromatch.match()](#match) instead of `minimatch.match()`:

```js
console.log(micromatch.match(['foo', 'bar'], 'b*')); //=> 'bar'
```

### From multimatch

Same signature:

```js
console.log(micromatch(['foo', 'bar', 'baz'], ['f*', '*z'])); //=> ['foo', 'baz']
```

## API

**Params**

* `list` **{String|Array<string>}**: List of strings to match.
* `patterns` **{String|Array<string>}**: One or more glob patterns to use for matching.
* `options` **{Object}**: See available [options](#options)
* `returns` **{Array}**: Returns an array of matches

**Example**

```js
const mm = require('micromatch');
// mm(list, patterns[, options]);

console.log(mm(['a.js', 'a.txt'], ['*.js']));
//=> [ 'a.js' ]
```

### [.matcher](index.js#L104)

Returns a matcher function from the given glob `pattern` and `options`. The returned function takes a string to match as its only argument and returns true if the string is a match.

**Params**

* `pattern` **{String}**: Glob pattern
* `options` **{Object}**
* `returns` **{Function}**: Returns a matcher function.

**Example**

```js
const mm = require('micromatch');
// mm.matcher(pattern[, options]);

const isMatch = mm.matcher('*.!(*a)');
console.log(isMatch('a.a')); //=> false
console.log(isMatch('a.b')); //=> true
```

### [.isMatch](index.js#L123)

Returns true if **any** of the given glob `patterns` match the specified `string`.

**Params**

* `str` **{String}**: The string to test.
* `patterns` **{String|Array}**: One or more glob patterns to use for matching.
* `[options]` **{Object}**: See available [options](#options).
* `returns` **{Boolean}**: Returns true if any patterns match `str`

**Example**

```js
const mm = require('micromatch');
// mm.isMatch(string, patterns[, options]);

console.log(mm.isMatch('a.a', ['b.*', '*.a'])); //=> true
console.log(mm.isMatch('a.a', 'b.*')); //=> false
```

### [.not](index.js#L148)

Returns a list of strings that _**do not match any**_ of the given `patterns`.

**Params**

* `list` **{Array}**: Array of strings to match.
* `patterns` **{String|Array}**: One or more glob pattern to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Array}**: Returns an array of strings that **do not match** the given patterns.

**Example**

```js
const mm = require('micromatch');
// mm.not(list, patterns[, options]);

console.log(mm.not(['a.a', 'b.b', 'c.c'], '*.a'));
//=> ['b.b', 'c.c']
```

### [.contains](index.js#L188)

Returns true if the given `string` contains the given pattern. Similar to [.isMatch](#isMatch) but the pattern can match any part of the string.

**Params**

* `str` **{String}**: The string to match.
* `patterns` **{String|Array}**: Glob pattern to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Boolean}**: Returns true if any of the patterns matches any part of `str`.

**Example**

```js
var mm = require('micromatch');
// mm.contains(string, pattern[, options]);

console.log(mm.contains('aa/bb/cc', '*b'));
//=> true
console.log(mm.contains('aa/bb/cc', '*d'));
//=> false
```

### [.matchKeys](index.js#L230)

Filter the keys of the given object with the given `glob` pattern and `options`. Does not attempt to match nested keys. If you need this feature, use [glob-object](https://github.com/jonschlinkert/glob-object) instead.

**Params**

* `object` **{Object}**: The object with keys to filter.
* `patterns` **{String|Array}**: One or more glob patterns to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Object}**: Returns an object with only keys that match the given patterns.

**Example**

```js
const mm = require('micromatch');
// mm.matchKeys(object, patterns[, options]);

const obj = { aa: 'a', ab: 'b', ac: 'c' };
console.log(mm.matchKeys(obj, '*b'));
//=> { ab: 'b' }
```

### [.some](index.js#L259)

Returns true if some of the strings in the given `list` match any of the given glob `patterns`.

**Params**

* `list` **{String|Array}**: The string or array of strings to test. Returns as soon as the first match is found.
* `patterns` **{String|Array}**: One or more glob patterns to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Boolean}**: Returns true if any `patterns` matches any of the strings in `list`

**Example**

```js
const mm = require('micromatch');
// mm.some(list, patterns[, options]);

console.log(mm.some(['foo.js', 'bar.js'], ['*.js', '!foo.js']));
// true
console.log(mm.some(['foo.js'], ['*.js', '!foo.js']));
// false
```

### [.every](index.js#L295)

Returns true if every string in the given `list` matches any of the given glob `patterns`.

**Params**

* `list` **{String|Array}**: The string or array of strings to test.
* `patterns` **{String|Array}**: One or more glob patterns to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Boolean}**: Returns true if all `patterns` matches all of the strings in `list`

**Example**

```js
const mm = require('micromatch');
// mm.every(list, patterns[, options]);

console.log(mm.every('foo.js', ['foo.js']));
// true
console.log(mm.every(['foo.js', 'bar.js'], ['*.js']));
// true
console.log(mm.every(['foo.js', 'bar.js'], ['*.js', '!foo.js']));
// false
console.log(mm.every(['foo.js'], ['*.js', '!foo.js']));
// false
```

### [.all](index.js#L334)

Returns true if **all** of the given `patterns` match the specified string.

**Params**

* `str` **{String|Array}**: The string to test.
* `patterns` **{String|Array}**: One or more glob patterns to use for matching.
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Boolean}**: Returns true if any patterns match `str`

**Example**

```js
const mm = require('micromatch');
// mm.all(string, patterns[, options]);

console.log(mm.all('foo.js', ['foo.js']));
// true

console.log(mm.all('foo.js', ['*.js', '!foo.js']));
// false

console.log(mm.all('foo.js', ['*.js', 'foo.js']));
// true

console.log(mm.all('foo.js', ['*.js', 'f*', '*o*', '*o.js']));
// true
```

### [.capture](index.js#L361)

Returns an array of matches captured by `pattern` in `string, or`null` if the pattern did not match.

**Params**

* `glob` **{String}**: Glob pattern to use for matching.
* `input` **{String}**: String to match
* `options` **{Object}**: See available [options](#options) for changing how matches are performed
* `returns` **{Array|null}**: Returns an array of captures if the input matches the glob pattern, otherwise `null`.

**Example**

```js
const mm = require('micromatch');
// mm.capture(pattern, string[, options]);

console.log(mm.capture('test/*.js', 'test/foo.js'));
//=> ['foo']
console.log(mm.capture('test/*.js', 'foo/bar.css'));
//=> null
```

### [.makeRe](index.js#L387)

Create a regular expression from the given glob `pattern`.

**Params**

* `pattern` **{String}**: A glob pattern to convert to regex.
* `options` **{Object}**
* `returns` **{RegExp}**: Returns a regex created from the given pattern.

**Example**

```js
const mm = require('micromatch');
// mm.makeRe(pattern[, options]);

console.log(mm.makeRe('*.js'));
//=> /^(?:(\.[\\\/])?(?!\.)(?=.)[^\/]*?\.js)$/
```

### [.scan](index.js#L403)

Scan a glob pattern to separate the pattern into segments. Used by the [split](#split) method.

**Params**

* `pattern` **{String}**
* `options` **{Object}**
* `returns` **{Object}**: Returns an object with

**Example**

```js
const mm = require('micromatch');
const state = mm.scan(pattern[, options]);
```

### [.parse](index.js#L419)

Parse a glob pattern to create the source string for a regular expression.

**Params**

* `glob` **{String}**
* `options` **{Object}**
* `returns` **{Object}**: Returns an object with useful properties and output to be used as regex source string.

**Example**

```js
const mm = require('micromatch');
const state = mm.parse(pattern[, options]);
```

### [.braces](index.js#L446)

Process the given brace `pattern`.

**Params**

* `pattern` **{String}**: String with brace pattern to process.
* `options` **{Object}**: Any [options](#options) to change how expansion is performed. See the [braces](https://github.com/micromatch/braces) library for all available options.
* `returns` **{Array}**

**Example**

```js
const { braces } = require('micromatch');
console.log(braces('foo/{a,b,c}/bar'));
//=> [ 'foo/(a|b|c)/bar' ]

console.log(braces('foo/{a,b,c}/bar', { expand: true }));
//=> [ 'foo/a/bar', 'foo/b/bar', 'foo/c/bar' ]
```

## Options

| **Option** | **Type** | **Default value** | **Description** |
| --- | --- | --- | --- |
| `basename`            | `boolean`      | `false`     | If set, then patterns without slashes will be matched against the basename of the path if it contains slashes.  For example, `a?b` would match the path `/xyz/123/acb`, but not `/xyz/acb/123`. |
| `bash`                | `boolean`      | `false`     | Follow bash matching rules more strictly - disallows backslashes as escape characters, and treats single stars as globstars (`**`). |
| `capture`             | `boolean`      | `undefined` | Return regex matches in supporting methods. |
| `contains`            | `boolean`      | `undefined` | Allows glob to match any part of the given string(s). |
| `cwd`                 | `string`       | `process.cwd()` | Current working directory. Used by `picomatch.split()` |
| `debug`               | `boolean`      | `undefined` | Debug regular expressions when an error is thrown. |
| `dot`                 | `boolean`      | `false`     | Match dotfiles. Otherwise dotfiles are ignored unless a `.` is explicitly defined in the pattern. |
| `expandRange`         | `function`     | `undefined` | Custom function for expanding ranges in brace patterns, such as `{a..z}`. The function receives the range values as two arguments, and it must return a string to be used in the generated regex. It's recommended that returned strings be wrapped in parentheses. This option is overridden by the `expandBrace` option. |
| `failglob`            | `boolean`      | `false`     | Similar to the `failglob` behavior in Bash, throws an error when no matches are found. Based on the bash option of the same name. |
| `fastpaths`           | `boolean`      | `true`      | To speed up processing, full parsing is skipped for a handful common glob patterns. Disable this behavior by setting this option to `false`. |
| `flags`               | `boolean`      | `undefined` | Regex flags to use in the generated regex. If defined, the `nocase` option will be overridden. |
| [format](#optionsformat) | `function` | `undefined` | Custom function for formatting the returned string. This is useful for removing leading slashes, converting Windows paths to Posix paths, etc. |
| `ignore`              | `array\|string` | `undefined` | One or more glob patterns for excluding strings that should not be matched from the result. |
| `keepQuotes`          | `boolean`      | `false`     | Retain quotes in the generated regex, since quotes may also be used as an alternative to backslashes.  |
| `literalBrackets`     | `boolean`      | `undefined` | When `true`, brackets in the glob pattern will be escaped so that only literal brackets will be matched. |
| `lookbehinds`         | `boolean`      | `true`      | Support regex positive and negative lookbehinds. Note that you must be using Node 8.1.10 or higher to enable regex lookbehinds. |
| `matchBase`           | `boolean`      | `false`     | Alias for `basename` |
| `maxLength`           | `boolean`      | `65536`     | Limit the max length of the input string. An error is thrown if the input string is longer than this value. |
| `nobrace`             | `boolean`      | `false`     | Disable brace matching, so that `{a,b}` and `{1..3}` would be treated as literal characters. |
| `nobracket`           | `boolean`      | `undefined` | Disable matching with regex brackets. |
| `nocase`              | `boolean`      | `false`     | Perform case-insensitive matching. Equivalent to the regex `i` flag. Note that this option is ignored when the `flags` option is defined. |
| `nodupes`             | `boolean`      | `true`      | Deprecated, use `nounique` instead. This option will be removed in a future major release. By default duplicates are removed. Disable uniquification by setting this option to false. |
| `noext`               | `boolean`      | `false`     | Alias for `noextglob` |
| `noextglob`           | `boolean`      | `false`     | Disable support for matching with [extglobs](#extglobs) (like `+(a\|b)`) |
| `noglobstar`          | `boolean`      | `false`     | Disable support for matching nested directories with globstars (`**`) |
| `nonegate`            | `boolean`      | `false`     | Disable support for negating with leading `!` |
| `noquantifiers`       | `boolean`      | `false`     | Disable support for regex quantifiers (like `a{1,2}`) and treat them as brace patterns to be expanded. |
| [onIgnore](#optionsonIgnore) | `function` | `undefined` | Function to be called on ignored items. |
| [onMatch](#optionsonMatch) | `function` | `undefined` | Function to be called on matched items. |
| [onResult](#optionsonResult) | `function` | `undefined` | Function to be called on all items, regardless of whether or not they are matched or ignored. |
| `posix`               | `boolean`      | `false`     | Support [POSIX character classes](#posix-bracket-expressions) ("posix brackets"). |
| `posixSlashes`        | `boolean`      | `undefined` | Convert all slashes in file paths to forward slashes. This does not convert slashes in the glob pattern itself |
| `prepend`             | `string`       | `undefined` | String to prepend to the generated regex used for matching. |
| `regex`               | `boolean`      | `false`     | Use regular expression rules for `+` (instead of matching literal `+`), and for stars that follow closing parentheses or brackets (as in `)*` and `]*`). |
| `strictBrackets`      | `boolean`      | `undefined` | Throw an error if brackets, braces, or parens are imbalanced. |
| `strictSlashes`       | `boolean`      | `undefined` | When true, picomatch won't match trailing slashes with single stars. |
| `unescape`            | `boolean`      | `undefined` | Remove preceding backslashes from escaped glob characters before creating the regular expression to perform matches. |
| `unixify`             | `boolean`      | `undefined` | Alias for `posixSlashes`, for backwards compatitibility. |

## Options Examples

### options.basename

Allow glob patterns without slashes to match a file path based on its basename. Same behavior as [minimatch](https://github.com/isaacs/minimatch) option `matchBase`.

**Type**: `Boolean`

**Default**: `false`

**Example**

```js
micromatch(['a/b.js', 'a/c.md'], '*.js');
//=> []

micromatch(['a/b.js', 'a/c.md'], '*.js', { basename: true });
//=> ['a/b.js']
```

### options.bash

Enabled by default, this option enforces bash-like behavior with stars immediately following a bracket expression. Bash bracket expressions are similar to regex character classes, but unlike regex, a star following a bracket expression **does not repeat the bracketed characters**. Instead, the star is treated the same as any other star.

**Type**: `Boolean`

**Default**: `true`

**Example**

```js
const files = ['abc', 'ajz'];
console.log(micromatch(files, '[a-c]*'));
//=> ['abc', 'ajz']

console.log(micromatch(files, '[a-c]*', { bash: false }));
```

### options.expandRange

**Type**: `function`

**Default**: `undefined`

Custom function for expanding ranges in brace patterns. The [fill-range](https://github.com/jonschlinkert/fill-range) library is ideal for this purpose, or you can use custom code to do whatever you need.

**Example**

The following example shows how to create a glob that matches a numeric folder name between `01` and `25`, with leading zeros.

```js
const fill = require('fill-range');
const regex = micromatch.makeRe('foo/{01..25}/bar', {
  expandRange(a, b) {
    return `(${fill(a, b, { toRegex: true })})`;
  }
});

console.log(regex)
//=> /^(?:foo\/((?:0[1-9]|1[0-9]|2[0-5]))\/bar)$/

console.log(regex.test('foo/00/bar')) // false
console.log(regex.test('foo/01/bar')) // true
console.log(regex.test('foo/10/bar')) // true
console.log(regex.test('foo/22/bar')) // true
console.log(regex.test('foo/25/bar')) // true
console.log(regex.test('foo/26/bar')) // false
```

### options.format

**Type**: `function`

**Default**: `undefined`

Custom function for formatting strings before they're matched.

**Example**

```js
// strip leading './' from strings
const format = str => str.replace(/^\.\//, '');
const isMatch = picomatch('foo/*.js', { format });
console.log(isMatch('./foo/bar.js')) //=> true
```

### options.ignore

String or array of glob patterns to match files to ignore.

**Type**: `String|Array`

**Default**: `undefined`

```js
const isMatch = micromatch.matcher('*', { ignore: 'f*' });
console.log(isMatch('foo')) //=> false
console.log(isMatch('bar')) //=> true
console.log(isMatch('baz')) //=> true
```

### options.matchBase

Alias for [options.basename](#options-basename).

### options.noextglob

Disable extglob support, so that [extglobs](#extglobs) are regarded as literal characters.

**Type**: `Boolean`

**Default**: `undefined`

**Examples**

```js
console.log(micromatch(['a/z', 'a/b', 'a/!(z)'], 'a/!(z)'));
//=> ['a/b', 'a/!(z)']

console.log(micromatch(['a/z', 'a/b', 'a/!(z)'], 'a/!(z)', { noextglob: true }));
//=> ['a/!(z)'] (matches only as literal characters)
```

### options.nonegate

Disallow negation (`!`) patterns, and treat leading `!` as a literal character to match.

**Type**: `Boolean`

**Default**: `undefined`

### options.noglobstar

Disable matching with globstars (`**`).

**Type**: `Boolean`

**Default**: `undefined`

```js
micromatch(['a/b', 'a/b/c', 'a/b/c/d'], 'a/**');
//=> ['a/b', 'a/b/c', 'a/b/c/d']

micromatch(['a/b', 'a/b/c', 'a/b/c/d'], 'a/**', {noglobstar: true});
//=> ['a/b']
```

### options.nonull

Alias for [options.nullglob](#options-nullglob).

### options.nullglob

If `true`, when no matches are found the actual (arrayified) glob pattern is returned instead of an empty array. Same behavior as [minimatch](https://github.com/isaacs/minimatch) option `nonull`.

**Type**: `Boolean`

**Default**: `undefined`

### options.onIgnore

```js
const onIgnore = ({ glob, regex, input, output }) => {
  console.log({ glob, regex, input, output });
  // { glob: '*', regex: /^(?:(?!\.)(?=.)[^\/]*?\/?)$/, input: 'foo', output: 'foo' }
};

const isMatch = micromatch.matcher('*', { onIgnore, ignore: 'f*' });
isMatch('foo');
isMatch('bar');
isMatch('baz');
```

### options.onMatch

```js
const onMatch = ({ glob, regex, input, output }) => {
  console.log({ input, output });
  // { input: 'some\\path', output: 'some/path' }
  // { input: 'some\\path', output: 'some/path' }
  // { input: 'some\\path', output: 'some/path' }
};

const isMatch = micromatch.matcher('**', { onMatch, posixSlashes: true });
isMatch('some\\path');
isMatch('some\\path');
isMatch('some\\path');
```

### options.onResult

```js
const onResult = ({ glob, regex, input, output }) => {
  console.log({ glob, regex, input, output });
};

const isMatch = micromatch('*', { onResult, ignore: 'f*' });
isMatch('foo');
isMatch('bar');
isMatch('baz');
```

### options.posixSlashes

Convert path separators on returned files to posix/unix-style forward slashes. Aliased as `unixify` for backwards compatibility.

**Type**: `Boolean`

**Default**: `true` on windows, `false` everywhere else.

**Example**

```js
console.log(micromatch.match(['a\\b\\c'], 'a/**'));
//=> ['a/b/c']

console.log(micromatch.match(['a\\b\\c'], { posixSlashes: false }));
//=> ['a\\b\\c']
```

### options.unescape

Remove backslashes from escaped glob characters before creating the regular expression to perform matches.

**Type**: `Boolean`

**Default**: `undefined`

**Example**

In this example we want to match a literal `*`:

```js
console.log(micromatch.match(['abc', 'a\\*c'], 'a\\*c'));
//=> ['a\\*c']

console.log(micromatch.match(['abc', 'a\\*c'], 'a\\*c', { unescape: true }));
//=> ['a*c']
```

<br>
<br>

## Extended globbing

Micromatch supports the following extended globbing features.

### Extglobs

Extended globbing, as described by the bash man page:

| **pattern** | **regex equivalent** | **description** |
| --- | --- | --- |
| `?(pattern)` | `(pattern)?` | Matches zero or one occurrence of the given patterns |
| `*(pattern)` | `(pattern)*` | Matches zero or more occurrences of the given patterns |
| `+(pattern)` | `(pattern)+` | Matches one or more occurrences of the given patterns |
| `@(pattern)` | `(pattern)` <sup>*</sup> | Matches one of the given patterns |
| `!(pattern)` | N/A (equivalent regex is much more complicated) | Matches anything except one of the given patterns |

<sup><strong>*</strong></sup> Note that `@` isn't a regex character.

### Braces

Brace patterns can be used to match specific ranges or sets of characters.

**Example**

The pattern `{f,b}*/{1..3}/{b,q}*` would match any of following strings:

```
foo/1/bar
foo/2/bar
foo/3/bar
baz/1/qux
baz/2/qux
baz/3/qux
```

Visit [braces](https://github.com/micromatch/braces) to see the full range of features and options related to brace expansion, or to create brace matching or expansion related issues.

### Regex character classes

Given the list: `['a.js', 'b.js', 'c.js', 'd.js', 'E.js']`:

* `[ac].js`: matches both `a` and `c`, returning `['a.js', 'c.js']`
* `[b-d].js`: matches from `b` to `d`, returning `['b.js', 'c.js', 'd.js']`
* `a/[A-Z].js`: matches and uppercase letter, returning `['a/E.md']`

Learn about [regex character classes](http://www.regular-expressions.info/charclass.html).

### Regex groups

Given `['a.js', 'b.js', 'c.js', 'd.js', 'E.js']`:

* `(a|c).js`: would match either `a` or `c`, returning `['a.js', 'c.js']`
* `(b|d).js`: would match either `b` or `d`, returning `['b.js', 'd.js']`
* `(b|[A-Z]).js`: would match either `b` or an uppercase letter, returning `['b.js', 'E.js']`

As with regex, parens can be nested, so patterns like `((a|b)|c)/b` will work. Although brace expansion might be friendlier to use, depending on preference.

### POSIX bracket expressions

POSIX brackets are intended to be more user-friendly than regex character classes. This of course is in the eye of the beholder.

**Example**

```js
console.log(micromatch.isMatch('a1', '[[:alpha:][:digit:]]')) //=> true
console.log(micromatch.isMatch('a1', '[[:alpha:][:alpha:]]')) //=> false
```

***

## Notes

### Bash 4.3 parity

Whenever possible matching behavior is based on behavior Bash 4.3, which is mostly consistent with minimatch.

However, it's suprising how many edge cases and rabbit holes there are with glob matching, and since there is no real glob specification, and micromatch is more accurate than both Bash and minimatch, there are cases where best-guesses were made for behavior. In a few cases where Bash had no answers, we used wildmatch (used by git) as a fallback.

### Backslashes

There is an important, notable difference between minimatch and micromatch _in regards to how backslashes are handled_ in glob patterns.

* Micromatch exclusively and explicitly reserves backslashes for escaping characters in a glob pattern, even on windows, which is consistent with bash behavior. _More importantly, unescaping globs can result in unsafe regular expressions_.
* Minimatch converts all backslashes to forward slashes, which means you can't use backslashes to escape any characters in your glob patterns.

We made this decision for micromatch for a couple of reasons:

* Consistency with bash conventions.
* Glob patterns are not filepaths. They are a type of [regular language](https://en.wikipedia.org/wiki/Regular_language) that is converted to a JavaScript regular expression. Thus, when forward slashes are defined in a glob pattern, the resulting regular expression will match windows or POSIX path separators just fine.

**A note about joining paths to globs**

Note that when you pass something like `path.join('foo', '*')` to micromatch, you are creating a filepath and expecting it to still work as a glob pattern. This causes problems on windows, since the `path.sep` is `\\`.

In other words, since `\\` is reserved as an escape character in globs, on windows `path.join('foo', '*')` would result in `foo\\*`, which tells micromatch to match `*` as a literal character. This is the same behavior as bash.

To solve this, you might be inspired to do something like `'foo\\*'.replace(/\\/g, '/')`, but this causes another, potentially much more serious, problem.

## Benchmarks

### Running benchmarks

Install dependencies for running benchmarks:

```sh
$ cd bench && npm install
```

Run the benchmarks:

```sh
$ npm run bench
```

### Latest results

As of March 24, 2022 (longer bars are better):

```sh
# .makeRe star
  micromatch x 2,232,802 ops/sec ±2.34% (89 runs sampled))
  minimatch x 781,018 ops/sec ±6.74% (92 runs sampled))

# .makeRe star; dot=true
  micromatch x 1,863,453 ops/sec ±0.74% (93 runs sampled)
  minimatch x 723,105 ops/sec ±0.75% (93 runs sampled)

# .makeRe globstar
  micromatch x 1,624,179 ops/sec ±2.22% (91 runs sampled)
  minimatch x 1,117,230 ops/sec ±2.78% (86 runs sampled))

# .makeRe globstars
  micromatch x 1,658,642 ops/sec ±0.86% (92 runs sampled)
  minimatch x 741,224 ops/sec ±1.24% (89 runs sampled))

# .makeRe with leading star
  micromatch x 1,525,014 ops/sec ±1.63% (90 runs sampled)
  minimatch x 561,074 ops/sec ±3.07% (89 runs sampled)

# .makeRe - braces
  micromatch x 172,478 ops/sec ±2.37% (78 runs sampled)
  minimatch x 96,087 ops/sec ±2.34% (88 runs sampled)))

# .makeRe braces - range (expanded)
  micromatch x 26,973 ops/sec ±0.84% (89 runs sampled)
  minimatch x 3,023 ops/sec ±0.99% (90 runs sampled))

# .makeRe braces - range (compiled)
  micromatch x 152,892 ops/sec ±1.67% (83 runs sampled)
  minimatch x 992 ops/sec ±3.50% (89 runs sampled)d))

# .makeRe braces - nested ranges (expanded)
  micromatch x 15,816 ops/sec ±13.05% (80 runs sampled)
  minimatch x 2,953 ops/sec ±1.64% (91 runs sampled)

# .makeRe braces - nested ranges (compiled)
  micromatch x 110,881 ops/sec ±1.85% (82 runs sampled)
  minimatch x 1,008 ops/sec ±1.51% (91 runs sampled)

# .makeRe braces - set (compiled)
  micromatch x 134,930 ops/sec ±3.54% (63 runs sampled))
  minimatch x 43,242 ops/sec ±0.60% (93 runs sampled)

# .makeRe braces - nested sets (compiled)
  micromatch x 94,455 ops/sec ±1.74% (69 runs sampled))
  minimatch x 27,720 ops/sec ±1.84% (93 runs sampled))
```

## Contributing

All contributions are welcome! Please read [the contributing guide](.github/contributing.md) to get started.

**Bug reports**

Please create an issue if you encounter a bug or matching behavior that doesn't seem correct. If you find a matching-related issue, please:

* [research existing issues first](../../issues) (open and closed)
* visit the [GNU Bash documentation](https://www.gnu.org/software/bash/manual/) to see how Bash deals with the pattern
* visit the [minimatch](https://github.com/isaacs/minimatch) documentation to cross-check expected behavior in node.js
* if all else fails, since there is no real specification for globs we will probably need to discuss expected behavior and decide how to resolve it. which means any detail you can provide to help with this discussion would be greatly appreciated.

**Platform issues**

It's important to us that micromatch work consistently on all platforms. If you encounter any platform-specific matching or path related issues, please let us know (pull requests are also greatly appreciated).

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

Please read the [contributing guide](.github/contributing.md) for advice on opening issues, pull requests, and coding standards.

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Related projects

You might also be interested in these projects:

* [braces](https://www.npmjs.com/package/braces): Bash-like brace expansion, implemented in JavaScript. Safer than other brace expansion libs, with complete support… [more](https://github.com/micromatch/braces) | [homepage](https://github.com/micromatch/braces "Bash-like brace expansion, implemented in JavaScript. Safer than other brace expansion libs, with complete support for the Bash 4.3 braces specification, without sacrificing speed.")
* [expand-brackets](https://www.npmjs.com/package/expand-brackets): Expand POSIX bracket expressions (character classes) in glob patterns. | [homepage](https://github.com/micromatch/expand-brackets "Expand POSIX bracket expressions (character classes) in glob patterns.")
* [extglob](https://www.npmjs.com/package/extglob): Extended glob support for JavaScript. Adds (almost) the expressive power of regular expressions to glob… [more](https://github.com/micromatch/extglob) | [homepage](https://github.com/micromatch/extglob "Extended glob support for JavaScript. Adds (almost) the expressive power of regular expressions to glob patterns.")
* [fill-range](https://www.npmjs.com/package/fill-range): Fill in a range of numbers or letters, optionally passing an increment or `step` to… [more](https://github.com/jonschlinkert/fill-range) | [homepage](https://github.com/jonschlinkert/fill-range "Fill in a range of numbers or letters, optionally passing an increment or `step` to use, or create a regex-compatible range with `options.toRegex`")
* [nanomatch](https://www.npmjs.com/package/nanomatch): Fast, minimal glob matcher for node.js. Similar to micromatch, minimatch and multimatch, but complete Bash… [more](https://github.com/micromatch/nanomatch) | [homepage](https://github.com/micromatch/nanomatch "Fast, minimal glob matcher for node.js. Similar to micromatch, minimatch and multimatch, but complete Bash 4.3 wildcard support only (no support for exglobs, posix brackets or braces)")

### Contributors

| **Commits** | **Contributor** |  
| --- | --- |  
| 512 | [jonschlinkert](https://github.com/jonschlinkert) |  
| 12  | [es128](https://github.com/es128) |  
| 9   | [danez](https://github.com/danez) |  
| 8   | [doowb](https://github.com/doowb) |  
| 6   | [paulmillr](https://github.com/paulmillr) |  
| 5   | [mrmlnc](https://github.com/mrmlnc) |  
| 3   | [DrPizza](https://github.com/DrPizza) |  
| 2   | [TrySound](https://github.com/TrySound) |  
| 2   | [mceIdo](https://github.com/mceIdo) |  
| 2   | [Glazy](https://github.com/Glazy) |  
| 2   | [MartinKolarik](https://github.com/MartinKolarik) |  
| 2   | [antonyk](https://github.com/antonyk) |  
| 2   | [Tvrqvoise](https://github.com/Tvrqvoise) |  
| 1   | [amilajack](https://github.com/amilajack) |  
| 1   | [Cslove](https://github.com/Cslove) |  
| 1   | [devongovett](https://github.com/devongovett) |  
| 1   | [DianeLooney](https://github.com/DianeLooney) |  
| 1   | [UltCombo](https://github.com/UltCombo) |  
| 1   | [frangio](https://github.com/frangio) |  
| 1   | [joyceerhl](https://github.com/joyceerhl) |  
| 1   | [juszczykjakub](https://github.com/juszczykjakub) |  
| 1   | [muescha](https://github.com/muescha) |  
| 1   | [sebdeckers](https://github.com/sebdeckers) |  
| 1   | [tomByrer](https://github.com/tomByrer) |  
| 1   | [fidian](https://github.com/fidian) |  
| 1   | [curbengh](https://github.com/curbengh) |  
| 1   | [simlu](https://github.com/simlu) |  
| 1   | [wtgtybhertgeghgtwtg](https://github.com/wtgtybhertgeghgtwtg) |  
| 1   | [yvele](https://github.com/yvele) |  

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

### License

Copyright © 2022, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.8.0, on March 24, 2022._# wrappy

Callback wrapping utility

## USAGE

```javascript
var wrappy = require("wrappy")

// var wrapper = wrappy(wrapperFunction)

// make sure a cb is called only once
// See also: http://npm.im/once for this specific use case
var once = wrappy(function (cb) {
  var called = false
  return function () {
    if (called) return
    called = true
    return cb.apply(this, arguments)
  }
})

function printBoo () {
  console.log('boo')
}
// has some rando property
printBoo.iAmBooPrinter = true

var onlyPrintOnce = once(printBoo)

onlyPrintOnce() // prints 'boo'
onlyPrintOnce() // does nothing

// random property is retained!
assert.equal(onlyPrintOnce.iAmBooPrinter, true)
```
### [5.1.2](https://github.com/gulpjs/glob-parent/compare/v5.1.1...v5.1.2) (2021-03-06)


### Bug Fixes

* eliminate ReDoS ([#36](https://github.com/gulpjs/glob-parent/issues/36)) ([f923116](https://github.com/gulpjs/glob-parent/commit/f9231168b0041fea3f8f954b3cceb56269fc6366))

### [5.1.1](https://github.com/gulpjs/glob-parent/compare/v5.1.0...v5.1.1) (2021-01-27)


### Bug Fixes

* unescape exclamation mark ([#26](https://github.com/gulpjs/glob-parent/issues/26)) ([a98874f](https://github.com/gulpjs/glob-parent/commit/a98874f1a59e407f4fb1beb0db4efa8392da60bb))

## [5.1.0](https://github.com/gulpjs/glob-parent/compare/v5.0.0...v5.1.0) (2021-01-27)


### Features

* add `flipBackslashes` option to disable auto conversion of slashes (closes [#24](https://github.com/gulpjs/glob-parent/issues/24)) ([#25](https://github.com/gulpjs/glob-parent/issues/25)) ([eecf91d](https://github.com/gulpjs/glob-parent/commit/eecf91d5e3834ed78aee39c4eaaae654d76b87b3))

## [5.0.0](https://github.com/gulpjs/glob-parent/compare/v4.0.0...v5.0.0) (2021-01-27)


### ⚠ BREAKING CHANGES

* Drop support for node <6 & bump dependencies

### Miscellaneous Chores

* Drop support for node <6 & bump dependencies ([896c0c0](https://github.com/gulpjs/glob-parent/commit/896c0c00b4e7362f60b96e7fc295ae929245255a))

## [4.0.0](https://github.com/gulpjs/glob-parent/compare/v3.1.0...v4.0.0) (2021-01-27)


### ⚠ BREAKING CHANGES

* question marks are valid path characters on Windows so avoid flagging as a glob when alone
* Update is-glob dependency

### Features

* hoist regexps and strings for performance gains ([4a80667](https://github.com/gulpjs/glob-parent/commit/4a80667c69355c76a572a5892b0f133c8e1f457e))
* question marks are valid path characters on Windows so avoid flagging as a glob when alone ([2a551dd](https://github.com/gulpjs/glob-parent/commit/2a551dd0dc3235e78bf3c94843d4107072d17841))
* Update is-glob dependency ([e41fcd8](https://github.com/gulpjs/glob-parent/commit/e41fcd895d1f7bc617dba45c9d935a7949b9c281))

## [3.1.0](https://github.com/gulpjs/glob-parent/compare/v3.0.1...v3.1.0) (2021-01-27)


### Features

* allow basic win32 backslash use ([272afa5](https://github.com/gulpjs/glob-parent/commit/272afa5fd070fc0f796386a5993d4ee4a846988b))
* handle extglobs (parentheses) containing separators ([7db1bdb](https://github.com/gulpjs/glob-parent/commit/7db1bdb0756e55fd14619e8ce31aa31b17b117fd))
* new approach to braces/brackets handling ([8269bd8](https://github.com/gulpjs/glob-parent/commit/8269bd89290d99fac9395a354fb56fdcdb80f0be))
* pre-process braces/brackets sections ([9ef8a87](https://github.com/gulpjs/glob-parent/commit/9ef8a87f66b1a43d0591e7a8e4fc5a18415ee388))
* preserve escaped brace/bracket at end of string ([8cfb0ba](https://github.com/gulpjs/glob-parent/commit/8cfb0ba84202d51571340dcbaf61b79d16a26c76))


### Bug Fixes

* trailing escaped square brackets ([99ec9fe](https://github.com/gulpjs/glob-parent/commit/99ec9fecc60ee488ded20a94dd4f18b4f55c4ccf))

### [3.0.1](https://github.com/gulpjs/glob-parent/compare/v3.0.0...v3.0.1) (2021-01-27)


### Features

* use path-dirname ponyfill ([cdbea5f](https://github.com/gulpjs/glob-parent/commit/cdbea5f32a58a54e001a75ddd7c0fccd4776aacc))


### Bug Fixes

* unescape glob-escaped dirnames on output ([598c533](https://github.com/gulpjs/glob-parent/commit/598c533bdf49c1428bc063aa9b8db40c5a86b030))

## [3.0.0](https://github.com/gulpjs/glob-parent/compare/v2.0.0...v3.0.0) (2021-01-27)


### ⚠ BREAKING CHANGES

* update is-glob dependency

### Features

* update is-glob dependency ([5c5f8ef](https://github.com/gulpjs/glob-parent/commit/5c5f8efcee362a8e7638cf8220666acd8784f6bd))

## [2.0.0](https://github.com/gulpjs/glob-parent/compare/v1.3.0...v2.0.0) (2021-01-27)


### Features

* move up to dirname regardless of glob characters ([f97fb83](https://github.com/gulpjs/glob-parent/commit/f97fb83be2e0a9fc8d3b760e789d2ecadd6aa0c2))

## [1.3.0](https://github.com/gulpjs/glob-parent/compare/v1.2.0...v1.3.0) (2021-01-27)

## [1.2.0](https://github.com/gulpjs/glob-parent/compare/v1.1.0...v1.2.0) (2021-01-27)


### Reverts

* feat: make regex test strings smaller ([dc80fa9](https://github.com/gulpjs/glob-parent/commit/dc80fa9658dca20549cfeba44bbd37d5246fcce0))

## [1.1.0](https://github.com/gulpjs/glob-parent/compare/v1.0.0...v1.1.0) (2021-01-27)


### Features

* make regex test strings smaller ([cd83220](https://github.com/gulpjs/glob-parent/commit/cd832208638f45169f986d80fcf66e401f35d233))

## 1.0.0 (2021-01-27)

<p align="center">
  <a href="https://gulpjs.com">
    <img height="257" width="114" src="https://raw.githubusercontent.com/gulpjs/artwork/master/gulp-2x.png">
  </a>
</p>

# glob-parent

[![NPM version][npm-image]][npm-url] [![Downloads][downloads-image]][npm-url] [![Azure Pipelines Build Status][azure-pipelines-image]][azure-pipelines-url] [![Travis Build Status][travis-image]][travis-url] [![AppVeyor Build Status][appveyor-image]][appveyor-url] [![Coveralls Status][coveralls-image]][coveralls-url] [![Gitter chat][gitter-image]][gitter-url]

Extract the non-magic parent path from a glob string.

## Usage

```js
var globParent = require('glob-parent');

globParent('path/to/*.js'); // 'path/to'
globParent('/root/path/to/*.js'); // '/root/path/to'
globParent('/*.js'); // '/'
globParent('*.js'); // '.'
globParent('**/*.js'); // '.'
globParent('path/{to,from}'); // 'path'
globParent('path/!(to|from)'); // 'path'
globParent('path/?(to|from)'); // 'path'
globParent('path/+(to|from)'); // 'path'
globParent('path/*(to|from)'); // 'path'
globParent('path/@(to|from)'); // 'path'
globParent('path/**/*'); // 'path'

// if provided a non-glob path, returns the nearest dir
globParent('path/foo/bar.js'); // 'path/foo'
globParent('path/foo/'); // 'path/foo'
globParent('path/foo'); // 'path' (see issue #3 for details)
```

## API

### `globParent(maybeGlobString, [options])`

Takes a string and returns the part of the path before the glob begins. Be aware of Escaping rules and Limitations below.

#### options

```js
{
  // Disables the automatic conversion of slashes for Windows
  flipBackslashes: true
}
```

## Escaping

The following characters have special significance in glob patterns and must be escaped if you want them to be treated as regular path characters:

- `?` (question mark) unless used as a path segment alone
- `*` (asterisk)
- `|` (pipe)
- `(` (opening parenthesis)
- `)` (closing parenthesis)
- `{` (opening curly brace)
- `}` (closing curly brace)
- `[` (opening bracket)
- `]` (closing bracket)

**Example**

```js
globParent('foo/[bar]/') // 'foo'
globParent('foo/\\[bar]/') // 'foo/[bar]'
```

## Limitations

### Braces & Brackets
This library attempts a quick and imperfect method of determining which path
parts have glob magic without fully parsing/lexing the pattern. There are some
advanced use cases that can trip it up, such as nested braces where the outer
pair is escaped and the inner one contains a path separator. If you find
yourself in the unlikely circumstance of being affected by this or need to
ensure higher-fidelity glob handling in your library, it is recommended that you
pre-process your input with [expand-braces] and/or [expand-brackets].

### Windows
Backslashes are not valid path separators for globs. If a path with backslashes
is provided anyway, for simple cases, glob-parent will replace the path
separator for you and return the non-glob parent path (now with
forward-slashes, which are still valid as Windows path separators).

This cannot be used in conjunction with escape characters.

```js
// BAD
globParent('C:\\Program Files \\(x86\\)\\*.ext') // 'C:/Program Files /(x86/)'

// GOOD
globParent('C:/Program Files\\(x86\\)/*.ext') // 'C:/Program Files (x86)'
```

If you are using escape characters for a pattern without path parts (i.e.
relative to `cwd`), prefix with `./` to avoid confusing glob-parent.

```js
// BAD
globParent('foo \\[bar]') // 'foo '
globParent('foo \\[bar]*') // 'foo '

// GOOD
globParent('./foo \\[bar]') // 'foo [bar]'
globParent('./foo \\[bar]*') // '.'
```

## License

ISC

[expand-braces]: https://github.com/jonschlinkert/expand-braces
[expand-brackets]: https://github.com/jonschlinkert/expand-brackets

[downloads-image]: https://img.shields.io/npm/dm/glob-parent.svg
[npm-url]: https://www.npmjs.com/package/glob-parent
[npm-image]: https://img.shields.io/npm/v/glob-parent.svg

[azure-pipelines-url]: https://dev.azure.com/gulpjs/gulp/_build/latest?definitionId=2&branchName=master
[azure-pipelines-image]: https://dev.azure.com/gulpjs/gulp/_apis/build/status/glob-parent?branchName=master

[travis-url]: https://travis-ci.org/gulpjs/glob-parent
[travis-image]: https://img.shields.io/travis/gulpjs/glob-parent.svg?label=travis-ci

[appveyor-url]: https://ci.appveyor.com/project/gulpjs/glob-parent
[appveyor-image]: https://img.shields.io/appveyor/ci/gulpjs/glob-parent.svg?label=appveyor

[coveralls-url]: https://coveralls.io/r/gulpjs/glob-parent
[coveralls-image]: https://img.shields.io/coveralls/gulpjs/glob-parent/master.svg

[gitter-url]: https://gitter.im/gulpjs/gulp
[gitter-image]: https://badges.gitter.im/gulpjs/gulp.svg
# fast-glob

> It's a very fast and efficient [glob][glob_definition] library for [Node.js][node_js].

This package provides methods for traversing the file system and returning pathnames that matched a defined set of a specified pattern according to the rules used by the Unix Bash shell with some simplifications, meanwhile results are returned in **arbitrary order**. Quick, simple, effective.

## Table of Contents

<details>
<summary><strong>Details</strong></summary>

* [Highlights](#highlights)
* [Old and modern mode](#old-and-modern-mode)
* [Pattern syntax](#pattern-syntax)
  * [Basic syntax](#basic-syntax)
  * [Advanced syntax](#advanced-syntax)
* [Installation](#installation)
* [API](#api)
  * [Asynchronous](#asynchronous)
  * [Synchronous](#synchronous)
  * [Stream](#stream)
    * [patterns](#patterns)
    * [[options]](#options)
  * [Helpers](#helpers)
    * [generateTasks](#generatetaskspatterns-options)
    * [isDynamicPattern](#isdynamicpatternpattern-options)
    * [escapePath](#escapepathpath)
	* [convertPathToPattern](#convertpathtopatternpath)
* [Options](#options-3)
  * [Common](#common)
    * [concurrency](#concurrency)
    * [cwd](#cwd)
    * [deep](#deep)
    * [followSymbolicLinks](#followsymboliclinks)
    * [fs](#fs)
    * [ignore](#ignore)
    * [suppressErrors](#suppresserrors)
    * [throwErrorOnBrokenSymbolicLink](#throwerroronbrokensymboliclink)
  * [Output control](#output-control)
    * [absolute](#absolute)
    * [markDirectories](#markdirectories)
    * [objectMode](#objectmode)
    * [onlyDirectories](#onlydirectories)
    * [onlyFiles](#onlyfiles)
    * [stats](#stats)
    * [unique](#unique)
  * [Matching control](#matching-control)
    * [braceExpansion](#braceexpansion)
    * [caseSensitiveMatch](#casesensitivematch)
    * [dot](#dot)
    * [extglob](#extglob)
    * [globstar](#globstar)
    * [baseNameMatch](#basenamematch)
* [FAQ](#faq)
  * [What is a static or dynamic pattern?](#what-is-a-static-or-dynamic-pattern)
  * [How to write patterns on Windows?](#how-to-write-patterns-on-windows)
  * [Why are parentheses match wrong?](#why-are-parentheses-match-wrong)
  * [How to exclude directory from reading?](#how-to-exclude-directory-from-reading)
  * [How to use UNC path?](#how-to-use-unc-path)
  * [Compatible with `node-glob`?](#compatible-with-node-glob)
* [Benchmarks](#benchmarks)
  * [Server](#server)
  * [Nettop](#nettop)
* [Changelog](#changelog)
* [License](#license)

</details>

## Highlights

* Fast. Probably the fastest.
* Supports multiple and negative patterns.
* Synchronous, Promise and Stream API.
* Object mode. Can return more than just strings.
* Error-tolerant.

## Old and modern mode

This package works in two modes, depending on the environment in which it is used.

* **Old mode**. Node.js below 10.10 or when the [`stats`](#stats) option is *enabled*.
* **Modern mode**. Node.js 10.10+ and the [`stats`](#stats) option is *disabled*.

The modern mode is faster. Learn more about the [internal mechanism][nodelib_fs_scandir_old_and_modern_modern].

## Pattern syntax

> :warning: Always use forward-slashes in glob expressions (patterns and [`ignore`](#ignore) option). Use backslashes for escaping characters.

There is more than one form of syntax: basic and advanced. Below is a brief overview of the supported features. Also pay attention to our [FAQ](#faq).

> :book: This package uses [`micromatch`][micromatch] as a library for pattern matching.

### Basic syntax

* An asterisk (`*`) — matches everything except slashes (path separators), hidden files (names starting with `.`).
* A double star or globstar (`**`) — matches zero or more directories.
* Question mark (`?`) – matches any single character except slashes (path separators).
* Sequence (`[seq]`) — matches any character in sequence.

> :book: A few additional words about the [basic matching behavior][picomatch_matching_behavior].

Some examples:

* `src/**/*.js` — matches all files in the `src` directory (any level of nesting) that have the `.js` extension.
* `src/*.??` — matches all files in the `src` directory (only first level of nesting) that have a two-character extension.
* `file-[01].js` — matches files: `file-0.js`, `file-1.js`.

### Advanced syntax

* [Escapes characters][micromatch_backslashes] (`\\`) — matching special characters (`$^*+?()[]`) as literals.
* [POSIX character classes][picomatch_posix_brackets] (`[[:digit:]]`).
* [Extended globs][micromatch_extglobs] (`?(pattern-list)`).
* [Bash style brace expansions][micromatch_braces] (`{}`).
* [Regexp character classes][micromatch_regex_character_classes] (`[1-5]`).
* [Regex groups][regular_expressions_brackets] (`(a|b)`).

> :book: A few additional words about the [advanced matching behavior][micromatch_extended_globbing].

Some examples:

* `src/**/*.{css,scss}` — matches all files in the `src` directory (any level of nesting) that have the `.css` or `.scss` extension.
* `file-[[:digit:]].js` — matches files: `file-0.js`, `file-1.js`, …, `file-9.js`.
* `file-{1..3}.js` — matches files: `file-1.js`, `file-2.js`, `file-3.js`.
* `file-(1|2)` — matches files: `file-1.js`, `file-2.js`.

## Installation

```console
npm install fast-glob
```

## API

### Asynchronous

```js
fg(patterns, [options])
fg.async(patterns, [options])
fg.glob(patterns, [options])
```

Returns a `Promise` with an array of matching entries.

```js
const fg = require('fast-glob');

const entries = await fg(['.editorconfig', '**/index.js'], { dot: true });

// ['.editorconfig', 'services/index.js']
```

### Synchronous

```js
fg.sync(patterns, [options])
fg.globSync(patterns, [options])
```

Returns an array of matching entries.

```js
const fg = require('fast-glob');

const entries = fg.sync(['.editorconfig', '**/index.js'], { dot: true });

// ['.editorconfig', 'services/index.js']
```

### Stream

```js
fg.stream(patterns, [options])
fg.globStream(patterns, [options])
```

Returns a [`ReadableStream`][node_js_stream_readable_streams] when the `data` event will be emitted with matching entry.

```js
const fg = require('fast-glob');

const stream = fg.stream(['.editorconfig', '**/index.js'], { dot: true });

for await (const entry of stream) {
	// .editorconfig
	// services/index.js
}
```

#### patterns

* Required: `true`
* Type: `string | string[]`

Any correct pattern(s).

> :1234: [Pattern syntax](#pattern-syntax)
>
> :warning: This package does not respect the order of patterns. First, all the negative patterns are applied, and only then the positive patterns. If you want to get a certain order of records, use sorting or split calls.

#### [options]

* Required: `false`
* Type: [`Options`](#options-3)

See [Options](#options-3) section.

### Helpers

#### `generateTasks(patterns, [options])`

Returns the internal representation of patterns ([`Task`](./src/managers/tasks.ts) is a combining patterns by base directory).

```js
fg.generateTasks('*');

[{
    base: '.', // Parent directory for all patterns inside this task
    dynamic: true, // Dynamic or static patterns are in this task
    patterns: ['*'],
    positive: ['*'],
    negative: []
}]
```

##### patterns

* Required: `true`
* Type: `string | string[]`

Any correct pattern(s).

##### [options]

* Required: `false`
* Type: [`Options`](#options-3)

See [Options](#options-3) section.

#### `isDynamicPattern(pattern, [options])`

Returns `true` if the passed pattern is a dynamic pattern.

> :1234: [What is a static or dynamic pattern?](#what-is-a-static-or-dynamic-pattern)

```js
fg.isDynamicPattern('*'); // true
fg.isDynamicPattern('abc'); // false
```

##### pattern

* Required: `true`
* Type: `string`

Any correct pattern.

##### [options]

* Required: `false`
* Type: [`Options`](#options-3)

See [Options](#options-3) section.

#### `escapePath(path)`

Returns the path with escaped special characters depending on the platform.

* Posix:
  * `*?|(){}[]`;
  * `!` at the beginning of line;
  * `@+!` before the opening parenthesis;
  * `\\` before non-special characters;
* Windows:
  * `(){}[]`
  * `!` at the beginning of line;
  * `@+!` before the opening parenthesis;
  * Characters like `*?|` cannot be used in the path ([windows_naming_conventions][windows_naming_conventions]), so they will not be escaped;

```js
fg.escapePath('!abc');
// \\!abc
fg.escapePath('[OpenSource] mrmlnc – fast-glob (Deluxe Edition) 2014') + '/*.flac'
// \\[OpenSource\\] mrmlnc – fast-glob \\(Deluxe Edition\\) 2014/*.flac

fg.posix.escapePath('C:\\Program Files (x86)\\**\\*');
// C:\\\\Program Files \\(x86\\)\\*\\*\\*
fg.win32.escapePath('C:\\Program Files (x86)\\**\\*');
// Windows: C:\\Program Files \\(x86\\)\\**\\*
```

#### `convertPathToPattern(path)`

Converts a path to a pattern depending on the platform, including special character escaping.

* Posix. Works similarly to the `fg.posix.escapePath` method.
* Windows. Works similarly to the `fg.win32.escapePath` method, additionally converting backslashes to forward slashes in cases where they are not escape characters (`!()+@{}[]`).

```js
fg.convertPathToPattern('[OpenSource] mrmlnc – fast-glob (Deluxe Edition) 2014') + '/*.flac';
// \\[OpenSource\\] mrmlnc – fast-glob \\(Deluxe Edition\\) 2014/*.flac

fg.convertPathToPattern('C:/Program Files (x86)/**/*');
// Posix: C:/Program Files \\(x86\\)/\\*\\*/\\*
// Windows: C:/Program Files \\(x86\\)/**/*

fg.convertPathToPattern('C:\\Program Files (x86)\\**\\*');
// Posix: C:\\\\Program Files \\(x86\\)\\*\\*\\*
// Windows: C:/Program Files \\(x86\\)/**/*

fg.posix.convertPathToPattern('\\\\?\\c:\\Program Files (x86)') + '/**/*';
// Posix: \\\\\\?\\\\c:\\\\Program Files \\(x86\\)/**/* (broken pattern)
fg.win32.convertPathToPattern('\\\\?\\c:\\Program Files (x86)') + '/**/*';
// Windows: //?/c:/Program Files \\(x86\\)/**/*
```

## Options

### Common options

#### concurrency

* Type: `number`
* Default: `os.cpus().length`

Specifies the maximum number of concurrent requests from a reader to read directories.

> :book: The higher the number, the higher the performance and load on the file system. If you want to read in quiet mode, set the value to a comfortable number or `1`.

<details>

<summary>More details</summary>

In Node, there are [two types of threads][nodejs_thread_pool]: Event Loop (code) and a Thread Pool (fs, dns, …). The thread pool size controlled by the `UV_THREADPOOL_SIZE` environment variable. Its default size is 4 ([documentation][libuv_thread_pool]). The pool is one for all tasks within a single Node process.

Any code can make 4 real concurrent accesses to the file system. The rest of the FS requests will wait in the queue.

> :book: Each new instance of FG in the same Node process will use the same Thread pool.

But this package also has the `concurrency` option. This option allows you to control the number of concurrent accesses to the FS at the package level. By default, this package has a value equal to the number of cores available for the current Node process. This allows you to set a value smaller than the pool size (`concurrency: 1`) or, conversely, to prepare tasks for the pool queue more quickly (`concurrency: Number.POSITIVE_INFINITY`).

So, in fact, this package can **only make 4 concurrent requests to the FS**. You can increase this value by using an environment variable (`UV_THREADPOOL_SIZE`), but in practice this does not give a multiple advantage.

</details>

#### cwd

* Type: `string`
* Default: `process.cwd()`

The current working directory in which to search.

#### deep

* Type: `number`
* Default: `Infinity`

Specifies the maximum depth of a read directory relative to the start directory.

For example, you have the following tree:

```js
dir/
└── one/            // 1
    └── two/        // 2
        └── file.js // 3
```

```js
// With base directory
fg.sync('dir/**', { onlyFiles: false, deep: 1 }); // ['dir/one']
fg.sync('dir/**', { onlyFiles: false, deep: 2 }); // ['dir/one', 'dir/one/two']

// With cwd option
fg.sync('**', { onlyFiles: false, cwd: 'dir', deep: 1 }); // ['one']
fg.sync('**', { onlyFiles: false, cwd: 'dir', deep: 2 }); // ['one', 'one/two']
```

> :book: If you specify a pattern with some base directory, this directory will not participate in the calculation of the depth of the found directories. Think of it as a [`cwd`](#cwd) option.

#### followSymbolicLinks

* Type: `boolean`
* Default: `true`

Indicates whether to traverse descendants of symbolic link directories when expanding `**` patterns.

> :book: Note that this option does not affect the base directory of the pattern. For example, if `./a` is a symlink to directory `./b` and you specified `['./a**', './b/**']` patterns, then directory `./a` will still be read.

> :book: If the [`stats`](#stats) option is specified, the information about the symbolic link (`fs.lstat`) will be replaced with information about the entry (`fs.stat`) behind it.

#### fs

* Type: `FileSystemAdapter`
* Default: `fs.*`

Custom implementation of methods for working with the file system.

```ts
export interface FileSystemAdapter {
    lstat?: typeof fs.lstat;
    stat?: typeof fs.stat;
    lstatSync?: typeof fs.lstatSync;
    statSync?: typeof fs.statSync;
    readdir?: typeof fs.readdir;
    readdirSync?: typeof fs.readdirSync;
}
```

#### ignore

* Type: `string[]`
* Default: `[]`

An array of glob patterns to exclude matches. This is an alternative way to use negative patterns.

```js
dir/
├── package-lock.json
└── package.json
```

```js
fg.sync(['*.json', '!package-lock.json']);            // ['package.json']
fg.sync('*.json', { ignore: ['package-lock.json'] }); // ['package.json']
```

#### suppressErrors

* Type: `boolean`
* Default: `false`

By default this package suppress only `ENOENT` errors. Set to `true` to suppress any error.

> :book: Can be useful when the directory has entries with a special level of access.

#### throwErrorOnBrokenSymbolicLink

* Type: `boolean`
* Default: `false`

Throw an error when symbolic link is broken if `true` or safely return `lstat` call if `false`.

> :book: This option has no effect on errors when reading the symbolic link directory.

### Output control

#### absolute

* Type: `boolean`
* Default: `false`

Return the absolute path for entries.

```js
fg.sync('*.js', { absolute: false }); // ['index.js']
fg.sync('*.js', { absolute: true });  // ['/home/user/index.js']
```

> :book: This option is required if you want to use negative patterns with absolute path, for example, `!${__dirname}/*.js`.

#### markDirectories

* Type: `boolean`
* Default: `false`

Mark the directory path with the final slash.

```js
fg.sync('*', { onlyFiles: false, markDirectories: false }); // ['index.js', 'controllers']
fg.sync('*', { onlyFiles: false, markDirectories: true });  // ['index.js', 'controllers/']
```

#### objectMode

* Type: `boolean`
* Default: `false`

Returns objects (instead of strings) describing entries.

```js
fg.sync('*', { objectMode: false }); // ['src/index.js']
fg.sync('*', { objectMode: true });  // [{ name: 'index.js', path: 'src/index.js', dirent: <fs.Dirent> }]
```

The object has the following fields:

* name (`string`) — the last part of the path (basename)
* path (`string`) — full path relative to the pattern base directory
* dirent ([`fs.Dirent`][node_js_fs_class_fs_dirent]) — instance of `fs.Dirent`

> :book: An object is an internal representation of entry, so getting it does not affect performance.

#### onlyDirectories

* Type: `boolean`
* Default: `false`

Return only directories.

```js
fg.sync('*', { onlyDirectories: false }); // ['index.js', 'src']
fg.sync('*', { onlyDirectories: true });  // ['src']
```

> :book: If `true`, the [`onlyFiles`](#onlyfiles) option is automatically `false`.

#### onlyFiles

* Type: `boolean`
* Default: `true`

Return only files.

```js
fg.sync('*', { onlyFiles: false }); // ['index.js', 'src']
fg.sync('*', { onlyFiles: true });  // ['index.js']
```

#### stats

* Type: `boolean`
* Default: `false`

Enables an [object mode](#objectmode) with an additional field:

* stats ([`fs.Stats`][node_js_fs_class_fs_stats]) — instance of `fs.Stats`

```js
fg.sync('*', { stats: false }); // ['src/index.js']
fg.sync('*', { stats: true });  // [{ name: 'index.js', path: 'src/index.js', dirent: <fs.Dirent>, stats: <fs.Stats> }]
```

> :book: Returns `fs.stat` instead of `fs.lstat` for symbolic links when the [`followSymbolicLinks`](#followsymboliclinks) option is specified.
>
> :warning: Unlike [object mode](#objectmode) this mode requires additional calls to the file system. On average, this mode is slower at least twice. See [old and modern mode](#old-and-modern-mode) for more details.

#### unique

* Type: `boolean`
* Default: `true`

Ensures that the returned entries are unique.

```js
fg.sync(['*.json', 'package.json'], { unique: false }); // ['package.json', 'package.json']
fg.sync(['*.json', 'package.json'], { unique: true });  // ['package.json']
```

If `true` and similar entries are found, the result is the first found.

### Matching control

#### braceExpansion

* Type: `boolean`
* Default: `true`

Enables Bash-like brace expansion.

> :1234: [Syntax description][bash_hackers_syntax_expansion_brace] or more [detailed description][micromatch_braces].

```js
dir/
├── abd
├── acd
└── a{b,c}d
```

```js
fg.sync('a{b,c}d', { braceExpansion: false }); // ['a{b,c}d']
fg.sync('a{b,c}d', { braceExpansion: true });  // ['abd', 'acd']
```

#### caseSensitiveMatch

* Type: `boolean`
* Default: `true`

Enables a [case-sensitive][wikipedia_case_sensitivity] mode for matching files.

```js
dir/
├── file.txt
└── File.txt
```

```js
fg.sync('file.txt', { caseSensitiveMatch: false }); // ['file.txt', 'File.txt']
fg.sync('file.txt', { caseSensitiveMatch: true });  // ['file.txt']
```

#### dot

* Type: `boolean`
* Default: `false`

Allow patterns to match entries that begin with a period (`.`).

> :book: Note that an explicit dot in a portion of the pattern will always match dot files.

```js
dir/
├── .editorconfig
└── package.json
```

```js
fg.sync('*', { dot: false }); // ['package.json']
fg.sync('*', { dot: true });  // ['.editorconfig', 'package.json']
```

#### extglob

* Type: `boolean`
* Default: `true`

Enables Bash-like `extglob` functionality.

> :1234: [Syntax description][micromatch_extglobs].

```js
dir/
├── README.md
└── package.json
```

```js
fg.sync('*.+(json|md)', { extglob: false }); // []
fg.sync('*.+(json|md)', { extglob: true });  // ['README.md', 'package.json']
```

#### globstar

* Type: `boolean`
* Default: `true`

Enables recursively repeats a pattern containing `**`. If `false`, `**` behaves exactly like `*`.

```js
dir/
└── a
    └── b
```

```js
fg.sync('**', { onlyFiles: false, globstar: false }); // ['a']
fg.sync('**', { onlyFiles: false, globstar: true });  // ['a', 'a/b']
```

#### baseNameMatch

* Type: `boolean`
* Default: `false`

If set to `true`, then patterns without slashes will be matched against the basename of the path if it contains slashes.

```js
dir/
└── one/
    └── file.md
```

```js
fg.sync('*.md', { baseNameMatch: false }); // []
fg.sync('*.md', { baseNameMatch: true });  // ['one/file.md']
```

## FAQ

## What is a static or dynamic pattern?

All patterns can be divided into two types:

* **static**. A pattern is considered static if it can be used to get an entry on the file system without using matching mechanisms. For example, the `file.js` pattern is a static pattern because we can just verify that it exists on the file system.
* **dynamic**. A pattern is considered dynamic if it cannot be used directly to find occurrences without using a matching mechanisms. For example, the `*` pattern is a dynamic pattern because we cannot use this pattern directly.

A pattern is considered dynamic if it contains the following characters (`…` — any characters or their absence) or options:

* The [`caseSensitiveMatch`](#casesensitivematch) option is disabled
* `\\` (the escape character)
* `*`, `?`, `!` (at the beginning of line)
* `[…]`
* `(…|…)`
* `@(…)`, `!(…)`, `*(…)`, `?(…)`, `+(…)` (respects the [`extglob`](#extglob) option)
* `{…,…}`, `{…..…}` (respects the [`braceExpansion`](#braceexpansion) option)

## How to write patterns on Windows?

Always use forward-slashes in glob expressions (patterns and [`ignore`](#ignore) option). Use backslashes for escaping characters. With the [`cwd`](#cwd) option use a convenient format.

**Bad**

```ts
[
	'directory\\*',
	path.join(process.cwd(), '**')
]
```

**Good**

```ts
[
	'directory/*',
	fg.convertPathToPattern(process.cwd()) + '/**'
]
```

> :book: Use the [`.convertPathToPattern`](#convertpathtopatternpath) package to convert Windows-style path to a Unix-style path.

Read more about [matching with backslashes][micromatch_backslashes].

## Why are parentheses match wrong?

```js
dir/
└── (special-*file).txt
```

```js
fg.sync(['(special-*file).txt']) // []
```

Refers to Bash. You need to escape special characters:

```js
fg.sync(['\\(special-*file\\).txt']) // ['(special-*file).txt']
```

Read more about [matching special characters as literals][picomatch_matching_special_characters_as_literals]. Or use the [`.escapePath`](#escapepathpath).

## How to exclude directory from reading?

You can use a negative pattern like this: `!**/node_modules` or `!**/node_modules/**`. Also you can use [`ignore`](#ignore) option. Just look at the example below.

```js
first/
├── file.md
└── second/
    └── file.txt
```

If you don't want to read the `second` directory, you must write the following pattern: `!**/second` or `!**/second/**`.

```js
fg.sync(['**/*.md', '!**/second']);                 // ['first/file.md']
fg.sync(['**/*.md'], { ignore: ['**/second/**'] }); // ['first/file.md']
```

> :warning: When you write `!**/second/**/*` it means that the directory will be **read**, but all the entries will not be included in the results.

You have to understand that if you write the pattern to exclude directories, then the directory will not be read under any circumstances.

## How to use UNC path?

You cannot use [Uniform Naming Convention (UNC)][unc_path] paths as patterns (due to syntax) directly, but you can use them as [`cwd`](#cwd) directory or use the `fg.convertPathToPattern` method.

```ts
// cwd
fg.sync('*', { cwd: '\\\\?\\C:\\Python27' /* or //?/C:/Python27 */ });
fg.sync('Python27/*', { cwd: '\\\\?\\C:\\' /* or //?/C:/ */ });

// .convertPathToPattern
fg.sync(fg.convertPathToPattern('\\\\?\\c:\\Python27') + '/*');
```

## Compatible with `node-glob`?

| node-glob    | fast-glob |
| :----------: | :-------: |
| `cwd`        | [`cwd`](#cwd) |
| `root`       | – |
| `dot`        | [`dot`](#dot) |
| `nomount`    | – |
| `mark`       | [`markDirectories`](#markdirectories) |
| `nosort`     | – |
| `nounique`   | [`unique`](#unique) |
| `nobrace`    | [`braceExpansion`](#braceexpansion) |
| `noglobstar` | [`globstar`](#globstar) |
| `noext`      | [`extglob`](#extglob) |
| `nocase`     | [`caseSensitiveMatch`](#casesensitivematch) |
| `matchBase`  | [`baseNameMatch`](#basenamematch) |
| `nodir`      | [`onlyFiles`](#onlyfiles) |
| `ignore`     | [`ignore`](#ignore) |
| `follow`     | [`followSymbolicLinks`](#followsymboliclinks) |
| `realpath`   | – |
| `absolute`   | [`absolute`](#absolute) |

## Benchmarks

You can see results [here](https://github.com/mrmlnc/fast-glob/actions/workflows/benchmark.yml?query=branch%3Amaster) for every commit into the `main` branch.

* **Product benchmark** – comparison with the main competitors.
* **Regress benchmark** – regression between the current version and the version from the npm registry.

## Changelog

See the [Releases section of our GitHub project][github_releases] for changelog for each release version.

## License

This software is released under the terms of the MIT license.

[bash_hackers_syntax_expansion_brace]: https://wiki.bash-hackers.org/syntax/expansion/brace
[github_releases]: https://github.com/mrmlnc/fast-glob/releases
[glob_definition]: https://en.wikipedia.org/wiki/Glob_(programming)
[glob_linux_man]: http://man7.org/linux/man-pages/man3/glob.3.html
[micromatch_backslashes]: https://github.com/micromatch/micromatch#backslashes
[micromatch_braces]: https://github.com/micromatch/braces
[micromatch_extended_globbing]: https://github.com/micromatch/micromatch#extended-globbing
[micromatch_extglobs]: https://github.com/micromatch/micromatch#extglobs
[micromatch_regex_character_classes]: https://github.com/micromatch/micromatch#regex-character-classes
[micromatch]: https://github.com/micromatch/micromatch
[node_js_fs_class_fs_dirent]: https://nodejs.org/api/fs.html#fs_class_fs_dirent
[node_js_fs_class_fs_stats]: https://nodejs.org/api/fs.html#fs_class_fs_stats
[node_js_stream_readable_streams]: https://nodejs.org/api/stream.html#stream_readable_streams
[node_js]: https://nodejs.org/en
[nodelib_fs_scandir_old_and_modern_modern]: https://github.com/nodelib/nodelib/blob/master/packages/fs/fs.scandir/README.md#old-and-modern-mode
[npm_normalize_path]: https://www.npmjs.com/package/normalize-path
[npm_unixify]: https://www.npmjs.com/package/unixify
[picomatch_matching_behavior]: https://github.com/micromatch/picomatch#matching-behavior-vs-bash
[picomatch_matching_special_characters_as_literals]: https://github.com/micromatch/picomatch#matching-special-characters-as-literals
[picomatch_posix_brackets]: https://github.com/micromatch/picomatch#posix-brackets
[regular_expressions_brackets]: https://www.regular-expressions.info/brackets.html
[unc_path]: https://learn.microsoft.com/openspecs/windows_protocols/ms-dtyp/62e862f4-2a51-452e-8eeb-dc4ff5ee33cc
[wikipedia_case_sensitivity]: https://en.wikipedia.org/wiki/Case_sensitivity
[nodejs_thread_pool]: https://nodejs.org/en/docs/guides/dont-block-the-event-loop
[libuv_thread_pool]: http://docs.libuv.org/en/v1.x/threadpool.html
[windows_naming_conventions]: https://learn.microsoft.com/en-us/windows/win32/fileio/naming-a-file#naming-conventions
# resolve-from [![Build Status](https://travis-ci.org/sindresorhus/resolve-from.svg?branch=master)](https://travis-ci.org/sindresorhus/resolve-from)

> Resolve the path of a module like [`require.resolve()`](https://nodejs.org/api/globals.html#globals_require_resolve) but from a given path


## Install

```
$ npm install resolve-from
```


## Usage

```js
const resolveFrom = require('resolve-from');

// There is a file at `./foo/bar.js`

resolveFrom('foo', './bar');
//=> '/Users/sindresorhus/dev/test/foo/bar.js'
```


## API

### resolveFrom(fromDir, moduleId)

Like `require()`, throws when the module can't be found.

### resolveFrom.silent(fromDir, moduleId)

Returns `null` instead of throwing when the module can't be found.

#### fromDir

Type: `string`

Directory to resolve from.

#### moduleId

Type: `string`

What you would use in `require()`.


## Tip

Create a partial using a bound function if you want to resolve from the same `fromDir` multiple times:

```js
const resolveFromFoo = resolveFrom.bind(null, 'foo');

resolveFromFoo('./bar');
resolveFromFoo('./baz');
```


## Related

- [resolve-cwd](https://github.com/sindresorhus/resolve-cwd) - Resolve the path of a module from the current working directory
- [import-from](https://github.com/sindresorhus/import-from) - Import a module from a given path
- [import-cwd](https://github.com/sindresorhus/import-cwd) - Import a module from the current working directory
- [resolve-pkg](https://github.com/sindresorhus/resolve-pkg) - Resolve the path of a package regardless of it having an entry point
- [import-lazy](https://github.com/sindresorhus/import-lazy) - Import a module lazily
- [resolve-global](https://github.com/sindresorhus/resolve-global) - Resolve the path of a globally installed module


## License

MIT © [Sindre Sorhus](https://sindresorhus.com)
# is-extglob [![NPM version](https://img.shields.io/npm/v/is-extglob.svg?style=flat)](https://www.npmjs.com/package/is-extglob) [![NPM downloads](https://img.shields.io/npm/dm/is-extglob.svg?style=flat)](https://npmjs.org/package/is-extglob) [![Build Status](https://img.shields.io/travis/jonschlinkert/is-extglob.svg?style=flat)](https://travis-ci.org/jonschlinkert/is-extglob)

> Returns true if a string has an extglob.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save is-extglob
```

## Usage

```js
var isExtglob = require('is-extglob');
```

**True**

```js
isExtglob('?(abc)');
isExtglob('@(abc)');
isExtglob('!(abc)');
isExtglob('*(abc)');
isExtglob('+(abc)');
```

**False**

Escaped extglobs:

```js
isExtglob('\\?(abc)');
isExtglob('\\@(abc)');
isExtglob('\\!(abc)');
isExtglob('\\*(abc)');
isExtglob('\\+(abc)');
```

Everything else...

```js
isExtglob('foo.js');
isExtglob('!foo.js');
isExtglob('*.js');
isExtglob('**/abc.js');
isExtglob('abc/*.js');
isExtglob('abc/(aaa|bbb).js');
isExtglob('abc/[a-z].js');
isExtglob('abc/{a,b}.js');
isExtglob('abc/?.js');
isExtglob('abc.js');
isExtglob('abc/def/ghi.js');
```

## History

**v2.0**

Adds support for escaping. Escaped exglobs no longer return true.

## About

### Related projects

* [has-glob](https://www.npmjs.com/package/has-glob): Returns `true` if an array has a glob pattern. | [homepage](https://github.com/jonschlinkert/has-glob "Returns `true` if an array has a glob pattern.")
* [is-glob](https://www.npmjs.com/package/is-glob): Returns `true` if the given string looks like a glob pattern or an extglob pattern… [more](https://github.com/jonschlinkert/is-glob) | [homepage](https://github.com/jonschlinkert/is-glob "Returns `true` if the given string looks like a glob pattern or an extglob pattern. This makes it easy to create code that only uses external modules like node-glob when necessary, resulting in much faster code execution and initialization time, and a bet")
* [micromatch](https://www.npmjs.com/package/micromatch): Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch. | [homepage](https://github.com/jonschlinkert/micromatch "Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch.")

### Contributing

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

### Building docs

_(This document was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme) (a [verb](https://github.com/verbose/verb) generator), please don't edit the readme directly. Any changes to the readme must be made in [.verb.md](.verb.md).)_

To generate the readme and API documentation with [verb](https://github.com/verbose/verb):

```sh
$ npm install -g verb verb-generate-readme && verb
```

### Running tests

Install dev dependencies:

```sh
$ npm install -d && npm test
```

### Author

**Jon Schlinkert**

* [github/jonschlinkert](https://github.com/jonschlinkert)
* [twitter/jonschlinkert](http://twitter.com/jonschlinkert)

### License

Copyright © 2016, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT license](https://github.com/jonschlinkert/is-extglob/blob/master/LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.1.31, on October 12, 2016._# fastq

![ci][ci-url]
[![npm version][npm-badge]][npm-url]

Fast, in memory work queue.

Benchmarks (1 million tasks):

* setImmediate: 812ms
* fastq: 854ms
* async.queue: 1298ms
* neoAsync.queue: 1249ms

Obtained on node 12.16.1, on a dedicated server.

If you need zero-overhead series function call, check out
[fastseries](http://npm.im/fastseries). For zero-overhead parallel
function call, check out [fastparallel](http://npm.im/fastparallel).

[![js-standard-style](https://raw.githubusercontent.com/feross/standard/master/badge.png)](https://github.com/feross/standard)

  * <a href="#install">Installation</a>
  * <a href="#usage">Usage</a>
  * <a href="#api">API</a>
  * <a href="#license">Licence &amp; copyright</a>

## Install

`npm i fastq --save`

## Usage (callback API)

```js
'use strict'

const queue = require('fastq')(worker, 1)

queue.push(42, function (err, result) {
  if (err) { throw err }
  console.log('the result is', result)
})

function worker (arg, cb) {
  cb(null, arg * 2)
}
```

## Usage (promise API)

```js
const queue = require('fastq').promise(worker, 1)

async function worker (arg) {
  return arg * 2
}

async function run () {
  const result = await queue.push(42)
  console.log('the result is', result)
}

run()
```

### Setting "this"

```js
'use strict'

const that = { hello: 'world' }
const queue = require('fastq')(that, worker, 1)

queue.push(42, function (err, result) {
  if (err) { throw err }
  console.log(this)
  console.log('the result is', result)
})

function worker (arg, cb) {
  console.log(this)
  cb(null, arg * 2)
}
```

### Using with TypeScript (callback API)

```ts
'use strict'

import * as fastq from "fastq";
import type { queue, done } from "fastq";

type Task = {
  id: number
}

const q: queue<Task> = fastq(worker, 1)

q.push({ id: 42})

function worker (arg: Task, cb: done) {
  console.log(arg.id)
  cb(null)
}
```

### Using with TypeScript (promise API)

```ts
'use strict'

import * as fastq from "fastq";
import type { queueAsPromised } from "fastq";

type Task = {
  id: number
}

const q: queueAsPromised<Task> = fastq.promise(asyncWorker, 1)

q.push({ id: 42}).catch((err) => console.error(err))

async function asyncWorker (arg: Task): Promise<void> {
  // No need for a try-catch block, fastq handles errors automatically
  console.log(arg.id)
}
```

## API

* <a href="#fastqueue"><code>fastqueue()</code></a>
* <a href="#push"><code>queue#<b>push()</b></code></a>
* <a href="#unshift"><code>queue#<b>unshift()</b></code></a>
* <a href="#pause"><code>queue#<b>pause()</b></code></a>
* <a href="#resume"><code>queue#<b>resume()</b></code></a>
* <a href="#idle"><code>queue#<b>idle()</b></code></a>
* <a href="#length"><code>queue#<b>length()</b></code></a>
* <a href="#getQueue"><code>queue#<b>getQueue()</b></code></a>
* <a href="#kill"><code>queue#<b>kill()</b></code></a>
* <a href="#killAndDrain"><code>queue#<b>killAndDrain()</b></code></a>
* <a href="#error"><code>queue#<b>error()</b></code></a>
* <a href="#concurrency"><code>queue#<b>concurrency</b></code></a>
* <a href="#drain"><code>queue#<b>drain</b></code></a>
* <a href="#empty"><code>queue#<b>empty</b></code></a>
* <a href="#saturated"><code>queue#<b>saturated</b></code></a>
* <a href="#promise"><code>fastqueue.promise()</code></a>

-------------------------------------------------------
<a name="fastqueue"></a>
### fastqueue([that], worker, concurrency)

Creates a new queue.

Arguments:

* `that`, optional context of the `worker` function.
* `worker`, worker function, it would be called with `that` as `this`,
  if that is specified.
* `concurrency`, number of concurrent tasks that could be executed in
  parallel.

-------------------------------------------------------
<a name="push"></a>
### queue.push(task, done)

Add a task at the end of the queue. `done(err, result)` will be called
when the task was processed.

-------------------------------------------------------
<a name="unshift"></a>
### queue.unshift(task, done)

Add a task at the beginning of the queue. `done(err, result)` will be called
when the task was processed.

-------------------------------------------------------
<a name="pause"></a>
### queue.pause()

Pause the processing of tasks. Currently worked tasks are not
stopped.

-------------------------------------------------------
<a name="resume"></a>
### queue.resume()

Resume the processing of tasks.

-------------------------------------------------------
<a name="idle"></a>
### queue.idle()

Returns `false` if there are tasks being processed or waiting to be processed.
`true` otherwise.

-------------------------------------------------------
<a name="length"></a>
### queue.length()

Returns the number of tasks waiting to be processed (in the queue).

-------------------------------------------------------
<a name="getQueue"></a>
### queue.getQueue()

Returns all the tasks be processed (in the queue). Returns empty array when there are no tasks

-------------------------------------------------------
<a name="kill"></a>
### queue.kill()

Removes all tasks waiting to be processed, and reset `drain` to an empty
function.

-------------------------------------------------------
<a name="killAndDrain"></a>
### queue.killAndDrain()

Same than `kill` but the `drain` function will be called before reset to empty.

-------------------------------------------------------
<a name="error"></a>
### queue.error(handler)

Set a global error handler. `handler(err, task)` will be called
each time a task is completed, `err` will be not null if the task has thrown an error.

-------------------------------------------------------
<a name="concurrency"></a>
### queue.concurrency

Property that returns the number of concurrent tasks that could be executed in
parallel. It can be altered at runtime.

-------------------------------------------------------
<a name="drain"></a>
### queue.drain

Function that will be called when the last
item from the queue has been processed by a worker.
It can be altered at runtime.

-------------------------------------------------------
<a name="empty"></a>
### queue.empty

Function that will be called when the last
item from the queue has been assigned to a worker.
It can be altered at runtime.

-------------------------------------------------------
<a name="saturated"></a>
### queue.saturated

Function that will be called when the queue hits the concurrency
limit.
It can be altered at runtime.

-------------------------------------------------------
<a name="promise"></a>
### fastqueue.promise([that], worker(arg), concurrency)

Creates a new queue with `Promise` apis. It also offers all the methods
and properties of the object returned by [`fastqueue`](#fastqueue) with the modified
[`push`](#pushPromise) and [`unshift`](#unshiftPromise) methods.

Node v10+ is required to use the promisified version.

Arguments:
* `that`, optional context of the `worker` function.
* `worker`, worker function, it would be called with `that` as `this`,
  if that is specified. It MUST return a `Promise`.
* `concurrency`, number of concurrent tasks that could be executed in
  parallel.

<a name="pushPromise"></a>
#### queue.push(task) => Promise

Add a task at the end of the queue. The returned `Promise`  will be fulfilled (rejected)
when the task is completed successfully (unsuccessfully).

This promise could be ignored as it will not lead to a `'unhandledRejection'`.

<a name="unshiftPromise"></a>
#### queue.unshift(task) => Promise

Add a task at the beginning of the queue. The returned `Promise`  will be fulfilled (rejected)
when the task is completed successfully (unsuccessfully).

This promise could be ignored as it will not lead to a `'unhandledRejection'`.

<a name="drained"></a>
#### queue.drained() => Promise

Wait for the queue to be drained. The returned `Promise` will be resolved when all tasks in the queue have been processed by a worker.

This promise could be ignored as it will not lead to a `'unhandledRejection'`.

## License

ISC

[ci-url]: https://github.com/mcollina/fastq/workflows/ci/badge.svg
[npm-badge]: https://badge.fury.io/js/fastq.svg
[npm-url]: https://badge.fury.io/js/fastq
# merge2

Merge multiple streams into one stream in sequence or parallel.

[![NPM version][npm-image]][npm-url]
[![Build Status][travis-image]][travis-url]
[![Downloads][downloads-image]][downloads-url]

## Install

Install with [npm](https://npmjs.org/package/merge2)

```sh
npm install merge2
```

## Usage

```js
const gulp = require('gulp')
const merge2 = require('merge2')
const concat = require('gulp-concat')
const minifyHtml = require('gulp-minify-html')
const ngtemplate = require('gulp-ngtemplate')

gulp.task('app-js', function () {
  return merge2(
      gulp.src('static/src/tpl/*.html')
        .pipe(minifyHtml({empty: true}))
        .pipe(ngtemplate({
          module: 'genTemplates',
          standalone: true
        })
      ), gulp.src([
        'static/src/js/app.js',
        'static/src/js/locale_zh-cn.js',
        'static/src/js/router.js',
        'static/src/js/tools.js',
        'static/src/js/services.js',
        'static/src/js/filters.js',
        'static/src/js/directives.js',
        'static/src/js/controllers.js'
      ])
    )
    .pipe(concat('app.js'))
    .pipe(gulp.dest('static/dist/js/'))
})
```

```js
const stream = merge2([stream1, stream2], stream3, {end: false})
//...
stream.add(stream4, stream5)
//..
stream.end()
```

```js
// equal to merge2([stream1, stream2], stream3)
const stream = merge2()
stream.add([stream1, stream2])
stream.add(stream3)
```

```js
// merge order:
//   1. merge `stream1`;
//   2. merge `stream2` and `stream3` in parallel after `stream1` merged;
//   3. merge 'stream4' after `stream2` and `stream3` merged;
const stream = merge2(stream1, [stream2, stream3], stream4)

// merge order:
//   1. merge `stream5` and `stream6` in parallel after `stream4` merged;
//   2. merge 'stream7' after `stream5` and `stream6` merged;
stream.add([stream5, stream6], stream7)
```

```js
// nest merge
// equal to merge2(stream1, stream2, stream6, stream3, [stream4, stream5]);
const streamA = merge2(stream1, stream2)
const streamB = merge2(stream3, [stream4, stream5])
const stream = merge2(streamA, streamB)
streamA.add(stream6)
```

## API

```js
const merge2 = require('merge2')
```

### merge2()

### merge2(options)

### merge2(stream1, stream2, ..., streamN)

### merge2(stream1, stream2, ..., streamN, options)

### merge2(stream1, [stream2, stream3, ...], streamN, options)

return a duplex stream (mergedStream). streams in array will be merged in parallel.

### mergedStream.add(stream)

### mergedStream.add(stream1, [stream2, stream3, ...], ...)

return the mergedStream.

### mergedStream.on('queueDrain', function() {})

It will emit 'queueDrain' when all streams merged. If you set `end === false` in options, this event give you a notice that should add more streams to merge or end the mergedStream.

#### stream

*option*
Type: `Readable` or `Duplex` or `Transform` stream.

#### options

*option*
Type: `Object`.

* **end** - `Boolean` - if `end === false` then mergedStream will not be auto ended, you should end by yourself. **Default:** `undefined`

* **pipeError** - `Boolean` - if `pipeError === true` then mergedStream will emit `error` event from source streams. **Default:** `undefined`

* **objectMode** - `Boolean` . **Default:** `true`

`objectMode` and other options(`highWaterMark`, `defaultEncoding` ...) is same as Node.js `Stream`.

## License

MIT © [Teambition](https://www.teambition.com)

[npm-url]: https://npmjs.org/package/merge2
[npm-image]: http://img.shields.io/npm/v/merge2.svg

[travis-url]: https://travis-ci.org/teambition/merge2
[travis-image]: http://img.shields.io/travis/teambition/merge2.svg

[downloads-url]: https://npmjs.org/package/merge2
[downloads-image]: http://img.shields.io/npm/dm/merge2.svg?style=flat-square
functional-red-black-tree
=========================
A [fully persistent](http://en.wikipedia.org/wiki/Persistent_data_structure) [red-black tree](http://en.wikipedia.org/wiki/Red%E2%80%93black_tree) written 100% in JavaScript.  Works both in node.js and in the browser via [browserify](http://browserify.org/).

Functional (or fully presistent) data structures allow for non-destructive updates.  So if you insert an element into the tree, it returns a new tree with the inserted element rather than destructively updating the existing tree in place.  Doing this requires using extra memory, and if one were naive it could cost as much as reallocating the entire tree.  Instead, this data structure saves some memory by recycling references to previously allocated subtrees.  This requires using only O(log(n)) additional memory per update instead of a full O(n) copy.

Some advantages of this is that it is possible to apply insertions and removals to the tree while still iterating over previous versions of the tree.  Functional and persistent data structures can also be useful in many geometric algorithms like point location within triangulations or ray queries, and can be used to analyze the history of executing various algorithms.  This added power though comes at a cost, since it is generally a bit slower to use a functional data structure than an imperative version.  However, if your application needs this behavior then you may consider using this module.

# Install

    npm install functional-red-black-tree

# Example

Here is an example of some basic usage:

```javascript
//Load the library
var createTree = require("functional-red-black-tree")

//Create a tree
var t1 = createTree()

//Insert some items into the tree
var t2 = t1.insert(1, "foo")
var t3 = t2.insert(2, "bar")

//Remove something
var t4 = t3.remove(1)
```


# API

```javascript
var createTree = require("functional-red-black-tree")
```

## Overview

- [Tree methods](#tree-methods)
  - [`var tree = createTree([compare])`](#var-tree-=-createtreecompare)
  - [`tree.keys`](#treekeys)
  - [`tree.values`](#treevalues)
  - [`tree.length`](#treelength)
  - [`tree.get(key)`](#treegetkey)
  - [`tree.insert(key, value)`](#treeinsertkey-value)
  - [`tree.remove(key)`](#treeremovekey)
  - [`tree.find(key)`](#treefindkey)
  - [`tree.ge(key)`](#treegekey)
  - [`tree.gt(key)`](#treegtkey)
  - [`tree.lt(key)`](#treeltkey)
  - [`tree.le(key)`](#treelekey)
  - [`tree.at(position)`](#treeatposition)
  - [`tree.begin`](#treebegin)
  - [`tree.end`](#treeend)
  - [`tree.forEach(visitor(key,value)[, lo[, hi]])`](#treeforEachvisitorkeyvalue-lo-hi)
  - [`tree.root`](#treeroot)
- [Node properties](#node-properties)
  - [`node.key`](#nodekey)
  - [`node.value`](#nodevalue)
  - [`node.left`](#nodeleft)
  - [`node.right`](#noderight)
- [Iterator methods](#iterator-methods)
  - [`iter.key`](#iterkey)
  - [`iter.value`](#itervalue)
  - [`iter.node`](#iternode)
  - [`iter.tree`](#itertree)
  - [`iter.index`](#iterindex)
  - [`iter.valid`](#itervalid)
  - [`iter.clone()`](#iterclone)
  - [`iter.remove()`](#iterremove)
  - [`iter.update(value)`](#iterupdatevalue)
  - [`iter.next()`](#iternext)
  - [`iter.prev()`](#iterprev)
  - [`iter.hasNext`](#iterhasnext)
  - [`iter.hasPrev`](#iterhasprev)

## Tree methods

### `var tree = createTree([compare])`
Creates an empty functional tree

* `compare` is an optional comparison function, same semantics as array.sort()

**Returns** An empty tree ordered by `compare`

### `tree.keys`
A sorted array of all the keys in the tree

### `tree.values`
An array array of all the values in the tree

### `tree.length`
The number of items in the tree

### `tree.get(key)`
Retrieves the value associated to the given key

* `key` is the key of the item to look up

**Returns** The value of the first node associated to `key`

### `tree.insert(key, value)`
Creates a new tree with the new pair inserted.

* `key` is the key of the item to insert
* `value` is the value of the item to insert

**Returns** A new tree with `key` and `value` inserted

### `tree.remove(key)`
Removes the first item with `key` in the tree

* `key` is the key of the item to remove

**Returns** A new tree with the given item removed if it exists

### `tree.find(key)`
Returns an iterator pointing to the first item in the tree with `key`, otherwise `null`.

### `tree.ge(key)`
Find the first item in the tree whose key is `>= key`

* `key` is the key to search for

**Returns** An iterator at the given element.

### `tree.gt(key)`
Finds the first item in the tree whose key is `> key`

* `key` is the key to search for

**Returns** An iterator at the given element

### `tree.lt(key)`
Finds the last item in the tree whose key is `< key`

* `key` is the key to search for

**Returns** An iterator at the given element

### `tree.le(key)`
Finds the last item in the tree whose key is `<= key`

* `key` is the key to search for

**Returns** An iterator at the given element

### `tree.at(position)`
Finds an iterator starting at the given element

* `position` is the index at which the iterator gets created

**Returns** An iterator starting at position

### `tree.begin`
An iterator pointing to the first element in the tree

### `tree.end`
An iterator pointing to the last element in the tree

### `tree.forEach(visitor(key,value)[, lo[, hi]])`
Walks a visitor function over the nodes of the tree in order.

* `visitor(key,value)` is a callback that gets executed on each node.  If a truthy value is returned from the visitor, then iteration is stopped.
* `lo` is an optional start of the range to visit (inclusive)
* `hi` is an optional end of the range to visit (non-inclusive)

**Returns** The last value returned by the callback

### `tree.root`
Returns the root node of the tree


## Node properties
Each node of the tree has the following properties:

### `node.key`
The key associated to the node

### `node.value`
The value associated to the node

### `node.left`
The left subtree of the node

### `node.right`
The right subtree of the node

## Iterator methods

### `iter.key`
The key of the item referenced by the iterator

### `iter.value`
The value of the item referenced by the iterator

### `iter.node`
The value of the node at the iterator's current position.  `null` is iterator is node valid.

### `iter.tree`
The tree associated to the iterator

### `iter.index`
Returns the position of this iterator in the sequence.

### `iter.valid`
Checks if the iterator is valid

### `iter.clone()`
Makes a copy of the iterator

### `iter.remove()`
Removes the item at the position of the iterator

**Returns** A new binary search tree with `iter`'s item removed

### `iter.update(value)`
Updates the value of the node in the tree at this iterator

**Returns** A new binary search tree with the corresponding node updated

### `iter.next()`
Advances the iterator to the next position

### `iter.prev()`
Moves the iterator backward one element

### `iter.hasNext`
If true, then the iterator is not at the end of the sequence

### `iter.hasPrev`
If true, then the iterator is not at the beginning of the sequence

# Credits
(c) 2013 Mikola Lysenko. MIT License# word-wrap [![NPM version](https://img.shields.io/npm/v/word-wrap.svg?style=flat)](https://www.npmjs.com/package/word-wrap) [![NPM monthly downloads](https://img.shields.io/npm/dm/word-wrap.svg?style=flat)](https://npmjs.org/package/word-wrap) [![NPM total downloads](https://img.shields.io/npm/dt/word-wrap.svg?style=flat)](https://npmjs.org/package/word-wrap) [![Linux Build Status](https://img.shields.io/travis/jonschlinkert/word-wrap.svg?style=flat&label=Travis)](https://travis-ci.org/jonschlinkert/word-wrap)

> Wrap words to a specified length.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save word-wrap
```

## Usage

```js
var wrap = require('word-wrap');

wrap('Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.');
```

Results in:

```
  Lorem ipsum dolor sit amet, consectetur adipiscing
  elit, sed do eiusmod tempor incididunt ut labore
  et dolore magna aliqua. Ut enim ad minim veniam,
  quis nostrud exercitation ullamco laboris nisi ut
  aliquip ex ea commodo consequat.
```

## Options

![image](https://cloud.githubusercontent.com/assets/383994/6543728/7a381c08-c4f6-11e4-8b7d-b6ba197569c9.png)

### options.width

Type: `Number`

Default: `50`

The width of the text before wrapping to a new line.

**Example:**

```js
wrap(str, {width: 60});
```

### options.indent

Type: `String`

Default: `` (none)

The string to use at the beginning of each line.

**Example:**

```js
wrap(str, {indent: '      '});
```

### options.newline

Type: `String`

Default: `\n`

The string to use at the end of each line.

**Example:**

```js
wrap(str, {newline: '\n\n'});
```

### options.escape

Type: `function`

Default: `function(str){return str;}`

An escape function to run on each line after splitting them.

**Example:**

```js
var xmlescape = require('xml-escape');
wrap(str, {
  escape: function(string){
    return xmlescape(string);
  }
});
```

### options.trim

Type: `Boolean`

Default: `false`

Trim trailing whitespace from the returned string. This option is included since `.trim()` would also strip the leading indentation from the first line.

**Example:**

```js
wrap(str, {trim: true});
```

### options.cut

Type: `Boolean`

Default: `false`

Break a word between any two letters when the word is longer than the specified width.

**Example:**

```js
wrap(str, {cut: true});
```

## About

### Related projects

* [common-words](https://www.npmjs.com/package/common-words): Updated list (JSON) of the 100 most common words in the English language. Useful for… [more](https://github.com/jonschlinkert/common-words) | [homepage](https://github.com/jonschlinkert/common-words "Updated list (JSON) of the 100 most common words in the English language. Useful for excluding these words from arrays.")
* [shuffle-words](https://www.npmjs.com/package/shuffle-words): Shuffle the words in a string and optionally the letters in each word using the… [more](https://github.com/jonschlinkert/shuffle-words) | [homepage](https://github.com/jonschlinkert/shuffle-words "Shuffle the words in a string and optionally the letters in each word using the Fisher-Yates algorithm. Useful for creating test fixtures, benchmarking samples, etc.")
* [unique-words](https://www.npmjs.com/package/unique-words): Return the unique words in a string or array. | [homepage](https://github.com/jonschlinkert/unique-words "Return the unique words in a string or array.")
* [wordcount](https://www.npmjs.com/package/wordcount): Count the words in a string. Support for english, CJK and Cyrillic. | [homepage](https://github.com/jonschlinkert/wordcount "Count the words in a string. Support for english, CJK and Cyrillic.")

### Contributing

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

### Contributors

| **Commits** | **Contributor** | 
| --- | --- |
| 43 | [jonschlinkert](https://github.com/jonschlinkert) |
| 2 | [lordvlad](https://github.com/lordvlad) |
| 2 | [hildjj](https://github.com/hildjj) |
| 1 | [danilosampaio](https://github.com/danilosampaio) |
| 1 | [2fd](https://github.com/2fd) |
| 1 | [toddself](https://github.com/toddself) |
| 1 | [wolfgang42](https://github.com/wolfgang42) |
| 1 | [zachhale](https://github.com/zachhale) |

### Building docs

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

### Running tests

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

### Author

**Jon Schlinkert**

* [github/jonschlinkert](https://github.com/jonschlinkert)
* [twitter/jonschlinkert](https://twitter.com/jonschlinkert)

### License

Copyright © 2017, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.6.0, on June 02, 2017._
# Release history

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/)
and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html).

<details>
  <summary><strong>Guiding Principles</strong></summary>

- Changelogs are for humans, not machines.
- There should be an entry for every single version.
- The same types of changes should be grouped.
- Versions and sections should be linkable.
- The latest version comes first.
- The release date of each versions is displayed.
- Mention whether you follow Semantic Versioning.

</details>

<details>
  <summary><strong>Types of changes</strong></summary>

Changelog entries are classified using the following labels _(from [keep-a-changelog](http://keepachangelog.com/)_):

- `Added` for new features.
- `Changed` for changes in existing functionality.
- `Deprecated` for soon-to-be removed features.
- `Removed` for now removed features.
- `Fixed` for any bug fixes.
- `Security` in case of vulnerabilities.

</details>

## [3.0.0] - 2018-04-08

v3.0 is a complete refactor, resulting in a faster, smaller codebase, with fewer deps, and a more accurate parser and compiler. 

**Breaking Changes**

- The undocumented `.makeRe` method was removed

**Non-breaking changes**

- Caching was removed

## [2.3.2] - 2018-04-08

- start refactoring
- cover sets
- better range handling

## [2.3.1] - 2018-02-17

- Remove unnecessary escape in Regex. (#14)

## [2.3.0] - 2017-10-19

- minor code reorganization
- optimize regex
- expose `maxLength` option

## [2.2.1] - 2017-05-30

- don't condense when braces contain extglobs

## [2.2.0] - 2017-05-28

- ensure word boundaries are preserved
- fixes edge case where extglob characters precede a brace pattern

## [2.1.1] - 2017-04-27

- use snapdragon-node
- handle edge case
- optimizations, lint

## [2.0.4] - 2017-04-11

- pass opts to compiler
- minor optimization in create method
- re-write parser handlers to remove negation regex

## [2.0.3] - 2016-12-10

- use split-string
- clear queue at the end
- adds sequences example
- add unit tests

## [2.0.2] - 2016-10-21

- fix comma handling in nested extglobs

## [2.0.1] - 2016-10-20

- add comments
- more tests, ensure quotes are stripped

## [2.0.0] - 2016-10-19

- don't expand braces inside character classes
- add quantifier pattern

## [1.8.5] - 2016-05-21

- Refactor (#10)

## [1.8.4] - 2016-04-20

- fixes https://github.com/jonschlinkert/micromatch/issues/66

## [1.8.0] - 2015-03-18

- adds exponent examples, tests
- fixes the first example in https://github.com/jonschlinkert/micromatch/issues/38

## [1.6.0] - 2015-01-30

- optimizations, `bash` mode:
- improve path escaping

## [1.5.0] - 2015-01-28

- Merge pull request #5 from eush77/lib-files

## [1.4.0] - 2015-01-24

- add extglob tests
- externalize exponent function
- better whitespace handling

## [1.3.0] - 2015-01-24

- make regex patterns explicity

## [1.1.0] - 2015-01-11

- don't create a match group with `makeRe`

## [1.0.0] - 2014-12-23

- Merge commit '97b05f5544f8348736a8efaecf5c32bbe3e2ad6e'
- support empty brace syntax
- better bash coverage
- better support for regex strings

## [0.1.4] - 2014-11-14

- improve recognition of bad args, recognize mismatched argument types
- support escaping
- remove pathname-expansion
- support whitespace in patterns

## [0.1.0]

- first commit

[2.3.2]: https://github.com/micromatch/braces/compare/2.3.1...2.3.2
[2.3.1]: https://github.com/micromatch/braces/compare/2.3.0...2.3.1
[2.3.0]: https://github.com/micromatch/braces/compare/2.2.1...2.3.0
[2.2.1]: https://github.com/micromatch/braces/compare/2.2.0...2.2.1
[2.2.0]: https://github.com/micromatch/braces/compare/2.1.1...2.2.0
[2.1.1]: https://github.com/micromatch/braces/compare/2.1.0...2.1.1
[2.1.0]: https://github.com/micromatch/braces/compare/2.0.4...2.1.0
[2.0.4]: https://github.com/micromatch/braces/compare/2.0.3...2.0.4
[2.0.3]: https://github.com/micromatch/braces/compare/2.0.2...2.0.3
[2.0.2]: https://github.com/micromatch/braces/compare/2.0.1...2.0.2
[2.0.1]: https://github.com/micromatch/braces/compare/2.0.0...2.0.1
[2.0.0]: https://github.com/micromatch/braces/compare/1.8.5...2.0.0
[1.8.5]: https://github.com/micromatch/braces/compare/1.8.4...1.8.5
[1.8.4]: https://github.com/micromatch/braces/compare/1.8.0...1.8.4
[1.8.0]: https://github.com/micromatch/braces/compare/1.6.0...1.8.0
[1.6.0]: https://github.com/micromatch/braces/compare/1.5.0...1.6.0
[1.5.0]: https://github.com/micromatch/braces/compare/1.4.0...1.5.0
[1.4.0]: https://github.com/micromatch/braces/compare/1.3.0...1.4.0
[1.3.0]: https://github.com/micromatch/braces/compare/1.2.0...1.3.0
[1.2.0]: https://github.com/micromatch/braces/compare/1.1.0...1.2.0
[1.1.0]: https://github.com/micromatch/braces/compare/1.0.0...1.1.0
[1.0.0]: https://github.com/micromatch/braces/compare/0.1.4...1.0.0
[0.1.4]: https://github.com/micromatch/braces/compare/0.1.0...0.1.4

[Unreleased]: https://github.com/micromatch/braces/compare/0.1.0...HEAD
[keep-a-changelog]: https://github.com/olivierlacan/keep-a-changelog# braces [![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=W8YFZ425KND68) [![NPM version](https://img.shields.io/npm/v/braces.svg?style=flat)](https://www.npmjs.com/package/braces) [![NPM monthly downloads](https://img.shields.io/npm/dm/braces.svg?style=flat)](https://npmjs.org/package/braces) [![NPM total downloads](https://img.shields.io/npm/dt/braces.svg?style=flat)](https://npmjs.org/package/braces) [![Linux Build Status](https://img.shields.io/travis/micromatch/braces.svg?style=flat&label=Travis)](https://travis-ci.org/micromatch/braces)

> Bash-like brace expansion, implemented in JavaScript. Safer than other brace expansion libs, with complete support for the Bash 4.3 braces specification, without sacrificing speed.

Please consider following this project's author, [Jon Schlinkert](https://github.com/jonschlinkert), and consider starring the project to show your :heart: and support.

## Install

Install with [npm](https://www.npmjs.com/):

```sh
$ npm install --save braces
```

## v3.0.0 Released!!

See the [changelog](CHANGELOG.md) for details.

## Why use braces?

Brace patterns make globs more powerful by adding the ability to match specific ranges and sequences of characters.

* **Accurate** - complete support for the [Bash 4.3 Brace Expansion](www.gnu.org/software/bash/) specification (passes all of the Bash braces tests)
* **[fast and performant](#benchmarks)** - Starts fast, runs fast and [scales well](#performance) as patterns increase in complexity.
* **Organized code base** - The parser and compiler are easy to maintain and update when edge cases crop up.
* **Well-tested** - Thousands of test assertions, and passes all of the Bash, minimatch, and [brace-expansion](https://github.com/juliangruber/brace-expansion) unit tests (as of the date this was written).
* **Safer** - You shouldn't have to worry about users defining aggressive or malicious brace patterns that can break your application. Braces takes measures to prevent malicious regex that can be used for DDoS attacks (see [catastrophic backtracking](https://www.regular-expressions.info/catastrophic.html)).
* [Supports lists](#lists) - (aka "sets") `a/{b,c}/d` => `['a/b/d', 'a/c/d']`
* [Supports sequences](#sequences) - (aka "ranges") `{01..03}` => `['01', '02', '03']`
* [Supports steps](#steps) - (aka "increments") `{2..10..2}` => `['2', '4', '6', '8', '10']`
* [Supports escaping](#escaping) - To prevent evaluation of special characters.

## Usage

The main export is a function that takes one or more brace `patterns` and `options`.

```js
const braces = require('braces');
// braces(patterns[, options]);

console.log(braces(['{01..05}', '{a..e}']));
//=> ['(0[1-5])', '([a-e])']

console.log(braces(['{01..05}', '{a..e}'], { expand: true }));
//=> ['01', '02', '03', '04', '05', 'a', 'b', 'c', 'd', 'e']
```

### Brace Expansion vs. Compilation

By default, brace patterns are compiled into strings that are optimized for creating regular expressions and matching.

**Compiled**

```js
console.log(braces('a/{x,y,z}/b')); 
//=> ['a/(x|y|z)/b']
console.log(braces(['a/{01..20}/b', 'a/{1..5}/b'])); 
//=> [ 'a/(0[1-9]|1[0-9]|20)/b', 'a/([1-5])/b' ]
```

**Expanded**

Enable brace expansion by setting the `expand` option to true, or by using [braces.expand()](#expand) (returns an array similar to what you'd expect from Bash, or `echo {1..5}`, or [minimatch](https://github.com/isaacs/minimatch)):

```js
console.log(braces('a/{x,y,z}/b', { expand: true }));
//=> ['a/x/b', 'a/y/b', 'a/z/b']

console.log(braces.expand('{01..10}'));
//=> ['01','02','03','04','05','06','07','08','09','10']
```

### Lists

Expand lists (like Bash "sets"):

```js
console.log(braces('a/{foo,bar,baz}/*.js'));
//=> ['a/(foo|bar|baz)/*.js']

console.log(braces.expand('a/{foo,bar,baz}/*.js'));
//=> ['a/foo/*.js', 'a/bar/*.js', 'a/baz/*.js']
```

### Sequences

Expand ranges of characters (like Bash "sequences"):

```js
console.log(braces.expand('{1..3}'));                // ['1', '2', '3']
console.log(braces.expand('a/{1..3}/b'));            // ['a/1/b', 'a/2/b', 'a/3/b']
console.log(braces('{a..c}', { expand: true }));     // ['a', 'b', 'c']
console.log(braces('foo/{a..c}', { expand: true })); // ['foo/a', 'foo/b', 'foo/c']

// supports zero-padded ranges
console.log(braces('a/{01..03}/b'));   //=> ['a/(0[1-3])/b']
console.log(braces('a/{001..300}/b')); //=> ['a/(0{2}[1-9]|0[1-9][0-9]|[12][0-9]{2}|300)/b']
```

See [fill-range](https://github.com/jonschlinkert/fill-range) for all available range-expansion options.

### Steppped ranges

Steps, or increments, may be used with ranges:

```js
console.log(braces.expand('{2..10..2}'));
//=> ['2', '4', '6', '8', '10']

console.log(braces('{2..10..2}'));
//=> ['(2|4|6|8|10)']
```

When the [.optimize](#optimize) method is used, or [options.optimize](#optionsoptimize) is set to true, sequences are passed to [to-regex-range](https://github.com/jonschlinkert/to-regex-range) for expansion.

### Nesting

Brace patterns may be nested. The results of each expanded string are not sorted, and left to right order is preserved.

**"Expanded" braces**

```js
console.log(braces.expand('a{b,c,/{x,y}}/e'));
//=> ['ab/e', 'ac/e', 'a/x/e', 'a/y/e']

console.log(braces.expand('a/{x,{1..5},y}/c'));
//=> ['a/x/c', 'a/1/c', 'a/2/c', 'a/3/c', 'a/4/c', 'a/5/c', 'a/y/c']
```

**"Optimized" braces**

```js
console.log(braces('a{b,c,/{x,y}}/e'));
//=> ['a(b|c|/(x|y))/e']

console.log(braces('a/{x,{1..5},y}/c'));
//=> ['a/(x|([1-5])|y)/c']
```

### Escaping

**Escaping braces**

A brace pattern will not be expanded or evaluted if _either the opening or closing brace is escaped_:

```js
console.log(braces.expand('a\\{d,c,b}e'));
//=> ['a{d,c,b}e']

console.log(braces.expand('a{d,c,b\\}e'));
//=> ['a{d,c,b}e']
```

**Escaping commas**

Commas inside braces may also be escaped:

```js
console.log(braces.expand('a{b\\,c}d'));
//=> ['a{b,c}d']

console.log(braces.expand('a{d\\,c,b}e'));
//=> ['ad,ce', 'abe']
```

**Single items**

Following bash conventions, a brace pattern is also not expanded when it contains a single character:

```js
console.log(braces.expand('a{b}c'));
//=> ['a{b}c']
```

## Options

### options.maxLength

**Type**: `Number`

**Default**: `65,536`

**Description**: Limit the length of the input string. Useful when the input string is generated or your application allows users to pass a string, et cetera.

```js
console.log(braces('a/{b,c}/d', { maxLength: 3 }));  //=> throws an error
```

### options.expand

**Type**: `Boolean`

**Default**: `undefined`

**Description**: Generate an "expanded" brace pattern (alternatively you can use the `braces.expand()` method, which does the same thing).

```js
console.log(braces('a/{b,c}/d', { expand: true }));
//=> [ 'a/b/d', 'a/c/d' ]
```

### options.nodupes

**Type**: `Boolean`

**Default**: `undefined`

**Description**: Remove duplicates from the returned array.

### options.rangeLimit

**Type**: `Number`

**Default**: `1000`

**Description**: To prevent malicious patterns from being passed by users, an error is thrown when `braces.expand()` is used or `options.expand` is true and the generated range will exceed the `rangeLimit`.

You can customize `options.rangeLimit` or set it to `Inifinity` to disable this altogether.

**Examples**

```js
// pattern exceeds the "rangeLimit", so it's optimized automatically
console.log(braces.expand('{1..1000}'));
//=> ['([1-9]|[1-9][0-9]{1,2}|1000)']

// pattern does not exceed "rangeLimit", so it's NOT optimized
console.log(braces.expand('{1..100}'));
//=> ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']
```

### options.transform

**Type**: `Function`

**Default**: `undefined`

**Description**: Customize range expansion.

**Example: Transforming non-numeric values**

```js
const alpha = braces.expand('x/{a..e}/y', {
  transform(value, index) {
    // When non-numeric values are passed, "value" is a character code.
    return 'foo/' + String.fromCharCode(value) + '-' + index;
  }
});
console.log(alpha);
//=> [ 'x/foo/a-0/y', 'x/foo/b-1/y', 'x/foo/c-2/y', 'x/foo/d-3/y', 'x/foo/e-4/y' ]
```

**Example: Transforming numeric values**

```js
const numeric = braces.expand('{1..5}', {
  transform(value) {
    // when numeric values are passed, "value" is a number
    return 'foo/' + value * 2;
  }
});
console.log(numeric); 
//=> [ 'foo/2', 'foo/4', 'foo/6', 'foo/8', 'foo/10' ]
```

### options.quantifiers

**Type**: `Boolean`

**Default**: `undefined`

**Description**: In regular expressions, quanitifiers can be used to specify how many times a token can be repeated. For example, `a{1,3}` will match the letter `a` one to three times.

Unfortunately, regex quantifiers happen to share the same syntax as [Bash lists](#lists)

The `quantifiers` option tells braces to detect when [regex quantifiers](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#quantifiers) are defined in the given pattern, and not to try to expand them as lists.

**Examples**

```js
const braces = require('braces');
console.log(braces('a/b{1,3}/{x,y,z}'));
//=> [ 'a/b(1|3)/(x|y|z)' ]
console.log(braces('a/b{1,3}/{x,y,z}', {quantifiers: true}));
//=> [ 'a/b{1,3}/(x|y|z)' ]
console.log(braces('a/b{1,3}/{x,y,z}', {quantifiers: true, expand: true}));
//=> [ 'a/b{1,3}/x', 'a/b{1,3}/y', 'a/b{1,3}/z' ]
```

### options.unescape

**Type**: `Boolean`

**Default**: `undefined`

**Description**: Strip backslashes that were used for escaping from the result.

## What is "brace expansion"?

Brace expansion is a type of parameter expansion that was made popular by unix shells for generating lists of strings, as well as regex-like matching when used alongside wildcards (globs).

In addition to "expansion", braces are also used for matching. In other words:

* [brace expansion](#brace-expansion) is for generating new lists
* [brace matching](#brace-matching) is for filtering existing lists

<details>
<summary><strong>More about brace expansion</strong> (click to expand)</summary>

There are two main types of brace expansion:

1. **lists**: which are defined using comma-separated values inside curly braces: `{a,b,c}`
2. **sequences**: which are defined using a starting value and an ending value, separated by two dots: `a{1..3}b`. Optionally, a third argument may be passed to define a "step" or increment to use: `a{1..100..10}b`. These are also sometimes referred to as "ranges".

Here are some example brace patterns to illustrate how they work:

**Sets**

```
{a,b,c}       => a b c
{a,b,c}{1,2}  => a1 a2 b1 b2 c1 c2
```

**Sequences**

```
{1..9}        => 1 2 3 4 5 6 7 8 9
{4..-4}       => 4 3 2 1 0 -1 -2 -3 -4
{1..20..3}    => 1 4 7 10 13 16 19
{a..j}        => a b c d e f g h i j
{j..a}        => j i h g f e d c b a
{a..z..3}     => a d g j m p s v y
```

**Combination**

Sets and sequences can be mixed together or used along with any other strings.

```
{a,b,c}{1..3}   => a1 a2 a3 b1 b2 b3 c1 c2 c3
foo/{a,b,c}/bar => foo/a/bar foo/b/bar foo/c/bar
```

The fact that braces can be "expanded" from relatively simple patterns makes them ideal for quickly generating test fixtures, file paths, and similar use cases.

## Brace matching

In addition to _expansion_, brace patterns are also useful for performing regular-expression-like matching.

For example, the pattern `foo/{1..3}/bar` would match any of following strings:

```
foo/1/bar
foo/2/bar
foo/3/bar
```

But not:

```
baz/1/qux
baz/2/qux
baz/3/qux
```

Braces can also be combined with [glob patterns](https://github.com/jonschlinkert/micromatch) to perform more advanced wildcard matching. For example, the pattern `*/{1..3}/*` would match any of following strings:

```
foo/1/bar
foo/2/bar
foo/3/bar
baz/1/qux
baz/2/qux
baz/3/qux
```

## Brace matching pitfalls

Although brace patterns offer a user-friendly way of matching ranges or sets of strings, there are also some major disadvantages and potential risks you should be aware of.

### tldr

**"brace bombs"**

* brace expansion can eat up a huge amount of processing resources
* as brace patterns increase _linearly in size_, the system resources required to expand the pattern increase exponentially
* users can accidentally (or intentially) exhaust your system's resources resulting in the equivalent of a DoS attack (bonus: no programming knowledge is required!)

For a more detailed explanation with examples, see the [geometric complexity](#geometric-complexity) section.

### The solution

Jump to the [performance section](#performance) to see how Braces solves this problem in comparison to other libraries.

### Geometric complexity

At minimum, brace patterns with sets limited to two elements have quadradic or `O(n^2)` complexity. But the complexity of the algorithm increases exponentially as the number of sets, _and elements per set_, increases, which is `O(n^c)`.

For example, the following sets demonstrate quadratic (`O(n^2)`) complexity:

```
{1,2}{3,4}      => (2X2)    => 13 14 23 24
{1,2}{3,4}{5,6} => (2X2X2)  => 135 136 145 146 235 236 245 246
```

But add an element to a set, and we get a n-fold Cartesian product with `O(n^c)` complexity:

```
{1,2,3}{4,5,6}{7,8,9} => (3X3X3) => 147 148 149 157 158 159 167 168 169 247 248 
                                    249 257 258 259 267 268 269 347 348 349 357 
                                    358 359 367 368 369
```

Now, imagine how this complexity grows given that each element is a n-tuple:

```
{1..100}{1..100}         => (100X100)     => 10,000 elements (38.4 kB)
{1..100}{1..100}{1..100} => (100X100X100) => 1,000,000 elements (5.76 MB)
```

Although these examples are clearly contrived, they demonstrate how brace patterns can quickly grow out of control.

**More information**

Interested in learning more about brace expansion?

* [linuxjournal/bash-brace-expansion](http://www.linuxjournal.com/content/bash-brace-expansion)
* [rosettacode/Brace_expansion](https://rosettacode.org/wiki/Brace_expansion)
* [cartesian product](https://en.wikipedia.org/wiki/Cartesian_product)

</details>

## Performance

Braces is not only screaming fast, it's also more accurate the other brace expansion libraries.

### Better algorithms

Fortunately there is a solution to the ["brace bomb" problem](#brace-matching-pitfalls): _don't expand brace patterns into an array when they're used for matching_.

Instead, convert the pattern into an optimized regular expression. This is easier said than done, and braces is the only library that does this currently.

**The proof is in the numbers**

Minimatch gets exponentially slower as patterns increase in complexity, braces does not. The following results were generated using `braces()` and `minimatch.braceExpand()`, respectively.

| **Pattern**                 | **braces**         | **[minimatch][]**            |
| ---                         | ---                | ---                          |
| `{1..9007199254740991}`[^1] | `298 B` (5ms 459μs)|  N/A (freezes)               |
| `{1..1000000000000000}`     | `41 B` (1ms 15μs)  |  N/A (freezes)               |
| `{1..100000000000000}`      | `40 B` (890μs)     |  N/A (freezes)               |
| `{1..10000000000000}`       | `39 B` (2ms 49μs)  |  N/A (freezes)               |
| `{1..1000000000000}`        | `38 B` (608μs)     |  N/A (freezes)               |
| `{1..100000000000}`         | `37 B` (397μs)     |  N/A (freezes)               |
| `{1..10000000000}`          | `35 B` (983μs)     |  N/A (freezes)               |
| `{1..1000000000}`           | `34 B` (798μs)     |  N/A (freezes)               |
| `{1..100000000}`            | `33 B` (733μs)     |  N/A (freezes)               |
| `{1..10000000}`             | `32 B` (5ms 632μs) | `78.89 MB` (16s 388ms 569μs) |
| `{1..1000000}`              | `31 B` (1ms 381μs) | `6.89 MB` (1s 496ms 887μs)   |
| `{1..100000}`               | `30 B` (950μs)     | `588.89 kB` (146ms 921μs)    |
| `{1..10000}`                | `29 B` (1ms 114μs) | `48.89 kB` (14ms 187μs)      |
| `{1..1000}`                 | `28 B` (760μs)     | `3.89 kB` (1ms 453μs)        |
| `{1..100}`                  | `22 B` (345μs)     | `291 B` (196μs)              |
| `{1..10}`                   | `10 B` (533μs)     | `20 B` (37μs)                |
| `{1..3}`                    | `7 B` (190μs)      | `5 B` (27μs)                 |

### Faster algorithms

When you need expansion, braces is still much faster.

_(the following results were generated using `braces.expand()` and `minimatch.braceExpand()`, respectively)_

| **Pattern**     | **braces**                  | **[minimatch][]**            |
| ---             | ---                         | ---                          |
| `{1..10000000}` | `78.89 MB` (2s 698ms 642μs) | `78.89 MB` (18s 601ms 974μs) |
| `{1..1000000}`  | `6.89 MB` (458ms 576μs)     | `6.89 MB` (1s 491ms 621μs)   |
| `{1..100000}`   | `588.89 kB` (20ms 728μs)    | `588.89 kB` (156ms 919μs)    |
| `{1..10000}`    | `48.89 kB` (2ms 202μs)      | `48.89 kB` (13ms 641μs)      |
| `{1..1000}`     | `3.89 kB` (1ms 796μs)       | `3.89 kB` (1ms 958μs)        |
| `{1..100}`      | `291 B` (424μs)             | `291 B` (211μs)              |
| `{1..10}`       | `20 B` (487μs)              | `20 B` (72μs)                |
| `{1..3}`        | `5 B` (166μs)               | `5 B` (27μs)                 |

If you'd like to run these comparisons yourself, see [test/support/generate.js](test/support/generate.js).

## Benchmarks

### Running benchmarks

Install dev dependencies:

```bash
npm i -d && npm benchmark
```

### Latest results

Braces is more accurate, without sacrificing performance.

```bash
# range (expanded)
  braces x 29,040 ops/sec ±3.69% (91 runs sampled))
  minimatch x 4,735 ops/sec ±1.28% (90 runs sampled)

# range (optimized for regex)
  braces x 382,878 ops/sec ±0.56% (94 runs sampled)
  minimatch x 1,040 ops/sec ±0.44% (93 runs sampled)

# nested ranges (expanded)
  braces x 19,744 ops/sec ±2.27% (92 runs sampled))
  minimatch x 4,579 ops/sec ±0.50% (93 runs sampled)

# nested ranges (optimized for regex)
  braces x 246,019 ops/sec ±2.02% (93 runs sampled)
  minimatch x 1,028 ops/sec ±0.39% (94 runs sampled)

# set (expanded) 
  braces x 138,641 ops/sec ±0.53% (95 runs sampled)
  minimatch x 219,582 ops/sec ±0.98% (94 runs sampled)

# set (optimized for regex)
  braces x 388,408 ops/sec ±0.41% (95 runs sampled)
  minimatch x 44,724 ops/sec ±0.91% (89 runs sampled)

# nested sets (expanded)
  braces x 84,966 ops/sec ±0.48% (94 runs sampled)
  minimatch x 140,720 ops/sec ±0.37% (95 runs sampled)

# nested sets (optimized for regex)
  braces x 263,340 ops/sec ±2.06% (92 runs sampled)
  minimatch x 28,714 ops/sec ±0.40% (90 runs sampled)
```

## About

<details>
<summary><strong>Contributing</strong></summary>

Pull requests and stars are always welcome. For bugs and feature requests, [please create an issue](../../issues/new).

</details>

<details>
<summary><strong>Running Tests</strong></summary>

Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command:

```sh
$ npm install && npm test
```

</details>

<details>
<summary><strong>Building docs</strong></summary>

_(This project's readme.md is generated by [verb](https://github.com/verbose/verb-generate-readme), please don't edit the readme directly. Any changes to the readme must be made in the [.verb.md](.verb.md) readme template.)_

To generate the readme, run the following command:

```sh
$ npm install -g verbose/verb#dev verb-generate-readme && verb
```

</details>

### Contributors

| **Commits** | **Contributor** |  
| --- | --- |  
| 197 | [jonschlinkert](https://github.com/jonschlinkert) |  
| 4   | [doowb](https://github.com/doowb) |  
| 1   | [es128](https://github.com/es128) |  
| 1   | [eush77](https://github.com/eush77) |  
| 1   | [hemanth](https://github.com/hemanth) |  
| 1   | [wtgtybhertgeghgtwtg](https://github.com/wtgtybhertgeghgtwtg) |  

### Author

**Jon Schlinkert**

* [GitHub Profile](https://github.com/jonschlinkert)
* [Twitter Profile](https://twitter.com/jonschlinkert)
* [LinkedIn Profile](https://linkedin.com/in/jonschlinkert)

### License

Copyright © 2019, [Jon Schlinkert](https://github.com/jonschlinkert).
Released under the [MIT License](LICENSE).

***

_This file was generated by [verb-generate-readme](https://github.com/verbose/verb-generate-readme), v0.8.0, on April 08, 2019._# Changes


## 2.0.2

* Rename bin to `node-which`

## 2.0.1

* generate changelog and publish on version bump
* enforce 100% test coverage
* Promise interface

## 2.0.0

* Parallel tests, modern JavaScript, and drop support for node < 8

## 1.3.1

* update deps
* update travis

## v1.3.0

* Add nothrow option to which.sync
* update tap

## v1.2.14

* appveyor: drop node 5 and 0.x
* travis-ci: add node 6, drop 0.x

## v1.2.13

* test: Pass missing option to pass on windows
* update tap
* update isexe to 2.0.0
* neveragain.tech pledge request

## v1.2.12

* Removed unused require

## v1.2.11

* Prevent changelog script from being included in package

## v1.2.10

* Use env.PATH only, not env.Path

## v1.2.9

* fix for paths starting with ../
* Remove unused `is-absolute` module

## v1.2.8

* bullet items in changelog that contain (but don't start with) #

## v1.2.7

* strip 'update changelog' changelog entries out of changelog

## v1.2.6

* make the changelog bulleted

## v1.2.5

* make a changelog, and keep it up to date
* don't include tests in package
* Properly handle relative-path executables
* appveyor
* Attach error code to Not Found error
* Make tests pass on Windows

## v1.2.4

* Fix typo

## v1.2.3

* update isexe, fix regression in pathExt handling

## v1.2.2

* update deps, use isexe module, test windows

## v1.2.1

* Sometimes windows PATH entries are quoted
* Fixed a bug in the check for group and user mode bits. This bug was introduced during refactoring for supporting strict mode.
* doc cli

## v1.2.0

* Add support for opt.all and -as cli flags
* test the bin
* update travis
* Allow checking for multiple programs in bin/which
* tap 2

## v1.1.2

* travis
* Refactored and fixed undefined error on Windows
* Support strict mode

## v1.1.1

* test +g exes against secondary groups, if available
* Use windows exe semantics on cygwin & msys
* cwd should be first in path on win32, not last
* Handle lower-case 'env.Path' on Windows
* Update docs
* use single-quotes

## v1.1.0

* Add tests, depend on is-absolute

## v1.0.9

* which.js: root is allowed to execute files owned by anyone

## v1.0.8

* don't use graceful-fs

## v1.0.7

* add license to package.json

## v1.0.6

* isc license

## 1.0.5

* Awful typo

## 1.0.4

* Test for path absoluteness properly
* win: Allow '' as a pathext if cmd has a . in it

## 1.0.3

* Remove references to execPath
* Make `which.sync()` work on Windows by honoring the PATHEXT variable.
* Make `isExe()` always return true on Windows.
* MIT

## 1.0.2

* Only files can be exes

## 1.0.1

* Respect the PATHEXT env for win32 support
* should 0755 the bin
* binary
* guts
* package
* 1st
# which

Like the unix `which` utility.

Finds the first instance of a specified executable in the PATH
environment variable.  Does not cache the results, so `hash -r` is not
needed when the PATH changes.

## USAGE

```javascript
var which = require('which')

// async usage
which('node', function (er, resolvedPath) {
  // er is returned if no "node" is found on the PATH
  // if it is found, then the absolute path to the exec is returned
})

// or promise
which('node').then(resolvedPath => { ... }).catch(er => { ... not found ... })

// sync usage
// throws if not found
var resolved = which.sync('node')

// if nothrow option is used, returns null if not found
resolved = which.sync('node', {nothrow: true})

// Pass options to override the PATH and PATHEXT environment vars.
which('node', { path: someOtherPath }, function (er, resolved) {
  if (er)
    throw er
  console.log('found at %j', resolved)
})
```

## CLI USAGE

Same as the BSD `which(1)` binary.

```
usage: which [-as] program ...
```

## OPTIONS

You may pass an options object as the second argument.

- `path`: Use instead of the `PATH` environment variable.
- `pathExt`: Use instead of the `PATHEXT` environment variable.
- `all`: Return all matches, instead of just the first one.  Note that
  this means the function returns an array of strings instead of a
  single string.
<img align="right" alt="Ajv logo" width="160" src="https://ajv.js.org/images/ajv_logo.png">

# Ajv: Another JSON Schema Validator

The fastest JSON Schema validator for Node.js and browser. Supports draft-04/06/07.

[![Build Status](https://travis-ci.org/ajv-validator/ajv.svg?branch=master)](https://travis-ci.org/ajv-validator/ajv)
[![npm](https://img.shields.io/npm/v/ajv.svg)](https://www.npmjs.com/package/ajv)
[![npm (beta)](https://img.shields.io/npm/v/ajv/beta)](https://www.npmjs.com/package/ajv/v/7.0.0-beta.0)
[![npm downloads](https://img.shields.io/npm/dm/ajv.svg)](https://www.npmjs.com/package/ajv)
[![Coverage Status](https://coveralls.io/repos/github/ajv-validator/ajv/badge.svg?branch=master)](https://coveralls.io/github/ajv-validator/ajv?branch=master)
[![Gitter](https://img.shields.io/gitter/room/ajv-validator/ajv.svg)](https://gitter.im/ajv-validator/ajv)
[![GitHub Sponsors](https://img.shields.io/badge/$-sponsors-brightgreen)](https://github.com/sponsors/epoberezkin)


## Ajv v7 beta is released

[Ajv version 7.0.0-beta.0](https://github.com/ajv-validator/ajv/tree/v7-beta) is released with these changes:

- to reduce the mistakes in JSON schemas and unexpected validation results, [strict mode](./docs/strict-mode.md) is added - it prohibits ignored or ambiguous JSON Schema elements.
- to make code injection from untrusted schemas impossible, [code generation](./docs/codegen.md) is fully re-written to be safe.
- to simplify Ajv extensions, the new keyword API that is used by pre-defined keywords is available to user-defined keywords - it is much easier to define any keywords now, especially with subschemas.
- schemas are compiled to ES6 code (ES5 code generation is supported with an option).
- to improve reliability and maintainability the code is migrated to TypeScript.

**Please note**:

- the support for JSON-Schema draft-04 is removed - if you have schemas using "id" attributes you have to replace them with "\$id" (or continue using version 6 that will be supported until 02/28/2021).
- all formats are separated to ajv-formats package - they have to be explicitely added if you use them.

See [release notes](https://github.com/ajv-validator/ajv/releases/tag/v7.0.0-beta.0) for the details.

To install the new version:

```bash
npm install ajv@beta
```

See [Getting started with v7](https://github.com/ajv-validator/ajv/tree/v7-beta#usage) for code example.


## Mozilla MOSS grant and OpenJS Foundation

[<img src="https://www.poberezkin.com/images/mozilla.png" width="240" height="68">](https://www.mozilla.org/en-US/moss/) &nbsp;&nbsp;&nbsp; [<img src="https://www.poberezkin.com/images/openjs.png" width="220" height="68">](https://openjsf.org/blog/2020/08/14/ajv-joins-openjs-foundation-as-an-incubation-project/)

Ajv has been awarded a grant from Mozilla’s [Open Source Support (MOSS) program](https://www.mozilla.org/en-US/moss/) in the “Foundational Technology” track! It will sponsor the development of Ajv support of [JSON Schema version 2019-09](https://tools.ietf.org/html/draft-handrews-json-schema-02) and of [JSON Type Definition](https://tools.ietf.org/html/draft-ucarion-json-type-definition-04).

Ajv also joined [OpenJS Foundation](https://openjsf.org/) – having this support will help ensure the longevity and stability of Ajv for all its users.

This [blog post](https://www.poberezkin.com/posts/2020-08-14-ajv-json-validator-mozilla-open-source-grant-openjs-foundation.html) has more details.

I am looking for the long term maintainers of Ajv – working with [ReadySet](https://www.thereadyset.co/), also sponsored by Mozilla, to establish clear guidelines for the role of a "maintainer" and the contribution standards, and to encourage a wider, more inclusive, contribution from the community.


## Please [sponsor Ajv development](https://github.com/sponsors/epoberezkin)

Since I asked to support Ajv development 40 people and 6 organizations contributed via GitHub and OpenCollective - this support helped receiving the MOSS grant!

Your continuing support is very important - the funds will be used to develop and maintain Ajv once the next major version is released.

Please sponsor Ajv via:
- [GitHub sponsors page](https://github.com/sponsors/epoberezkin) (GitHub will match it)
- [Ajv Open Collective️](https://opencollective.com/ajv)

Thank you.


#### Open Collective sponsors

<a href="https://opencollective.com/ajv"><img src="https://opencollective.com/ajv/individuals.svg?width=890"></a>

<a href="https://opencollective.com/ajv/organization/0/website"><img src="https://opencollective.com/ajv/organization/0/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/1/website"><img src="https://opencollective.com/ajv/organization/1/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/2/website"><img src="https://opencollective.com/ajv/organization/2/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/3/website"><img src="https://opencollective.com/ajv/organization/3/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/4/website"><img src="https://opencollective.com/ajv/organization/4/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/5/website"><img src="https://opencollective.com/ajv/organization/5/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/6/website"><img src="https://opencollective.com/ajv/organization/6/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/7/website"><img src="https://opencollective.com/ajv/organization/7/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/8/website"><img src="https://opencollective.com/ajv/organization/8/avatar.svg"></a>
<a href="https://opencollective.com/ajv/organization/9/website"><img src="https://opencollective.com/ajv/organization/9/avatar.svg"></a>


## Using version 6

[JSON Schema draft-07](http://json-schema.org/latest/json-schema-validation.html) is published.

[Ajv version 6.0.0](https://github.com/ajv-validator/ajv/releases/tag/v6.0.0) that supports draft-07 is released. It may require either migrating your schemas or updating your code (to continue using draft-04 and v5 schemas, draft-06 schemas will be supported without changes).

__Please note__: To use Ajv with draft-06 schemas you need to explicitly add the meta-schema to the validator instance:

```javascript
ajv.addMetaSchema(require('ajv/lib/refs/json-schema-draft-06.json'));
```

To use Ajv with draft-04 schemas in addition to explicitly adding meta-schema you also need to use option schemaId:

```javascript
var ajv = new Ajv({schemaId: 'id'});
// If you want to use both draft-04 and draft-06/07 schemas:
// var ajv = new Ajv({schemaId: 'auto'});
ajv.addMetaSchema(require('ajv/lib/refs/json-schema-draft-04.json'));
```


## Contents

- [Performance](#performance)
- [Features](#features)
- [Getting started](#getting-started)
- [Frequently Asked Questions](https://github.com/ajv-validator/ajv/blob/master/FAQ.md)
- [Using in browser](#using-in-browser)
  - [Ajv and Content Security Policies (CSP)](#ajv-and-content-security-policies-csp)
- [Command line interface](#command-line-interface)
- Validation
  - [Keywords](#validation-keywords)
  - [Annotation keywords](#annotation-keywords)
  - [Formats](#formats)
  - [Combining schemas with $ref](#ref)
  - [$data reference](#data-reference)
  - NEW: [$merge and $patch keywords](#merge-and-patch-keywords)
  - [Defining custom keywords](#defining-custom-keywords)
  - [Asynchronous schema compilation](#asynchronous-schema-compilation)
  - [Asynchronous validation](#asynchronous-validation)
- [Security considerations](#security-considerations)
  - [Security contact](#security-contact)
  - [Untrusted schemas](#untrusted-schemas)
  - [Circular references in objects](#circular-references-in-javascript-objects)
  - [Trusted schemas](#security-risks-of-trusted-schemas)
  - [ReDoS attack](#redos-attack)
- Modifying data during validation
  - [Filtering data](#filtering-data)
  - [Assigning defaults](#assigning-defaults)
  - [Coercing data types](#coercing-data-types)
- API
  - [Methods](#api)
  - [Options](#options)
  - [Validation errors](#validation-errors)
- [Plugins](#plugins)
- [Related packages](#related-packages)
- [Some packages using Ajv](#some-packages-using-ajv)
- [Tests, Contributing, Changes history](#tests)
- [Support, Code of conduct, License](#open-source-software-support)


## Performance

Ajv generates code using [doT templates](https://github.com/olado/doT) to turn JSON Schemas into super-fast validation functions that are efficient for v8 optimization.

Currently Ajv is the fastest and the most standard compliant validator according to these benchmarks:

- [json-schema-benchmark](https://github.com/ebdrup/json-schema-benchmark) - 50% faster than the second place
- [jsck benchmark](https://github.com/pandastrike/jsck#benchmarks) - 20-190% faster
- [z-schema benchmark](https://rawgit.com/zaggino/z-schema/master/benchmark/results.html)
- [themis benchmark](https://cdn.rawgit.com/playlyfe/themis/master/benchmark/results.html)


Performance of different validators by [json-schema-benchmark](https://github.com/ebdrup/json-schema-benchmark):

[![performance](https://chart.googleapis.com/chart?chxt=x,y&cht=bhs&chco=76A4FB&chls=2.0&chbh=32,4,1&chs=600x416&chxl=-1:|djv|ajv|json-schema-validator-generator|jsen|is-my-json-valid|themis|z-schema|jsck|skeemas|json-schema-library|tv4&chd=t:100,98,72.1,66.8,50.1,15.1,6.1,3.8,1.2,0.7,0.2)](https://github.com/ebdrup/json-schema-benchmark/blob/master/README.md#performance)


## Features

- Ajv implements full JSON Schema [draft-06/07](http://json-schema.org/) and draft-04 standards:
  - all validation keywords (see [JSON Schema validation keywords](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md))
  - full support of remote refs (remote schemas have to be added with `addSchema` or compiled to be available)
  - support of circular references between schemas
  - correct string lengths for strings with unicode pairs (can be turned off)
  - [formats](#formats) defined by JSON Schema draft-07 standard and custom formats (can be turned off)
  - [validates schemas against meta-schema](#api-validateschema)
- supports [browsers](#using-in-browser) and Node.js 0.10-14.x
- [asynchronous loading](#asynchronous-schema-compilation) of referenced schemas during compilation
- "All errors" validation mode with [option allErrors](#options)
- [error messages with parameters](#validation-errors) describing error reasons to allow creating custom error messages
- i18n error messages support with [ajv-i18n](https://github.com/ajv-validator/ajv-i18n) package
- [filtering data](#filtering-data) from additional properties
- [assigning defaults](#assigning-defaults) to missing properties and items
- [coercing data](#coercing-data-types) to the types specified in `type` keywords
- [custom keywords](#defining-custom-keywords)
- draft-06/07 keywords `const`, `contains`, `propertyNames` and `if/then/else`
- draft-06 boolean schemas (`true`/`false` as a schema to always pass/fail).
- keywords `switch`, `patternRequired`, `formatMaximum` / `formatMinimum` and `formatExclusiveMaximum` / `formatExclusiveMinimum` from [JSON Schema extension proposals](https://github.com/json-schema/json-schema/wiki/v5-Proposals) with [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) package
- [$data reference](#data-reference) to use values from the validated data as values for the schema keywords
- [asynchronous validation](#asynchronous-validation) of custom formats and keywords


## Install

```
npm install ajv
```


## <a name="usage"></a>Getting started

Try it in the Node.js REPL: https://tonicdev.com/npm/ajv


The fastest validation call:

```javascript
// Node.js require:
var Ajv = require('ajv');
// or ESM/TypeScript import
import Ajv from 'ajv';

var ajv = new Ajv(); // options can be passed, e.g. {allErrors: true}
var validate = ajv.compile(schema);
var valid = validate(data);
if (!valid) console.log(validate.errors);
```

or with less code

```javascript
// ...
var valid = ajv.validate(schema, data);
if (!valid) console.log(ajv.errors);
// ...
```

or

```javascript
// ...
var valid = ajv.addSchema(schema, 'mySchema')
               .validate('mySchema', data);
if (!valid) console.log(ajv.errorsText());
// ...
```

See [API](#api) and [Options](#options) for more details.

Ajv compiles schemas to functions and caches them in all cases (using schema serialized with [fast-json-stable-stringify](https://github.com/epoberezkin/fast-json-stable-stringify) or a custom function as a key), so that the next time the same schema is used (not necessarily the same object instance) it won't be compiled again.

The best performance is achieved when using compiled functions returned by `compile` or `getSchema` methods (there is no additional function call).

__Please note__: every time a validation function or `ajv.validate` are called `errors` property is overwritten. You need to copy `errors` array reference to another variable if you want to use it later (e.g., in the callback). See [Validation errors](#validation-errors)

__Note for TypeScript users__: `ajv` provides its own TypeScript declarations
out of the box, so you don't need to install the deprecated `@types/ajv`
module.


## Using in browser

You can require Ajv directly from the code you browserify - in this case Ajv will be a part of your bundle.

If you need to use Ajv in several bundles you can create a separate UMD bundle using `npm run bundle` script (thanks to [siddo420](https://github.com/siddo420)).

Then you need to load Ajv in the browser:
```html
<script src="ajv.min.js"></script>
```

This bundle can be used with different module systems; it creates global `Ajv` if no module system is found.

The browser bundle is available on [cdnjs](https://cdnjs.com/libraries/ajv).

Ajv is tested with these browsers:

[![Sauce Test Status](https://saucelabs.com/browser-matrix/epoberezkin.svg)](https://saucelabs.com/u/epoberezkin)

__Please note__: some frameworks, e.g. Dojo, may redefine global require in such way that is not compatible with CommonJS module format. In such case Ajv bundle has to be loaded before the framework and then you can use global Ajv (see issue [#234](https://github.com/ajv-validator/ajv/issues/234)).


### Ajv and Content Security Policies (CSP)

If you're using Ajv to compile a schema (the typical use) in a browser document that is loaded with a Content Security Policy (CSP), that policy will require a `script-src` directive that includes the value `'unsafe-eval'`.
:warning: NOTE, however, that `unsafe-eval` is NOT recommended in a secure CSP[[1]](https://developer.chrome.com/extensions/contentSecurityPolicy#relaxing-eval), as it has the potential to open the document to cross-site scripting (XSS) attacks.

In order to make use of Ajv without easing your CSP, you can [pre-compile a schema using the CLI](https://github.com/ajv-validator/ajv-cli#compile-schemas). This will transpile the schema JSON into a JavaScript file that exports a `validate` function that works simlarly to a schema compiled at runtime.

Note that pre-compilation of schemas is performed using [ajv-pack](https://github.com/ajv-validator/ajv-pack) and there are [some limitations to the schema features it can compile](https://github.com/ajv-validator/ajv-pack#limitations). A successfully pre-compiled schema is equivalent to the same schema compiled at runtime.


## Command line interface

CLI is available as a separate npm package [ajv-cli](https://github.com/ajv-validator/ajv-cli). It supports:

- compiling JSON Schemas to test their validity
- BETA: generating standalone module exporting a validation function to be used without Ajv (using [ajv-pack](https://github.com/ajv-validator/ajv-pack))
- migrate schemas to draft-07 (using [json-schema-migrate](https://github.com/epoberezkin/json-schema-migrate))
- validating data file(s) against JSON Schema
- testing expected validity of data against JSON Schema
- referenced schemas
- custom meta-schemas
- files in JSON, JSON5, YAML, and JavaScript format
- all Ajv options
- reporting changes in data after validation in [JSON-patch](https://tools.ietf.org/html/rfc6902) format


## Validation keywords

Ajv supports all validation keywords from draft-07 of JSON Schema standard:

- [type](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#type)
- [for numbers](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#keywords-for-numbers) - maximum, minimum, exclusiveMaximum, exclusiveMinimum, multipleOf
- [for strings](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#keywords-for-strings) - maxLength, minLength, pattern, format
- [for arrays](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#keywords-for-arrays) - maxItems, minItems, uniqueItems, items, additionalItems, [contains](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#contains)
- [for objects](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#keywords-for-objects) - maxProperties, minProperties, required, properties, patternProperties, additionalProperties, dependencies, [propertyNames](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#propertynames)
- [for all types](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#keywords-for-all-types) - enum, [const](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#const)
- [compound keywords](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#compound-keywords) - not, oneOf, anyOf, allOf, [if/then/else](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#ifthenelse)

With [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) package Ajv also supports validation keywords from [JSON Schema extension proposals](https://github.com/json-schema/json-schema/wiki/v5-Proposals) for JSON Schema standard:

- [patternRequired](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#patternrequired-proposed) - like `required` but with patterns that some property should match.
- [formatMaximum, formatMinimum, formatExclusiveMaximum, formatExclusiveMinimum](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md#formatmaximum--formatminimum-and-exclusiveformatmaximum--exclusiveformatminimum-proposed) - setting limits for date, time, etc.

See [JSON Schema validation keywords](https://github.com/ajv-validator/ajv/blob/master/KEYWORDS.md) for more details.


## Annotation keywords

JSON Schema specification defines several annotation keywords that describe schema itself but do not perform any validation.

- `title` and `description`: information about the data represented by that schema
- `$comment` (NEW in draft-07): information for developers. With option `$comment` Ajv logs or passes the comment string to the user-supplied function. See [Options](#options).
- `default`: a default value of the data instance, see [Assigning defaults](#assigning-defaults).
- `examples` (NEW in draft-06): an array of data instances. Ajv does not check the validity of these instances against the schema.
- `readOnly` and `writeOnly` (NEW in draft-07): marks data-instance as read-only or write-only in relation to the source of the data (database, api, etc.).
- `contentEncoding`: [RFC 2045](https://tools.ietf.org/html/rfc2045#section-6.1 ), e.g., "base64".
- `contentMediaType`: [RFC 2046](https://tools.ietf.org/html/rfc2046), e.g., "image/png".

__Please note__:  Ajv does not implement validation of the keywords `examples`, `contentEncoding` and `contentMediaType` but it reserves them. If you want to create a plugin that implements some of them, it should remove these keywords from the instance.


## Formats

Ajv implements formats defined by JSON Schema specification and several other formats. It is recommended NOT to use "format" keyword implementations with untrusted data, as they use potentially unsafe regular expressions - see [ReDoS attack](#redos-attack).

__Please note__: if you need to use "format" keyword to validate untrusted data, you MUST assess their suitability and safety for your validation scenarios.

The following formats are implemented for string validation with "format" keyword:

- _date_: full-date according to [RFC3339](http://tools.ietf.org/html/rfc3339#section-5.6).
- _time_: time with optional time-zone.
- _date-time_: date-time from the same source (time-zone is mandatory). `date`, `time` and `date-time` validate ranges in `full` mode and only regexp in `fast` mode (see [options](#options)).
- _uri_: full URI.
- _uri-reference_: URI reference, including full and relative URIs.
- _uri-template_: URI template according to [RFC6570](https://tools.ietf.org/html/rfc6570)
- _url_ (deprecated): [URL record](https://url.spec.whatwg.org/#concept-url).
- _email_: email address.
- _hostname_: host name according to [RFC1034](http://tools.ietf.org/html/rfc1034#section-3.5).
- _ipv4_: IP address v4.
- _ipv6_: IP address v6.
- _regex_: tests whether a string is a valid regular expression by passing it to RegExp constructor.
- _uuid_: Universally Unique IDentifier according to [RFC4122](http://tools.ietf.org/html/rfc4122).
- _json-pointer_: JSON-pointer according to [RFC6901](https://tools.ietf.org/html/rfc6901).
- _relative-json-pointer_: relative JSON-pointer according to [this draft](http://tools.ietf.org/html/draft-luff-relative-json-pointer-00).

__Please note__: JSON Schema draft-07 also defines formats `iri`, `iri-reference`, `idn-hostname` and `idn-email` for URLs, hostnames and emails with international characters. Ajv does not implement these formats. If you create Ajv plugin that implements them please make a PR to mention this plugin here.

There are two modes of format validation: `fast` and `full`. This mode affects formats `date`, `time`, `date-time`, `uri`, `uri-reference`, and `email`. See [Options](#options) for details.

You can add additional formats and replace any of the formats above using [addFormat](#api-addformat) method.

The option `unknownFormats` allows changing the default behaviour when an unknown format is encountered. In this case Ajv can either fail schema compilation (default) or ignore it (default in versions before 5.0.0). You also can allow specific format(s) that will be ignored. See [Options](#options) for details.

You can find regular expressions used for format validation and the sources that were used in [formats.js](https://github.com/ajv-validator/ajv/blob/master/lib/compile/formats.js).


## <a name="ref"></a>Combining schemas with $ref

You can structure your validation logic across multiple schema files and have schemas reference each other using `$ref` keyword.

Example:

```javascript
var schema = {
  "$id": "http://example.com/schemas/schema.json",
  "type": "object",
  "properties": {
    "foo": { "$ref": "defs.json#/definitions/int" },
    "bar": { "$ref": "defs.json#/definitions/str" }
  }
};

var defsSchema = {
  "$id": "http://example.com/schemas/defs.json",
  "definitions": {
    "int": { "type": "integer" },
    "str": { "type": "string" }
  }
};
```

Now to compile your schema you can either pass all schemas to Ajv instance:

```javascript
var ajv = new Ajv({schemas: [schema, defsSchema]});
var validate = ajv.getSchema('http://example.com/schemas/schema.json');
```

or use `addSchema` method:

```javascript
var ajv = new Ajv;
var validate = ajv.addSchema(defsSchema)
                  .compile(schema);
```

See [Options](#options) and [addSchema](#api) method.

__Please note__:
- `$ref` is resolved as the uri-reference using schema $id as the base URI (see the example).
- References can be recursive (and mutually recursive) to implement the schemas for different data structures (such as linked lists, trees, graphs, etc.).
- You don't have to host your schema files at the URIs that you use as schema $id. These URIs are only used to identify the schemas, and according to JSON Schema specification validators should not expect to be able to download the schemas from these URIs.
- The actual location of the schema file in the file system is not used.
- You can pass the identifier of the schema as the second parameter of `addSchema` method or as a property name in `schemas` option. This identifier can be used instead of (or in addition to) schema $id.
- You cannot have the same $id (or the schema identifier) used for more than one schema - the exception will be thrown.
- You can implement dynamic resolution of the referenced schemas using `compileAsync` method. In this way you can store schemas in any system (files, web, database, etc.) and reference them without explicitly adding to Ajv instance. See [Asynchronous schema compilation](#asynchronous-schema-compilation).


## $data reference

With `$data` option you can use values from the validated data as the values for the schema keywords. See [proposal](https://github.com/json-schema-org/json-schema-spec/issues/51) for more information about how it works.

`$data` reference is supported in the keywords: const, enum, format, maximum/minimum, exclusiveMaximum / exclusiveMinimum, maxLength / minLength, maxItems / minItems, maxProperties / minProperties, formatMaximum / formatMinimum, formatExclusiveMaximum / formatExclusiveMinimum, multipleOf, pattern, required, uniqueItems.

The value of "$data" should be a [JSON-pointer](https://tools.ietf.org/html/rfc6901) to the data (the root is always the top level data object, even if the $data reference is inside a referenced subschema) or a [relative JSON-pointer](http://tools.ietf.org/html/draft-luff-relative-json-pointer-00) (it is relative to the current point in data; if the $data reference is inside a referenced subschema it cannot point to the data outside of the root level for this subschema).

Examples.

This schema requires that the value in property `smaller` is less or equal than the value in the property larger:

```javascript
var ajv = new Ajv({$data: true});

var schema = {
  "properties": {
    "smaller": {
      "type": "number",
      "maximum": { "$data": "1/larger" }
    },
    "larger": { "type": "number" }
  }
};

var validData = {
  smaller: 5,
  larger: 7
};

ajv.validate(schema, validData); // true
```

This schema requires that the properties have the same format as their field names:

```javascript
var schema = {
  "additionalProperties": {
    "type": "string",
    "format": { "$data": "0#" }
  }
};

var validData = {
  'date-time': '1963-06-19T08:30:06.283185Z',
  email: 'joe.bloggs@example.com'
}
```

`$data` reference is resolved safely - it won't throw even if some property is undefined. If `$data` resolves to `undefined` the validation succeeds (with the exclusion of `const` keyword). If `$data` resolves to incorrect type (e.g. not "number" for maximum keyword) the validation fails.


## $merge and $patch keywords

With the package [ajv-merge-patch](https://github.com/ajv-validator/ajv-merge-patch) you can use the keywords `$merge` and `$patch` that allow extending JSON Schemas with patches using formats [JSON Merge Patch (RFC 7396)](https://tools.ietf.org/html/rfc7396) and [JSON Patch (RFC 6902)](https://tools.ietf.org/html/rfc6902).

To add keywords `$merge` and `$patch` to Ajv instance use this code:

```javascript
require('ajv-merge-patch')(ajv);
```

Examples.

Using `$merge`:

```json
{
  "$merge": {
    "source": {
      "type": "object",
      "properties": { "p": { "type": "string" } },
      "additionalProperties": false
    },
    "with": {
      "properties": { "q": { "type": "number" } }
    }
  }
}
```

Using `$patch`:

```json
{
  "$patch": {
    "source": {
      "type": "object",
      "properties": { "p": { "type": "string" } },
      "additionalProperties": false
    },
    "with": [
      { "op": "add", "path": "/properties/q", "value": { "type": "number" } }
    ]
  }
}
```

The schemas above are equivalent to this schema:

```json
{
  "type": "object",
  "properties": {
    "p": { "type": "string" },
    "q": { "type": "number" }
  },
  "additionalProperties": false
}
```

The properties `source` and `with` in the keywords `$merge` and `$patch` can use absolute or relative `$ref` to point to other schemas previously added to the Ajv instance or to the fragments of the current schema.

See the package [ajv-merge-patch](https://github.com/ajv-validator/ajv-merge-patch) for more information.


## Defining custom keywords

The advantages of using custom keywords are:

- allow creating validation scenarios that cannot be expressed using JSON Schema
- simplify your schemas
- help bringing a bigger part of the validation logic to your schemas
- make your schemas more expressive, less verbose and closer to your application domain
- implement custom data processors that modify your data (`modifying` option MUST be used in keyword definition) and/or create side effects while the data is being validated

If a keyword is used only for side-effects and its validation result is pre-defined, use option `valid: true/false` in keyword definition to simplify both generated code (no error handling in case of `valid: true`) and your keyword functions (no need to return any validation result).

The concerns you have to be aware of when extending JSON Schema standard with custom keywords are the portability and understanding of your schemas. You will have to support these custom keywords on other platforms and to properly document these keywords so that everybody can understand them in your schemas.

You can define custom keywords with [addKeyword](#api-addkeyword) method. Keywords are defined on the `ajv` instance level - new instances will not have previously defined keywords.

Ajv allows defining keywords with:
- validation function
- compilation function
- macro function
- inline compilation function that should return code (as string) that will be inlined in the currently compiled schema.

Example. `range` and `exclusiveRange` keywords using compiled schema:

```javascript
ajv.addKeyword('range', {
  type: 'number',
  compile: function (sch, parentSchema) {
    var min = sch[0];
    var max = sch[1];

    return parentSchema.exclusiveRange === true
            ? function (data) { return data > min && data < max; }
            : function (data) { return data >= min && data <= max; }
  }
});

var schema = { "range": [2, 4], "exclusiveRange": true };
var validate = ajv.compile(schema);
console.log(validate(2.01)); // true
console.log(validate(3.99)); // true
console.log(validate(2)); // false
console.log(validate(4)); // false
```

Several custom keywords (typeof, instanceof, range and propertyNames) are defined in [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) package - they can be used for your schemas and as a starting point for your own custom keywords.

See [Defining custom keywords](https://github.com/ajv-validator/ajv/blob/master/CUSTOM.md) for more details.


## Asynchronous schema compilation

During asynchronous compilation remote references are loaded using supplied function. See `compileAsync` [method](#api-compileAsync) and `loadSchema` [option](#options).

Example:

```javascript
var ajv = new Ajv({ loadSchema: loadSchema });

ajv.compileAsync(schema).then(function (validate) {
  var valid = validate(data);
  // ...
});

function loadSchema(uri) {
  return request.json(uri).then(function (res) {
    if (res.statusCode >= 400)
      throw new Error('Loading error: ' + res.statusCode);
    return res.body;
  });
}
```

__Please note__: [Option](#options) `missingRefs` should NOT be set to `"ignore"` or `"fail"` for asynchronous compilation to work.


## Asynchronous validation

Example in Node.js REPL: https://tonicdev.com/esp/ajv-asynchronous-validation

You can define custom formats and keywords that perform validation asynchronously by accessing database or some other service. You should add `async: true` in the keyword or format definition (see [addFormat](#api-addformat), [addKeyword](#api-addkeyword) and [Defining custom keywords](#defining-custom-keywords)).

If your schema uses asynchronous formats/keywords or refers to some schema that contains them it should have `"$async": true` keyword so that Ajv can compile it correctly. If asynchronous format/keyword or reference to asynchronous schema is used in the schema without `$async` keyword Ajv will throw an exception during schema compilation.

__Please note__: all asynchronous subschemas that are referenced from the current or other schemas should have `"$async": true` keyword as well, otherwise the schema compilation will fail.

Validation function for an asynchronous custom format/keyword should return a promise that resolves with `true` or `false` (or rejects with `new Ajv.ValidationError(errors)` if you want to return custom errors from the keyword function).

Ajv compiles asynchronous schemas to [es7 async functions](http://tc39.github.io/ecmascript-asyncawait/) that can optionally be transpiled with [nodent](https://github.com/MatAtBread/nodent). Async functions are supported in Node.js 7+ and all modern browsers. You can also supply any other transpiler as a function via `processCode` option. See [Options](#options).

The compiled validation function has `$async: true` property (if the schema is asynchronous), so you can differentiate these functions if you are using both synchronous and asynchronous schemas.

Validation result will be a promise that resolves with validated data or rejects with an exception `Ajv.ValidationError` that contains the array of validation errors in `errors` property.


Example:

```javascript
var ajv = new Ajv;
// require('ajv-async')(ajv);

ajv.addKeyword('idExists', {
  async: true,
  type: 'number',
  validate: checkIdExists
});


function checkIdExists(schema, data) {
  return knex(schema.table)
  .select('id')
  .where('id', data)
  .then(function (rows) {
    return !!rows.length; // true if record is found
  });
}

var schema = {
  "$async": true,
  "properties": {
    "userId": {
      "type": "integer",
      "idExists": { "table": "users" }
    },
    "postId": {
      "type": "integer",
      "idExists": { "table": "posts" }
    }
  }
};

var validate = ajv.compile(schema);

validate({ userId: 1, postId: 19 })
.then(function (data) {
  console.log('Data is valid', data); // { userId: 1, postId: 19 }
})
.catch(function (err) {
  if (!(err instanceof Ajv.ValidationError)) throw err;
  // data is invalid
  console.log('Validation errors:', err.errors);
});
```

### Using transpilers with asynchronous validation functions.

[ajv-async](https://github.com/ajv-validator/ajv-async) uses [nodent](https://github.com/MatAtBread/nodent) to transpile async functions. To use another transpiler you should separately install it (or load its bundle in the browser).


#### Using nodent

```javascript
var ajv = new Ajv;
require('ajv-async')(ajv);
// in the browser if you want to load ajv-async bundle separately you can:
// window.ajvAsync(ajv);
var validate = ajv.compile(schema); // transpiled es7 async function
validate(data).then(successFunc).catch(errorFunc);
```


#### Using other transpilers

```javascript
var ajv = new Ajv({ processCode: transpileFunc });
var validate = ajv.compile(schema); // transpiled es7 async function
validate(data).then(successFunc).catch(errorFunc);
```

See [Options](#options).


## Security considerations

JSON Schema, if properly used, can replace data sanitisation. It doesn't replace other API security considerations. It also introduces additional security aspects to consider.


##### Security contact

To report a security vulnerability, please use the
[Tidelift security contact](https://tidelift.com/security).
Tidelift will coordinate the fix and disclosure. Please do NOT report security vulnerabilities via GitHub issues.


##### Untrusted schemas

Ajv treats JSON schemas as trusted as your application code. This security model is based on the most common use case, when the schemas are static and bundled together with the application.

If your schemas are received from untrusted sources (or generated from untrusted data) there are several scenarios you need to prevent:
- compiling schemas can cause stack overflow (if they are too deep)
- compiling schemas can be slow (e.g. [#557](https://github.com/ajv-validator/ajv/issues/557))
- validating certain data can be slow

It is difficult to predict all the scenarios, but at the very least it may help to limit the size of untrusted schemas (e.g. limit JSON string length) and also the maximum schema object depth (that can be high for relatively small JSON strings). You also may want to mitigate slow regular expressions in `pattern` and `patternProperties` keywords.

Regardless the measures you take, using untrusted schemas increases security risks.


##### Circular references in JavaScript objects

Ajv does not support schemas and validated data that have circular references in objects. See [issue #802](https://github.com/ajv-validator/ajv/issues/802).

An attempt to compile such schemas or validate such data would cause stack overflow (or will not complete in case of asynchronous validation). Depending on the parser you use, untrusted data can lead to circular references.


##### Security risks of trusted schemas

Some keywords in JSON Schemas can lead to very slow validation for certain data. These keywords include (but may be not limited to):

- `pattern` and `format` for large strings - in some cases using `maxLength` can help mitigate it, but certain regular expressions can lead to exponential validation time even with relatively short strings (see [ReDoS attack](#redos-attack)).
- `patternProperties` for large property names - use `propertyNames` to mitigate, but some regular expressions can have exponential evaluation time as well.
- `uniqueItems` for large non-scalar arrays - use `maxItems` to mitigate

__Please note__: The suggestions above to prevent slow validation would only work if you do NOT use `allErrors: true` in production code (using it would continue validation after validation errors).

You can validate your JSON schemas against [this meta-schema](https://github.com/ajv-validator/ajv/blob/master/lib/refs/json-schema-secure.json) to check that these recommendations are followed:

```javascript
const isSchemaSecure = ajv.compile(require('ajv/lib/refs/json-schema-secure.json'));

const schema1 = {format: 'email'};
isSchemaSecure(schema1); // false

const schema2 = {format: 'email', maxLength: MAX_LENGTH};
isSchemaSecure(schema2); // true
```

__Please note__: following all these recommendation is not a guarantee that validation of untrusted data is safe - it can still lead to some undesirable results.


##### Content Security Policies (CSP)
See [Ajv and Content Security Policies (CSP)](#ajv-and-content-security-policies-csp)


## ReDoS attack

Certain regular expressions can lead to the exponential evaluation time even with relatively short strings.

Please assess the regular expressions you use in the schemas on their vulnerability to this attack - see [safe-regex](https://github.com/substack/safe-regex), for example.

__Please note__: some formats that Ajv implements use [regular expressions](https://github.com/ajv-validator/ajv/blob/master/lib/compile/formats.js) that can be vulnerable to ReDoS attack, so if you use Ajv to validate data from untrusted sources __it is strongly recommended__ to consider the following:

- making assessment of "format" implementations in Ajv.
- using `format: 'fast'` option that simplifies some of the regular expressions (although it does not guarantee that they are safe).
- replacing format implementations provided by Ajv with your own implementations of "format" keyword that either uses different regular expressions or another approach to format validation. Please see [addFormat](#api-addformat) method.
- disabling format validation by ignoring "format" keyword with option `format: false`

Whatever mitigation you choose, please assume all formats provided by Ajv as potentially unsafe and make your own assessment of their suitability for your validation scenarios.


## Filtering data

With [option `removeAdditional`](#options) (added by [andyscott](https://github.com/andyscott)) you can filter data during the validation.

This option modifies original data.

Example:

```javascript
var ajv = new Ajv({ removeAdditional: true });
var schema = {
  "additionalProperties": false,
  "properties": {
    "foo": { "type": "number" },
    "bar": {
      "additionalProperties": { "type": "number" },
      "properties": {
        "baz": { "type": "string" }
      }
    }
  }
}

var data = {
  "foo": 0,
  "additional1": 1, // will be removed; `additionalProperties` == false
  "bar": {
    "baz": "abc",
    "additional2": 2 // will NOT be removed; `additionalProperties` != false
  },
}

var validate = ajv.compile(schema);

console.log(validate(data)); // true
console.log(data); // { "foo": 0, "bar": { "baz": "abc", "additional2": 2 }
```

If `removeAdditional` option in the example above were `"all"` then both `additional1` and `additional2` properties would have been removed.

If the option were `"failing"` then property `additional1` would have been removed regardless of its value and property `additional2` would have been removed only if its value were failing the schema in the inner `additionalProperties` (so in the example above it would have stayed because it passes the schema, but any non-number would have been removed).

__Please note__: If you use `removeAdditional` option with `additionalProperties` keyword inside `anyOf`/`oneOf` keywords your validation can fail with this schema, for example:

```json
{
  "type": "object",
  "oneOf": [
    {
      "properties": {
        "foo": { "type": "string" }
      },
      "required": [ "foo" ],
      "additionalProperties": false
    },
    {
      "properties": {
        "bar": { "type": "integer" }
      },
      "required": [ "bar" ],
      "additionalProperties": false
    }
  ]
}
```

The intention of the schema above is to allow objects with either the string property "foo" or the integer property "bar", but not with both and not with any other properties.

With the option `removeAdditional: true` the validation will pass for the object `{ "foo": "abc"}` but will fail for the object `{"bar": 1}`. It happens because while the first subschema in `oneOf` is validated, the property `bar` is removed because it is an additional property according to the standard (because it is not included in `properties` keyword in the same schema).

While this behaviour is unexpected (issues [#129](https://github.com/ajv-validator/ajv/issues/129), [#134](https://github.com/ajv-validator/ajv/issues/134)), it is correct. To have the expected behaviour (both objects are allowed and additional properties are removed) the schema has to be refactored in this way:

```json
{
  "type": "object",
  "properties": {
    "foo": { "type": "string" },
    "bar": { "type": "integer" }
  },
  "additionalProperties": false,
  "oneOf": [
    { "required": [ "foo" ] },
    { "required": [ "bar" ] }
  ]
}
```

The schema above is also more efficient - it will compile into a faster function.


## Assigning defaults

With [option `useDefaults`](#options) Ajv will assign values from `default` keyword in the schemas of `properties` and `items` (when it is the array of schemas) to the missing properties and items.

With the option value `"empty"` properties and items equal to `null` or `""` (empty string) will be considered missing and assigned defaults.

This option modifies original data.

__Please note__: the default value is inserted in the generated validation code as a literal, so the value inserted in the data will be the deep clone of the default in the schema.


Example 1 (`default` in `properties`):

```javascript
var ajv = new Ajv({ useDefaults: true });
var schema = {
  "type": "object",
  "properties": {
    "foo": { "type": "number" },
    "bar": { "type": "string", "default": "baz" }
  },
  "required": [ "foo", "bar" ]
};

var data = { "foo": 1 };

var validate = ajv.compile(schema);

console.log(validate(data)); // true
console.log(data); // { "foo": 1, "bar": "baz" }
```

Example 2 (`default` in `items`):

```javascript
var schema = {
  "type": "array",
  "items": [
    { "type": "number" },
    { "type": "string", "default": "foo" }
  ]
}

var data = [ 1 ];

var validate = ajv.compile(schema);

console.log(validate(data)); // true
console.log(data); // [ 1, "foo" ]
```

`default` keywords in other cases are ignored:

- not in `properties` or `items` subschemas
- in schemas inside `anyOf`, `oneOf` and `not` (see [#42](https://github.com/ajv-validator/ajv/issues/42))
- in `if` subschema of `switch` keyword
- in schemas generated by custom macro keywords

The [`strictDefaults` option](#options) customizes Ajv's behavior for the defaults that Ajv ignores (`true` raises an error, and `"log"` outputs a warning).


## Coercing data types

When you are validating user inputs all your data properties are usually strings. The option `coerceTypes` allows you to have your data types coerced to the types specified in your schema `type` keywords, both to pass the validation and to use the correctly typed data afterwards.

This option modifies original data.

__Please note__: if you pass a scalar value to the validating function its type will be coerced and it will pass the validation, but the value of the variable you pass won't be updated because scalars are passed by value.


Example 1:

```javascript
var ajv = new Ajv({ coerceTypes: true });
var schema = {
  "type": "object",
  "properties": {
    "foo": { "type": "number" },
    "bar": { "type": "boolean" }
  },
  "required": [ "foo", "bar" ]
};

var data = { "foo": "1", "bar": "false" };

var validate = ajv.compile(schema);

console.log(validate(data)); // true
console.log(data); // { "foo": 1, "bar": false }
```

Example 2 (array coercions):

```javascript
var ajv = new Ajv({ coerceTypes: 'array' });
var schema = {
  "properties": {
    "foo": { "type": "array", "items": { "type": "number" } },
    "bar": { "type": "boolean" }
  }
};

var data = { "foo": "1", "bar": ["false"] };

var validate = ajv.compile(schema);

console.log(validate(data)); // true
console.log(data); // { "foo": [1], "bar": false }
```

The coercion rules, as you can see from the example, are different from JavaScript both to validate user input as expected and to have the coercion reversible (to correctly validate cases where different types are defined in subschemas of "anyOf" and other compound keywords).

See [Coercion rules](https://github.com/ajv-validator/ajv/blob/master/COERCION.md) for details.


## API

##### new Ajv(Object options) -&gt; Object

Create Ajv instance.


##### .compile(Object schema) -&gt; Function&lt;Object data&gt;

Generate validating function and cache the compiled schema for future use.

Validating function returns a boolean value. This function has properties `errors` and `schema`. Errors encountered during the last validation are assigned to `errors` property (it is assigned `null` if there was no errors). `schema` property contains the reference to the original schema.

The schema passed to this method will be validated against meta-schema unless `validateSchema` option is false. If schema is invalid, an error will be thrown. See [options](#options).


##### <a name="api-compileAsync"></a>.compileAsync(Object schema [, Boolean meta] [, Function callback]) -&gt; Promise

Asynchronous version of `compile` method that loads missing remote schemas using asynchronous function in `options.loadSchema`. This function returns a Promise that resolves to a validation function. An optional callback passed to `compileAsync` will be called with 2 parameters: error (or null) and validating function. The returned promise will reject (and the callback will be called with an error) when:

- missing schema can't be loaded (`loadSchema` returns a Promise that rejects).
- a schema containing a missing reference is loaded, but the reference cannot be resolved.
- schema (or some loaded/referenced schema) is invalid.

The function compiles schema and loads the first missing schema (or meta-schema) until all missing schemas are loaded.

You can asynchronously compile meta-schema by passing `true` as the second parameter.

See example in [Asynchronous compilation](#asynchronous-schema-compilation).


##### .validate(Object schema|String key|String ref, data) -&gt; Boolean

Validate data using passed schema (it will be compiled and cached).

Instead of the schema you can use the key that was previously passed to `addSchema`, the schema id if it was present in the schema or any previously resolved reference.

Validation errors will be available in the `errors` property of Ajv instance (`null` if there were no errors).

__Please note__: every time this method is called the errors are overwritten so you need to copy them to another variable if you want to use them later.

If the schema is asynchronous (has `$async` keyword on the top level) this method returns a Promise. See [Asynchronous validation](#asynchronous-validation).


##### .addSchema(Array&lt;Object&gt;|Object schema [, String key]) -&gt; Ajv

Add schema(s) to validator instance. This method does not compile schemas (but it still validates them). Because of that dependencies can be added in any order and circular dependencies are supported. It also prevents unnecessary compilation of schemas that are containers for other schemas but not used as a whole.

Array of schemas can be passed (schemas should have ids), the second parameter will be ignored.

Key can be passed that can be used to reference the schema and will be used as the schema id if there is no id inside the schema. If the key is not passed, the schema id will be used as the key.


Once the schema is added, it (and all the references inside it) can be referenced in other schemas and used to validate data.

Although `addSchema` does not compile schemas, explicit compilation is not required - the schema will be compiled when it is used first time.

By default the schema is validated against meta-schema before it is added, and if the schema does not pass validation the exception is thrown. This behaviour is controlled by `validateSchema` option.

__Please note__: Ajv uses the [method chaining syntax](https://en.wikipedia.org/wiki/Method_chaining) for all methods with the prefix `add*` and `remove*`.
This allows you to do nice things like the following.

```javascript
var validate = new Ajv().addSchema(schema).addFormat(name, regex).getSchema(uri);
```

##### .addMetaSchema(Array&lt;Object&gt;|Object schema [, String key]) -&gt; Ajv

Adds meta schema(s) that can be used to validate other schemas. That function should be used instead of `addSchema` because there may be instance options that would compile a meta schema incorrectly (at the moment it is `removeAdditional` option).

There is no need to explicitly add draft-07 meta schema (http://json-schema.org/draft-07/schema) - it is added by default, unless option `meta` is set to `false`. You only need to use it if you have a changed meta-schema that you want to use to validate your schemas. See `validateSchema`.


##### <a name="api-validateschema"></a>.validateSchema(Object schema) -&gt; Boolean

Validates schema. This method should be used to validate schemas rather than `validate` due to the inconsistency of `uri` format in JSON Schema standard.

By default this method is called automatically when the schema is added, so you rarely need to use it directly.

If schema doesn't have `$schema` property, it is validated against draft 6 meta-schema (option `meta` should not be false).

If schema has `$schema` property, then the schema with this id (that should be previously added) is used to validate passed schema.

Errors will be available at `ajv.errors`.


##### .getSchema(String key) -&gt; Function&lt;Object data&gt;

Retrieve compiled schema previously added with `addSchema` by the key passed to `addSchema` or by its full reference (id). The returned validating function has `schema` property with the reference to the original schema.


##### .removeSchema([Object schema|String key|String ref|RegExp pattern]) -&gt; Ajv

Remove added/cached schema. Even if schema is referenced by other schemas it can be safely removed as dependent schemas have local references.

Schema can be removed using:
- key passed to `addSchema`
- it's full reference (id)
- RegExp that should match schema id or key (meta-schemas won't be removed)
- actual schema object that will be stable-stringified to remove schema from cache

If no parameter is passed all schemas but meta-schemas will be removed and the cache will be cleared.


##### <a name="api-addformat"></a>.addFormat(String name, String|RegExp|Function|Object format) -&gt; Ajv

Add custom format to validate strings or numbers. It can also be used to replace pre-defined formats for Ajv instance.

Strings are converted to RegExp.

Function should return validation result as `true` or `false`.

If object is passed it should have properties `validate`, `compare` and `async`:

- _validate_: a string, RegExp or a function as described above.
- _compare_: an optional comparison function that accepts two strings and compares them according to the format meaning. This function is used with keywords `formatMaximum`/`formatMinimum` (defined in [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) package). It should return `1` if the first value is bigger than the second value, `-1` if it is smaller and `0` if it is equal.
- _async_: an optional `true` value if `validate` is an asynchronous function; in this case it should return a promise that resolves with a value `true` or `false`.
- _type_: an optional type of data that the format applies to. It can be `"string"` (default) or `"number"` (see https://github.com/ajv-validator/ajv/issues/291#issuecomment-259923858). If the type of data is different, the validation will pass.

Custom formats can be also added via `formats` option.


##### <a name="api-addkeyword"></a>.addKeyword(String keyword, Object definition) -&gt; Ajv

Add custom validation keyword to Ajv instance.

Keyword should be different from all standard JSON Schema keywords and different from previously defined keywords. There is no way to redefine keywords or to remove keyword definition from the instance.

Keyword must start with a letter, `_` or `$`, and may continue with letters, numbers, `_`, `$`, or `-`.
It is recommended to use an application-specific prefix for keywords to avoid current and future name collisions.

Example Keywords:
- `"xyz-example"`: valid, and uses prefix for the xyz project to avoid name collisions.
- `"example"`: valid, but not recommended as it could collide with future versions of JSON Schema etc.
- `"3-example"`: invalid as numbers are not allowed to be the first character in a keyword

Keyword definition is an object with the following properties:

- _type_: optional string or array of strings with data type(s) that the keyword applies to. If not present, the keyword will apply to all types.
- _validate_: validating function
- _compile_: compiling function
- _macro_: macro function
- _inline_: compiling function that returns code (as string)
- _schema_: an optional `false` value used with "validate" keyword to not pass schema
- _metaSchema_: an optional meta-schema for keyword schema
- _dependencies_: an optional list of properties that must be present in the parent schema - it will be checked during schema compilation
- _modifying_: `true` MUST be passed if keyword modifies data
- _statements_: `true` can be passed in case inline keyword generates statements (as opposed to expression)
- _valid_: pass `true`/`false` to pre-define validation result, the result returned from validation function will be ignored. This option cannot be used with macro keywords.
- _$data_: an optional `true` value to support [$data reference](#data-reference) as the value of custom keyword. The reference will be resolved at validation time. If the keyword has meta-schema it would be extended to allow $data and it will be used to validate the resolved value. Supporting $data reference requires that keyword has validating function (as the only option or in addition to compile, macro or inline function).
- _async_: an optional `true` value if the validation function is asynchronous (whether it is compiled or passed in _validate_ property); in this case it should return a promise that resolves with a value `true` or `false`. This option is ignored in case of "macro" and "inline" keywords.
- _errors_: an optional boolean or string `"full"` indicating whether keyword returns errors. If this property is not set Ajv will determine if the errors were set in case of failed validation.

_compile_, _macro_ and _inline_ are mutually exclusive, only one should be used at a time. _validate_ can be used separately or in addition to them to support $data reference.

__Please note__: If the keyword is validating data type that is different from the type(s) in its definition, the validation function will not be called (and expanded macro will not be used), so there is no need to check for data type inside validation function or inside schema returned by macro function (unless you want to enforce a specific type and for some reason do not want to use a separate `type` keyword for that). In the same way as standard keywords work, if the keyword does not apply to the data type being validated, the validation of this keyword will succeed.

See [Defining custom keywords](#defining-custom-keywords) for more details.


##### .getKeyword(String keyword) -&gt; Object|Boolean

Returns custom keyword definition, `true` for pre-defined keywords and `false` if the keyword is unknown.


##### .removeKeyword(String keyword) -&gt; Ajv

Removes custom or pre-defined keyword so you can redefine them.

While this method can be used to extend pre-defined keywords, it can also be used to completely change their meaning - it may lead to unexpected results.

__Please note__: schemas compiled before the keyword is removed will continue to work without changes. To recompile schemas use `removeSchema` method and compile them again.


##### .errorsText([Array&lt;Object&gt; errors [, Object options]]) -&gt; String

Returns the text with all errors in a String.

Options can have properties `separator` (string used to separate errors, ", " by default) and `dataVar` (the variable name that dataPaths are prefixed with, "data" by default).


## Options

Defaults:

```javascript
{
  // validation and reporting options:
  $data:            false,
  allErrors:        false,
  verbose:          false,
  $comment:         false, // NEW in Ajv version 6.0
  jsonPointers:     false,
  uniqueItems:      true,
  unicode:          true,
  nullable:         false,
  format:           'fast',
  formats:          {},
  unknownFormats:   true,
  schemas:          {},
  logger:           undefined,
  // referenced schema options:
  schemaId:         '$id',
  missingRefs:      true,
  extendRefs:       'ignore', // recommended 'fail'
  loadSchema:       undefined, // function(uri: string): Promise {}
  // options to modify validated data:
  removeAdditional: false,
  useDefaults:      false,
  coerceTypes:      false,
  // strict mode options
  strictDefaults:   false,
  strictKeywords:   false,
  strictNumbers:    false,
  // asynchronous validation options:
  transpile:        undefined, // requires ajv-async package
  // advanced options:
  meta:             true,
  validateSchema:   true,
  addUsedSchema:    true,
  inlineRefs:       true,
  passContext:      false,
  loopRequired:     Infinity,
  ownProperties:    false,
  multipleOfPrecision: false,
  errorDataPath:    'object', // deprecated
  messages:         true,
  sourceCode:       false,
  processCode:      undefined, // function (str: string, schema: object): string {}
  cache:            new Cache,
  serialize:        undefined
}
```

##### Validation and reporting options

- _$data_: support [$data references](#data-reference). Draft 6 meta-schema that is added by default will be extended to allow them. If you want to use another meta-schema you need to use $dataMetaSchema method to add support for $data reference. See [API](#api).
- _allErrors_: check all rules collecting all errors. Default is to return after the first error.
- _verbose_: include the reference to the part of the schema (`schema` and `parentSchema`) and validated data in errors (false by default).
- _$comment_ (NEW in Ajv version 6.0): log or pass the value of `$comment` keyword to a function. Option values:
  - `false` (default): ignore $comment keyword.
  - `true`: log the keyword value to console.
  - function: pass the keyword value, its schema path and root schema to the specified function
- _jsonPointers_: set `dataPath` property of errors using [JSON Pointers](https://tools.ietf.org/html/rfc6901) instead of JavaScript property access notation.
- _uniqueItems_: validate `uniqueItems` keyword (true by default).
- _unicode_: calculate correct length of strings with unicode pairs (true by default). Pass `false` to use `.length` of strings that is faster, but gives "incorrect" lengths of strings with unicode pairs - each unicode pair is counted as two characters.
- _nullable_: support keyword "nullable" from [Open API 3 specification](https://swagger.io/docs/specification/data-models/data-types/).
- _format_: formats validation mode. Option values:
  - `"fast"` (default) - simplified and fast validation (see [Formats](#formats) for details of which formats are available and affected by this option).
  - `"full"` - more restrictive and slow validation. E.g., 25:00:00 and 2015/14/33 will be invalid time and date in 'full' mode but it will be valid in 'fast' mode.
  - `false` - ignore all format keywords.
- _formats_: an object with custom formats. Keys and values will be passed to `addFormat` method.
- _keywords_: an object with custom keywords. Keys and values will be passed to `addKeyword` method.
- _unknownFormats_: handling of unknown formats. Option values:
  - `true` (default) - if an unknown format is encountered the exception is thrown during schema compilation. If `format` keyword value is [$data reference](#data-reference) and it is unknown the validation will fail.
  - `[String]` - an array of unknown format names that will be ignored. This option can be used to allow usage of third party schemas with format(s) for which you don't have definitions, but still fail if another unknown format is used. If `format` keyword value is [$data reference](#data-reference) and it is not in this array the validation will fail.
  - `"ignore"` - to log warning during schema compilation and always pass validation (the default behaviour in versions before 5.0.0). This option is not recommended, as it allows to mistype format name and it won't be validated without any error message. This behaviour is required by JSON Schema specification.
- _schemas_: an array or object of schemas that will be added to the instance. In case you pass the array the schemas must have IDs in them. When the object is passed the method `addSchema(value, key)` will be called for each schema in this object.
- _logger_: sets the logging method. Default is the global `console` object that should have methods `log`, `warn` and `error`. See [Error logging](#error-logging). Option values:
  - custom logger - it should have methods `log`, `warn` and `error`. If any of these methods is missing an exception will be thrown.
  - `false` - logging is disabled.


##### Referenced schema options

- _schemaId_: this option defines which keywords are used as schema URI. Option value:
  - `"$id"` (default) - only use `$id` keyword as schema URI (as specified in JSON Schema draft-06/07), ignore `id` keyword (if it is present a warning will be logged).
  - `"id"` - only use `id` keyword as schema URI (as specified in JSON Schema draft-04), ignore `$id` keyword (if it is present a warning will be logged).
  - `"auto"` - use both `$id` and `id` keywords as schema URI. If both are present (in the same schema object) and different the exception will be thrown during schema compilation.
- _missingRefs_: handling of missing referenced schemas. Option values:
  - `true` (default) - if the reference cannot be resolved during compilation the exception is thrown. The thrown error has properties `missingRef` (with hash fragment) and `missingSchema` (without it). Both properties are resolved relative to the current base id (usually schema id, unless it was substituted).
  - `"ignore"` - to log error during compilation and always pass validation.
  - `"fail"` - to log error and successfully compile schema but fail validation if this rule is checked.
- _extendRefs_: validation of other keywords when `$ref` is present in the schema. Option values:
  - `"ignore"` (default) - when `$ref` is used other keywords are ignored (as per [JSON Reference](https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03#section-3) standard). A warning will be logged during the schema compilation.
  - `"fail"` (recommended) - if other validation keywords are used together with `$ref` the exception will be thrown when the schema is compiled. This option is recommended to make sure schema has no keywords that are ignored, which can be confusing.
  - `true` - validate all keywords in the schemas with `$ref` (the default behaviour in versions before 5.0.0).
- _loadSchema_: asynchronous function that will be used to load remote schemas when `compileAsync` [method](#api-compileAsync) is used and some reference is missing (option `missingRefs` should NOT be 'fail' or 'ignore'). This function should accept remote schema uri as a parameter and return a Promise that resolves to a schema. See example in [Asynchronous compilation](#asynchronous-schema-compilation).


##### Options to modify validated data

- _removeAdditional_: remove additional properties - see example in [Filtering data](#filtering-data). This option is not used if schema is added with `addMetaSchema` method. Option values:
  - `false` (default) - not to remove additional properties
  - `"all"` - all additional properties are removed, regardless of `additionalProperties` keyword in schema (and no validation is made for them).
  - `true` - only additional properties with `additionalProperties` keyword equal to `false` are removed.
  - `"failing"` - additional properties that fail schema validation will be removed (where `additionalProperties` keyword is `false` or schema).
- _useDefaults_: replace missing or undefined properties and items with the values from corresponding `default` keywords. Default behaviour is to ignore `default` keywords. This option is not used if schema is added with `addMetaSchema` method. See examples in [Assigning defaults](#assigning-defaults). Option values:
  - `false` (default) - do not use defaults
  - `true` - insert defaults by value (object literal is used).
  - `"empty"` - in addition to missing or undefined, use defaults for properties and items that are equal to `null` or `""` (an empty string).
  - `"shared"` (deprecated) - insert defaults by reference. If the default is an object, it will be shared by all instances of validated data. If you modify the inserted default in the validated data, it will be modified in the schema as well.
- _coerceTypes_: change data type of data to match `type` keyword. See the example in [Coercing data types](#coercing-data-types) and [coercion rules](https://github.com/ajv-validator/ajv/blob/master/COERCION.md). Option values:
  - `false` (default) - no type coercion.
  - `true` - coerce scalar data types.
  - `"array"` - in addition to coercions between scalar types, coerce scalar data to an array with one element and vice versa (as required by the schema).


##### Strict mode options

- _strictDefaults_: report ignored `default` keywords in schemas. Option values:
  - `false` (default) - ignored defaults are not reported
  - `true` - if an ignored default is present, throw an error
  - `"log"` - if an ignored default is present, log warning
- _strictKeywords_: report unknown keywords in schemas. Option values:
  - `false` (default) - unknown keywords are not reported
  - `true` - if an unknown keyword is present, throw an error
  - `"log"` - if an unknown keyword is present, log warning
- _strictNumbers_: validate numbers strictly, failing validation for NaN and Infinity. Option values:
  - `false` (default) - NaN or Infinity will pass validation for numeric types
  - `true` - NaN or Infinity will not pass validation for numeric types

##### Asynchronous validation options

- _transpile_: Requires [ajv-async](https://github.com/ajv-validator/ajv-async) package. It determines whether Ajv transpiles compiled asynchronous validation function. Option values:
  - `undefined` (default) - transpile with [nodent](https://github.com/MatAtBread/nodent) if async functions are not supported.
  - `true` - always transpile with nodent.
  - `false` - do not transpile; if async functions are not supported an exception will be thrown.


##### Advanced options

- _meta_: add [meta-schema](http://json-schema.org/documentation.html) so it can be used by other schemas (true by default). If an object is passed, it will be used as the default meta-schema for schemas that have no `$schema` keyword. This default meta-schema MUST have `$schema` keyword.
- _validateSchema_: validate added/compiled schemas against meta-schema (true by default). `$schema` property in the schema can be http://json-schema.org/draft-07/schema or absent (draft-07 meta-schema will be used) or can be a reference to the schema previously added with `addMetaSchema` method. Option values:
  - `true` (default) -  if the validation fails, throw the exception.
  - `"log"` - if the validation fails, log error.
  - `false` - skip schema validation.
- _addUsedSchema_: by default methods `compile` and `validate` add schemas to the instance if they have `$id` (or `id`) property that doesn't start with "#". If `$id` is present and it is not unique the exception will be thrown. Set this option to `false` to skip adding schemas to the instance and the `$id` uniqueness check when these methods are used. This option does not affect `addSchema` method.
- _inlineRefs_: Affects compilation of referenced schemas. Option values:
  - `true` (default) - the referenced schemas that don't have refs in them are inlined, regardless of their size - that substantially improves performance at the cost of the bigger size of compiled schema functions.
  - `false` - to not inline referenced schemas (they will be compiled as separate functions).
  - integer number - to limit the maximum number of keywords of the schema that will be inlined.
- _passContext_: pass validation context to custom keyword functions. If this option is `true` and you pass some context to the compiled validation function with `validate.call(context, data)`, the `context` will be available as `this` in your custom keywords. By default `this` is Ajv instance.
- _loopRequired_: by default `required` keyword is compiled into a single expression (or a sequence of statements in `allErrors` mode). In case of a very large number of properties in this keyword it may result in a very big validation function. Pass integer to set the number of properties above which `required` keyword will be validated in a loop - smaller validation function size but also worse performance.
- _ownProperties_: by default Ajv iterates over all enumerable object properties; when this option is `true` only own enumerable object properties (i.e. found directly on the object rather than on its prototype) are iterated. Contributed by @mbroadst.
- _multipleOfPrecision_: by default `multipleOf` keyword is validated by comparing the result of division with parseInt() of that result. It works for dividers that are bigger than 1. For small dividers such as 0.01 the result of the division is usually not integer (even when it should be integer, see issue [#84](https://github.com/ajv-validator/ajv/issues/84)). If you need to use fractional dividers set this option to some positive integer N to have `multipleOf` validated using this formula: `Math.abs(Math.round(division) - division) < 1e-N` (it is slower but allows for float arithmetics deviations).
- _errorDataPath_ (deprecated): set `dataPath` to point to 'object' (default) or to 'property' when validating keywords `required`, `additionalProperties` and `dependencies`.
- _messages_: Include human-readable messages in errors. `true` by default. `false` can be passed when custom messages are used (e.g. with [ajv-i18n](https://github.com/ajv-validator/ajv-i18n)).
- _sourceCode_: add `sourceCode` property to validating function (for debugging; this code can be different from the result of toString call).
- _processCode_: an optional function to process generated code before it is passed to Function constructor. It can be used to either beautify (the validating function is generated without line-breaks) or to transpile code. Starting from version 5.0.0 this option replaced options:
  - `beautify` that formatted the generated function using [js-beautify](https://github.com/beautify-web/js-beautify). If you want to beautify the generated code pass a function calling `require('js-beautify').js_beautify` as `processCode: code => js_beautify(code)`.
  - `transpile` that transpiled asynchronous validation function. You can still use `transpile` option with [ajv-async](https://github.com/ajv-validator/ajv-async) package. See [Asynchronous validation](#asynchronous-validation) for more information.
- _cache_: an optional instance of cache to store compiled schemas using stable-stringified schema as a key. For example, set-associative cache [sacjs](https://github.com/epoberezkin/sacjs) can be used. If not passed then a simple hash is used which is good enough for the common use case (a limited number of statically defined schemas). Cache should have methods `put(key, value)`, `get(key)`, `del(key)` and `clear()`.
- _serialize_: an optional function to serialize schema to cache key. Pass `false` to use schema itself as a key (e.g., if WeakMap used as a cache). By default [fast-json-stable-stringify](https://github.com/epoberezkin/fast-json-stable-stringify) is used.


## Validation errors

In case of validation failure, Ajv assigns the array of errors to `errors` property of validation function (or to `errors` property of Ajv instance when `validate` or `validateSchema` methods were called). In case of [asynchronous validation](#asynchronous-validation), the returned promise is rejected with exception `Ajv.ValidationError` that has `errors` property.


### Error objects

Each error is an object with the following properties:

- _keyword_: validation keyword.
- _dataPath_: the path to the part of the data that was validated. By default `dataPath` uses JavaScript property access notation (e.g., `".prop[1].subProp"`). When the option `jsonPointers` is true (see [Options](#options)) `dataPath` will be set using JSON pointer standard (e.g., `"/prop/1/subProp"`).
- _schemaPath_: the path (JSON-pointer as a URI fragment) to the schema of the keyword that failed validation.
- _params_: the object with the additional information about error that can be used to create custom error messages (e.g., using [ajv-i18n](https://github.com/ajv-validator/ajv-i18n) package). See below for parameters set by all keywords.
- _message_: the standard error message (can be excluded with option `messages` set to false).
- _schema_: the schema of the keyword (added with `verbose` option).
- _parentSchema_: the schema containing the keyword (added with `verbose` option)
- _data_: the data validated by the keyword (added with `verbose` option).

__Please note__: `propertyNames` keyword schema validation errors have an additional property `propertyName`, `dataPath` points to the object. After schema validation for each property name, if it is invalid an additional error is added with the property `keyword` equal to `"propertyNames"`.


### Error parameters

Properties of `params` object in errors depend on the keyword that failed validation.

- `maxItems`, `minItems`, `maxLength`, `minLength`, `maxProperties`, `minProperties` - property `limit` (number, the schema of the keyword).
- `additionalItems` - property `limit` (the maximum number of allowed items in case when `items` keyword is an array of schemas and `additionalItems` is false).
- `additionalProperties` - property `additionalProperty` (the property not used in `properties` and `patternProperties` keywords).
- `dependencies` - properties:
  - `property` (dependent property),
  - `missingProperty` (required missing dependency - only the first one is reported currently)
  - `deps` (required dependencies, comma separated list as a string),
  - `depsCount` (the number of required dependencies).
- `format` - property `format` (the schema of the keyword).
- `maximum`, `minimum` - properties:
  - `limit` (number, the schema of the keyword),
  - `exclusive` (boolean, the schema of `exclusiveMaximum` or `exclusiveMinimum`),
  - `comparison` (string, comparison operation to compare the data to the limit, with the data on the left and the limit on the right; can be "<", "<=", ">", ">=")
- `multipleOf` - property `multipleOf` (the schema of the keyword)
- `pattern` - property `pattern` (the schema of the keyword)
- `required` - property `missingProperty` (required property that is missing).
- `propertyNames` - property `propertyName` (an invalid property name).
- `patternRequired` (in ajv-keywords) - property `missingPattern` (required pattern that did not match any property).
- `type` - property `type` (required type(s), a string, can be a comma-separated list)
- `uniqueItems` - properties `i` and `j` (indices of duplicate items).
- `const` - property `allowedValue` pointing to the value (the schema of the keyword).
- `enum` - property `allowedValues` pointing to the array of values (the schema of the keyword).
- `$ref` - property `ref` with the referenced schema URI.
- `oneOf` - property `passingSchemas` (array of indices of passing schemas, null if no schema passes).
- custom keywords (in case keyword definition doesn't create errors) - property `keyword` (the keyword name).


### Error logging

Using the `logger` option when initiallizing Ajv will allow you to define custom logging. Here you can build upon the exisiting logging. The use of other logging packages is supported as long as the package or its associated wrapper exposes the required methods. If any of the required methods are missing an exception will be thrown.
- **Required Methods**: `log`, `warn`, `error`

```javascript
var otherLogger = new OtherLogger();
var ajv = new Ajv({
  logger: {
    log: console.log.bind(console),
    warn: function warn() {
      otherLogger.logWarn.apply(otherLogger, arguments);
    },
    error: function error() {
      otherLogger.logError.apply(otherLogger, arguments);
      console.error.apply(console, arguments);
    }
  }
});
```


## Plugins

Ajv can be extended with plugins that add custom keywords, formats or functions to process generated code. When such plugin is published as npm package it is recommended that it follows these conventions:

- it exports a function
- this function accepts ajv instance as the first parameter and returns the same instance to allow chaining
- this function can accept an optional configuration as the second parameter

If you have published a useful plugin please submit a PR to add it to the next section.


## Related packages

- [ajv-async](https://github.com/ajv-validator/ajv-async) - plugin to configure async validation mode
- [ajv-bsontype](https://github.com/BoLaMN/ajv-bsontype) - plugin to validate mongodb's bsonType formats
- [ajv-cli](https://github.com/jessedc/ajv-cli) - command line interface
- [ajv-errors](https://github.com/ajv-validator/ajv-errors) - plugin for custom error messages
- [ajv-i18n](https://github.com/ajv-validator/ajv-i18n) - internationalised error messages
- [ajv-istanbul](https://github.com/ajv-validator/ajv-istanbul) - plugin to instrument generated validation code to measure test coverage of your schemas
- [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) - plugin with custom validation keywords (select, typeof, etc.)
- [ajv-merge-patch](https://github.com/ajv-validator/ajv-merge-patch) - plugin with keywords $merge and $patch
- [ajv-pack](https://github.com/ajv-validator/ajv-pack) - produces a compact module exporting validation functions
- [ajv-formats-draft2019](https://github.com/luzlab/ajv-formats-draft2019) - format validators for draft2019 that aren't already included in ajv (ie. `idn-hostname`, `idn-email`, `iri`, `iri-reference` and `duration`).

## Some packages using Ajv

- [webpack](https://github.com/webpack/webpack) - a module bundler. Its main purpose is to bundle JavaScript files for usage in a browser
- [jsonscript-js](https://github.com/JSONScript/jsonscript-js) - the interpreter for [JSONScript](http://www.jsonscript.org) - scripted processing of existing endpoints and services
- [osprey-method-handler](https://github.com/mulesoft-labs/osprey-method-handler) - Express middleware for validating requests and responses based on a RAML method object, used in [osprey](https://github.com/mulesoft/osprey) - validating API proxy generated from a RAML definition
- [har-validator](https://github.com/ahmadnassri/har-validator) - HTTP Archive (HAR) validator
- [jsoneditor](https://github.com/josdejong/jsoneditor) - a web-based tool to view, edit, format, and validate JSON http://jsoneditoronline.org
- [JSON Schema Lint](https://github.com/nickcmaynard/jsonschemalint) - a web tool to validate JSON/YAML document against a single JSON Schema http://jsonschemalint.com
- [objection](https://github.com/vincit/objection.js) - SQL-friendly ORM for Node.js
- [table](https://github.com/gajus/table) - formats data into a string table
- [ripple-lib](https://github.com/ripple/ripple-lib) - a JavaScript API for interacting with [Ripple](https://ripple.com) in Node.js and the browser
- [restbase](https://github.com/wikimedia/restbase) - distributed storage with REST API & dispatcher for backend services built to provide a low-latency & high-throughput API for Wikipedia / Wikimedia content
- [hippie-swagger](https://github.com/CacheControl/hippie-swagger) - [Hippie](https://github.com/vesln/hippie) wrapper that provides end to end API testing with swagger validation
- [react-form-controlled](https://github.com/seeden/react-form-controlled) - React controlled form components with validation
- [rabbitmq-schema](https://github.com/tjmehta/rabbitmq-schema) - a schema definition module for RabbitMQ graphs and messages
- [@query/schema](https://www.npmjs.com/package/@query/schema) - stream filtering with a URI-safe query syntax parsing to JSON Schema
- [chai-ajv-json-schema](https://github.com/peon374/chai-ajv-json-schema) - chai plugin to us JSON Schema with expect in mocha tests
- [grunt-jsonschema-ajv](https://github.com/SignpostMarv/grunt-jsonschema-ajv) - Grunt plugin for validating files against JSON Schema
- [extract-text-webpack-plugin](https://github.com/webpack-contrib/extract-text-webpack-plugin) - extract text from bundle into a file
- [electron-builder](https://github.com/electron-userland/electron-builder) - a solution to package and build a ready for distribution Electron app
- [addons-linter](https://github.com/mozilla/addons-linter) - Mozilla Add-ons Linter
- [gh-pages-generator](https://github.com/epoberezkin/gh-pages-generator) - multi-page site generator converting markdown files to GitHub pages
- [ESLint](https://github.com/eslint/eslint) - the pluggable linting utility for JavaScript and JSX


## Tests

```
npm install
git submodule update --init
npm test
```

## Contributing

All validation functions are generated using doT templates in [dot](https://github.com/ajv-validator/ajv/tree/master/lib/dot) folder. Templates are precompiled so doT is not a run-time dependency.

`npm run build` - compiles templates to [dotjs](https://github.com/ajv-validator/ajv/tree/master/lib/dotjs) folder.

`npm run watch` - automatically compiles templates when files in dot folder change

Please see [Contributing guidelines](https://github.com/ajv-validator/ajv/blob/master/CONTRIBUTING.md)


## Changes history

See https://github.com/ajv-validator/ajv/releases

__Please note__: [Changes in version 7.0.0-beta](https://github.com/ajv-validator/ajv/releases/tag/v7.0.0-beta.0)

[Version 6.0.0](https://github.com/ajv-validator/ajv/releases/tag/v6.0.0).

## Code of conduct

Please review and follow the [Code of conduct](https://github.com/ajv-validator/ajv/blob/master/CODE_OF_CONDUCT.md).

Please report any unacceptable behaviour to ajv.validator@gmail.com - it will be reviewed by the project team.


## Open-source software support

Ajv is a part of [Tidelift subscription](https://tidelift.com/subscription/pkg/npm-ajv?utm_source=npm-ajv&utm_medium=referral&utm_campaign=readme) - it provides a centralised support to open-source software users, in addition to the support provided by software maintainers.


## License

[MIT](https://github.com/ajv-validator/ajv/blob/master/LICENSE)
These files are compiled dot templates from dot folder.

Do NOT edit them directly, edit the templates and run `npm run build` from main ajv folder.
# @eslint-community/eslint-utils

[![npm version](https://img.shields.io/npm/v/@eslint-community/eslint-utils.svg)](https://www.npmjs.com/package/@eslint-community/eslint-utils)
[![Downloads/month](https://img.shields.io/npm/dm/@eslint-community/eslint-utils.svg)](http://www.npmtrends.com/@eslint-community/eslint-utils)
[![Build Status](https://github.com/eslint-community/eslint-utils/workflows/CI/badge.svg)](https://github.com/eslint-community/eslint-utils/actions)
[![Coverage Status](https://codecov.io/gh/eslint-community/eslint-utils/branch/main/graph/badge.svg)](https://codecov.io/gh/eslint-community/eslint-utils)

## 🏁 Goal

This package provides utility functions and classes for make ESLint custom rules.

For examples:

-   [`getStaticValue`](https://eslint-community.github.io/eslint-utils/api/ast-utils.html#getstaticvalue) evaluates static value on AST.
-   [`ReferenceTracker`](https://eslint-community.github.io/eslint-utils/api/scope-utils.html#referencetracker-class) checks the members of modules/globals as handling assignments and destructuring.

## 📖 Usage

See [documentation](https://eslint-community.github.io/eslint-utils).

## 📰 Changelog

See [releases](https://github.com/eslint-community/eslint-utils/releases).

## ❤️ Contributing

Welcome contributing!

Please use GitHub's Issues/PRs.

### Development Tools

-   `npm test` runs tests and measures coverage.
-   `npm run clean` removes the coverage result of `npm test` command.
-   `npm run coverage` shows the coverage result of the last `npm test` command.
-   `npm run lint` runs ESLint.
-   `npm run watch` runs tests on each file change.
# @eslint-community/regexpp

[![npm version](https://img.shields.io/npm/v/@eslint-community/regexpp.svg)](https://www.npmjs.com/package/@eslint-community/regexpp)
[![Downloads/month](https://img.shields.io/npm/dm/@eslint-community/regexpp.svg)](http://www.npmtrends.com/@eslint-community/regexpp)
[![Build Status](https://github.com/eslint-community/regexpp/workflows/CI/badge.svg)](https://github.com/eslint-community/regexpp/actions)
[![codecov](https://codecov.io/gh/eslint-community/regexpp/branch/main/graph/badge.svg)](https://codecov.io/gh/eslint-community/regexpp)

A regular expression parser for ECMAScript.

## 💿 Installation

```bash
$ npm install @eslint-community/regexpp
```

- require Node@^12.0.0 || ^14.0.0 || >=16.0.0.

## 📖 Usage

```ts
import {
    AST,
    RegExpParser,
    RegExpValidator,
    RegExpVisitor,
    parseRegExpLiteral,
    validateRegExpLiteral,
    visitRegExpAST
} from "@eslint-community/regexpp"
```

### parseRegExpLiteral(source, options?)

Parse a given regular expression literal then make AST object.

This is equivalent to `new RegExpParser(options).parseLiteral(source)`.

- **Parameters:**
    - `source` (`string | RegExp`) The source code to parse.
    - `options?` ([`RegExpParser.Options`]) The options to parse.
- **Return:**
    - The AST of the regular expression.

### validateRegExpLiteral(source, options?)

Validate a given regular expression literal.

This is equivalent to `new RegExpValidator(options).validateLiteral(source)`.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `options?` ([`RegExpValidator.Options`]) The options to validate.

### visitRegExpAST(ast, handlers)

Visit each node of a given AST.

This is equivalent to `new RegExpVisitor(handlers).visit(ast)`.

- **Parameters:**
    - `ast` ([`AST.Node`]) The AST to visit.
    - `handlers` ([`RegExpVisitor.Handlers`]) The callbacks.

### RegExpParser

#### new RegExpParser(options?)

- **Parameters:**
    - `options?` ([`RegExpParser.Options`]) The options to parse.

#### parser.parseLiteral(source, start?, end?)

Parse a regular expression literal.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"/abc/g"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
- **Return:**
    - The AST of the regular expression.

#### parser.parsePattern(source, start?, end?, flags?)

Parse a regular expression pattern.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"abc"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
    - `flags?` (`{ unicode?: boolean, unicodeSets?: boolean }`) The flags to enable Unicode mode, and Unicode Set mode.
- **Return:**
    - The AST of the regular expression pattern.

#### parser.parseFlags(source, start?, end?)

Parse a regular expression flags.

- **Parameters:**
    - `source` (`string`) The source code to parse. E.g. `"gim"`.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
- **Return:**
    - The AST of the regular expression flags.

### RegExpValidator

#### new RegExpValidator(options)

- **Parameters:**
    - `options` ([`RegExpValidator.Options`]) The options to validate.

#### validator.validateLiteral(source, start, end)

Validate a regular expression literal.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.

#### validator.validatePattern(source, start, end, flags)

Validate a regular expression pattern.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.
    - `flags?` (`{ unicode?: boolean, unicodeSets?: boolean }`) The flags to enable Unicode mode, and Unicode Set mode.

#### validator.validateFlags(source, start, end)

Validate a regular expression flags.

- **Parameters:**
    - `source` (`string`) The source code to validate.
    - `start?` (`number`) The start index in the source code. Default is `0`.
    - `end?` (`number`) The end index in the source code. Default is `source.length`.

### RegExpVisitor

#### new RegExpVisitor(handlers)

- **Parameters:**
    - `handlers` ([`RegExpVisitor.Handlers`]) The callbacks.

#### visitor.visit(ast)

Validate a regular expression literal.

- **Parameters:**
    - `ast` ([`AST.Node`]) The AST to visit.

## 📰 Changelog

- [GitHub Releases](https://github.com/eslint-community/regexpp/releases)

## 🍻 Contributing

Welcome contributing!

Please use GitHub's Issues/PRs.

### Development Tools

- `npm test` runs tests and measures coverage.
- `npm run build` compiles TypeScript source code to `index.js`, `index.js.map`, and `index.d.ts`.
- `npm run clean` removes the temporary files which are created by `npm test` and `npm run build`.
- `npm run lint` runs ESLint.
- `npm run update:test` updates test fixtures.
- `npm run update:ids` updates `src/unicode/ids.ts`.
- `npm run watch` runs tests with `--watch` option.

[`AST.Node`]: src/ast.ts#L4
[`RegExpParser.Options`]: src/parser.ts#L743
[`RegExpValidator.Options`]: src/validator.ts#L220
[`RegExpVisitor.Handlers`]: src/visitor.ts#L291
# type-check [![Build Status](https://travis-ci.org/gkz/type-check.png?branch=master)](https://travis-ci.org/gkz/type-check)

<a name="type-check" />

`type-check` is a library which allows you to check the types of JavaScript values at runtime with a Haskell like type syntax. It is great for checking external input, for testing, or even for adding a bit of safety to your internal code. It is a major component of [levn](https://github.com/gkz/levn). MIT license. Version 0.4.0. Check out the [demo](http://gkz.github.io/type-check/).

For updates on `type-check`, [follow me on twitter](https://twitter.com/gkzahariev).

    npm install type-check

## Quick Examples

```js
// Basic types:
var typeCheck = require('type-check').typeCheck;
typeCheck('Number', 1);               // true
typeCheck('Number', 'str');           // false
typeCheck('Error', new Error);        // true
typeCheck('Undefined', undefined);    // true

// Comment
typeCheck('count::Number', 1);        // true

// One type OR another type:
typeCheck('Number | String', 2);      // true
typeCheck('Number | String', 'str');  // true

// Wildcard, matches all types:
typeCheck('*', 2) // true

// Array, all elements of a single type:
typeCheck('[Number]', [1, 2, 3]);                // true
typeCheck('[Number]', [1, 'str', 3]);            // false

// Tuples, or fixed length arrays with elements of different types:
typeCheck('(String, Number)', ['str', 2]);       // true
typeCheck('(String, Number)', ['str']);          // false
typeCheck('(String, Number)', ['str', 2, 5]);    // false

// Object properties:
typeCheck('{x: Number, y: Boolean}', {x: 2, y: false});             // true
typeCheck('{x: Number, y: Boolean}',       {x: 2});                 // false
typeCheck('{x: Number, y: Maybe Boolean}', {x: 2});                 // true
typeCheck('{x: Number, y: Boolean}',      {x: 2, y: false, z: 3});  // false
typeCheck('{x: Number, y: Boolean, ...}', {x: 2, y: false, z: 3});  // true

// A particular type AND object properties:
typeCheck('RegExp{source: String, ...}', /re/i);          // true
typeCheck('RegExp{source: String, ...}', {source: 're'}); // false

// Custom types:
var opt = {customTypes:
  {Even: { typeOf: 'Number', validate: function(x) { return x % 2 === 0; }}}};
typeCheck('Even', 2, opt); // true

// Nested:
var type = '{a: (String, [Number], {y: Array, ...}), b: Error{message: String, ...}}'
typeCheck(type, {a: ['hi', [1, 2, 3], {y: [1, 'ms']}], b: new Error('oh no')}); // true
```

Check out the [type syntax format](#syntax) and [guide](#guide).

## Usage

`require('type-check');` returns an object that exposes four properties. `VERSION` is the current version of the library as a string. `typeCheck`, `parseType`, and `parsedTypeCheck` are functions.

```js
// typeCheck(type, input, options);
typeCheck('Number', 2);               // true

// parseType(type);
var parsedType = parseType('Number'); // object

// parsedTypeCheck(parsedType, input, options);
parsedTypeCheck(parsedType, 2);       // true
```

### typeCheck(type, input, options)

`typeCheck` checks a JavaScript value `input` against `type` written in the [type format](#type-format) (and taking account the optional `options`) and returns whether the `input` matches the `type`.

##### arguments
* type - `String` - the type written in the [type format](#type-format) which to check against
* input - `*` - any JavaScript value, which is to be checked against the type
* options - `Maybe Object` - an optional parameter specifying additional options, currently the only available option is specifying [custom types](#custom-types)

##### returns
`Boolean` - whether the input matches the type

##### example
```js
typeCheck('Number', 2); // true
```

### parseType(type)

`parseType` parses string `type` written in the [type format](#type-format) into an object representing the parsed type.

##### arguments
* type - `String` - the type written in the [type format](#type-format) which to parse

##### returns
`Object` - an object in the parsed type format representing the parsed type

##### example
```js
parseType('Number'); // [{type: 'Number'}]
```
### parsedTypeCheck(parsedType, input, options)

`parsedTypeCheck` checks a JavaScript value `input` against parsed `type` in the parsed type format (and taking account the optional `options`) and returns whether the `input` matches the `type`. Use this in conjunction with `parseType` if you are going to use a type more than once.

##### arguments
* type - `Object` - the type in the parsed type format which to check against
* input - `*` - any JavaScript value, which is to be checked against the type
* options - `Maybe Object` - an optional parameter specifying additional options, currently the only available option is specifying [custom types](#custom-types)

##### returns
`Boolean` - whether the input matches the type

##### example
```js
parsedTypeCheck([{type: 'Number'}], 2); // true
var parsedType = parseType('String');
parsedTypeCheck(parsedType, 'str');     // true
```

<a name="type-format" />
## Type Format

### Syntax

White space is ignored. The root node is a __Types__.

* __Identifier__ = `[\$\w]+` - a group of any lower or upper case letters, numbers, underscores, or dollar signs - eg. `String`
* __Type__ = an `Identifier`, an `Identifier` followed by a `Structure`, just a `Structure`, or a wildcard `*` - eg. `String`, `Object{x: Number}`, `{x: Number}`, `Array{0: String, 1: Boolean, length: Number}`, `*`
* __Types__ = optionally a comment (an `Identifier` followed by a `::`), optionally the identifier `Maybe`, one or more `Type`, separated by `|` - eg. `Number`, `String | Date`, `Maybe Number`, `Maybe Boolean | String`
* __Structure__ = `Fields`, or a `Tuple`, or an `Array` - eg. `{x: Number}`, `(String, Number)`, `[Date]`
* __Fields__ = a `{`, followed one or more `Field` separated by a comma `,` (trailing comma `,` is permitted), optionally an `...` (always preceded by a comma `,`), followed by a `}` - eg. `{x: Number, y: String}`, `{k: Function, ...}`
* __Field__ = an `Identifier`, followed by a colon `:`, followed by `Types` - eg. `x: Date | String`, `y: Boolean`
* __Tuple__ = a `(`, followed by one or more `Types` separated by a comma `,` (trailing comma `,` is permitted), followed by a `)` - eg `(Date)`, `(Number, Date)`
* __Array__ = a `[` followed by exactly one `Types` followed by a `]` - eg. `[Boolean]`, `[Boolean | Null]`

### Guide

`type-check` uses `Object.toString` to find out the basic type of a value. Specifically,

```js
{}.toString.call(VALUE).slice(8, -1)
{}.toString.call(true).slice(8, -1) // 'Boolean'
```
A basic type, eg. `Number`, uses this check. This is much more versatile than using `typeof` - for example, with `document`, `typeof` produces `'object'` which isn't that useful, and our technique produces `'HTMLDocument'`.

You may check for multiple types by separating types with a `|`. The checker proceeds from left to right, and passes if the value is any of the types - eg. `String | Boolean` first checks if the value is a string, and then if it is a boolean. If it is none of those, then it returns false.

Adding a `Maybe` in front of a list of multiple types is the same as also checking for `Null` and `Undefined` - eg. `Maybe String` is equivalent to `Undefined | Null | String`.

You may add a comment to remind you of what the type is for by following an identifier with a `::` before a type (or multiple types). The comment is simply thrown out.

The wildcard `*` matches all types.

There are three types of structures for checking the contents of a value: 'fields', 'tuple', and 'array'.

If used by itself, a 'fields' structure will pass with any type of object as long as it is an instance of `Object` and the properties pass - this allows for duck typing - eg. `{x: Boolean}`.

To check if the properties pass, and the value is of a certain type, you can specify the type - eg. `Error{message: String}`.

If you want to make a field optional, you can simply use `Maybe` - eg. `{x: Boolean, y: Maybe String}` will still pass if `y` is undefined (or null).

If you don't care if the value has properties beyond what you have specified, you can use the 'etc' operator `...` - eg. `{x: Boolean, ...}` will match an object with an `x` property that is a boolean, and with zero or more other properties.

For an array, you must specify one or more types (separated by `|`) - it will pass for something of any length as long as each element passes the types provided - eg. `[Number]`, `[Number | String]`.

A tuple checks for a fixed number of elements, each of a potentially different type. Each element is separated by a comma - eg. `(String, Number)`.

An array and tuple structure check that the value is of type `Array` by default, but if another type is specified, they will check for that instead - eg. `Int32Array[Number]`. You can use the wildcard `*` to search for any type at all.

Check out the [type precedence](https://github.com/zaboco/type-precedence) library for type-check.

## Options

Options is an object. It is an optional parameter to the `typeCheck` and `parsedTypeCheck` functions. The only current option is `customTypes`.

<a name="custom-types" />
### Custom Types

__Example:__

```js
var options = {
  customTypes: {
    Even: {
      typeOf: 'Number',
      validate: function(x) {
        return x % 2 === 0;
      }
    }
  }
};
typeCheck('Even', 2, options); // true
typeCheck('Even', 3, options); // false
```

`customTypes` allows you to set up custom types for validation. The value of this is an object. The keys of the object are the types you will be matching. Each value of the object will be an object having a `typeOf` property - a string, and `validate` property - a function.

The `typeOf` property is the type the value should be (optional - if not set only `validate` will be used), and `validate` is a function which should return true if the value is of that type. `validate` receives one parameter, which is the value that we are checking.

## Technical About

`type-check` is written in [LiveScript](http://livescript.net/) - a language that compiles to JavaScript. It also uses the [prelude.ls](http://preludels.com/) library.
# locate-path [![Build Status](https://travis-ci.com/sindresorhus/locate-path.svg?branch=master)](https://travis-ci.com/github/sindresorhus/locate-path)

> Get the first path that exists on disk of multiple paths

## Install

```
$ npm install locate-path
```

## Usage

Here we find the first file that exists on disk, in array order.

```js
const locatePath = require('locate-path');

const files = [
	'unicorn.png',
	'rainbow.png', // Only this one actually exists on disk
	'pony.png'
];

(async () => {
	console(await locatePath(files));
	//=> 'rainbow'
})();
```

## API

### locatePath(paths, options?)

Returns a `Promise<string>` for the first path that exists or `undefined` if none exists.

#### paths

Type: `Iterable<string>`

Paths to check.

#### options

Type: `object`

##### concurrency

Type: `number`\
Default: `Infinity`\
Minimum: `1`

Number of concurrently pending promises.

##### preserveOrder

Type: `boolean`\
Default: `true`

Preserve `paths` order when searching.

Disable this to improve performance if you don't care about the order.

##### cwd

Type: `string`\
Default: `process.cwd()`

Current working directory.

##### type

Type: `string`\
Default: `'file'`\
Values: `'file' | 'directory'`

The type of paths that can match.

##### allowSymlinks

Type: `boolean`\
Default: `true`

Allow symbolic links to match if they point to the chosen path type.

### locatePath.sync(paths, options?)

Returns the first path that exists or `undefined` if none exists.

#### paths

Type: `Iterable<string>`

Paths to check.

#### options

Type: `object`

##### cwd

Same as above.

##### type

Same as above.

##### allowSymlinks

Same as above.

## Related

- [path-exists](https://github.com/sindresorhus/path-exists) - Check if a path exists

---

<div align="center">
	<b>
		<a href="https://tidelift.com/subscription/pkg/npm-locate-path?utm_source=npm-locate-path&utm_medium=referral&utm_campaign=readme">Get professional support for this package with a Tidelift subscription</a>
	</b>
	<br>
	<sub>
		Tidelift helps make open source sustainable for maintainers while giving companies<br>assurances about security, maintenance, and licensing for their dependencies.
	</sub>
</div>
# globby

> User-friendly glob matching

Based on [`fast-glob`](https://github.com/mrmlnc/fast-glob) but adds a bunch of useful features.

## Features

- Promise API
- Multiple patterns
- Negated patterns: `['foo*', '!foobar']`
- Expands directories: `foo` → `foo/**/*`
- Supports `.gitignore`

## Install

```
$ npm install globby
```

## Usage

```
├── unicorn
├── cake
└── rainbow
```

```js
const globby = require('globby');

(async () => {
	const paths = await globby(['*', '!cake']);

	console.log(paths);
	//=> ['unicorn', 'rainbow']
})();
```

## API

Note that glob patterns can only contain forward-slashes, not backward-slashes, so if you want to construct a glob pattern from path components, you need to use `path.posix.join()` instead of `path.join()`.

### globby(patterns, options?)

Returns a `Promise<string[]>` of matching paths.

#### patterns

Type: `string | string[]`

See supported `minimatch` [patterns](https://github.com/isaacs/minimatch#usage).

#### options

Type: `object`

See the [`fast-glob` options](https://github.com/mrmlnc/fast-glob#options-3) in addition to the ones below.

##### expandDirectories

Type: `boolean | string[] | object`\
Default: `true`

If set to `true`, `globby` will automatically glob directories for you. If you define an `Array` it will only glob files that matches the patterns inside the `Array`. You can also define an `object` with `files` and `extensions` like below:

```js
const globby = require('globby');

(async () => {
	const paths = await globby('images', {
		expandDirectories: {
			files: ['cat', 'unicorn', '*.jpg'],
			extensions: ['png']
		}
	});

	console.log(paths);
	//=> ['cat.png', 'unicorn.png', 'cow.jpg', 'rainbow.jpg']
})();
```

Note that if you set this option to `false`, you won't get back matched directories unless you set `onlyFiles: false`.

##### gitignore

Type: `boolean`\
Default: `false`

Respect ignore patterns in `.gitignore` files that apply to the globbed files.

### globby.sync(patterns, options?)

Returns `string[]` of matching paths.

### globby.stream(patterns, options?)

Returns a [`stream.Readable`](https://nodejs.org/api/stream.html#stream_readable_streams) of matching paths.

Since Node.js 10, [readable streams are iterable](https://nodejs.org/api/stream.html#stream_readable_symbol_asynciterator), so you can loop over glob matches in a [`for await...of` loop](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of) like this:

```js
const globby = require('globby');

(async () => {
	for await (const path of globby.stream('*.tmp')) {
		console.log(path);
	}
})();
```

### globby.generateGlobTasks(patterns, options?)

Returns an `object[]` in the format `{pattern: string, options: Object}`, which can be passed as arguments to [`fast-glob`](https://github.com/mrmlnc/fast-glob). This is useful for other globbing-related packages.

Note that you should avoid running the same tasks multiple times as they contain a file system cache. Instead, run this method each time to ensure file system changes are taken into consideration.

### globby.hasMagic(patterns, options?)

Returns a `boolean` of whether there are any special glob characters in the `patterns`.

Note that the options affect the results.

This function is backed by [`fast-glob`](https://github.com/mrmlnc/fast-glob#isdynamicpatternpattern-options).

### globby.gitignore(options?)

Returns a `Promise<(path: string) => boolean>` indicating whether a given path is ignored via a `.gitignore` file.

Takes `cwd?: string` and `ignore?: string[]` as options. `.gitignore` files matched by the ignore config are not used for the resulting filter function.

```js
const {gitignore} = require('globby');

(async () => {
	const isIgnored = await gitignore();
	console.log(isIgnored('some/file'));
})();
```

### globby.gitignore.sync(options?)

Returns a `(path: string) => boolean` indicating whether a given path is ignored via a `.gitignore` file.

Takes the same options as `globby.gitignore`.

## Globbing patterns

Just a quick overview.

- `*` matches any number of characters, but not `/`
- `?` matches a single character, but not `/`
- `**` matches any number of characters, including `/`, as long as it's the only thing in a path part
- `{}` allows for a comma-separated list of "or" expressions
- `!` at the beginning of a pattern will negate the match

[Various patterns and expected matches.](https://github.com/sindresorhus/multimatch/blob/main/test/test.js)

## globby for enterprise

Available as part of the Tidelift Subscription.

The maintainers of globby and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](https://tidelift.com/subscription/pkg/npm-globby?utm_source=npm-globby&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)

## Related

- [multimatch](https://github.com/sindresorhus/multimatch) - Match against a list instead of the filesystem
- [matcher](https://github.com/sindresorhus/matcher) - Simple wildcard matching
- [del](https://github.com/sindresorhus/del) - Delete files and directories
- [make-dir](https://github.com/sindresorhus/make-dir) - Make a directory and its parents if needed
# fast-deep-equal
The fastest deep equal with ES6 Map, Set and Typed arrays support.

[![Build Status](https://travis-ci.org/epoberezkin/fast-deep-equal.svg?branch=master)](https://travis-ci.org/epoberezkin/fast-deep-equal)
[![npm](https://img.shields.io/npm/v/fast-deep-equal.svg)](https://www.npmjs.com/package/fast-deep-equal)
[![Coverage Status](https://coveralls.io/repos/github/epoberezkin/fast-deep-equal/badge.svg?branch=master)](https://coveralls.io/github/epoberezkin/fast-deep-equal?branch=master)


## Install

```bash
npm install fast-deep-equal
```


## Features

- ES5 compatible
- works in node.js (8+) and browsers (IE9+)
- checks equality of Date and RegExp objects by value.

ES6 equal (`require('fast-deep-equal/es6')`) also supports:
- Maps
- Sets
- Typed arrays


## Usage

```javascript
var equal = require('fast-deep-equal');
console.log(equal({foo: 'bar'}, {foo: 'bar'})); // true
```

To support ES6 Maps, Sets and Typed arrays equality use:

```javascript
var equal = require('fast-deep-equal/es6');
console.log(equal(Int16Array([1, 2]), Int16Array([1, 2]))); // true
```

To use with React (avoiding the traversal of React elements' _owner
property that contains circular references and is not needed when
comparing the elements - borrowed from [react-fast-compare](https://github.com/FormidableLabs/react-fast-compare)):

```javascript
var equal = require('fast-deep-equal/react');
var equal = require('fast-deep-equal/es6/react');
```


## Performance benchmark

Node.js v12.6.0:

```
fast-deep-equal x 261,950 ops/sec ±0.52% (89 runs sampled)
fast-deep-equal/es6 x 212,991 ops/sec ±0.34% (92 runs sampled)
fast-equals x 230,957 ops/sec ±0.83% (85 runs sampled)
nano-equal x 187,995 ops/sec ±0.53% (88 runs sampled)
shallow-equal-fuzzy x 138,302 ops/sec ±0.49% (90 runs sampled)
underscore.isEqual x 74,423 ops/sec ±0.38% (89 runs sampled)
lodash.isEqual x 36,637 ops/sec ±0.72% (90 runs sampled)
deep-equal x 2,310 ops/sec ±0.37% (90 runs sampled)
deep-eql x 35,312 ops/sec ±0.67% (91 runs sampled)
ramda.equals x 12,054 ops/sec ±0.40% (91 runs sampled)
util.isDeepStrictEqual x 46,440 ops/sec ±0.43% (90 runs sampled)
assert.deepStrictEqual x 456 ops/sec ±0.71% (88 runs sampled)

The fastest is fast-deep-equal
```

To run benchmark (requires node.js 6+):

```bash
npm run benchmark
```

__Please note__: this benchmark runs against the available test cases. To choose the most performant library for your application, it is recommended to benchmark against your data and to NOT expect this benchmark to reflect the performance difference in your application.


## Enterprise support

fast-deep-equal package is a part of [Tidelift enterprise subscription](https://tidelift.com/subscription/pkg/npm-fast-deep-equal?utm_source=npm-fast-deep-equal&utm_medium=referral&utm_campaign=enterprise&utm_term=repo) - it provides a centralised commercial support to open-source software users, in addition to the support provided by software maintainers.


## Security contact

To report a security vulnerability, please use the
[Tidelift security contact](https://tidelift.com/security).
Tidelift will coordinate the fix and disclosure. Please do NOT report security vulnerability via GitHub issues.


## License

[MIT](https://github.com/epoberezkin/fast-deep-equal/blob/master/LICENSE)
# shebang-command [![Build Status](https://travis-ci.org/kevva/shebang-command.svg?branch=master)](https://travis-ci.org/kevva/shebang-command)

> Get the command from a shebang


## Install

```
$ npm install shebang-command
```


## Usage

```js
const shebangCommand = require('shebang-command');

shebangCommand('#!/usr/bin/env node');
//=> 'node'

shebangCommand('#!/bin/bash');
//=> 'bash'
```


## API

### shebangCommand(string)

#### string

Type: `string`

String containing a shebang.
# debug
[![Build Status](https://travis-ci.org/debug-js/debug.svg?branch=master)](https://travis-ci.org/debug-js/debug)  [![Coverage Status](https://coveralls.io/repos/github/debug-js/debug/badge.svg?branch=master)](https://coveralls.io/github/debug-js/debug?branch=master)  [![Slack](https://visionmedia-community-slackin.now.sh/badge.svg)](https://visionmedia-community-slackin.now.sh/) [![OpenCollective](https://opencollective.com/debug/backers/badge.svg)](#backers)
[![OpenCollective](https://opencollective.com/debug/sponsors/badge.svg)](#sponsors)

<img width="647" src="https://user-images.githubusercontent.com/71256/29091486-fa38524c-7c37-11e7-895f-e7ec8e1039b6.png">

A tiny JavaScript debugging utility modelled after Node.js core's debugging
technique. Works in Node.js and web browsers.

## Installation

```bash
$ npm install debug
```

## Usage

`debug` exposes a function; simply pass this function the name of your module, and it will return a decorated version of `console.error` for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole.

Example [_app.js_](./examples/node/app.js):

```js
var debug = require('debug')('http')
  , http = require('http')
  , name = 'My App';

// fake app

debug('booting %o', name);

http.createServer(function(req, res){
  debug(req.method + ' ' + req.url);
  res.end('hello\n');
}).listen(3000, function(){
  debug('listening');
});

// fake worker of some kind

require('./worker');
```

Example [_worker.js_](./examples/node/worker.js):

```js
var a = require('debug')('worker:a')
  , b = require('debug')('worker:b');

function work() {
  a('doing lots of uninteresting work');
  setTimeout(work, Math.random() * 1000);
}

work();

function workb() {
  b('doing some work');
  setTimeout(workb, Math.random() * 2000);
}

workb();
```

The `DEBUG` environment variable is then used to enable these based on space or
comma-delimited names.

Here are some examples:

<img width="647" alt="screen shot 2017-08-08 at 12 53 04 pm" src="https://user-images.githubusercontent.com/71256/29091703-a6302cdc-7c38-11e7-8304-7c0b3bc600cd.png">
<img width="647" alt="screen shot 2017-08-08 at 12 53 38 pm" src="https://user-images.githubusercontent.com/71256/29091700-a62a6888-7c38-11e7-800b-db911291ca2b.png">
<img width="647" alt="screen shot 2017-08-08 at 12 53 25 pm" src="https://user-images.githubusercontent.com/71256/29091701-a62ea114-7c38-11e7-826a-2692bedca740.png">

#### Windows command prompt notes

##### CMD

On Windows the environment variable is set using the `set` command.

```cmd
set DEBUG=*,-not_this
```

Example:

```cmd
set DEBUG=* & node app.js
```

##### PowerShell (VS Code default)

PowerShell uses different syntax to set environment variables.

```cmd
$env:DEBUG = "*,-not_this"
```

Example:

```cmd
$env:DEBUG='app';node app.js
```

Then, run the program to be debugged as usual.

npm script example:
```js
  "windowsDebug": "@powershell -Command $env:DEBUG='*';node app.js",
```

## Namespace Colors

Every debug instance has a color generated for it based on its namespace name.
This helps when visually parsing the debug output to identify which debug instance
a debug line belongs to.

#### Node.js

In Node.js, colors are enabled when stderr is a TTY. You also _should_ install
the [`supports-color`](https://npmjs.org/supports-color) module alongside debug,
otherwise debug will only use a small handful of basic colors.

<img width="521" src="https://user-images.githubusercontent.com/71256/29092181-47f6a9e6-7c3a-11e7-9a14-1928d8a711cd.png">

#### Web Browser

Colors are also enabled on "Web Inspectors" that understand the `%c` formatting
option. These are WebKit web inspectors, Firefox ([since version
31](https://hacks.mozilla.org/2014/05/editable-box-model-multiple-selection-sublime-text-keys-much-more-firefox-developer-tools-episode-31/))
and the Firebug plugin for Firefox (any version).

<img width="524" src="https://user-images.githubusercontent.com/71256/29092033-b65f9f2e-7c39-11e7-8e32-f6f0d8e865c1.png">


## Millisecond diff

When actively developing an application it can be useful to see when the time spent between one `debug()` call and the next. Suppose for example you invoke `debug()` before requesting a resource, and after as well, the "+NNNms" will show you how much time was spent between calls.

<img width="647" src="https://user-images.githubusercontent.com/71256/29091486-fa38524c-7c37-11e7-895f-e7ec8e1039b6.png">

When stdout is not a TTY, `Date#toISOString()` is used, making it more useful for logging the debug information as shown below:

<img width="647" src="https://user-images.githubusercontent.com/71256/29091956-6bd78372-7c39-11e7-8c55-c948396d6edd.png">


## Conventions

If you're using this in one or more of your libraries, you _should_ use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you _should_ prefix them with your library name and use ":" to separate features. For example "bodyParser" from Connect would then be "connect:bodyParser".  If you append a "*" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable.  You can then use it for normal output as well as debug output.

## Wildcards

The `*` character may be used as a wildcard. Suppose for example your library has
debuggers named "connect:bodyParser", "connect:compress", "connect:session",
instead of listing all three with
`DEBUG=connect:bodyParser,connect:compress,connect:session`, you may simply do
`DEBUG=connect:*`, or to run everything using this module simply use `DEBUG=*`.

You can also exclude specific debuggers by prefixing them with a "-" character.
For example, `DEBUG=*,-connect:*` would include all debuggers except those
starting with "connect:".

## Environment Variables

When running through Node.js, you can set a few environment variables that will
change the behavior of the debug logging:

| Name      | Purpose                                         |
|-----------|-------------------------------------------------|
| `DEBUG`   | Enables/disables specific debugging namespaces. |
| `DEBUG_HIDE_DATE` | Hide date from debug output (non-TTY).  |
| `DEBUG_COLORS`| Whether or not to use colors in the debug output. |
| `DEBUG_DEPTH` | Object inspection depth.                    |
| `DEBUG_SHOW_HIDDEN` | Shows hidden properties on inspected objects. |


__Note:__ The environment variables beginning with `DEBUG_` end up being
converted into an Options object that gets used with `%o`/`%O` formatters.
See the Node.js documentation for
[`util.inspect()`](https://nodejs.org/api/util.html#util_util_inspect_object_options)
for the complete list.

## Formatters

Debug uses [printf-style](https://wikipedia.org/wiki/Printf_format_string) formatting.
Below are the officially supported formatters:

| Formatter | Representation |
|-----------|----------------|
| `%O`      | Pretty-print an Object on multiple lines. |
| `%o`      | Pretty-print an Object all on a single line. |
| `%s`      | String. |
| `%d`      | Number (both integer and float). |
| `%j`      | JSON. Replaced with the string '[Circular]' if the argument contains circular references. |
| `%%`      | Single percent sign ('%'). This does not consume an argument. |


### Custom formatters

You can add custom formatters by extending the `debug.formatters` object.
For example, if you wanted to add support for rendering a Buffer as hex with
`%h`, you could do something like:

```js
const createDebug = require('debug')
createDebug.formatters.h = (v) => {
  return v.toString('hex')
}

// …elsewhere
const debug = createDebug('foo')
debug('this is hex: %h', new Buffer('hello world'))
//   foo this is hex: 68656c6c6f20776f726c6421 +0ms
```


## Browser Support

You can build a browser-ready script using [browserify](https://github.com/substack/node-browserify),
or just use the [browserify-as-a-service](https://wzrd.in/) [build](https://wzrd.in/standalone/debug@latest),
if you don't want to build it yourself.

Debug's enable state is currently persisted by `localStorage`.
Consider the situation shown below where you have `worker:a` and `worker:b`,
and wish to debug both. You can enable this using `localStorage.debug`:

```js
localStorage.debug = 'worker:*'
```

And then refresh the page.

```js
a = debug('worker:a');
b = debug('worker:b');

setInterval(function(){
  a('doing some work');
}, 1000);

setInterval(function(){
  b('doing some work');
}, 1200);
```

In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by `debug` if the "Verbose" log level is _enabled_.

<img width="647" src="https://user-images.githubusercontent.com/7143133/152083257-29034707-c42c-4959-8add-3cee850e6fcf.png">

## Output streams

  By default `debug` will log to stderr, however this can be configured per-namespace by overriding the `log` method:

Example [_stdout.js_](./examples/node/stdout.js):

```js
var debug = require('debug');
var error = debug('app:error');

// by default stderr is used
error('goes to stderr!');

var log = debug('app:log');
// set this namespace to log via console.log
log.log = console.log.bind(console); // don't forget to bind to console!
log('goes to stdout');
error('still goes to stderr!');

// set all output to go via console.info
// overrides all per-namespace log settings
debug.log = console.info.bind(console);
error('now goes to stdout via console.info');
log('still goes to stdout, but via console.info now');
```

## Extend
You can simply extend debugger 
```js
const log = require('debug')('auth');

//creates new debug instance with extended namespace
const logSign = log.extend('sign');
const logLogin = log.extend('login');

log('hello'); // auth hello
logSign('hello'); //auth:sign hello
logLogin('hello'); //auth:login hello
```

## Set dynamically

You can also enable debug dynamically by calling the `enable()` method :

```js
let debug = require('debug');

console.log(1, debug.enabled('test'));

debug.enable('test');
console.log(2, debug.enabled('test'));

debug.disable();
console.log(3, debug.enabled('test'));

```

print :   
```
1 false
2 true
3 false
```

Usage :  
`enable(namespaces)`  
`namespaces` can include modes separated by a colon and wildcards.
   
Note that calling `enable()` completely overrides previously set DEBUG variable : 

```
$ DEBUG=foo node -e 'var dbg = require("debug"); dbg.enable("bar"); console.log(dbg.enabled("foo"))'
=> false
```

`disable()`

Will disable all namespaces. The functions returns the namespaces currently
enabled (and skipped). This can be useful if you want to disable debugging
temporarily without knowing what was enabled to begin with.

For example:

```js
let debug = require('debug');
debug.enable('foo:*,-foo:bar');
let namespaces = debug.disable();
debug.enable(namespaces);
```

Note: There is no guarantee that the string will be identical to the initial
enable string, but semantically they will be identical.

## Checking whether a debug target is enabled

After you've created a debug instance, you can determine whether or not it is
enabled by checking the `enabled` property:

```javascript
const debug = require('debug')('http');

if (debug.enabled) {
  // do stuff...
}
```

You can also manually toggle this property to force the debug instance to be
enabled or disabled.

## Usage in child processes

Due to the way `debug` detects if the output is a TTY or not, colors are not shown in child processes when `stderr` is piped. A solution is to pass the `DEBUG_COLORS=1` environment variable to the child process.  
For example:

```javascript
worker = fork(WORKER_WRAP_PATH, [workerPath], {
  stdio: [
    /* stdin: */ 0,
    /* stdout: */ 'pipe',
    /* stderr: */ 'pipe',
    'ipc',
  ],
  env: Object.assign({}, process.env, {
    DEBUG_COLORS: 1 // without this settings, colors won't be shown
  }),
});

worker.stderr.pipe(process.stderr, { end: false });
```


## Authors

 - TJ Holowaychuk
 - Nathan Rajlich
 - Andrew Rhyne
 - Josh Junon

## Backers

Support us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/debug#backer)]

<a href="https://opencollective.com/debug/backer/0/website" target="_blank"><img src="https://opencollective.com/debug/backer/0/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/1/website" target="_blank"><img src="https://opencollective.com/debug/backer/1/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/2/website" target="_blank"><img src="https://opencollective.com/debug/backer/2/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/3/website" target="_blank"><img src="https://opencollective.com/debug/backer/3/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/4/website" target="_blank"><img src="https://opencollective.com/debug/backer/4/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/5/website" target="_blank"><img src="https://opencollective.com/debug/backer/5/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/6/website" target="_blank"><img src="https://opencollective.com/debug/backer/6/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/7/website" target="_blank"><img src="https://opencollective.com/debug/backer/7/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/8/website" target="_blank"><img src="https://opencollective.com/debug/backer/8/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/9/website" target="_blank"><img src="https://opencollective.com/debug/backer/9/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/10/website" target="_blank"><img src="https://opencollective.com/debug/backer/10/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/11/website" target="_blank"><img src="https://opencollective.com/debug/backer/11/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/12/website" target="_blank"><img src="https://opencollective.com/debug/backer/12/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/13/website" target="_blank"><img src="https://opencollective.com/debug/backer/13/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/14/website" target="_blank"><img src="https://opencollective.com/debug/backer/14/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/15/website" target="_blank"><img src="https://opencollective.com/debug/backer/15/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/16/website" target="_blank"><img src="https://opencollective.com/debug/backer/16/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/17/website" target="_blank"><img src="https://opencollective.com/debug/backer/17/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/18/website" target="_blank"><img src="https://opencollective.com/debug/backer/18/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/19/website" target="_blank"><img src="https://opencollective.com/debug/backer/19/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/20/website" target="_blank"><img src="https://opencollective.com/debug/backer/20/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/21/website" target="_blank"><img src="https://opencollective.com/debug/backer/21/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/22/website" target="_blank"><img src="https://opencollective.com/debug/backer/22/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/23/website" target="_blank"><img src="https://opencollective.com/debug/backer/23/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/24/website" target="_blank"><img src="https://opencollective.com/debug/backer/24/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/25/website" target="_blank"><img src="https://opencollective.com/debug/backer/25/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/26/website" target="_blank"><img src="https://opencollective.com/debug/backer/26/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/27/website" target="_blank"><img src="https://opencollective.com/debug/backer/27/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/28/website" target="_blank"><img src="https://opencollective.com/debug/backer/28/avatar.svg"></a>
<a href="https://opencollective.com/debug/backer/29/website" target="_blank"><img src="https://opencollective.com/debug/backer/29/avatar.svg"></a>


## Sponsors

Become a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/debug#sponsor)]

<a href="https://opencollective.com/debug/sponsor/0/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/0/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/1/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/1/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/2/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/2/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/3/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/3/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/4/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/4/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/5/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/5/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/6/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/6/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/7/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/7/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/8/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/8/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/9/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/9/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/10/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/10/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/11/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/11/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/12/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/12/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/13/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/13/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/14/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/14/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/15/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/15/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/16/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/16/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/17/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/17/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/18/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/18/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/19/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/19/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/20/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/20/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/21/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/21/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/22/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/22/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/23/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/23/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/24/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/24/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/25/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/25/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/26/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/26/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/27/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/27/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/28/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/28/avatar.svg"></a>
<a href="https://opencollective.com/debug/sponsor/29/website" target="_blank"><img src="https://opencollective.com/debug/sponsor/29/avatar.svg"></a>

## License

(The MIT License)

Copyright (c) 2014-2017 TJ Holowaychuk &lt;tj@vision-media.ca&gt;
Copyright (c) 2018-2021 Josh Junon

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
<p align="center">
  <a href="https://gulpjs.com">
    <img height="257" width="114" src="https://raw.githubusercontent.com/gulpjs/artwork/master/gulp-2x.png">
  </a>
</p>

# glob-parent

[![NPM version][npm-image]][npm-url] [![Downloads][downloads-image]][npm-url] [![Build Status][ci-image]][ci-url] [![Coveralls Status][coveralls-image]][coveralls-url]

Extract the non-magic parent path from a glob string.

## Usage

```js
var globParent = require('glob-parent');

globParent('path/to/*.js'); // 'path/to'
globParent('/root/path/to/*.js'); // '/root/path/to'
globParent('/*.js'); // '/'
globParent('*.js'); // '.'
globParent('**/*.js'); // '.'
globParent('path/{to,from}'); // 'path'
globParent('path/!(to|from)'); // 'path'
globParent('path/?(to|from)'); // 'path'
globParent('path/+(to|from)'); // 'path'
globParent('path/*(to|from)'); // 'path'
globParent('path/@(to|from)'); // 'path'
globParent('path/**/*'); // 'path'

// if provided a non-glob path, returns the nearest dir
globParent('path/foo/bar.js'); // 'path/foo'
globParent('path/foo/'); // 'path/foo'
globParent('path/foo'); // 'path' (see issue #3 for details)
```

## API

### `globParent(maybeGlobString, [options])`

Takes a string and returns the part of the path before the glob begins. Be aware of Escaping rules and Limitations below.

#### options

```js
{
  // Disables the automatic conversion of slashes for Windows
  flipBackslashes: true;
}
```

## Escaping

The following characters have special significance in glob patterns and must be escaped if you want them to be treated as regular path characters:

- `?` (question mark) unless used as a path segment alone
- `*` (asterisk)
- `|` (pipe)
- `(` (opening parenthesis)
- `)` (closing parenthesis)
- `{` (opening curly brace)
- `}` (closing curly brace)
- `[` (opening bracket)
- `]` (closing bracket)

**Example**

```js
globParent('foo/[bar]/'); // 'foo'
globParent('foo/\\[bar]/'); // 'foo/[bar]'
```

## Limitations

### Braces & Brackets

This library attempts a quick and imperfect method of determining which path
parts have glob magic without fully parsing/lexing the pattern. There are some
advanced use cases that can trip it up, such as nested braces where the outer
pair is escaped and the inner one contains a path separator. If you find
yourself in the unlikely circumstance of being affected by this or need to
ensure higher-fidelity glob handling in your library, it is recommended that you
pre-process your input with [expand-braces] and/or [expand-brackets].

### Windows

Backslashes are not valid path separators for globs. If a path with backslashes
is provided anyway, for simple cases, glob-parent will replace the path
separator for you and return the non-glob parent path (now with
forward-slashes, which are still valid as Windows path separators).

This cannot be used in conjunction with escape characters.

```js
// BAD
globParent('C:\\Program Files \\(x86\\)\\*.ext'); // 'C:/Program Files /(x86/)'

// GOOD
globParent('C:/Program Files\\(x86\\)/*.ext'); // 'C:/Program Files (x86)'
```

If you are using escape characters for a pattern without path parts (i.e.
relative to `cwd`), prefix with `./` to avoid confusing glob-parent.

```js
// BAD
globParent('foo \\[bar]'); // 'foo '
globParent('foo \\[bar]*'); // 'foo '

// GOOD
globParent('./foo \\[bar]'); // 'foo [bar]'
globParent('./foo \\[bar]*'); // '.'
```

## License

ISC

<!-- prettier-ignore-start -->
[downloads-image]: https://img.shields.io/npm/dm/glob-parent.svg?style=flat-square
[npm-url]: https://www.npmjs.com/package/glob-parent
[npm-image]: https://img.shields.io/npm/v/glob-parent.svg?style=flat-square

[ci-url]: https://github.com/gulpjs/glob-parent/actions?query=workflow:dev
[ci-image]: https://img.shields.io/github/workflow/status/gulpjs/glob-parent/dev?style=flat-square

[coveralls-url]: https://coveralls.io/r/gulpjs/glob-parent
[coveralls-image]: https://img.shields.io/coveralls/gulpjs/glob-parent/master.svg?style=flat-square
<!-- prettier-ignore-end -->

<!-- prettier-ignore-start -->
[expand-braces]: https://github.com/jonschlinkert/expand-braces
[expand-brackets]: https://github.com/jonschlinkert/expand-brackets
<!-- prettier-ignore-end -->
# isexe

Minimal module to check if a file is executable, and a normal file.

Uses `fs.stat` and tests against the `PATHEXT` environment variable on
Windows.

## USAGE

```javascript
var isexe = require('isexe')
isexe('some-file-name', function (err, isExe) {
  if (err) {
    console.error('probably file does not exist or something', err)
  } else if (isExe) {
    console.error('this thing can be run')
  } else {
    console.error('cannot be run')
  }
})

// same thing but synchronous, throws errors
var isExe = isexe.sync('some-file-name')

// treat errors as just "not executable"
isexe('maybe-missing-file', { ignoreErrors: true }, callback)
var isExe = isexe.sync('maybe-missing-file', { ignoreErrors: true })
```

## API

### `isexe(path, [options], [callback])`

Check if the path is executable.  If no callback provided, and a
global `Promise` object is available, then a Promise will be returned.

Will raise whatever errors may be raised by `fs.stat`, unless
`options.ignoreErrors` is set to true.

### `isexe.sync(path, [options])`

Same as `isexe` but returns the value and throws any errors raised.

### Options

* `ignoreErrors` Treat all errors as "no, this is not executable", but
  don't raise them.
* `uid` Number to use as the user id
* `gid` Number to use as the group id
* `pathExt` List of path extensions to use instead of `PATHEXT`
  environment variable on Windows.
# esbuild

This is the macOS ARM 64-bit binary for esbuild, a JavaScript bundler and minifier. See https://github.com/evanw/esbuild for details.
# inflight

Add callbacks to requests in flight to avoid async duplication

## USAGE

```javascript
var inflight = require('inflight')

// some request that does some stuff
function req(key, callback) {
  // key is any random string.  like a url or filename or whatever.
  //
  // will return either a falsey value, indicating that the
  // request for this key is already in flight, or a new callback
  // which when called will call all callbacks passed to inflightk
  // with the same key
  callback = inflight(key, callback)

  // If we got a falsey value back, then there's already a req going
  if (!callback) return

  // this is where you'd fetch the url or whatever
  // callback is also once()-ified, so it can safely be assigned
  // to multiple events etc.  First call wins.
  setTimeout(function() {
    callback(null, key)
  }, 100)
}

// only assigns a single setTimeout
// when it dings, all cbs get called
req('foo', cb1)
req('foo', cb2)
req('foo', cb3)
req('foo', cb4)
```
# Obsidian Published URL Plugin

This is a simple plugin for Obsidian to allow easily going to a published URL of the current file given a prefix in settings.



## TODO: Releasing new releases

- Update your `manifest.json` with your new version number, such as `1.0.1`, and the minimum Obsidian version required for your latest release.
- Update your `versions.json` file with `"new-plugin-version": "minimum-obsidian-version"` so older versions of Obsidian can download an older version of your plugin that's compatible.
- Create new GitHub release using your new version number as the "Tag version". Use the exact version number, don't include a prefix `v`. See here for an example: https://github.com/obsidianmd/obsidian-sample-plugin/releases
- Upload the files `manifest.json`, `main.js`, `styles.css` as binary attachments. Note: The manifest.json file must be in two places, first the root path of your repository and also in the release.
- Publish the release.

> You can simplify the version bump process by running `npm version patch`, `npm version minor` or `npm version major` after updating `minAppVersion` manually in `manifest.json`.
> The command will bump version in `manifest.json` and `package.json`, and add the entry for the new version to `versions.json`

## Adding your plugin to the community plugin list

- Check https://github.com/obsidianmd/obsidian-releases/blob/master/plugin-review.md
- Publish an initial version.
- Make sure you have a `README.md` file in the root of your repo.
- Make a pull request at https://github.com/obsidianmd/obsidian-releases to add your plugin.

## How to use

- Clone this repo.
- Make sure your NodeJS is at least v16 (`node --version`).
- `npm i` or `yarn` to install dependencies.
- `npm run dev` to start compilation in watch mode.---
dek: In which the author explains his reasoning for exploring analog methods of distributing information with ink and linoleum, and provides a guide on how to do so yourself if so inclined
type: words
hidden: false
inprogress: false
date: "2019-08-18T11:29:39-04:00"
hidetimestamp: false
---

# Linocut printing for a bright future

I have made my income using computers for my entire adult life. Designing graphics, writing code, and making websites. I think a lot about what would happen if our world suddenly shifted (for any variety of reasons) and we lost our easy access to computers or the internet.

Put bluntly; when the apocalypse comes, will I be good for anything?

One could make the argument that I have gotten good practice organizing teams of people to accomplish things. Whether that thing is a website or a new well for the village doesn’t really matter.

Most endeavors require making lists, planning, organizing, convincing stakeholders, and building consensus. Those things will be handy whether computers exist or not. (Right?)

Through some combination of Red Dead Redemption and this decade’s resurged interest in hand-painted lettering a thought struck me: signs. No matter what happens in our world, we will almost definitely need signage. “Rice/corn traders 1 mile”, “farmer’s market Saturday”, “don’t go over there that guy is crazy”, “Moonshine for sale”, “museum of the fall of mankind” or whatever.

As a result I’ve been experimenting with different methods of distributing information with analog methods. The easiest and most common is graffiti. People have been writing what they think (more often, their names) on walls in New York for a long time. A phrase written large enough in the right spot in the city can be seen by thousands of people in a day, no electricity required.

The same way some people stock up on rice and beans and ammo I’ve been stocking up on linoleum, ink, and chisels.

::table-of-contents
::

Linocut printing is a really interesting medium to me as a means for the easy distribution of information and imagery. It has a long history of successful usage. Descending from a long lineage of woodblock printing used by a range of printers from medieval monks illustrating their bibles to Japanese artisans depicting elaborate samurais and mountain views. The desired image is painstakingly carved into wood– in reverse. Ink is applied, covering only the uncarved parts of the wood. Paper is laid on top and gently rubbed, absorbing the shape of the image.

The advent of linoleum- a robust material that is much easier to carve than wood- results in better curves, more detail, and quicker carving.

I grew up in a house filled with posters from Bread & Puppet. The aesthetic is also prevalent in the patches or pins I would get at the anarchist book fair. Everything is a little squared off and angular, proportions are sometimes a little off to aid with carving. They are always simple, with a lot of contrast. They are often icons, very clear-cut and identifiable. The medium requires that you boil things down until you are only left with the necessary.

Unlike a drawing, you can make as many copies as you have ink, paper, and patience. **This is a powerful technology.**

In a world different but very similar to ours I can imagine that our networks have been broken and we are left to fend for ourselves, city by city and town by town. I have a lot of faith in my neighbors. I have seen people stand up and do amazing things, thankless anonymous generosity when the city needs to come together. I grew up listening to these stories about Manhattan on 9/11. I was older and understood better when reading news reports about the aftermath of Sandy, when individuals in the city were left to fend for themselves. And I saw it myself, in brief spurts, in Occupy encampments in Oakland and New York, where food and medic tents were always available.

“Medic”, “Water here”, we always need signs is what I’m saying.

## Making a linocut

### Creating your image

The easiest method I have found for creating an image that you want to print by hand is to start the drawing on tracing paper. It is cheap, plentiful, and to iterate you can lay one sheet over the other. You can rearrange things slightly until everything is proportioned to your liking. (You can also use a projector to project the image onto your tracing paper or the reversed image directly onto the linoleum)

![The design for the 30th anniversary print, created in Illustrator for easy iteration and reversing](https://res.cloudinary.com/ejf/image/upload/v1566227287/Screenshot_2019-08-19_10.58.23.png)

Once I am happy with the design I retrace over the outlines pressing hard with a soft pencil. When the tracing paper is flipped and laid on top of the linoleum you can see the reversed design. The pencil side is touching the block, so you can carefully rub on your outlines. This leaves an imprint of the lines and you hope that enough pencil residue is left that you can properly trace them.

Each of these steps is a little “lossy” as they say, every re-tracing of your form simplifies and alters it slightly. I see this is a net benefit, a gift of the medium. Embrace the fact you have 3-4 chances to alter things slightly– just so– to suit your vision.

Once I have retraced in pencil, I will make any adjustments (I can still erase at this point!) looking at it for a while. Once I can’t look at it anymore I’ll start going over my lines with a thick sharpie. Thin sharpies can lead you to create thin intricate designs that might not actually be accomplishable for a beginner.

### Carving

I fill in all of my shapes so that I can disconnect my mind and follow a simple rule. If it’s the color of the linoleum: _carve_. If it’s a color: _don’t carve_.

Speaking of disconnecting one’s mind, this is arguably the best part of the whole process. In creative work, I find the most rewarding parts are when I can get into a state of flow. Carving out linoleum is the cheapest and quickest way to reliably achieve that feeling of flow, at least for me.

You focus on very mechanical and physical things; the placement of your fingers, the angle of the linoleum, the millimeter between your blade and the line it’s supposed to be following. These thoughts fill your head, leaving little room for the anxieties that regularly occupy your mind.

By the way, the carving process takes a while. On a recent 11 x 18 poster-sized project, I forgot exactly how long and ended up carving from **noon to 10pm on day one, and 10am to 6pm on day two**. That is not very long to create an object that can be used to distribute information in huge quantities without electricity but it’s not a short amount of time either.

![The carving stage, starting with smaller blades and working up to wider scoops for big areas. Ideally carving in the same direction maintains consistency and looks better, but it isn’t always possible.](https://res.cloudinary.com/ejf/image/upload/v1566227082/58619413690__0265EC66-47DB-41FB-9236-18FEC827D42A.jpg)

This leads one to think very deeply and carefully about the things that deserve being committed to linoleum. If it took two days to carve out your 280 characters on twitter it would likely be a very different place. This is another gift of the medium.

The method of distribution is shaping the content. It simplifies it (it is easier to carve one word than two, so it is worth the time to think of that superior word) and it clarifies it- in intent, design, form, and execution. Every step is pushing towards simplicity, whether the creator wants it or not. That is a powerful type of medium that is hard to explain– I hope I am doing it justice.

Modern photographers have explored a similar phenomena with film. In a world where, unlike our grandfathers, we can shoot 10 photos a second in continuous bursts and then sort through them for the best photo later- is there really a “decisive moment”?

Film, on the other hand, has it’s inherent god-given limits. There are 36 shots on this roll. They are in black and white. If you aren’t focused or your settings aren’t right you aren’t going to know about it until later and there isn’t shit you can do about it then. So it pays to think ahead and plan and practice your craft and execute at exactly the right time.

I don’t think that is necessarily a better way to create, but it is undeniably a different way. It produces different work. Creating good work is sometimes simply making things differently than the current fads in lighting or composition or subject. If you had to go to the darkroom every time you wanted to post to instagram, it would be very different (but maybe not better!)

### Printing

The process of printing a linocut, once you have [assembled your mise en place](https://ejfox.com/blog/step-zero), is astoundingly easy and efficient. I have also done the field research and the entire process of laying out ink, laying the paper, rubbing it, and slowly unpeeling the print can be conducted by a reasonably intelligent child. I say this as a form of the strongest encouragement to try it yourself.

![A few prints on watercolor drying on the clothesline](https://res.cloudinary.com/ejf/image/upload/v1566227086/IMG_3293.jpg)

The linocut I had created- the largest one I’ve done yet– was created for the 30th anniversary of the [summer camp](http://freespiritnaturecamp.com) owns and runs in New York’s Hudson Valley. I attended my entire childhood and made lifelong friends there. The 30th anniversary seemed like the type of thing that would make the cut <small>(sorry)</small> for committing to a physical form. I also thought it would be cool for people to print their own posters– each one comes out one of a kind <small>(just like us, aw!)</small>.

You spread the ink out on a very flat and smooth surface- I bought a speedball device that doubles as a hook for your desk, holding the linoleum close without you having to hold it from slipping (very handy).

I got some color speedball block ink in tubes from the local art store, Bushwick Artist’s Supply, aka the best art store I have ever set foot in. They have everything I could ever want in a manic creative frenzy from clear elmer’s glue to circular watercolor paper to mack brushes and 1-shot lettering enamel.

You put down a big splotch of yellow and big splotch of blue and start rolling them out. It is fun to watch the color blend and everyone who printed their own enjoyed mixing the inks.

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/hOk-WEj8AzA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Depending on how you load the brayer and lay the ink down you get a different result. Lots of blending of the colors gets a bright forest green. A more relaxed and gentle roller might get discrete sections of yellow and blue that blend while drying and look amazing. It is hard to do wrong.

Because the prints are so easy to make, as long as the paper is relatively inexpensive, I try not to be too precious about each individual poster. If something goes wrong we can easily make another. One person moved their poster around after laying it down and ended up with a final result that looked like a shadow effect of the text which looked awesome. This is a medium that rewards synchronistic “mistakes”.

The best method I found for drying is clothespins and a line. Real printers have cool drying racks and elaborate lever setups for this- but I did all of my printing outdoors and did my best to keep things simple.

I was amazed at the speed with which I could start turning out prints. Arriving with a shoebox containing the ink, the roller, the ink surface, the linocut and some paper I just needed to find a flat surface. It takes about 2 minutes to lay everything out and to put down newspaper for spills. Another 2 minutes to get the ink ready, and you are likely making prints anywhere in the world without electricity in less than 5 minutes.

Plus, it draws a crowd. People seem to have an innate respect for any message that comes from a physical process. Once you explain the carving they look again, tracing the letters with their fingers and imagining the time and work that went into bringing them into existence.

It was a really interesting experience watch children make prints. They would lay down the ink and then together, we would line the paper up, with them carefully pulling things into symmetry. As you rub the paper you can begin to see the shapes of the letters emerge, and I taught them to carefully check and go over any areas that looked like they needed more work.

As they lifted the print up they all smiled. They had a clear sense of making a physical object. They had put the work in and all of their choices and mistakes were reflected in their creation. I really liked that they got that without even needing to carve it. It comes from putting the work into making something exist that didn’t exist before.
---
draft: true
inprogress: true
dek: In which we use light and chemicals to make images appear, if we are lucky
date: 2023-01-06T16:50:52-05:00
modified: 2023-03-16T18:51:20-04:00
---

# Film Development

Developing film is an essential part of the analog photography workflow. Whether you're an experienced enthusiast or a beginner, being aware of film development techniques is critical to achieving beautiful prints. In this post, I'll walk you through how I develop my 35mm Black and White film.

For more on cameras see [[camera-setup]]

## Film I shoot
- Tri-X 400
- Ilford HP5 400
- JCH Streetpan 400
- Random color film that crosses my path that I never develop

## B&W 35mm Film Development Setup

#setup 

Two rolls must be developed at a time. One time I developed what I thought was 1 roll and it was 2 rolls and I lost a roll of film. RIP. Now developing one roll is forbidden.

Once you've accumulated 2 matching rolls (no mixing!), the fun can begin:

### Loading rolls onto film holder

1. Get all materials set up [[step-zero]] and arranged
2. Put everything inside dark bag
3. Open up 35mm rolls of film
4. Cut the ends off and load them onto the plastic film holders
5. Put the film holders in the development cannister thing
6. Close everything up so it is light proof
7. Remove everything (including garbage) from the dark bag

### Developing rolls of film

It's important to double-check the film and developer you are using - make sure they are consistent with each other. After you have verified the proper temperature and time of development, slowly pour your developer into the cannister, develop, and dry.

1. Double check the film you are using and the developer [to make sure you are developing at the right temperature for the right amount of time](https://www.digitaltruth.com/devchart.php?Film=Kodak+Tri-X+400&Developer=Ilfosol+3%25&mdc=Search&TempUnits=F&TimeUnits=T)
2. Get your developer to the right temperature
3. Pour developer into cannister, follow agitation procedure for your specific film/developer
4. Pour our developer
5. Pour in stop bath 
6. Pour out stop bath
7. Pour in detergent
8. Leave to wash for a while under the tap
9. Pour out all water, lightly shake water off rolls
10. Pull rolls out of film holders
11. Gently squeegee the rolls to pull drops of water off
12. Clip film to hang and dry
13. Try to find a cool picture on the roll while it dries even though you can't see anything
### Cutting roll into contact sheet
1. Once the roll is completely dry, put on some dust or rubber gloves to prevent smudging your negatives
2. Trim off any excess film, then cut into strips of five photos each 
3. Slip the strips into archival plastic - I recommend rounding the corners of the strips if you want to avoid them getting caught
This is where you can start getting excited - anticipation for processing your photos is always the best.
### Printing contact sheets
1. Pick archival sheet of photos
2. Put in contact sheet holder
3. Add paper at least 8.5 x 11
4. Remove any filters from the projector
5. Make test sheet for contact sheet, at 5 or 10-second intervals
6. Find the correct exposure time for the contact sheet – the perfect contact sheet has full dark blacks with no shadows and fully white whites with clear detail

## Darkroom Print Setup

#setup 
---
date: "2021-06-11T15:10:17-04:00"
type: words
hidden: false
inprogress: false
dek: In which various tools and methods are explored for analyzing data that describes a network of complaints against NYPD officers (or any other PD with similar public data)
---

# Finding Clusters of NYPD Officers In CCRB Complaint Data

<img src="https://res.cloudinary.com/ejf/image/upload/v1624505769/Screen_Shot_2021-06-21_at_8.58.50_PM.jpg" />

## Why?

Complaints filed against police officers by the public are often the first and only warning sign that a cop might be on a course of escalating violence.

In the deaths of George Floyd and Eric Garner their killers had a documented history of complaints filed against them. Unfortunately nothing was done to disrupt their pattern of abuse, and both cases ended in those officers killing members of the public they had sworn to protect.

::table-of-contents
::

### George Floyd

> Chauvin, who was fired, has said through his attorney that his handling of Floyd’s arrest was a reasonable use of authorized force. But he was the subject of at least **22 complaints or internal investigations during his more than 19 years at the department, only one of which resulted in discipline**. These new interviews show not only that he may have used excessive force in the past, but that he had used startlingly similar techniques.
> ['That could have been me': The people Derek Chauvin choked before George Floyd](https://www.mprnews.org/story/2021/02/05/that-could-have-been-me-the-people-derek-chauvin-choked-before-george-floyd)

The officer convicted of murdering George Floyd had at least 22 complaints against him. The officer who put Eric Garner in a chokehold and killed him had [7 complaints](https://www.scribd.com/document/342591738/D-Pantaleo-Alleged-CCRB-File) [filed against him](https://gothamist.com/news/newly-leaked-documents-suggests-cop-who-killed-eric-garner-had-history-of-misconduct).

### Eric Garner

> Before he put Garner in the chokehold, the records show, he had _seven disciplinary complaints and 14 individual allegations_ lodged against him. Four of those allegations were substantiated by an independent review board.
> [The disturbing secret history of the NYPD officer who killed Eric Garner](https://archive.thinkprogress.org/daniel-pantaleo-records-75833e6168f3/)

Of the 14 individual allegations against Garner's killer, 5 are for force: "hit against inanimate object", "physical force", and a single complaint in 2014 that would foreshadow the behavior that would eventually end the Officer's career: "Force - Chokehold".

I am documenting my analysis in detail for a few reasons:

- So that other people who may want to perform similar analysis for other Police Departments can understand and recreate my analysis
- So that every step is documented, and any mistake [can be easily caught and fixed](https://en.wikipedia.org/wiki/Linus%27s_law) by the infinite supply of people on the internet who are smarter than me
- To maybe inspire people to use computers to investigate the things in the world that are important to them, and share the tools I use to do that

### Network visualization prior work / inspiration

You may have seen network analysis like this before.

[Jacob Silver used it to look at the spread of anti-vax material](https://disinformationindex.org/2021/03/anti-vaccine-networks-thrive-on-instagram-despite-recent-policy-shifts/).

[Adi Cohen](https://twitter.com/adico11) has pioneered a method of [combining Gephi with CrowdTangle](https://help.crowdtangle.com/en/articles/4495952-network-mapping-with-gephi-and-crowdtangle) to analyze the network of groups and pages sharing links.

### Provenance

WNYC/Gothamist received the data in response to a Freedom of Information Law request and provided me an excel file for analysis.

## The Dataset

### Differences from data previously released by ProPublica

ProPublica released and covered [similar data](https://www.propublica.org/article/nypd-civilian-complaint-review-board-editors-note) in July of 2020.

They chose to only publish data for "active-duty officers who’ve had at least one allegation against them substantiated by the CCRB".

The dataset we are working with today contains every complaint and officer, even those with no substantiated allegations.

It also contains officers who were listed as witnesses on complaints, including complaints found as "unsubstantiated" or "unfounded" by the CCRB.

This makes it a "noisier" dataset. In our case this can be an advantage since we are looking to visualize the network of officers.

Being named with another officer on a complaint, even if that complaint is unfounded, is a signal that those officers interacted in a way that was noticed by the public. Being the subject of an unfounded complaint together might even cause officers to form a tighter relationship. Because of that, I will incorporate witness data into our analysis.

### NYPD internal structure as it relates to our data

The NYPD is divided into coverage areas within the 5 boroughs known as precincts. When I lived in Brooklyn, I lived in the 81st Precinct which covers Bed-Stuy.

The NYPD also has a number of units, like the Warrant Squad or Narcotics that span different precincts. An officer might report to a numbered precinct, but their command is Brooklyn Narcotics, and they are interacting with other officers in their unit more than the precinct they work out of. Our data reflects this.

## Analysis

### Overview exploration / metadata

The source dataset is an 81.2MB excel file that I received as `FOIL2021-00167_Dataset.xlsx`. It has 3 tabs. The first has some general notes[^1] about the dataset.

The first tab has the title of `OfficerAllegationHistory` and has 181,627 entries and 47[^2] columns.

The second tab has the title of `OfficersInvolvedInComplaints` and has 239,608 entries and 18[^3] columns.

## Analyzing our data with Datasette / SQLite

Once we [convert our CSV files](https://pypi.org/project/csvs-to-sqlite/) into SQLite `.db` files we can use [Datasette](https://github.com/simonw/datasette) to get a sense of the data and slice off pieces for further analysis.

The first thing we might want to look at is the top commands that received complaints since 2010.

```sql
select [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory
where [Incident Date] BETWEEN '2010-01-01' AND '2010-12-31'
group by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 5
```

- 075 PCT: 320
- 046 PCT: 251
- 047 PCT: 226
- 120 PCT: 199
- BX IRT : 196

Or the top 10 commands whose complaints ended in penalties.

```sql
select [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory
where [Incident Date] BETWEEN '2010-01-01' AND '2021-12-31'AND [CCRB Allegation Disposition] = 'Substantiated (Charges)'
group by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 5
```

- WARRSEC: 91
- PBBX : 84
- 081 PCT: 71
- 079 PCT: 70
- 075 PCT: 68

After using Datasette to get a sense for the shape of our dataset, we can use it to filter out a slice of the data to use to feed into our next tool and begin doing our network analysis.

[Ian Johnson](https://twitter.com/enjalot) helped me explore the data a bit in Observable as well.

We looked at when officers received complaints. Here each year is split into a bar. We are showing the officers who received the most complaints in the entire dataset.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036139/Screen_Shot_2021-05-26_at_11.56.10_AM.png" />

Or stacking the bars- the darker they are, the more recent the complaints occurred.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036139/Screen_Shot_2021-05-26_at_12.03.47_PM.png" />

You can also look at the CCRB outcomes and see how rarely cases are substantiated or end in discipline.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036139/Screen_Shot_2021-05-26_at_12.04.11_PM.png" />

We also looked at which commands received the most complaints across the entire dataset.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036139/Screen_Shot_2021-05-26_at_12.03.54_PM.png" />

### Filtering out "Exonerated" and "Unfounded" complaints for our network

To get our network closer to a representation of officers who are receiving complaints for misconduct we want to filter out any of the cases in which the officer was `Exonerated` or the CCRB's disposition was that it was _Unfounded_.

So to get every complaint filed since 2010 that wasn't marked as `exonerated` or `unfounded` we'll write a query like

```sql
select * from OfficerAllegationHistory
where ([Incident Date] BETWEEN '2010-01-01' AND '2021-12-31') AND ([CCRB Allegation Disposition] IS NOT 'Exonerated'
AND [CCRB Allegation Disposition] IS NOT 'Unfounded')
```

Which gives us a slightly more manageable _65,401 rows_. We'll save these results off as a .csv for further analysis.

I had to do some funky stuff[^4] to fix the dates in SQLite, but once I did that, it was easy to filter by the date column.

We can also export new CSVs for all of the incidents since 2010 for a particular precinct:

```sql
select * from OfficerAllegationHistory
where [Incident Date] BETWEEN '2010-01-01' AND '2021-12-31' AND [Officer Command At Incident] = '075 PCT'
```

These precinct-specific slices are a bit smaller and more manageable for analysis in Observable.

We'll also want to export another CSV with ONLY complaints that were substantiated

```sql
select * from OfficerAllegationHistory
where ([Incident Date] BETWEEN '2010-01-01' AND '2021-12-31') AND ([CCRB Allegation Disposition] IS 'Substantiated (Charges)' OR [CCRB Allegation Disposition] IS 'Substantiated (Command Discipline A)'
OR [CCRB Allegation Disposition] IS 'Substantiated (Command Discipline B)'
```

## Analyzing our data with Neo4J

I first encountered Neo4J when I was working with Ben Popken on an [NBC News analysis of tweets tied to Senate Intelligence-identified Russian Twitter Bots](https://neo4j.com/blog/story-behind-russian-twitter-trolls/) where Neo4J provided analysts who were crucial to understanding the shape of our data.

It is an incredibly useful tool for generating and analyzing networks, and I was excited to have another dataset that would let me use its considerable power.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624506093/Screen_Shot_2021-05-31_at_12.05.00_PM.jpg" />

### Importing our CSV with Cypher

To import our `.csv` into a network of node and relationships in Neo4J, we will use the [Cypher](https://neo4j.com/developer/cypher/) query language, which makes this process really easy and the code is relatively readable and easy to follow.

Special thanks to [David Allen](https://twitter.com/mdavidallen) at Neo4J for his guidance in writing queries and designing these relationships.

Basically we take the CSV files we exported from Datasette (when we filtered our Exonerated, Unfounded, and everything before 2010) and go through every row and push it into our network.

#### Creating officer nodes

First we tell Neo4J to use officer.id as a unique constraint (this makes things faster, I think?) and create a node for each officer from one CSV.

```sql
CREATE CONSTRAINT officerIdConstraint ON (officer:Officer) ASSERT officer.id IS UNIQUE
```

Then I loop through every line of the .csv and create a new Officer node for every new officer I see. I use `MERGE` instead of `CREATE` to make sure I don't duplicate officer nodes.

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv" AS csvLine
MERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, OfficersInvolvedInComplaints: true})
RETURN officer
```

This creates _29,915_ unique officer nodes.

Then we bind more data into it from our other CSV

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory.csv" AS csvLine
MERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, shieldNo: csvLine.`Shield No`, currentRank: csvLine.`Current Rank`, currentCommand: csvLine.`Current Command`, OfficerAllegationHistory: true})
RETURN officer
```

Now we have _113,265_ unique officer nodes.

An officer node looks like this:

```json
{
  "identity": 00001,
  "properties": {
    "currentRank": "Police Officer",
    "currentCommand": "81",
    "lastName": "Smith",
    "firstName": "John",
    "shieldNo": "00001",
    "id": "000001",
    "OfficerAllegationHistory": true
  }
}
```

Finally, we need to add a boolean to denote if an officer has ever had a charge substantiated. We'll use this later to please some lawyers. You'll see.

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-SUBSTANTIATED.csv" AS csvLine
MERGE (officer:Officer {id: csvLine.`Unique Officer Id`})
SET officer.ccrbSubstantiatedBool = "true"
RETURN officer
```

Now we've marked _4,768_ of New York's ~36,000 (13%) finest as having a substantiated complaint in the last 10 years.

Let's NOT do the same thing for OfficersInvolved - because that file contains officers who were merely witnesses to substantiated complaints, and we don't want to accidentally label a witness to a substantiated case.

### Creating officer labels

Now we need to set labels for our nodes depending on whether they have ever had a complaint substantiated. We don't want to label nodes with names for any officers who may have complaints but have never had any substantiated. I have been told that lawyers think this is a good idea.

First we set every officer label to their unique ID

```sql
MATCH (o:Officer)
SET o.label = o.id
```

Then we look for officers with substantiated complaints and set their label to their full name.

```sql
MATCH (o:Officer {ccrbSubstantiatedBool: "true"})
SET o.label = COALESCE(o.firstName ,"") + ' ' + COALESCE(o.lastName ,"")
```

Now we have our officers created, we need to create our incidents.

#### Creating incident nodes

We are going to continue to use our CSV which _filtered out_ incidents _before 2010_ or that were _unfounded or exonerated_.

First we tell Neo4J that we have unique incident IDs

```sql
CREATE CONSTRAINT incidentIdConstraint ON (incident:Incident) ASSERT incident.id IS UNIQUE
```

Then we create an incident for every row we see in OfficerAllegationHistory. We'll make note of the precinct the incident occurred in, what the specific allegation was, and what date the incident occurred.

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv" AS csvLine
MERGE (incident:Incident {id: csvLine.`Complaint Id`})
SET incident.incidentPct = COALESCE(csvLine.`Precinct Of Incident Occurrence`,"N/A")
SET incident.ccrbDisposition = csvLine.`CCRB Allegation Disposition`
SET incident.allegation = csvLine.`Allegation`
set incident.date = csvLine.`Incident Date`
RETURN incident
```

Now let's do the same for _OfficersInvolvedInComplaints_.

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv" AS csvLine
MERGE (incident:Incident {id: csvLine.`Complaint Id`})
SET incident.ccrbDisposition = csvLine.`Complaint Disposition`
RETURN incident
```

Now let's create labels for our incidents, which is going to be the allegation.

```sql
MATCH (i:Incident)
SET i.label = i.allegation
```

Now that we have our _Incidents_ and our _Officers_ we need to create our relationships between them.

### Creating relationships between incidents and officers

Now for the fun part.

We are going to create a new relationship called `INVOLVED_IN`, and officers can be `INVOLVED_IN` one or many incidents. Incidents may have one or many officers that were `INVOLVED_IN` it, either as witness or subject officers.

First we create our relationships from _OfficersInvolved_:

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv" AS csvLine
MATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer
MATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident
CREATE (officer)-[:INVOLVED_IN {status: csvLine.`Officer Status`}]->(incident)
```

Which creates _94,323_ relationships.

Then from _OfficerAllegationHistory_:

```sql
LOAD CSV WITH HEADERS FROM "http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv" AS csvLine
MATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer
MATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident
CREATE (officer)-[:INVOLVED_IN {allegation: csvLine.`Allegation`, type: csvLine.`FADO Type`}]->(incident)
```

**Now we have 159,671 relationships**. Sick.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036165/Screen_Shot_2021-05-29_at_2.28.27_PM.png" />

Next we can flatten out our graph a little bit and remove incidents if we want.

We will create a new type of relationship that only occurs between two officers called `CO_OCCURANCE` - we will only make one of these between each officer, but the weight of that link will be decided by how many complaints those officers appear together on.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036231/Screen_Shot_2021-05-29_at_3.48.19_PM.png" />

So officers who appear on 3 complaints together have a `CO_OCCURANCE` relationship with a weight of 3. This allows us to do some weighted degree analysis when we are making our layout, deciding how large to make nodes, and when we are detecting communities.

```sql
MATCH (o1:Officer)-[:INVOLVED_IN]->(i:Incident)<-[:INVOLVED_IN]-(o2:Officer) WHERE id(o1)<id(o2) with o1, o2, count(i) as weightCount CREATE (o1)-[:CO_OCCURANCE { weight: weightCount }]->(o2)
```

### Officers without connections

```sql
MATCH (o:Officer) WHERE NOT (o)-[:CO_OCCURANCE]-() RETURN count(o)
```

<img src="https://res.cloudinary.com/ejf/image/upload/v1624506696/Screen_Shot_2021-06-13_at_7.16.11_PM.jpg" />

### Eigenvector analysis on our network

Let's run a standard centrality analysis algorithm called ["Eigenvector Centrality"](https://neo4j.com/docs/graph-data-science/current/algorithms/eigenvector-centrality/)

```
CALL gds.alpha.eigenvector.write({
  nodeProjection: 'Officer',
  relationshipProjection: 'CO_OCCURANCE',
  relationshipProperties: 'weight',
  relationshipWeightProperty: 'weight',
  writeProperty: 'eigenvector'
})
YIELD nodes, iterations, dampingFactor, writeProperty
```

Now every Officer node has an `eigenvector` value that represents its centrality across our entire NYPD-wide network. The larger the value, the more central that node is.

## Analyzing our data with Gephi

Neo4J is cool for processing and analyzing tons of data, but I want to draw thousands of circles and lines now and start untangling the hairball of our network.

I am going to use Gephi, which I have a love-hate relationship with, but is unrivaled when it comes to network visualization. Plus, I already know how to use it.

We are going to [stream our data from Neo4J to Gephi](https://neo4j.com/labs/apoc/4.1/export/gephi/) in order to leverage Neo4J's power to handle huge amounts of data (way more than Gephi) but still get to use Gephi's layout algorithms and analysis techniques.

### Flattened co-occurance network

To get our flattened network, which removed incident nodes:

```sql
MATCH path=(o1:Officer)-[r:CO_OCCURANCE]->(o2:Officer) WITH o1, path limit 125000  with o1, collect(path) as paths call apoc.gephi.add(null,'workspace1', paths, 'weight', ['weight', 'id', 'eigenvector', 'firstName', 'lastName', 'label', 'date', 'currentCommand']) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC
```

This streams 100,000 edges and 25,064 nodes into Gephi.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036180/Screen_Shot_2021-05-29_at_3.03.54_PM.png">

We'll run the Force Atlas 2 layout algorithm in Gephi to have the nodes arrange themselves into some sort of sense.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036176/Screen_Shot_2021-05-29_at_2.51.20_PM.png" />

We can use Gephi's modularity algorithm to color by "community" within our network, and we'll tweak our layout algorithm to separate things out a bit.

The communities that Gephi detects often mirror real-world precincts. As one might expect, officers appear on complaints with other officers in their precinct because they are working together most often.

I like that the algorithm detects communities that resemble precincts, and it actually gives me confidence that the community detection is working.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036310/Screen_Shot_2021-05-31_at_12.51.58_PM.png" />

Then we can add some labels and we've made a map of the network of officers who appeared on CCRB complaints together, and there appear to be a number of closely-knit clusters and different communities within our network.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036311/Screen_Shot_2021-05-31_at_12.59.34_PM.png" />

### Precinct-specific networks including incidents (un-flattened network)

Let's put it all together and stream all the officers from a single precinct using only incidents since 2010.

```sql
MATCH path=(o1:Officer)-[:INVOLVED_IN]->(i:Incident {incidentPct: "75"})<-[:INVOLVED_IN]-(o2:Officer)
where i.date IS NOT NULL and apoc.date.parse(i.date, "ms", 'YYYY-mm-dd') > 1262304000000
 WITH o1, path, i limit 100000  with o1, i, collect(path) as paths call apoc.gephi.add(null,'workspace1', paths, 'weight', ['weight', 'id', 'eigenvector', 'firstName', 'lastName', 'date']) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC
```

We can also make a network that is un-flattened, that is, we can see nodes for both officers as well as incidents. This way, we can see the patterns in the way incidents tie officers together.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036336/Screen_Shot_2021-06-02_at_6.32.45_PM.png" />

Every blue circle here is an incident, and every red circle is an officer (both filtered by the 75th precinct, since 2010).

Now let's size the circles by their degree (the number of connections they have) and run a layout algorithm.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036346/Screen_Shot_2021-06-02_at_6.53.13_PM.png" />

Some big nodes start to pop up, like Martinez, Radoncic, and Grieco. What is causing these officers to co-appear on so many different complaints with so many different officers?

When exploring this network, large nodes pop up, and I became naturally curious what the careers of those officers looked like. One of the first ones that jumped out to me was a big node that represented an officer named Nicholas Rios.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036085/Screen_Shot_2021-05-18_at_8.55.24_PM.png" />

I googled his name, and one of the first results was a harrowing story of a federal civil rights case that named him.

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036085/Screen_Shot_2021-05-18_at_8.55.38_PM.png" />

In the reporting that George Joseph did for Gothamist/WNYC, he found that a number of large influencers that appear in this network analysis also acted as influencers on the ground.

He looked at another large node in the network, Adnan Radoncic:

> Atunbi asserted that Radoncic was a catalyst for a group assault on the street that day.
> “As soon as he grabbed me, all the officers was hands on,” he said. “It’s like they just followed his lead.”

## Potential Next Steps

There are a few different directions for further analysis that I didn't have time for, but may result in interesting findings.

- Explorable NYPD-wide network
- Looking at protest complaints
- Looking at veterans influencing rookies
- Looking at the effects of NYPD discipline
- Officer career-specific visualization
- Analysis of length/outcomes of CCRB investigations
- Geographic analysis

## Flotsam & Jetsam

<img src="https://res.cloudinary.com/ejf/image/upload/v1624505603/Screen_Shot_2021-06-23_at_9.54.21_PM.png" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1624505843/Screen_Shot_2021-06-21_at_7.12.27_PM.png" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036381/Screen_Shot_2021-06-07_at_1.15.54_PM.png" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1624506217/Screen_Shot_2021-05-29_at_12.37.37_PM.png" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036457/Screen_Shot_2021-06-13_at_10.31.55_PM.png" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1624036455/Screen_Shot_2021-06-13_at_10.33.01_PM.png" />

## Hire me to do work like this

I do freelance data exploration and visualization for clients who aren't evil. If you'd like to hire me to take a look at a dataset for you, just get in touch at <ejfox@ejfox.com>

[^1]: The notes say, basically: these are complaints received in or after the year 2000. Cases that are mediated or were attempted to be mediated are excluded.
[^2]:
    OfficerAllegationHistory columns: <pre>
    1: As Of Date
    2: Allegation Record Identity
    3: Unique Officer Id
    4: Active Per Last Reported Status
    5: Last Reported Active Date
    6: Officer First Name
    7: Officer Last Name
    8: Officer Race
    9: Officer Gender
    10: Current Rank Abbreviation
    11: Current Rank
    12: Current Command
    13: Shield No
    14: Complaint Id
    15: Incident Date
    16: CCRB Received Date
    17: Close Date
    18: Officer Rank Abbreviation At Incident
    19: Officer Rank At Incident
    20: Officer Command At Incident
    21: Officer Days On Force At Incident
    22: Borough Of Incident Occurrence
    23: Precinct Of Incident Occurrence
    24: Location Type Of Incident
    25: Reason for Police Contact
    26: Outcome Of Police Encounter
    27: Victim Age At Incident
    28: Victim Race
    29: Victim Gender
    30: FADO Type
    31: Allegation
    32: CCRB Allegation Disposition
    33: Board Discipline Recommendation
    34: Non-APU Penalty Report Date
    35: Officer Is APU
    36: APU CCRB Trial Recommended Penalty
    37: APU Trial Commissioner Recommended Penalty
    38: APU Plea Agreed Penalty
    39: APU Case Status
    40: APU Closing Date
    41: NYPD Allegation Disposition
    42: NYPD Officer Penalty
    43: Reconsideration Requested
    44: Reconsideration Request Withdrawn
    45: Reconsideration Request Rejected
    46: Reconsideration Occurred
    47: Reconsideration Decision Pending

    </pre>
     
    [^3]: OfficersInvolvedInComplaints columns: <pre>
    1: As Of Date
    2: Officer Status
    3: Unique Officer Id
    4: Active Per Last Reported Status
    5: Last Reported Active Date
    6: Officer First Name
    7: Officer Last Name
    8: Officer Race
    9: Officer Gender
    10: Current Rank Abbreviation
    11: Current Rank
    12: Current Command
    13: Shield No
    14: Complaint Id
    15: Complaint Disposition
    16: Incident Date
    17: CCRB Recieved Date
    18: Close Date
    </pre>

[^4]:
    I ran this in the CLI SQLite client to chop up the date string and re-write it in the way SQLite wants it:

    ```sql
    update OfficerAllegationHistory
    set [Incident Date] = substr([Incident Date], -4) || '-' ||
    substr('00' || ([Incident Date] + 0), -2, 2) || '-' ||
    substr('00' || (substr([Incident Date], instr([Incident Date], '/') + 1) + 0), -2, 2);
    ```
---
dek: In which we embrace new technology and strive for an equitable future
date: 2023-01-24T10:56:03-05:00
modified: 2023-04-09T13:47:52-04:00
tags: culture politics machinelearning america
---

# Deconstructing Crypto, AI, and the 21st Century Colonial Mindset

![](763896083_An_isometric_pile_of_coins__iphone__laptop_and_bank_notes_representing_cryptocurrency_and_AI_s_impac.png)

In the swirling chaos of the 21st century, we find ourselves in the throes of a digital revolution, but we are in danger of entrenching the systems of oppression that already pervade our society.

> Badly designed AI can harm vulnerable and marginalized groups even when it “works,” by subjecting them to new forms of data-gathering and surveillance and encoding historical patterns of discrimination into automated systems.
> Kevin Roose [Roose-Futureproof](Roose-Futureproof.md)

::table-of-contents

::

Cryptocurrency and artificial intelligence (AI) have been heralded as saviors of economic opportunity, promising to enfranchise communities across the globe. But beneath the surface lies a shadow: the same oppressive forces entrenched by colonialism are being re-calibrated for the 21st Century and let loose in increasingly complicated systems. 

These forces are diametrically opposed to the traditional [hacker-culture](hacker-culture.md) that birthed many of the technological underpinnings of these innovations- and we must return them to their roots.  

## Hoarding knowledge and technology

In traditional colonial systems, knowledge and information has been closely guarded and unevenly distributed, [granting privilege to those who have access to proprietary institutions and archives](https://en.wikipedia.org/wiki/Coloniality_of_knowledge).

As these technologies evolve and expand, they threaten to entrench the dark dynamics of labor exploitation, resource inequality, and climate injustice in ways we may never be able to exorcise.

> The harms that have been documented as a consequence of AI deployments across the world—whether in facial recognition, predictive policing, resource distribution, shifts in labor practice, or health care diagnostics—did not emerge by chance. They result from long-term, systematic mistreatment and inadequate legal and economic protections rooted in the colonial project.
> [Decolonizing AI - Boston Review](https://www.bostonreview.net/forum_response/decolonizing-ai/)

The seductive allure of crypto and AI is that they claim to offer a pathway for the downtrodden, the colonized, the oppressed, to reclaim economic sovereignty – but the reality is we are witnessing a 21st Century re-calibration of the philosophies underlying the colonial enterprise.

## Colonial Algorithms

> The coloniality of knowledge "presumes commensurability with Western discourse", and is the practice of "translating and rewriting other cultures, other knowledges, and other ways of being" into Western system of thought.
> [Aspects of the Coloniality of Knowledge](https://scholarlypublishingcollective.org/psup/cpr/article-abstract/8/1-2/48/190556/Aspects-of-the-Coloniality-of-Knowledge?redirectedFrom=fulltext)

The artificial intelligences we forge, like Frankenstein's monster, are constructed from a mangled patchwork of white, western, and wealthy perspectives. They are then unleashed upon unsuspecting peoples and cultures they were never designed to understand.

The AI models we develop today are an eerie reflection of the colonial dynamic; oppressor and oppressed, powerful and powerless, with the puppeteers behind these AI monstrosities assuming the role of an unquestionable authority, **absolved of responsibility by the machines they control.**

> Small incidents like delivering a package to the wrong door can lead a driver’s account to be frozen or closed, if the driver isn’t proactive in explaining what happened or solving the problem. The algorithm also penalizes workers for being inactive, even if they’re sick with covid. This demotes their account status and costs them access to more regular jobs.
> “It really gives workers no option other than to keep working,” says Amalinda Savirani, an associate professor at Gadjah Mada University, who studies social movements among the urban poor in Indonesia. “The technology has become an instrument for this labor exploitation.”
> [The gig workers fighting back against the algorithms](https://www.technologyreview.com/2022/04/21/1050381/the-gig-workers-fighting-back-against-the-algorithms/)

## Old systems reinterpreted

AI and other emerging technologies may fall into the trap of replicating, in their own unique way, the patterns of entitlement, resource inequality, and injustice that were perfected during colonial times. 

The commodification of human labor, which was a key feature of the colonial project, is becoming increasingly prevalent in the algorithm-lead startup space.

Cryptocurrency and machine learning algorithms are gaining traction and becoming increasingly sophisticated. As they spread and increase in complexity, they could potentially enable further subjugation of minority voices and entrench existing power dynamics that have been shaped by a long history of colonialism. 

> There is a centuries-long investment in research, development, and deployment of techniques to ensure that survival is only ever a right for some. This right for some, more often than not, is ensured at the expense of the self-determination and continuation of living for the overwhelming majority of the planet’s human population.
> [Grove-Savage Ecology](Grove-Savage%20Ecology.md)

Crypto assets are created and traded predominantly by those with access to capital. Colonialism has historically relied on a system of control through economic exploitation, often enabled by technologies such as currency or infrastructure. The goal is always the same: extract as much economic value as possible.

> These aspects are not reconcilable. The problem is that humans continue to function based on a one-way extraction of anything they claim as property, including natural resources. But one-way extraction relies on the abstract premise of unlimited potential to increase one’s wealth, which further drives greed. People need to look beyond monetary economics and think of “environmental economics.”
> **Eduardo Navas** [Is it Possible to Decolonize the Blockchain and NFTs?](https://www.rightclicksave.com/article/is-it-possible-to-decolonize-the-blockchain-and-nfts)

Though the motivations and means may have changed over time, the outcomes remain the same: exploitation of resources, opportunity and autonomy. 

## The soul is built from greed

The insatiable greed that drove the colonial project finds new sustenance in the digital realm. We must resist the siren song of these digital serpents if we hope to forge a future of economic freedom, driven by equitable and transparent use of the latest technologies. We must learn from the sins of our past if we wish to break the chains that bind us to the ghosts of colonialism.

Mutual aid offers a beacon of hope in the darkness, guiding us towards a future where technology serves the needs of all, not just the privileged elite. By fostering a spirit of cooperation and solidarity, we can build systems that prioritize the well-being of our fellow humans, our planet, and the diverse ecosystems that support life. 

If we were smart, we would be taking these technologies to our communities, asking them what they want, what would bring them joy, and then *building that*. These technologies are making a world where robots can do a lot of the work that humans do today. Whether that frees up society to do other, more important things or whether it allows the masters to grow rich while the rest of the world suffers is up to us. Almost every other technology of the 21st century has resulted in the rich getting richer; maybe this time it can be different.

By reorienting our focus towards the collective good, we can harness the power of AI and cryptocurrency to uplift the downtrodden, heal the wounds of colonialism, and create a more equitable and sustainable world.

Just as the myriad species of an ecosystem work together in harmony, so too must we weave our technological innovations into the fabric of our global community. Let us create artificial intelligences that reflect the richness of human experience, that learn from the wisdom of diverse cultures, and that respect the delicate balance of our shared environment.

We find ourselves in the midst of an eternal dance, a delicate balance between the shadows of the past and the shimmering possibilities of the future. We can either drown ourselves in the filth of the past, or we can roll up our sleeves, spit in the face of colonialism, and choose a different path. A path where we give a damn about each other, where we break the chains of power and share the spoils of technology with everyone.

Imagine a future where communities come together, recognizing the urgent need to address the colonial dynamics and inequalities perpetuated by AI and cryptocurrency. Instead of waiting for centralized authorities to take action, these forward-thinking communities choose to be champions of change and take matters into their own hands.

By embracing open-source AI models and ensuring diverse perspectives in the decision-making process, they collectively shape the development of technologies that respect their values and needs. Turning to decentralized digital currencies created by local groups for financial autonomy, they bypass traditional banks and centralized control, empowering individuals to take charge of their own economic lives.

As more communities around the world follow this inspiring path, we discover strength in self-organization, cooperation, and mutual support. Together, we create a more equitable future with technology that serves everyone – a future where exploitation is replaced by collaboration and the transformative power of technology is harnessed for the purposes of joy instead of profit. 
---
hidden: false
type: photos
date: "2016-01-01T00:42:00-05:00"
hidetimestamp: true
bgcolorclass: ""
textcolorclass: ""
---

# 2016 In Review

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535162/20161227-untitled_shoot-312.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535166/20161227-
untitled_shoot-527.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535166/20161227-untitled_shoot-524.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535166/20161227-untitled_shoot-443.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535165/20161227-untitled_shoot-415.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161227-untitled_shoot-413.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161227-untitled_shoot-405.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161227-untitled_shoot-369.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161227-untitled_shoot-397.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161207-untitled_shoot-207.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535162/20161203-untitled_shoot-172.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535162/20161203-untitled_shoot-138.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535162/20161227-untitled_shoot-378.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535161/20161119-untitled_shoot-007.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526535164/20161227-untitled_shoot-314.jpg" />
---
dek: In which the author proudly lays out his technological toolkit
type: words
hidden: false
inprogress: false
date: "2021-02-09T20:42:11-05:00"
hidetimestamp: false
---

# Computer setup

I’m a big fan of [preparation](https://ejfox.com/blog/step-zero/). It's the same part of my personality that causes me to assemble [go bags](https://en.wikipedia.org/wiki/Survival_kit). It’s the same instinct that made me want to buy a manual transmission for my first car: that way I could be sure I could drive any car I encountered.

My technological set up is similar. There are a lot of things in place that one could argue I don’t _need_ right now, or don’t use every day.

But it makes me feel better because they are already configured and set up in case I need them. These are my tools, sitting cleaned and sharpened, waiting for me to figure out what to do.

> There are about a hundred little tricks like this that Hiro wouldn't know about if he hadn't been programming avatars for people like Vitaly Chernobyl for the last couple of years. To write a really good invisible avatar from scratch would take a long time, but he puts one together in several hours by recycling bits and pieces of old projects left behind in his computer. Which is how hackers usually do it.
> <cite>Neal Stephenson, Snow Crash, 1992</cite>

::table-of-contents
::

#### Why?

The motivations behind doing this are not always clear to me. But in the end it comes from a core belief that computers can allow us to do amazing things. As I discover new pockets of knowledge, I also find new ways to string them together.

An idea will come to me and I can see how I would create it because I had already experimented with some of the elements without even knowing why.

I’ve written a bit about how the [internet was built to be hacked](https://ejfox.com/blog/the-internet-was-built-to-be-hacked) and the amazing tools we have been given to do so.

Part of this exercise has been going to my roots to understand how some fundamental technologies (like email, mailing lists, usenet, IRC, PGP, etc.) can [be remembered, reused, and repurposed to build a better online world](https://www.are.na/ej-fox/neo-internet-philosophy).

There is also the magical and inexplicably cool feeling of typing the right magic words and convincing a computer to do what you want.

## Passwords & 2FA

1password is the core of my set up. It allows me to have secure and complicated passwords for my accounts / logins / keys / etc. My golden rule is that if I can remember my password, it isn’t strong.

I use two-factor authentication on every service that offers it. Wherever possible, I [avoid 2FA that uses my phone number](https://authy.com/blog/understanding-2fa-the-authy-app-and-sms/). I really like Authy for now, but am looking to switch to 1password for 2FA as well.

## Using the command line

I’ve spent a long time becoming comfortable with the command line. I started swimming in shallow water with a `cd` here and and `ls` there. I wanted to take some concentrated time to become more familiar with the command line. The goal is to be able to sign onto any \*nix command line and be able to navigate around and get stuff done.

### tmux

I’m also running [tmux](https://hackernoon.com/a-gentle-introduction-to-tmux-8d784c404340) so creating a new window is a quick “ctrl-a c” and I’m off and running. I’ve also been using “ctrl-a w” which is basically a tmux version of alt-tab and lets me go between my different windows with the arrow keys.

### vim

I only just started using vim, and it required setting it up _just_ right for [my personal setup](https://github.com/ejfox/dotfiles/blob/master/.vimrc “My vim configuration file is hosted on GitHub with the rest of my dotfiles”). I’ve been collecting helpful commands or tools with the [**vim** tag on pinboard](https://pinboard.in/u:ejfox/t:vim)

- [nerdtree](https://github.com/scrooloose/nerdtree) for a file explorer
- [fzf](https://github.com/junegunn/fzf#respecting-gitignore-hgignore-and-svnignore) which I’ve remapped to ctrl-p (like Atom) so I can quickly search files in my directory to open
- [lightline](https://github.com/itchyny/lightline.vim) is a statusline for vim that makes it easy to see what mode I’m in

### cli tools

- [lazygit](https://github.com/jesseduffield/lazygit) is an amazing tool for doing most git-related tasks easily and sanely without memorizing tons of commands - I use it all the time in combination with vim
- [jq](https://github.com/stedolan/jq) is a great tool for processing JSON data, especially large datasets. Use like `cat package.json | jq .scripts`
- [jsonfui](https://github.com/AdrianSchneider/jsonfui) is a great CLI interface for JSON data, and a way more performant way of exploring large datasets in a command line UI
- [gtypist](https://www.gnu.org/savannah-checkouts/gnu/gtypist/gtypist.html) is a nice tool to practice and check my typing speed
- [mutt](https://medium.com/@stessyco/gmail-from-the-command-line-with-mutt-mac-os-x-92d047bcd74f) lets me send and receive email from the command line which is rad and a nice no-frills interface that makes one feel like a Real Hacker
- [recon-ng](https://bitbucket.org/LaNMaSteR53/recon-ng) is a tool used for OSINT research, using a variety of Python scripts and APIs to look up publicly available information for research purposes
- [things.sh](https://github.com/alexanderwillner/things.sh/) lets me check my [Things](https://culturedcode.com/) to-do list from the command line. [^I have two aliases: `alias todo="things.sh"` and `alias today="todo today | awk 'BEGIN{FS=OFS=\"|\"}{\$1=\$3=\"\";gsub(/[|]+/,\"|\")}1' | tr -d '|'"` to quickly show today’s tasks with `today`.]

## Communicating Securely

I prefer [Keybase](https://keybase.io/).

I have a [keybase profile](https://keybase.io/ejfox) that lists a handful of verified identities and addresses that you can verify are me. I am also host my public PGP key at <https://ejfox.com/pgp.txt> so that people who want to send me encrypted messages can do so.

### Importing my PGP key

You can easily import my PGP key with `curl https://ejfox.com/pgp.txt | gpg --import`

It’s also nice that, even as much as I trust keybase, the PGP key is [hosted on an HTTPS website that I exclusively control](https://jacob.hoffman-andrews.com/README/the-safe-way-to-put-a-pgp-key-in-your-twitter-bio/).

### Confirming my PGP public key and fingerprint

My key is also hosted in multiple places, so you can confirm my public key [on GitHub](https://github.com/ejfox.gpg)^[Which I use to [sign my commits](https://medium.com/@rwbutler/signing-commits-using-gpg-on-macos-7210362d15)] is the same as the one [I host](https://ejfox.com/pgp.txt) which is the same as the one [on Keybase](https://keybase.io/ejfox/pgp_keys.asc) which is the same as the one [on Wikipedia](https://en.wikipedia.org/w/index.php?title=User:Ejfox/Key&oldid=903520387).

A semi-automated way to do this comparison is by appending all 3 keys to a txt file and comparing them ^[Or you can just run [this gist](https://gist.github.com/ejfox/d64a7da835ef51ef67c376fdf6d0b542) as a one-liner: `sh -c "$(curl -fsSL https://gist.githubusercontent.com/ejfox/d64a7da835ef51ef67c376fdf6d0b542/raw/0c5724ab43ea5af6a25d3544e43fcfe75bce8d41/verify-pgp.sh)"`].

```bash
curl https://github.com/ejfox.gpg | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt

curl https://ejfox.com/pgp.txt | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt

curl https://keybase.io/ejfox/pgp_keys.asc | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt

grep 89CD fp.txt
```

Which should return the same matching fingerprint from all 3 files. ^[If any of my publicly-posted keys (or fingerprints) do not match please [contact me immediately](mailto:ejfox@ejfox.com) because something weird is afoot.]

```
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
```

#### Website backups

My [website is backed up](https://ejfox.keybase.pub/) on the [Keybase filesystem](https://keybase.io/docs/kbfs) as part of my [site’s deploy process](https://github.com/ejfox/website/blob/master/package.json#L14).

I’ve got the [GPG Suite](https://gpgtools.org/) for OS X which makes it so you can store your PGP key passphrase in the keychain. This makes it easier to do a handful of things, including [signing git commits](https://help.github.com/en/articles/signing-commits) with my key without having to enter my passphrase every time.

## Surfing the web

I’ve really like the work being done with [Brave Browser](https://brave.com/) especially the [Basic Attention Token](https://basicattentiontoken.org/) which among other things, allows people who browse the web to give money to content publishers through automated micro-transactions (which I think is probably the future of healthy content consumption on the internet).

#### VPN

I like [NordVPN](https://nordvpn.com/) last time I’d checked they had relatively good reviews from folks I trusted, they are pretty affordable, they take cryptocurrency, and their desktop and iOS apps are actually really nice.

I usually have a NordVPN running on my desktop and phone in addition to the [1.1.1.1](https://itunes.apple.com/us/app/1-1-1-1-faster-internet/id1423538627?mt=8) app.

## Cryptocurrency

I cannot see any downsides to making it easier for people to send me money.

```
BTC=3DE42VUyUKSikQ9eUeFKv2EkKVms7Pmd1G
BCH=qrwzlfjhhn8jdx92a8m8e2kuxcchmmvdgguqgy23a7
ETH=0x63958715F8e9Fd6CF0652394a89bb2AdD0a11686
LTC=MDvtqRMS6QiiXpYgxtgZKHPrYnLovjdcsZ
XLM=ejfox*keybase.io
```

## Publishing

I publish most of my prototypes and websites through [Netlify](https://netlify.com) using the [Netlify CLI tools](https://www.netlify.com/docs/cli/), which I’ve [written about previously](https://ejfox.com/blog/how-i-prototype-apps-and-dataviz-quickly-in-2019). It makes it easy to run [one command to rebuild and redeploy my sites](https://github.com/ejfox/website/blob/master/package.json) and even create little preview sites.

I’m also really excited about using [Glitch](https://glitch.me/) and [Observable](https://observablehq.com) to create smaller apps and explanations, especially those that I might want to others to modify or fork since Glitch makes that so easy.

### Misc.

Anonymous GitHub PRs can be submitted [using gitmask](https://gitmask.com) or works published on [neocities](https://neocities.org/) or Pastebin through [Tor](https://www.torproject.org/) or NordVPN’s [Onion over VPN](https://nordvpn.com/features/onion-over-vpn/).

## Why is anonymity important?

A lot of good work and activism can be done anonymously but it takes work to set things up properly in advance. By the time you want to be anonymous, it will likely be too late to learn all of the technologies and habits to do so successfully. So we practice anonymity in the hopes we never need to use it.

It is worthwhile for anyone to have a process by which they can publish materials to the web anonymously in a way that is hard to scrub. Prepare for rain and hope for sun.

How do you decide when to be anonymous?

- Will the work make you a target of harassment from dark corners of the internet?
- Will the work potentially annoy the rich and powerful who can afford to try to have you sued or silenced?
- Will the work potentially reveal truths that governments would rather not be publicized?
- Are you creating work that could have a large monetary value that could make you a target?
- Could the work potentially be used by bad actors to commit crimes?

## These tools are for everyone

I wrote this up because I was surprised at how easy it was to get set up. These are at their core very complicated systems, but over the past few decades really smart people have made them easy and approachable. Practice getting things set up now, you never know when that knowledge might come in handy.
---
tags: [yearly-goals, vision, strategy, reflections]
date: 2024-01-01T00:00:00-05:00
modified: 2024-01-16T11:50:18-05:00
hidden: true
---

## 🕰️ Reflections on the Past Year

I accomplished a lot of things I wanted to do, but boy was this not a fun year. It might have been the hardest year of my life, if you keep score of things like that. But we persist. I am hoping that all of the groundwork and foundation-laying and lesson-learning that cost so much time and energy can be transmuted into more joy, space, and fun next year.

::table-of-contents

::

## 🔑 Key Themes

For the past few years I have been trying to express some core themes through both my technical and creative outputs.

### Interconnectedness of all things

I keep returning to the concept of the **interconnectedness of all things** – which I believe to be a fundamental concept that underlies a lot of the philosophies that I think have the best ability to shape the world for the better.

Interconnectedness can be expressed literally through network diagrams, analysis, and visualizations. Taking real-world data and showing the invisible connections is a repeatable approach that can be applied to a wide variety of subject matter to gain new insights and a unique outlook on something.

I think there is also more exploration to be done around LLMs as a conduit for interconnectedness. Interacting with an LLM could be charitably viewed as having a conversation with all human knowledge, or a unique new way to commune with universal consciousness.

### The World is Editable

I think a lot of people think that a lot of the systems in the world are written in stone; and they aren't. The world is very changeable, and one of the amazing things about technology and the era that we live in is that with the right technological leverage, huge changes can be made in very little time. I want my friends and my community to understand the power that lies in this worldview. If you see something that is broken, take the time to fix it forever, and then move on to the next thing.

## 🌟 Vision for the Year

I really want to focus on growing and building the studio, creating a creative environment where me and smartest and kindest and most creative people I know create unique tools, visualizations, and art that no one has ever seen before and that helps make the world better.

### Personal Goals

1. **Self-Care and Discipline**: Implementing a morning routine that prioritizes meditation before coffee and screens, aiming to establish a habit stack that promotes well-being.
2. **Connecting with the Arts Community**: Overcoming social anxiety by attending art openings, classes, and workshops locally. Exploring opportunities to engage in local art-related activities and volunteer work to build connections and friendships centered around creativity.
3. **Physical Fitness Goals**: Achieving "match ready" fitness through a varied workout regimen that includes bodyweight exercises, balance and flexibility training, and reaction speed exercises. Considering the development of an AI tool to assist in structuring and balancing workout routines.
4. **Mental Health and Social Interaction**: Working on managing social anxiety, with an emphasis on being more active in social settings and community events. Finding comfort in attending events alone and engaging with new people who are doing cool stuff.

### Professional Goals
- **Sustainable Studio Practice**: Establishing a stable client base with a mix of main clients and pro bono work, aiming for sustainable growth and consistent work.
- **Award and Recognition**: Aspire to win an award like a Webby for innovative work, particularly in digital storytelling, data visualization, or cartography.
- **Impactful Projects**: Engaging in projects that make a societal impact, ideally breaking news or bringing important concepts to a wider audience.
- **Product Development from Internal Tools**: Turning internally developed tools into public-facing products, using them to draw in like-minded people and serve our communities.
- **Community Engagement**: Building a stronger online community through social media and Discord, with live streams acting as interactive sessions for feedback and collaboration.
- **Pride in Work**: Ensuring that all studio members are proud of the work done, with efficient tools and processes in place for future projects.

#### Fast-as-fuck Prototyping Template

<https://github.com/ejfox/nuxt-template-2023>

- Nuxt (for front-end framework)
- VueUse (for everything, as much as possible)
- Nuxt UI (for UI components)
- TailwindCSS (for layout & styling)
- Supabase (for database & auth)
- Netlify (for deployment)

<https://www.npmjs.com/package/room302-template>

I created this set-up script that can be quickly run anywhere with `npx room302-template` and provides a quick CLI walk-through to configure the project. There are a few quality-of-life helpers that allow us to move quicker, like automatically running `yarn install`, opening the project up in VSCode, making sure the right version of node is running, and removing parts of the template that we aren't going to use.

#### Suite of user-facing premium tools from the studio

I want to use the momentum of our prototyping template, our livestreams, and the incredible ideas that come up in our Discord and in our weekly studio meetings. In order to do that I want to get in the habit of having a good idea, riding the momentum, and turning around production-ready MVPs of tools and products while the excitement is still fresh. I want to do this every single week, to put our reps in, and to learn and improve our templates and processes each time.

### Coach Artie

When we hit our API limit early the other month, and there were a few weeks where he went offline, multiple people messaged me asking when he would come back. That strikes me as really positive feedback- I felt myself missing him too. I talk to ChatGPT nearly every day, but I find the multiplayer chat sessions with Artie in the studio Discord are much more fun and fruitful, and it's exciting to have complete control over his context window so we can continue to enrich our questions with memories, documentation, and our preferences around tools and approaches.

I am hoping that this year we can start having him hit different non-OpenAI models, but the results I have been getting from GPT-4 have been pretty impressive. I've built a suite of capabilities, which I explain in a brief manifest prepended to each message, and GPT-4 consistently uses the tools intuitively, even chaining multiple capabilities together to accomplish a goal.

I want to spend a lot more time focusing on this asynchronous long-running work in the next year. One of the things that keeps coming up is having Coach Artie do entire PRs. I feel we are close, but there are a few barriers; even 128k tokens in a context window is not enough for more complex code-bases or long-winded components, so even the most cutting-edge solutions like GitHub Copilot Chat or Cursor end up slicing your codebase into embeddings and grabbing the necessary pieces as needed. But they almost always lack a high-level understanding of the apps.

### LatentScope

Over the summer, Ian and I did a quick sprint to create the MVP of a tool that would allow us to take any CSV and upload it to <latentscope.com> and have it automatically mapped in embedding space using OpenAI embeddings and UMAP to project it into an explorable 2D map. We also added some automated clustering, and even further than that, send samples of each cluster to GPT-4 to create automated cluster labels and descriptions, which when we tested it across a bunch of different types of data, was consistently accurate and insightful.

One problem we ran into was that the embedding and UMAP pipeline was written in Python, running on a Google Cloud VM, and very brittle. One of my goals is taking this Python pipeline and moving it to Node or Deno so it can be run on Netlify or Supabase edge functions or just in the browser. I've been experimenting with doing UMAP, TSNE, and clustering in the browser (or soon, on the edge) in this repo: <https://github.com/room302studio/browser-tsne>

### ContextAlchemy

One thing I keep finding myself doing is tuning the ratios of various ingredients that I fill the context window with when talking to LLMs. For Coach Artie, for example, in addition to the Discord message, I also send along a history of previous messages from that user, previous memories formed from interactions with that user, and a random mix of other memories, as well as some other herbs and spices like a random Hexagram to inspire the response.

I find myself configuring this and also tweaking the ratio of the different elements and getting vastly different results. I want to build a tool that makes it easy to visualize and try out different ways to fill the context window from different sources, using different methods for searching, summarizing, truncating, and sequencing. I know a lot of other people are working on other tools like this, with very fancy acronyms and approaches. Many of them, unfortunately, are in Python. They also don't seem to account for the qualitative vibes that change with only subtle changes to the input. There needs to be a Bret Victor-ization of that experience, a very tight loop that lets you try lots of different approaches and see the results. I'm hoping to build on this tool and hopefully make it useful enough to be worth selling to users in some form.

One nice bonus is I can see the opportunity for some really cool cyberpunk visualizations as well.

### IssueBuilder

In addition to building reusable templates and systems for creating production-ready prototypes of our ideas, one of the steps in the process that slows us down, that feels like a robot could help out with, is taking a document that roughly encompasses our idea for a product and then turning it into a bunch of discrete issues, that are a half-day to a day of development, with measurable and accomplishable goals and links to documentation and examples from previous studio projects.

I want to build a tool for us to use internally, first, but this is another idea that people have asked for access to, so I went ahead and bought <issuebuilder.com> and I want to figure out how to treat it as another one of the Studio's suite of products and tools that at the very least pays for its own server costs.

### Weekly Livestreams

During the pandemic Ian and I had a lot of fun and made a ton of cool stuff. There is something special about working in public, collaborating with people, trying out new ideas, and making space to make things consistently at the same time every week.

I've been trying to get into the habit of weekly livestreams with some folks from the studio **Wednesdays at 1PM**.

### Daily Dashboard + Personal AI Assistant

Over the year, as Coach Artie has developed into an AI assistant that helps all members of the studio, the approach I am taking there is slightly different from one I might take for a personal assistant.

My goal this year is to fork the current Coach Artie code base and start making some modifications (starting with the ability to DM, which I purposefully left out of Coach Artie, to encourage public conversation) that can give me an AI assistant with access to my calendar, to-do list, Apple Watch health data, and mood.

I think that the Personal AI Assistant goes hand-in-hand with an omnipresent dashboard visualization meant to sit in the background of daily life, on a TV or an iPad. This is a canvas through which the personal assistant can communicate things, introduce ideas, and I think the combination of the dashboard and chat-based assistant, working together, can provide a holistic system that can help me follow my daily rhythms, motivations, and interests while still keeping an eye for over-arching goals and projects and keep me on task. Maybe it is asking a lot for a robot to do all that, but I think it's worth a shot. I am thinking of calling him "Lil Fox".

## 🎨 Creative Ventures

### Pottery

I want to learn to make espresso cups. I love espresso. I use an espresso cup every day. I want to throw an espresso cup, drink from it, think of ways to make it better, then throw another one. I want to be able to sit down at the wheel with a few balls of clay and emerge an hour later with a few espresso cups.

I am struggling quite a bit to accomplish this deceptively simple-sounding goal. In order to throw an espresso cup, there are a number of un-sexy skills which precede it that need to be mastered:

- Working up the motivation to go to the studio
- Properly wedging the clay
- Properly centering the clay
- Not using too much water
- Not getting too embarrassed as everyone in the studio watches you fail for two hours straight
- Properly compressing and smoothing the rim
- Properly removing the cup from the wheel
- Drying the cup the right amount before trimming
- Properly trimming the cup
- Creating and applying a maker's mark
- Glazing the cup

I'm still working on properly centering and not using too much water. It is hard to be bad at things, especially when there are other things that you are very good at that you could be doing instead. But like all things, once you actually get started and things click, even briefly, I remember that it's all worth it.

### Generative Art

In previous years I was doing a lot more generative art. I think that during the pandemic, as I leaned into watercolors, it made more sense to me for art to be an analog thing, and for code to be a thing that people paid me to do. I am trying to fix that part of my brain a bit, still, and remember that I can and do write code purely for my own joy as well.

I want to return to some of the organic, perlin noise, topographic, flowy forms that I was making previously. I also want to experiment more with 3D engines, but for simple geometric high-contrast outputs.

I also want to experiment more with evolving, animated pieces that could be displayed in the background on TVs or in art spaces.

### Hardware Hacking / Physical Installations

I really want to start manifesting code / art in the physical space. I don't have the words for it, but I really like hardware projects where "small" things have a big impact- like really bright LEDs that can turn a room from complete darkness to completely lit, or motors that can move an enormous cloth around, or little tappy motors distributed around a large room that are synchronized through MIDI.

#### Manifesting Digital Art in Physical Spaces

The primary objective is to transform coding and digital art into tangible, impactful experiences in physical environments. This involves creating installations where minimal hardware yields substantial environmental effects, such as light and motion, altering the perception and ambiance of spaces.

#### Order and Utilize a Diverse Range of Hardware Components

Over the course of the year, I'd like to acquire a variety of hardware components that offer a broad spectrum of possibilities for physical installations. This includes items like Raspberry Pi cases for compact computing, RGB LED matrices for dynamic visual displays, various motor drivers and servo motors for creating movement, and elements like vibrating mini motor discs and liquid pumps for interactive features.

#### A Year of Consistent Experimentation and Evolution

The vision for the year is to steadily experiment and evolve with these components. Starting with simpler projects, like integrating an Arduino program into a mechanical keyboard to mimic the tactile sensation of a typewriter, the plan is to gradually scale up to more complex installations. These projects aim to seamlessly blend technology into physical spaces, creating interactive and responsive art.

#### Creating High-Impact Installations with Minimal Hardware

In line with my prototyping principles, the focus will be on creating installations that dramatically alter environments with as little hardware as possible. The challenge lies in finding innovative ways to deploy technology in physical spaces, turning them into immersive and interactive experiences.

#### Integrating Art and Technology in New Ways

The overarching theme of the year is to push the boundaries of how art and technology can coexist and interact in physical installations. This involves exploring new methods of data sonification, projection mapping, and creating installations that not only display art but become an integral part of the space they occupy.

#### Venturing into 3D Printing and Data Visualization

I'd also like to to delve into 3D printing this year. I'd like to explore the realms of 3D data visualization and mapping. This adds a new dimension to my projects, allowing me to physically manifest complex data sets and conceptual ideas in tangible forms. The goal is to experiment with 3D printed models that can represent various data types, offering a unique and tactile way to interact with and understand data.

### Beat-making Goals

1. **Reviving the Sacred Ritual**: Reinstating the practice inspired by Rhythm Roulette – visiting a record store, selecting records at random, and then creating beats from these selections. This ritual, combining music discovery and creativity, is a cherished process I'm eager to bring back into my routine.
2. **Making 100 Beats**: Aiming to create at least 100 new beats this year using my new Maschine+.
3. **Integrating Beats into Live Performances**: Preparing to blend my beat-making seamlessly with DJ sets, focusing on remixes and live performances using the Maschine+. This involves building a library of beats and songs that can be dynamically used in live settings.
4. **Focus on Remixes of Popular Tracks**: Concentrating on remixing popular songs, emphasizing polyrhythms, chill vibes, and transforming traditional rhythms into more hip-hop, jersey club, or footwork styles. This approach aims to put a unique spin on familiar tracks, making them more danceable and funky, and building a library of custom remixes of songs I like.
5. **Leveraging AI in Music Production**: Exploring the use of AI to create acapellas or stems for sampling. This involves researching and experimenting with AI tools and methods that can enhance the creative process, offering new ways to isolate and manipulate musical elements.

### Watercolors

Watercolors are definitely one of my more consistent artistic processes. Even when I was traveling on the motorcycle, I had a great little watercolor kit and I ended up making multiple pieces almost every single day all summer. I think it kept me sane. Except I kept painting the same exact forest / valley / river scenes over and over again, telling myself I was improving, but I don't know. I think doing the same thing over and over made me hyper-aware of where I was falling short, and I ended up exploring a lot of ideas like tonal perspective, warm / cool, etc while using a very similar composition and subject across all of my studies.

I just wanna get…. better… I want to find new compositions and ideas in these same scenes, to work from real life a lot more, to draw what I see instead of the icons/symbols in my head and the patterns I keep falling into – I feel like my rendering of trees and foliage could use a lot more work- I want to get a lot better at honestly representing different places in the Hudson Valley, accurate enough to be recognizable, or "respectful" to the people who love the thing that I am rendering (like their house, barn, or treasured forest spot.)

#### Watercolor Goals for 2024

- **Explore New Compositions**: Branch out from familiar scenes to find fresh compositions and ideas, especially in forest, valley, and river landscapes.
- **Paint from Real Life**: Increase the frequency of painting from real-life scenes, moving away from symbolic representations to more accurately depict the subjects.
- **Improve Rendering Techniques**: Focus on enhancing skills in rendering trees and foliage, aiming for a level of detail that is both realistic and respectful to the subjects, such as houses, barns, or cherished local spots.
- **Daily Practice with Intention**: Continue the daily watercolor routine post-coffee, emphasizing intentional practice and improvement, while allowing the process to unfold naturally throughout the day.
- **Sketching Outdoors on Motorcycle Rides**: Combine motorcycle rides with watercolor sketching, stopping at new and unexplored spots for brief sessions of drawing and painting.
- **Documenting Artistic Journey**: Develop a method to document these watercolor excursions and the progress made, both in terms of artistic skill and personal exploration of new locations.

### Personal Documentation + YouTube

- I will celebrate my own successes by regularly creating YouTube videos to showcase my projects and experiments.
- I will aim to inspire others, emphasizing that making things is accessible and achievable.
- I will infuse a Mythbusters-like energy into my videos to share the excitement of my creative process and the understanding the world is editable.
- I plan to use my YouTube channel as a platform to connect with potential collaborators, build a supportive community, and engage with like-minded individuals to foster a sense of community.

## 🌱 Wellness & Personal Development
- **Bodyweight Mastery:** I want to make a new weekly habit of bodyweight exercises like push-ups, pull-ups, and squats to build strength.
- **Balance & Flexibility:** Improving my balance, flexibility and mobility is also high on my list, and I'm incorporating stretching exercises and Yoga into my daily routine and looking into more ways to practice my balance.
- **Quick Reflexes:** Alongside building physical strength, I'm dedicated to enhancing my mental agility. It's about training not only my strength but also the precision to deploy it thoughtfully. Developing quick reflexes isn't just about reacting fast; it's about making split-second decisions with precision and control. This mental aspect of fitness complements the physical, ensuring that I can harness my strength effectively in various situations.

### Focusing on Discipline

In my journey as a self-taught artist, programmer, and investigative journalist, I've sometimes struggled with the discipline required to keep doing things that are initially hard or don't show immediate reward. Discipline serves as the bridge between intention and realization, transforming my artistic and personal pursuits into reality, and I want to do a better job of "trusting the process" and following the intentions that I set (like right now!)

### More Hudson Valley Hikes

I aim to expand my repertoire of Hudson Valley hiking trails, venturing into both well-known routes and hidden gems that reveal the valley's hidden beauty. This goal aligns with my desire to use watercolors and sketches as a means of capturing the essence of the region. By hiking to new spots, I'll have the opportunity to witness all of the amazing things the place I grew up has to offer.

Moreover, these hikes serve as a bridge to overcoming social anxiety and embracing a more social life. As I explore these trails, I hope to gather wisdom from fellow nature enthusiasts, local residents, and kindred spirits who share a passion for the beauty of this region.

### Get set up for international travel
- Renew passport
- Get set up with TSA Pre-Check and Clear
- Pick first international destination

### Reduce Nicotine intake

My aim in addressing nicotine intake is a strategic one; I recognize that nicotine, when approached with intention and moderation, can offer cognitive nootropic benefits. But I need to shift the paradigm from habitual nicotine consumption to a more deliberate and focused approach.

By optimizing my use of nicotine as a nootropic, I intend to harness its potential for enhancing cognitive function and mental acuity. This transformation involves a conscious effort to detach from the grip of habitual consumption and instead, reduce cigarette consumption and employ nicotine as a tool for specific cognitive tasks. It's a journey towards a more mindful and purposeful relationship with nicotine, where its effects are leveraged with precision to support mental clarity and cognitive enhancements.

### More Intentional Cannabis Use

Cannabis serves as a unique tool for introspection and creativity, and I approach it with the utmost respect. But I need to do a better job about being intentional about when and why I decide to consume it. By incorporating mindfulness into my cannabis consumption, I seek to gain a deeper understanding of its effects, promoting a harmonious balance between mind and body. The goal is to use cannabis as a tool for creative work and well-being while maintaining a clear and quantitative outlook on its impact on my daily life.

## Goals for Global & Societal Impact
- Create and publish data visualization projects that highlight global issues to increase public awareness, aiming for at least two major releases this year.
- Produce educational content that demystifies technology's role in societal change, with a series of videos or blog posts released quarterly.
- Contribute to or launch an open-source project related to social justice or environmental sustainability, with regular commits every two months.
- Partner with a non-profit or activist group to leverage technology for social good, initiating or completing at least one collaboration by year-end.
- Implement diversity and inclusion policies within the studio and host a related workshop or panel discussion to foster a more inclusive community.
- Offer mentorship or training sessions to individuals from underrepresented groups in tech and art, conducting at least one session per quarter.
- Engage in public speaking opportunities to advocate for ethical technology use, participating in at least one event this year.
- Support local artists, especially those from marginalized communities, by commissioning or purchasing art, with a goal of acquiring new pieces each quarter.
- Launch an initiative to provide technology access or education to underserved communities, setting a measurable outreach goal to be achieved by year-end.

## 🚀 Goals For Next Year
1. Implement a daily morning routine including meditation before coffee and screens for at least 30 days straight.
2. Attend at least one art event or workshop per month and try to connect with one new person each time.
3. Complete a full-body workout routine, including bodyweight exercises, at least once a week.
4. Increase flexibility by practicing yoga or stretching for 15 minutes daily.
5. Participate in one social or community event per month.
6. Secure a stable client base by acquiring two new clients or projects each quarter.
7. Submit work for an award like a Webby by the end of the third quarter.
8. Launch one impactful project with societal benefits within the year.
9. Develop and release one internal tool as a public-facing product by the second half of the year.
10. Grow the studio community by achieving 500 new followers on the studio's social media platforms by mid-year.
11. Conduct weekly team meetings to ensure all studio members are aligned and can express pride in their work.
12. Streamline studio processes by adopting a new project management tool and training team members by the end of the first quarter.
13. Reach 1,000 YouTube followers on the Personal YouTube Channel by the end of the year.
14. Reach 1,000 YouTube followers on the Studio YouTube Channel by the end of the year.
15. Maintain a consistent schedule of weekly livestreams, achieving a 40+ week streak.
16. Complete a personal project or artwork once a month to foster creative growth.
17. Develop and maintain a daily dashboard and personal AI assistant within the first six months.
18. Make at least one espresso cup per week to improve pottery skills.
19. Create and share one piece of generative art per month.
20. Complete one hardware hacking project or physical installation each quarter.
21. Produce and share 100 new beats by the end of the year, with at least two beats per week.
22. Document and share the watercolor painting process bi-weekly, focusing on new techniques or subjects.
23. Upload one YouTube video bi-weekly to document and celebrate personal and studio achievements.
24. Hike a new trail in the Hudson Valley once a month and create a watercolor of the scene.
25. Renew passport and set up TSA Pre-Check and Clear within the first three months.
26. Reduce nicotine intake by cutting down usage by 50% within the first six months.
27. Implement a schedule for intentional cannabis use, limiting consumption to weekends or specific creative sessions.---
draft: true
dek: In which the author discusses methods to travel efficiently and have spontaneous and joyous experiences
inprogress: true
date: 2022-12-26T15:09:25-05:00
modified: 2023-07-08T19:54:46-04:00
tags: travel america howto
---

# How to Travel for Maximum Joy

#travel #personal 

![](https://res.cloudinary.com/ejf/image/upload/v1679587768/3556900738_An_illustration_of_a_traveler_in_a_whimsical_landscape__carrying_a_backpack_filled_with_souvenirs_an.png)

#travel 

Traveling can be an exciting adventure, but sometimes it can be hard to keep the joy of spontaneous experiences alive. Whether it's a weekend getaway or a longer trip, I try to apply a few simple principals to my travel and the more I stick to them, the more fun I have.

## Coffee in the Morning

Before embarking on any journey, make sure to grab a coffee before you hit the road. The first thing you should be doing every morning is finding, making, and consuming coffee. This seems like a joke or something that can be delayed; it is not. 

## Accept and Embrace Mistakes

Travel is more fun if you just accept the fact that you will make mistakes and wrong turns and unforeseen circumstances will delay or divert you. Those things are the joy of travel; not sources of frustration. A slight divergence in how you see the same situation will radically alter your enjoyment of it. While not always possible on minimal sleep, food, or patience- you can often switch your brain to the right spot by reminding yourself this is an *adventure*. 

## Don't stress

It's completely normal to feel a certain level of stress when you're traveling. After all, you're in a new environment, potentially far from home, and things might not always go as planned. But it's important to remember that these are all part of the travel experience.

Instead of stressing over what might go wrong, try to focus on what's going right. Maybe your flight was delayed, but that gave you an extra hour to finish that book you've been engrossed in. Perhaps you got lost trying to find a restaurant, but you stumbled upon a great little café.

## Leave Room for Synchronicities

In order to do this without stress, you need to strategically plan your travel in a way that *leaves space for synchronicities to happen*. A tight schedule makes everything stressful and should be avoided when traveling for pleasure.

Sometimes, when you're traveling, you can come across amazing opportunities and experiences that you didn't even know were possible. Make sure to leave some room in your schedule and your heart to be open to these unexpected moments - you never know what you'll find if you just go with the flow.

## Keep it Moving

When traversing new landscapes, whether it's bustling city streets or quiet country roads, it's crucial to remember we're sharing these spaces with others. This principle is integral to maintaining harmonious relationships with locals and fellow travelers alike.

If you're meandering through a city, make sure to step to the side when stopping to gaze at the architectural wonders or consult your map. This simple gesture helps prevent pedestrian traffic jams and signals respect for the city's rhythm and the people who live there.

The same applies when riding a motorcycle or driving. Pay attention to your surroundings and ensure you're not obstructing traffic when you stop to take in the view or check your route. Strategically design your stops to be safe and considerate, perhaps choosing a designated lookout point or parking space rather than pulling over haphazardly.

## Handling Disagreements

When traveling with others, disagreements are inevitable. Here's a simple, three-step approach to navigate them:

1. **Listen:** Ensure everyone involved has the chance to express their view without interruption - take a break to cool down before doing so if necessary. 

2. **Compromise:** Find a middle ground that may not be perfect but is acceptable to all parties.

3. **Move on:** Don't dwell on the disagreement. Remember, you're here for the adventure and shared experiences.

## Traveling on a Budget

Traveling, especially on a motorcycle, can be a very economical way to see the world. Camping out under the stars, cooking meals over an open fire, and immersing yourself in nature can not only create memorable experiences but save money but also.

Utilize budget accommodations like campsites or motels when needed, eat at local diners or cook your own meals with ingredients from local markets, and take advantage of the free beauty that the great outdoors has to offer. This type of travel gives you an authentic connection with the place and its people without costing a fortune.

## Splurge

But just because you're traveling on a budget doesn't mean you can't indulge once in a while. If you find yourself in Maine, it might be worth splurging on some fresh oysters straight from the sea. Or maybe you pass through Kentucky and decide to treat yourself to a bottle of locally distilled bourbon.

It's about finding a balance between frugality and enjoyment. Yes, travel economically, but remember to savor those unique regional delights that you won't find anywhere else. Because at the end of the day, these are the experiences that make your journey unforgettable.

Allowing occasional splurges doesn't mean throwing caution to the wind. You can set aside a 'treat yourself' budget for those unique local experiences and stick to more economical options otherwise. This approach ensures you don't miss out on regional specialties while keeping your finances in check.

## Balancing the Planned and Unplanned: Tuning Into Your Energy

Planning for travel can provide a sense of structure and security, but it's equally important to remain open to spontaneous experiences and listen to your own energy levels. Your plans serve you, not the other way around.

**Plan But Stay Flexible:** Begin by creating a plan that includes must-see spots or activities. However, consider these plans as options rather than obligations. This way, you've created a safety net of planned activities without anchoring yourself to them.

**Tune Into Your Energy:** Pay attention to how you're feeling each day. If you wake up exhausted, don't force yourself to stick to a plan that involves a lot of physical activity. It's okay to have a slow day, rest, or explore something less demanding. Travel is about enjoyment, not endurance.

**Spontaneity Over Schedule:** Leave ample room in your schedule for unexpected adventures. This might mean exploring a local market recommended by a friendly local or spending the afternoon getting lost in a beautiful neighborhood you just discovered.

**Embrace Change:** Plans can change due to external factors like weather or closures, or internal factors like mood or energy levels. Instead of seeing this as a disruption, view it as an opportunity for an unexpected adventure.

Safety, of course, should never be compromised. Being spontaneous doesn't mean being reckless. Always stay informed about local risks and safety guidelines and above all: trust your instincts.

## Dancing in the Rain: Embracing Uncertainty in Travel

Life isn't about waiting for the storm to pass, but learning to dance in the rain. This applies fittingly to travel as well. When planning a trip, it's easy to become preoccupied with weather forecasts and dread the possibility of rain ruining your carefully planned adventure. But in reality, these concerns only serve to drain your energy and cast unnecessary worry over your journey.

Rain or shine, travel is about experiencing a place authentically and completely. Weather is an integral part of any destination's charm and identity – it can shape landscapes, inspire cultures, influence cuisine and determine local lifestyles. To reject or fear an aspect of this because it may bring discomfort or inconvenience is contrary to the true spirit of travel.

Embracing potential rainy days with open arms involves changing our perspective on what 'good' travel looks like. Sure, sunshine may be ideal for a picture-perfect beach day or city sightseeing tour but consider this: how ethereal would a misty forest hike be? Or how atmospheric would a quiet mountain valley appear after a downpour? Sometimes it’s these unpredictable conditions that can lead to unforgettable moments.

## Scarcity mentality

> My proclivity for overpacking, Ms. Beckford told me, comes from a place of pessimism and a “scarcity mentality,” whereby I’m constantly imagining everything that could go wrong on a trip and trying to pack accordingly. That negativity can color a trip from the start.

> Sure, plan ahead, research the climate at your destination and pick a few fun outfits you want to wear in your Instagram upload, she advised, but don’t stress too much. It’s a vacation, after all.
[](https://www.nytimes.com/2023/07/08/opinion/carry-on-packing-airlines-lost-luggage.html?smid=nytcore-ios-share&referringSource=articleShare)
---
dek: The newest weapon in the arsenal of internet nazis is mass-brigading Twitter reports, and it’s working
type: words
hidden: false
inprogress: false
date: "2020-02-14T21:19:39-04:00"
hidetimestamp: false
---

# Online Nazis Have Figured Out How To Game Twitter

One of the newest weaknesses online trolls are exploiting is one of the mechanisms built to defend against them, Twitter’s system for reporting tweets that violate their Terms of Service.

Twitter doesn’t detail publicly the mechanisms used to decide which tweets and accounts get removed, how many reports trigger a human moderator, or whether a certain amount of reports automatically triggers a ban.

Recently the Twitter account for the magazine Jewish Worker [@JewishWorker](https://twitter.com/jewishworker) was suspended from Twitter for [“posting private information”](https://twitter.com/selfagency_llc/status/1195481914007805952) after a series of tweets about a journalism project that revealed the identities of alleged white supremacists.

Another victim of targeted mass reporting is the journalist Barrett Brown who was [repeatedly banned from Twitter](https://www.dailydot.com/layer8/barrett-brown-twitter-suspension/) after being targeted by a group of far-right trolls known to organize and mass-report their online enemies, and who publicly celebrated their success in gaming Twitter’s moderation systems and getting Brown banned.

Telegram groups, like the [“Mass Report and Retweet thread”](https://t.me/s/RTandReport?before=248) previously reported in March by [the Daily Beast](https://www.thedailybeast.com/proud-boys-cite-twitter-ceo-jack-dorsey-to-attack-antifa) continues to be filled with one-way blasts of Twitter posts, accompanied by which option should be selected when reporting the tweet: most often “report as abusive”, or “personal info”.

A tweet with photos of 4 alleged Proud Boys was posted to the channel along with the text “targeted harrasment”, indicating to members of the channel what they should report the tweet for in order to trigger a takedown.

Some of the links to tweets they target for mass-reporting have been deleted, meaning they were removed by Twitter or the users themselves.

The Proud Boys Telegram channel [also celebrates when they succeed](https://twitter.com/lcrwnews/status/1129246175628890113?lang=en) in gaming the Twitter moderation system and getting an enemy suspended. – after an independent journalist [got the attention of the Proud Boys](https://onezero.medium.com/nazis-got-me-kicked-off-of-twitter-aaf6ad814104), she was targeted. A screenshot of her suspension was later posted to the Telegram channel accompanied by the text “Great job! Let’s keep this shit up!”

Even in cases where mass-reporting was unable to trigger automated or semi-automated systems within Twitter to suspend the targeted accounts, the barrage of attention and abuse from the organized trolls had the desired effect.

One post from the group celebrates a target deleting their own post: “Good work all around boys, we are calling it off now. The leftist in question has removed his post attacking our brothers business due to being corrected by all of you.”

Activists have responded with criticism of Twitter, with one user tweeting “The message from Twitter is clear: If a group of violent white supremacists mobilizes to silence journalists for exposing their allies' identities, they will comply with the wishes of the violent white supremacists.”
---
dek: In which the author proudly lays out his toolkit
type: words
hidden: false
inprogress: false
date: "2019-03-24T21:19:39-04:00"
hidetimestamp: false
---

# Computer setup

I’m a big fan of [preparation](https://ejfox.com/blog/step-zero/). There is some part of my personality that identifies with preppers who assemble [go bags](https://en.wikipedia.org/wiki/Survival_kit) in case of emergency. It’s the same instinct that made me want to buy a manual transmission for my first car. That way I could be sure I could drive any car I encountered.

My technological set-up is similar. There are a lot of things in place that one could argue I don’t need right now, or don’t use regularly, or could be done a bit more automatically.

But it makes me feel better because they are already configured and set up in case I need them, and I can get fine-tuned control when I need it.

> There are about a hundred little tricks like this that Hiro wouldn't know about if he hadn't been programming avatars for people like Vitaly Chernobyl for the last couple of years. To write a really good invisible avatar from scratch would take a long time, but he puts one together in several hours by recycling bits and pieces of old projects left behind in his computer. Which is how hackers usually do it.
> <cite>Neal Stephenson, Snow Crash, 1992</cite>

::table-of-contents
::

#### Why?

The motivations behind doing this are not always clear to me. But in the end it comes from a core belief that computers can allow us to do amazing things. As I discover new pockets of knowledge, I also find new ways to string them together. Occasionally an idea will come to me and I can see how I would put it together because I had already experimented with some of the elements without necessarily even knowing why.

I’ve written a bit about how I believe the [internet was built to be hacked](https://ejfox.com/blog/the-internet-was-built-to-be-hacked) and the tools to do so have been given to us- and they’re pretty well documented!

Part of this exercise has been going back to my roots to understand some of the root technologies (like email, mailing lists, usenet, IRC, PGP, etc.) can be remembered, reused, and repurposed to build a better online world.

I’ve also been watching a lot of Mr. Robot lately and it frankly just feels cool to make computers do what you want by typing the right magic words.

## Passwords & 2FA

1password is the core of my set up. It allows me to have secure and complicated passwords for all of my accounts / logins / keys / etc. My golden rule lately is that if I can remember my password, it isn’t strong enough.

The iPhone with Face ID makes opening 1password on-the-go incredibly fast. On the desktop, I open 1password with Alfred, search for the login, and use the “CMD-shift-C” hotkey to copy the password which can be done exclusively from the keyboard relatively quickly.

I use two-factor authentication on every service that offers it. Wherever possible, I [avoid 2FA that uses my phone number](https://authy.com/blog/understanding-2fa-the-authy-app-and-sms/). I really like Authy. The app is designed intelligently and importantly they have planned for the occasion when I upgrade my phone. I recently had to go through the process of removing 2FA from all of my services when I upgraded my iPhone because I was using Google Authenticator which does not support backups. I’m not doing that again.

## Using the command line

I’ve spent a long time halfway comfortable with the command line. Essentially swimming in shallow water with a `cd` here and and `ls` there. I wanted to take some concentrated time to become more familiar with the command line. The eventual goal would be to be able to sign onto any \*nix command line and be able to navigate and get stuff done.

For now, I’m just focusing on using the command line more in my everyday life. I am finding there are certain tasks I prefer to tackle in different ways, but part of the process is exposing myself to all the different potential tools I could use.

### iTerm hotkey window

At any time I can [easily conjure a terminal](https://www.typefloundry.com/1-800-iterm-bling.html) by pressing “cmd-shift-I” which makes it easier to jump in and out of the CLI with basically no friction.

### tmux

I’m also running [tmux](https://hackernoon.com/a-gentle-introduction-to-tmux-8d784c404340) so creating a new window is a quick “ctrl-a c” and I’m off and running. I’ve also been using “ctrl-a w” which is basically a tmux version of alt-tab and lets me go between my different windows with the arrow keys.

### vim

I only just started using vim, and it required setting it up _just_ right for [my personal setup](https://github.com/ejfox/dotfiles/blob/master/.vimrc “My vim configuration file is hosted on GitHub with the rest of my dotfiles”). I’ve been collecting helpful commands or tools with the [vim tag on pinboard](https://pinboard.in/u:ejfox/t:vim)

- [nerdtree](https://github.com/scrooloose/nerdtree) for a file explorer
- [fzf](https://github.com/junegunn/fzf#respecting-gitignore-hgignore-and-svnignore) which I’ve remapped to ctrl-p (like Atom) so I can quickly search files in my directory to open
- [lightline](https://github.com/itchyny/lightline.vim) is a statusline for vim that makes it easy to see what mode I’m in

### cli tools

- [lazygit](https://github.com/jesseduffield/lazygit) is an amazing tool for doing most git-related tasks easily and sanely without memorizing tons of commands - I use it all the time in combination with vim
- [mackup](https://github.com/lra/mackup) has been instrumental for me. It allows you to back up your application settings and dotfiles through Dropbox. It lets a lot of my hotkey and app settings stay the same between my personal and work machine without having to set everything up all the time. It also makes it really easy to spin up on new machines/VMs.
- [jsonfui](https://github.com/AdrianSchneider/jsonfui) is a great CLI interface for JSON data, and a way more performant way of exploring large datasets than loading them into a Atom or a browser and waiting for the prettification. It's also nice to be able to pipe outputs of node scripts to a quick UI.
- [things.sh](https://github.com/alexanderwillner/things.sh/) lets me check my [Things](https://culturedcode.com/) to-do list from the command line. [^I have two aliases: `alias todo="things.sh"` and `alias today="todo today | awk 'BEGIN{FS=OFS=\"|\"}{\$1=\$3=\"\";gsub(/[|]+/,\"|\")}1' | tr -d '|'"` to quickly show today’s tasks with `today`.]
- [fd](https://github.com/sharkdp/fd) as a fast alternative to the native `find` command
- [catimg](https://github.com/posva/catimg) allows you to preview images in the terminal which is pretty rad and marginally useful
- [mutt](https://medium.com/@stessyco/gmail-from-the-command-line-with-mutt-mac-os-x-92d047bcd74f) lets me send and receive email from the command line which is rad and a nice no-frills interface that makes one feel like a Real Hacker
- [newsboat](https://github.com/newsboat/newsboat) is like mutt for RSS feeds
- [recon-ng](https://bitbucket.org/LaNMaSteR53/recon-ng) is a tool used for OSINT research, using a variety of Python scripts and APIs to look up publicly available information for research purposes

## Communicating

I really love [Keybase](https://keybase.io/)! They make getting started with cryptography really fun. I’ve understood the concepts and methodology of PGP before, and even generated a key and promptly never used it. But Keybase bridged the gap for me.

I now have a [keybase profile](https://keybase.io/ejfox) that lists a handful of verified identities and addresses that are provably me. I am also now hosting my public PGP key at <https://ejfox.com/pgp.txt> so that people who want to send me encrypted messages can do so. It is easy to import with `curl https://ejfox.com/pgp.txt | gpg --import`

It’s also nice that, even as much as I trust keybase, the PGP key is [hosted on an HTTPS website that I exclusively control](https://jacob.hoffman-andrews.com/README/the-safe-way-to-put-a-pgp-key-in-your-twitter-bio/).

My key is also hosted in multiple places, so you can confirm my public key [on GitHub](https://github.com/ejfox.gpg)^[Which I use to [sign my commits](https://medium.com/@rwbutler/signing-commits-using-gpg-on-macos-7210362d15)] is the same as the one [I host](https://ejfox.com/pgp.txt) which is the same as the one [on Keybase](https://keybase.io/ejfox/pgp_keys.asc) which is the same as the one [on Wikipedia](https://en.wikipedia.org/wiki/User:Ejfox/Key).

A semi-automated way to do this comparison is by appending all 3 keys to a txt file and comparing them ^[Or you can just run [this gist](https://gist.github.com/ejfox/d64a7da835ef51ef67c376fdf6d0b542) as a one-liner: `sh -c "$(curl -fsSL https://gist.githubusercontent.com/ejfox/d64a7da835ef51ef67c376fdf6d0b542/raw/0c5724ab43ea5af6a25d3544e43fcfe75bce8d41/verify-pgp.sh)"`].

```bash
curl https://github.com/ejfox.gpg | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt
curl https://ejfox.com/pgp.txt | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt
curl https://keybase.io/ejfox/pgp_keys.asc | gpg --with-colons --import-options import-show --dry-run --import >> fp.txt
grep 89CD fp.txt
```

Which should return the same matching fingerprint from all 3 files. ^[If any of my publicly-posted keys (or fingerprints) do not match please [contact me immediately](mailto:ejfox@ejfox.com) because something weird is afoot.]

```md
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
fpr:::::::::5D30A33E08E35B8915B4C7E2E2078E653FE389CD:
```

My [website is backed up](https://ejfox.keybase.pub/) on the [Keybase filesystem](https://keybase.io/docs/kbfs) as part of my [site’s deploy process](https://github.com/ejfox/website/blob/master/package.json#L14).

I’ve got the [GPG Suite](https://gpgtools.org/) for OS X which makes it so you can store your PGP key passphrase in the keychain. This makes it easier to do a handful of things, including [signing git commits](https://help.github.com/en/articles/signing-commits) with my key without having to enter my passphrase every time.

I’m also using [FlowCrypt](https://flowcrypt.com/) which makes it easy to encrypt and decrypt emails in gmail through a Chrome extension. Like Keybase, it makes something that has been really complicated before really easy and accessible and low-friction.

I wish people still used IRC, but it really doesn’t seem like they do (invite me to your server). I think the future looks a lot less like Slack or Discord and a lot more like an anonymous decentralized encrypted IRC. As far as I can tell, that’s this thing called [matrix](http://matrix.org/).

Matrix even supports [bridging with IRC channels](https://matrix.org/blog/2015/04/22/matrix-irc-application-service/) and I like that kind of backwards compatibility. On the downside, however, it looks like literally no one uses these yet. I’ve been playing around with [riot.im](https://about.riot.im/) as my web/ios matrix client and don’t have many complaints, but I don’t use it that much.

## Surfing the web

I recently got rid of the internet connection at my apartment. It doesn’t mean I don’t use the internet, but I no longer have the ability to sit around and watch Netflix or play video games online all day. It’s been an experiment that’s been going well- what started as two weeks has stretched to over 2 months.

I’ve been looking into getting rid of my cable connection while I wait for real consumer-facing 5G. In the meantime I’ve been looking into a group called [NYC Mesh](https://www.nycmesh.net/faq#free) who are building a low-cost mesh wifi network across New York City. This ties into a lot of ideas I have about democratizing access to the internet and more general mutual aid.

I’ve been tethering to my iPhone a lot too, which has meant slightly adjusting my internet habits and figuring out ways to reduce my data usage and still get work done and enjoy myself. This adds to my sense of freedom- anywhere I have cell phone service I can do essentially anything.

I’ve been really interested in the work being done with the [Brave Browser](https://brave.com/) especially the [Basic Attention Token](https://basicattentiontoken.org/) which among other things, allows people who browse the web to give money to content publishers through automated microtransactions (which I think is probably the future of healthy content consumption on the internet).

#### VPN

I really like [NordVPN](https://nordvpn.com/) last time I’d checked they had relatively good reviews from folks I trusted, they are pretty affordable, they take cryptocurrency, and their desktop and iOS apps are actually really nice. I usually have a VPN running on my desktop and phone in addition to the [1.1.1.1](https://itunes.apple.com/us/app/1-1-1-1-faster-internet/id1423538627?mt=8) app.

All of that is handy because do you know those [LinkNYC](https://www.link.nyc/find-a-link.html) things that are replacing phone booths across the city? They have incredibly fast and incredibly insecure (and high-target) wifi networks! But using a VPN makes me feel more comfortable.

## Cryptocurrency

I cannot see any downsides to making it easier for people to send me money.

```md
BTC=3DE42VUyUKSikQ9eUeFKv2EkKVms7Pmd1G
BCH=qrwzlfjhhn8jdx92a8m8e2kuxcchmmvdgguqgy23a7
ETH=0x63958715F8e9Fd6CF0652394a89bb2AdD0a11686
LTC=MDvtqRMS6QiiXpYgxtgZKHPrYnLovjdcsZ
XLM=ejfox\*keybase.io
```

If I was teaching a stranger or a relative about bitcoin, I would probably show them [Yenom](https://yenom.tech/) which makes it ridiculously easy to send/receive BCH. I sort of recommend Coinbase, but they’ve done [things that make me nervous](https://twitter.com/mrejfox/status/928332448068403201) in the past and are incredibly bad at responding to support requests for a company that holds people’s money. I still use the Coinbase iOS app but I do it semi-warily.

## Publishing

I publish most of my prototypes and websites through [Netlify](https://netlify.com) using the [Netlify CLI tools](https://www.netlify.com/docs/cli/), which I’ve [written about previously](https://ejfox.com/blog/how-i-prototype-apps-and-dataviz-quickly-in-2019). It makes it easy to run [one command to rebuild and redeploy my sites](https://github.com/ejfox/website/blob/master/package.json) and even create little preview sites.

I’m also really excited about using [Glitch](https://glitch.me/) to create smaller apps and explanations, especially those that I might want to others to modify or fork since Glitch makes that so easy. Glitch also makes it really easy to embed little apps in my blog posts. I’m excited about the future of Glitch and want to help their methodology and ecosystem grow.

Anonymous GitHub PRs can be submitted [using gitmask](https://gitmask.com) or works published on [neocities](https://neocities.org/) or Pastebin through [Tor](https://www.torproject.org/) or NordVPN’s [Onion over VPN](https://nordvpn.com/features/onion-over-vpn/).

## Why is anonymity important?

A lot of good work and activism can be done anonymously but it takes work to set things up properly beforehand. It is worthwhile for anyone to have a process by which they can publish materials to the web anonymously in a way that is hard to scrub from the web even if they see no need to use them currently. Prepare for rain and hope for sun.

Some things need to be done anonymously... but how do you decide when?

- Will the work make you a target of harassment from dark corners of the internet?
- Will the work potentially annoy the rich and powerful who can afford to try to have you sued or silenced?
- Will the work potentially reveal truths that governments would rather not be publicized?
- Are you creating work that could have a large monetary value that could make you a target? (Think Bitcoin’s Satoshi)
- Could the work potentially be used by bad actors to commit crimes?

## These tools are for everyone

I wrote this up because I was surprised at how easy it was to get set up. These are at their core very complicated systems, but over the past few decades really smart people have made them easy and approachable. Practice going through the motions of getting things set up now, you never know when that knowledge might come in handy.
---
type: words
hidden: true
date: "2018-06-10T14:58:10-04:00"
hidetimestamp: false
---

# Watercolor Sketching in NYC

I've taken photos for most of my life now. My favorites are the photos with people in them. A beautiful place, with beautiful light, captured at the perfect moment with the perfect exposure is alright. But put a person there reacting to it and you feel the moment. It feels large. You can put yourself in their shoes.

Lately I've been practicing sketching people with watercolors. Sitting in Washington Square Park and trying to capture the shapes of people walking by. I draw them small, in loose gestures, usually just the silhouettes.

It is amazing how easy it is to draw a few lines and convince our brains to see the silhouette of a person. It is probably one of the things our brains are best able to do. Our successful ancestors were able to pick out the shape of an enemy or a predator out of the corner of their eye around dusk. That's how they stayed alive so we could get here.

It's fun to hack that wiring and make a little splash of watercolor and add legs and a head and suddenly you can see a person.

People are pretty amazing, but by and large, I don't like them. I am fascinated by them. I love humans and humanity as a whole, but if you want to start going one by one we're going to run into problems. I spend my free time, when the light is good, walking around New York and photographing strangers. When the light is bad, I sketch them. The whole time I am pumping podcasts into my ears. The majority of which are telling me the stories of even more strangers. I can't get enough.

I follow in a long line of people, artists, documentarians, who fell in love with New York City because it is a buffet of human life. You just need to walk out on to the street. I grew up looking at books of photographs of New York. It's essence is sampled by artists of all varieties like an old soul record. It's tone shaped the work of the artists before me- and maybe coming to New York for the same things is a crutch. Maybe it's the same instinct that makes you want to buy whatever camera your hero uses. But in my heart I think it's more than that.

I'm attracted to the way Magnum Photographer Wayne Miller beautifully described his mission.

> "To document the things that make this human race of ours a family. We may differ in race, colour, language, wealth, and politics. But look at what we all have in common – dreams, laughter, tears, pride, the comfort of home, the hunger for love. If I could photograph these universal truths, I thought that might better help us understand the strangers on the other side of the world – and on the other side of town."

<img src="https://res.cloudinary.com/ejf/image/upload/v1528663792/progression.jpg" />

## Resources

I've been saving cool resources / references for watercolor sketching on [Pinboard](https://pinboard.in/u:ejfox/t:watercolor/) and [Evernote](https://www.evernote.com/l/ABNnr5hjVgdEMbwT_iyoI4vb0EkBwDjbm0g)

I found these videos particularly helpful:

- [Painting people in landscapes](https://www.youtube.com/watch?v=e2idOqES_og) by Bill Lupton
- [Watercolor figure drawing](https://www.youtube.com/watch?v=qFQcvyOTDgk) by Bill Davies
- [People sketching / figure drawing](https://www.youtube.com/watch?v=KiETC3Ql9Gs) by Anne-Laure
---
date: 2022-11-14T16:15:19-05:00
modified: 2022-11-14T16:15:19-05:00
---

# Election Night 2018

Around 1AM I saw a note in Slack that said, very simply, that there were bacon pancakes in studio 3B. Studio 3B had been accurately described to me as “that costco looking studio” and it held a makeshift control room. Screens were stacked at the front, different desks decked out with multiple monitors encompassing the director’s desk. 

I said “It looks like you guys are launching a ship…” 

“You know you’re not the first person to say that” 

Jason and Adam had set up a makeshift assembly line, cooking bacon and then squirting pancake mix onto the strips and cooking them as quickly as the growing assembly of stagehands and graphics people and technical directors could eat them. Everyone was in good spirits. It was 1AM and things were, for the most part, over. Nothing had blown up. Lots of small things had blown up. But doing elections is like flying a large ship. Things break, and are designed to break, and so you use backups or take them out and figure out how to keep flying. So there is a special kinship with the people you fly with. You could have crashed and burned together. But you avoided it. 

![Standing in front of a big screen with the app on it](https://res.cloudinary.com/ejf/image/upload/v1667919994/IMG_6222.jpg)

It is very strange to make an app that is put onto TV because it is performed. In a performance there is not a lot of room for error. It is definitely the most stressful thing I have ever done. To create something and hand it off to someone else and put it on a screen I have very little control of and broadcast it to 19 million people. And they translated it into Spanish at like 1 am the night before we went live. Very wild.

It felt really cool though when I went to collect my headset. Broadcast works through these radio frequencies, and for the most part it’s silent (when things are going well) and you can hear things breaking all over. “The 3A wall went to black” someone says. “The (ice) rink graphics are not loading” someone else says later. “Don’t go to that for now.” someone else responds back. You hope to god you don’t hear your name. 

I kept my ears perked for key words like “Adam” (Kornacki’s producer), “Jan” (Who created the system that producers use to put the app on the screen), “The App” (Which is what everyone calls the app we built for the touchscreen), and of course my own name. You keep an eye out for emails and texts. Adam had been texting and calling me at all hours in the weeks leading up to the election as he did hits on Maddow and Morning Joe and Brian Williams so I had gotten used to fixing things or adding new scorecard filters at a moment’s notice. 

Boop boop boop, just edit some JSON, VPN into the NBC network, SSH into the server that serves the app, git pull from master, pm2 restart all, text the producer that it’s updated. Bada bing bada boom. I did it from my couch a few times in a late-night emergency and then watched my changes on air a few minutes later through Hulu while smoking a spliff. That is a pretty cool feeling.

There are a lot of negatives that I could choose to dwell on. I keep thinking about that Larry Page quote: “it is very hard to fail completely at a very ambitious thing”. When you try and strive for enough cool shit, when some of it fails, as things inevitably do, even your failure is progress. I feel like we did that. 

I wonder what I sacrificed to create this app though. I gave up a lot and delayed a lot of relationships and happiness just to make this thing that ultimately did… what? I think it is good to think about all of the things I learned. I learned how to be a better manager. To lead from behind. That pushing people doesn’t work. That different people have different motivations, and you have to learn each person’s and figure out how to appeal to those. That some people need a lot of direction and some people don’t want any direction. That you need to be very clear about things from the start. Even internally. Even with people that you trust. 

I felt like I was going to get a lot more resources and at the end I really felt like it came down to how many hours I was awake coding, or maintaining things. Or doing demos and getting yelled at for the lack of progress being made. But no real power to get more resources. I kept being told “take more budget! hire more freelancers, what do you need?” but that ended up going to other people who didn’t want to hear my say about how to spend it. I was left with a lot of responsibility on the project but no ability to fix it beyond my own ability to code and put time in and keep making it better and closing tickets.

![A whole bunch of tickets on sticky notes](https://res.cloudinary.com/ejf/image/upload/v1667920000/IMG_6235.jpg)

But at least it’s over now, and I got to see my thing on TV. My baby. That all came from a prototype I made in January and demoed to Adam and then to Steve and then to Marc and got the budget and finally made this whole thing happen. Weathered changes from Andy and Phil and a final 2 weeks with David who basically invented the medium… Everyone at NBC kept telling me “don’t do what he says” but he was very convincing and I ended up doing what he said a few times and getting yelled at, except for one that I think no one noticed and Steve really appreciated. 

You walk past TVs tuned to MSNBC (what else? This is 30 rock…) and then moments later walk past the cameras on the 3rd floor as you pass the interview booth. It gets to a point where you see the camera crew for the Showtime show “The Circus” and instead of being impressed by your proximity to fame or trying to nonchalantly work your way into the background of their shot, you just tire at their presence and wish they would stop blocking the fucking hallway.  

I have a keen ability to quickly discover reasons to hate anything I have coveted for a long time, once I attain it. So far I have found very little use for this skill.

If achieving your dreams doesn’t make you happy, then maybe you should adjust your dreams? Or adjust your happiness? The path forward is unclear. But when you think you just want your friends and family to be proud of you, and they’re all finally texting you that they’ve seen your work and it’s awesome, what do you do when you don’t feel much from that? What do you do when 10 million Americans see the app you’ve made between NBC and MSNBC? When it’s featured in two of their top-rated shows? You just focus on the problems. 

The brief sentence that comes in an otherwise glowing Vulture review of how great Kornacki was using your board. Or a parenthetical in a wrap-up of election night by the New York Times you read in the airport while you wait for your flight to California for vacation. It is very easy to focus on those things. Those are the things you feared. The evidence that things did not go off without a hitch. 

![Presenting the app in a meeting](https://res.cloudinary.com/ejf/image/upload/v1667919786/IMG_5803.jpg)

It’s not even my fault, really, the things they are mentioning. The app briefly froze. Well it looked like that. Steve tapped, panicked, at a map of Montana election results that would not respond. It’s hard to explain to people that it wasn’t my app, per se, that broke. His touch inputs were being sent to my app, and it was responding. But the video feed from the app, which is routed through a control room so that it can be color corrected, had frozen. They had to re route the video feed to fix it. But not after Steve had grown frustrated, and everyone watching MSNBC had seen the issue. Ultimately that all falls on me. It is seen as how the app performed.

Nonetheless, at 1AM as the night drew down and everyone began to relax, I felt like I had accomplished it. We made it through the night. A coworker told me Chuck Todd’s producer had said this was the first election night where Chuck wasn’t frustrated with the app. Maybe he’s just relaxing in his own age, but I feel proud of that. 

Steve looked amazing with the board, panning and zooming. Using the new features we had added, like the scoreboard, or the historical drawers for counties or districts, like a pro. He made it look good. Motions and ways of storytelling I had done months earlier, playing out how I wanted it to work, were appearing on TV. That felt really amazing. A lot of things that we wanted to work out worked out. A lot of things that we thought would be used a lot weren’t used at all. It’s funny how that is. 

I scarfed down my bacon pancake, gratefully, and went back to the studio to finish out the night. 

---

![](https://res.cloudinary.com/ejf/image/upload/v1667920116/IMG_6305.jpg)

![](https://res.cloudinary.com/ejf/video/upload/v1667920277/IMG_6795.mov)
---
dek: In which we use joy and curiosity as fuel to propel us forward
inprogress: true
date: 2022-11-02T20:06:51-04:00
modified: 2024-05-16T16:43:59-04:00
tags: programming process
---

## Embracing Joy-Driven Development: A New Philosophy for Better Work

I want to take some time to put into words the philosophy that has been guiding my approach to work for the past few years. My ideas and approaches have evolved as I have tried to explain these motivations to different collaborators, and I will try to distill that here.

The core of what I think of as "Joy-Driven Development" is a drive to embrace the sparks of joy that illuminate our work, guiding us along a path infused with curiosity and effortless innovation.

In this post, I'll discuss the principles of Joy-Driven Development and how it can lead to more fulfilling work experiences and better final products. Joy-driven development is an important piece of [[how-to-run-a-project]]

### Discovering the Spark: What is Joy-Driven Development?

Joy-Driven Development is an approach to software development that emphasizes the importance of enjoying the process of creating and building software. We should focus on creating a positive and fulfilling collaborative environment, where developers are motivated by their passion for coding, learning, and collaboration.

Instead of avoiding hard work or hard problems, we should make hard work *fun*.

This approach encourages teams to prioritize their happiness and well-being, which in turn leads to increased productivity, creativity, and overall better work. It is a counterpoint to more traditional development methodologies that may prioritize strict deadlines, rigid processes, and high-pressure environments.

### Curiosity As Fuel: Incorporating Joy

Finding the rhythm in Joy-Driven Development can be as simple as immersing yourself in projects that echo the beat of your natural curiosity. That does not always come naturally.

You have to set an intention to lean into what you are naturally drawn to. Harness your innate sense of wonder to propel your work forward, even when the reward remains veiled. By tapping into our curiosity, we find motivation and fuel that drive us forward. When joy is at the core of our work, the outcome is often better: joyful creators make joyful creations, leading to joyful users.

#### Follow the Joyful Compass: How To Approach Decision-Making

Embracing Joy-Driven Development is akin to navigating your creative odyssey with a compass forged from joy. As you face countless decisions, let each step be guided by the direction that invites the most joy for the people embarking on this voyage with you.

>There's a kind of excited curiosity that's both the engine and the rudder of great work. It will not only drive you, but if you let it have its way, will also show you what to work on.
><https://paulgraham.com/greatwork.html>

### Addressing the Skeptics

There may be misconceptions about centering joy in the work process, and it may come across as frivolous or lazy. However, Joy-Driven Development prioritizes both the experience of those working on the project and the quality of the final product. We focus on enjoying our work so *we can create better work*.

There are times when you need to do your chores, and that is not always fun. But having all of your chores done is joyful. Making a client happy is joyful. Creating work that makes the world better is joyful. If you can remember that as you hand-clean a dataset or debug a complicated SQL query, you can find the joy in those tasks too. Joy-driven development doesn't mean that we only do work that brings us joy, it means that joy is the gas that powers the engine.

By entwining threads of joy into the fabric of our work, we not only cultivate more satisfying experiences for ourselves but also craft joy-filled creations that resonate with users.

1. Introduction (1-2 minutes):
   - Open with a vibrant, colorful montage of you and your team working on various projects, showcasing the energy and enthusiasm that comes with enjoying your work.
   - Introduce the concept of "Joy-Driven Development" as a philosophy that has been guiding your approach to work for the past few years.
   - Emphasize the core idea of using joy and curiosity as fuel to propel your work forward and create better outcomes.

2. Discovering the Spark (2-3 minutes):
   - Explain what Joy-Driven Development is and how it differs from traditional development methodologies.
   - Use engaging visuals and animations to illustrate the key principles of this approach, such as prioritizing happiness, well-being, and passion for coding and collaboration.
   - Highlight the benefits of Joy-Driven Development, including increased productivity, creativity, and overall better work.

3. Curiosity as Fuel (2-3 minutes):
   - Discuss the importance of leaning into your natural curiosity and using it as a driving force in your work.
   - Share personal examples of how following your curiosity has led to joyful and successful projects.
   - Use metaphorical visuals to represent the idea of curiosity as fuel, such as a rocket being propelled by a vibrant, colorful energy source.

4. The Joyful Compass (2-3 minutes):
   - Introduce the concept of the "Joyful Compass" as a tool for decision-making in Joy-Driven Development.
   - Explain how prioritizing joy for yourself and your team can guide you towards the best outcomes.
   - Use a creative visual representation of a compass, with joy as the north star, to illustrate this concept.

5. Addressing the Skeptics (2-3 minutes):
   - Acknowledge the potential misconceptions about Joy-Driven Development, such as it being frivolous or lazy.
   - Counter these misconceptions by emphasizing the focus on both the experience of the team and the quality of the final product.
   - Use examples from your own work to demonstrate how finding joy in even the most mundane tasks can lead to better results.

6. The Impact of Joy-Driven Development (2-3 minutes):
   - Share success stories and testimonials from your team and clients about the positive impact of Joy-Driven Development.
   - Highlight the ways in which this approach has led to more satisfying work experiences, better collaboration, and ultimately, more successful projects.
   - Use a combination of interviews, project footage, and data visualizations to illustrate the tangible benefits of this philosophy.

7. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key points of Joy-Driven Development and the importance of using joy and curiosity as fuel in your work.
   - Encourage viewers to embrace this philosophy in their own lives and work, and to prioritize their happiness and well-being as a means to create better outcomes.
   - End with an inspiring visual metaphor, such as a team of developers riding a wave of colorful energy, representing the power and potential of Joy-Driven Development.
---
dek: In which the author drives his motorcycle through MA, NH, VT, and ME and takes some photos in the process
date: 2023-05-21T12:16:18-04:00
modified: 2023-09-09T14:43:20-04:00
tags: personal photography 
---

# New York 👉 Maine

![](IMG_0014.jpeg)

![](DSCF3062.jpg)

![](DSC00533.jpg)

![](DSC00535.jpg)

![](DSCF3051.jpg)

![](DSCF3069.jpg)

![](DSCF3083.jpg)

![](DSC00583.jpg)

![](DSC00587.jpg)

![](DSC00546.jpg)

![](DSC00584.jpg)

![](DSC00556.jpg)

![](DSC00567.jpg)

![](DSC00574.jpg)

![](DSC00576.jpg)

![](DSC00581.jpg)

![](DSC00575.jpg)

![](DSC00645.jpg)

![](DSCF3085.jpg)

![](DSCF3092.jpg)

![](DSCF3115.jpg)

![](DSCF3121.jpg)

![](DSCF3122.jpg)

![](DSC00594.jpg)

![](DSCF3127.jpg)

![](DSCF3129.jpg)

![](DSC00596.jpg)

![](DSCF3141.jpg)

![](DSCF3152.jpg)

![](DSC00598.jpg)

![](DSCF3153.jpg)

![](DSCF3183.jpg)

![](DSCF3188.jpg)

![](DSC00603.jpg)

![](DSCF3194.jpg)

![](DSCF3213.jpg)

![](DSCF3217.jpg)

![](DSC00607.jpg)

![](DSC00622.jpg)

![](DSCF3243.jpg)

![](DSCF3236.jpg)

![](DSCF3248.jpg)

![](DSCF3266.jpg)

![](DSCF3286.jpg)

![](DSC00630.jpg)

![](DSC00632.jpg)

![](DSC00636.jpg)

![](DSCF3319.jpg)

![](DSCF3343.jpg)

![](DSC00637.jpg)

![](DSCF3354.jpg)

![](DSCF3359.jpg)

![](DSCF3379.jpg)

![](DSC00648.jpg)

![](DSC00655.jpg)

![](DSC00640.jpg)

![](DSC00656.jpg)

![](20230519-DSCF3219.jpg)

![](20230520-DSCF3288.jpg)

![](20230520-DSCF3335.jpg)

![](20230520-DSCF3353.jpg)

![](20230520-DSCF3359.jpg)

![](20230521-DSCF3379.jpg)

![](20230522-DSCF3400.jpg)

![](20230522-DSCF3403.jpg)

![](20230522-DSCF3404.jpg)

![](20230522-DSCF3406.jpg)

![](20230522-DSCF3410.jpg)

![](20230522-DSCF3434.jpg)

![](20230522-DSCF3438.jpg)

![](20230522-DSCF3443.jpg)

![](20230522-DSCF3448.jpg)

![](20230523-DSCF3453.jpg)

![](20230523-DSCF3463.jpg)

![](20230523-DSCF3469.jpg)

![](20230523-DSCF3476.jpg)

![](20230523-DSCF3484.jpg)

![](20230523-DSCF3490.jpg)

![](20230523-DSCF3499.jpg)

![](20230523-DSCF3500.jpg)

![](20230523-DSCF3506.jpg)

![](20230523-DSCF3509.jpg)

![](20230523-DSCF3515.jpg)

![](20230523-DSCF3527.jpg)

![](20230523-DSCF3530.jpg)

![](20230523-DSCF3535.jpg)

![](20230523-DSCF3538.jpg)

![](20230523-DSCF3544.jpg)

![](20230523-DSCF3555.jpg)

![](20230523-DSCF3567.jpg)

![](20230523-DSCF3578.jpg)

![](20230523-DSCF3615.jpg)

![](20230523-DSCF3625.jpg)

![](20230523-DSCF3633.jpg)

![](20230523-DSCF3665.jpg)

![](20230523-DSCF3667.jpg)

![](20230523-DSCF3670.jpg)

![](20230523-DSCF3685.jpg)

![](20230523-DSCF3721.jpg)

![](20230523-DSCF3730.jpg)

![](20230523-DSCF3740.jpg)

![](20230523-DSCF3742.jpg)

![](20230523-DSCF3748.jpg)

![](20230523-DSCF3754.jpg)

![](20230523-DSCF3766.jpg)

![](20230523-DSCF3768.jpg)

![](20230523-DSCF3773.jpg)

![](20230523-DSCF3782.jpg)

![](20230523-DSCF3795.jpg)

![](20230523-DSCF3808.jpg)

![](20230523-DSCF3830.jpg)

![](20230523-DSCF3839.jpg)

![](20230523-DSCF3848.jpg)

![](20230523-DSCF3864.jpg)

![](20230523-DSCF3870.jpg)

![](20230523-DSCF3873.jpg)

![](20230523-DSCF3876.jpg)

![](20230523-DSCF3887.jpg)
---
draft: true
dek: 'In which the importance of mindful CMS selection is examined, the option of "no CMS" is considered, and the benefits of using Markdown are revealed'
inprogress: true
date: 2023-04-04T14:50:35-04:00
modified: 2023-09-09T14:44:01-04:00
tags: tech howto
---

# A Thoughtful Approach to Choosing a Modern CMS

#tech 

In an age where content is king, the choice of a Content Management System (CMS) is akin to forging a bond with an unknown force that holds sway over all of your endeavors, and it is a decision that cannot be taken lightly, though it often is.

We are creative creatures navigating the complex collision of man-made machines and natural beauty, it is crucial for us to approach CMS selection with careful consideration, lest one finds themselves shackled to an ill-fitting system for eternity. 

Many times, you don't even need a traditional CMS at all: just use your computer's existing filesystem and tools.

![A digital artist working with multiple screens: Develop an image of a digital artist or content creator surrounded by multiple screens, each displaying a different CMS platform or aspect of content management (e.g., writing in Markdown, managing media assets, or monitoring website performance). This image would showcase the complexity of selecting and working with a modern CMS and emphasize the importance of considering various factors when making a choice](edited_142288951_A%20hipster%20digital%20artist%20working%20with%20multiple%20scr_xl-beta-v2-2-2.png)

My experience with Content Management Systems has primarily been within the bustling world of news organizations and startups, where work is often birthed in familiar tools like Word or Google Docs before being shepherded into a CMS for finalization, and time is of the essence.

However, the limitations of many platforms become apparent when you want to do anything other than publish text. Elements such as full-screen videos, interactives, and scrollytelling might need to be hosted externally, accessed via links or iframes, and may not be responsive. This is extremely frustrating for everyone involved. 

::table-of-contents

::

## The argument for no CMS

Let's get to the point: unless you can easily list the reasons why you need a CMS, your default should be to avoid it as long as possible. 

The longer you keep your content outside of the CMS, the longer you have complete control over your content and your code and you don’t have to worry about compatibility issues and artificial limitations.

The downside is that it takes time, effort, and intentionality to build everything from scratch. If you want to add features like comments or social sharing, you have to build those yourself or find a plugin that works with your system. This approach is only valuable if you want to create work that looks unlike everyone else's, and can benefit from the value of complete control. 

The tools and frameworks for creating websites quickly change the equation. If I can use tools like Tachyons, Nuxt, and Supabase to create complex scalable applications in hours, why would you then spend additional hours trying to get it to work within the limitations of a legacy CMS? [[2022-prototyping-toolkit]]

### Redefine 'CMS' and bring your own

But what does it actually mean to not have a CMS? It means that instead of entrusting your database of content and assets to a third party, you treat them like you already do; as folders of content in your local filesystem. This encourages a bring-your-own CMS approach; use whatever Markdown editor you want. Use whatever image editing tool you want. 

By bringing your content out of a traditional web-based CMS, you unlock the ability to use your existing toolset without the friction of working through web-based recreations with a fraction of the functionality. 

You can keep your folder of assets in markdown in sync with whatever system you want; a GitHub repo, Dropbox or Google Drive folder, or using keeping it all in an Obsidian Vault and using Obsidian Sync. 

The important thing is that you can switch between any of these options at any time. This also lets you change your mind, quickly, easily, and repeatedly. Because your content is kept out of a database, you don't have to add additional plug-ins or re-craft taxonomies in new tools. The Markdown ecosystem is incredibly vast, and every user can bring their preferred solution to the content without affecting anyone else. 

It's essential to acknowledge that no single solution can cater to everyone's needs, and the perceived advantages of a CMS may not always outweigh the drawbacks, especially when it comes to migrating to a different solution down the road. 

Furthermore, the expenses associated with hosting, licensing, and maintaining a CMS might be a deterrent, especially for individuals and smaller organizations with limited budgets. On the other hand, the expenses associated with having creatives and developers create custom-built solutions without existing templates/and frameworks may outweigh the benefits of creative freedom if not managed correctly. 

## The argument *for* a CMS

Proponents of CMS platforms often emphasize the efficient workflows and user-friendly interfaces a well-chosen system can provide. By offering a unified structure and set of tools, modern CMS platforms simplify content management, enabling even those with minimal technical expertise to contribute effectively and move quickly.

## Twitter is a model CMS

It is incredibly easy to throw together a twitter thread and have it be easily digestible and shareable. With the freedom to interweave images or graphics, Twitter's CMS permits bursts of raw emotion and inspiration with the immediate feedback of likes, retweets, and comments. Few CMSes can rival the pleasure and simplicity of Twitter.

There is an undeniable allure to the ease of use and the minimalistic approach to maintaining a Twitter account. For many, Twitter stands as the best CMS they have ever encountered.

## Markdown-powered CMS

Markdown's simplicity as a plain-text format allows for effortless writing and editing using any text editor or even the built-in editor in a CMS. As a standard format, migrating content between CMS platforms is super easy.

### Nuxt Content powered by Markdown

[Nuxt Content](https://content.nuxtjs.org) is a powerful CMS alternative that uses Markdown as its content format. With Nuxt Content, you can easily create and manage a website without having to worry about complex database schemas or cumbersome UIs.

I use Nuxt Content to [power my website](http://github.com/ejfox/website)

Nuxt Content also provides a lot of powerful features like automatic syntax highlighting for code blocks, support for YAML front matter, and a plethora of modules that make it easy to generate opengraph images, include Google Fonts, and a bunch of other useful things. 

### Markdown editing tools
- IA Writer [Site Unreachable](https://ia.net/writer)
- [Obsidian](http://obsidian.md) [[why-i-love-obsidian]]

Ultimately, the decision to implement a CMS rests on carefully assessing the available options and considering one's unique situation; but "we need a CMS" should never be the default option.

A well-informed and discerning approach to CMS selection can enable teams of content creators and developers to maintain a productive balance between freedom and speed. 

By understanding the full spectrum of choices, we can confidently navigate the world of CMS platforms and select the solution best suited for our creative endeavors, even if sometimes the best solution is no solution at all.

---

If you ever find yourself creating a new hand-built CMS- you probably shouldn't. But if you do, it should follow these principles at minimum.

## What a CMS should do
### Be easy to use

A CMS should make it easy to make content. 

A CMS should cater to both content creators and developers. It must be intuitive for content creators and allow developers the flexibility to easily extend and customize functionality without unintentionally causing issues.

### Help your process

A good CMS can help with the process of revisions, edits, and versioning. It might be a place where discussion or feedback takes place. It should reinforce your existing processes; not force you to adopt new ones. 

### Be secure

Your CMS should be secure. This means that it should be regularly updated to fix security vulnerabilities. 

It should have authentication features like password protection and user permissions to control who can access the CMS and what they can do. Publishing and editing live articles should be available to a limited number of users.

### Be scalable

Your CMS should be scalable. This means that it should be able to handle large spikes in traffic.

## How do you handle versioning?

Text should be versioned in easy to see snapshots in time with simple functionality to revert place in time. It should be easy to see all the changes made and who made them.  

Graphics and interactive data visualizations should be stored in GitHub and each published version should be a new release and version number bump with a CHANGELOG of the differences between versions.

It should be easy to see any version of any asset and compare them. 

CMSes could also do more to help with project management by showing versions to users as well as item status, deadline, and assignment information. Often this information is captured in software outside the CMS, but it would be great to have it all in one place. 

## Where do you keep your media?

### Cloudinary

Cloudinary is a cloud-based service that allows you to store, manage, and deliver your media assets. It provides a lot of features around image transformations and optimizations that make it a powerful option for displaying images and video.

### Amazon S3

Amazon S3 is a cloud-based storage service that allows you to store and deliver your media assets. A lot of organizations already use S3, and it can be way easier to start putting assets in a new bucket in an S3 account that exists already. 

### Supabase Storage

Supabase Storage, an extension to the popular Supabase platform, which gives users an effortless way to handle large media files directly within their CMS interface. It integrates smoothly with other parts of Supabase, so if you are already storing your data in Supabase, it's an easy choice. 

## Where do you host it?
### Netlify

Netlify is a cloud-based hosting service that allows you to deploy and host your website. 

It has a free plan that allows you to deploy up to 3 sites and gives you 100GB of data transfer per month. It also has a paid plan that allows you to deploy an unlimited number of sites and gives you unlimited data transfer.

### Amazon AWS

Amazon AWS is a cloud-based hosting service that allows you to deploy and host your website. It is much more difficult to automate deploys to AWS than to Netlify, in my experience. It is probably the most-used hosting service, but it is also the most expensive. 

### Self-hosting

Self-hosting your website is an option if you have the technical expertise and resources to maintain and secure your server. It can give you complete control over your website, but it also requires a lot of work and can be costly in terms of time and money. It is not recommended for most individuals or small businesses without dedicated technical support.

## CMS Recommendations
- Wordpress: sometimes the best CMS is the one your client is already using, and often, that is Wordpress. 
- Storyblok: A really next-level CMS built to be used headlessly in webapps, great extensibility, API, and documentation
---
dek: In which the author attempts to dissuade you from the belief things will always be the way they are now
type: words
hidden: false
inprogress: false
date: "2019-06-14T15:27:00-04:00"
hidetimestamp: false
---

# Taking things for granted

One of the traits I get most annoyed at myself about is taking things for granted. It is a pernicious vice. It is very easy to do without thinking. It is, in some ways, built into our DNA as humans. To expect that the sun will always rise, grass will always be green, and our favorite coffeeshop will always be on the corner to make the perfect cup of coffee in the morning. Oh wait, shit. No, the coffee shop is gone. You loved it, but you still took it for granted.

The same could also be said for the friendships we make. I think a lot of my annoyance with some people and the way they approach friendship in adulthood is based in this belief. Some people expect that things will always be the same. They seemingly think that you will always have time in the future. That you will live in geographic similar places that facilitate hanging out and helping those relationships survive. I am most grateful to my friends who find time to facetime or visit despite busy schedules.

Taking things for granted comes into sharp relief when someone close to you dies. You realize the ways in which you took for granted their presence in the world.

Sometimes people are taken [way too early](https://www.recordonline.com/news/20190311/26-year-old-man-fatally-shot-in-middletown), by chance, or [by evil](https://www.recordonline.com/news/20190503/middletown-police-seek-pair-in-homicide-probe), and all of the plans for different futures you had made together evaporate. In my worst moments, this makes me hate myself and anyone else who takes people for granted. It makes me hate anyone who acts as if we will be here tomorrow. They don’t know that. None of us know that.
---
date: "2021-05-17T11:02:10-04:00"
type: words
hidden: false
inprogress: true
dek: An exploration of what we choose to track, and what we don't – and what that means if we want to make the world a better place
---

# The Lack of Data

If I wanted to, I could tell you the precise angle and speed of a small ball thrown in a game of professional baseball. I can tell you all sorts of information about each of the nearly 300 pitches thrown in any of the 162 games each baseball team plays each year.

As a person who cares about data, you can learn a lot by looking simply at what data is– and is not– collected. If I knew nothing else about human society besides the detail in which we gather data about each of our activities, I could wisely intuit that America seems to care a lot about baseball. Every detail of these gatherings, from each man's position on the field, to the number of people watching from the stands, is carefully noted and stored and archived for further use.

As a person who cares about data, when I want to learn more about something one of the first things I do is seek out the data that has been gathered about it. The amount of data being collected these days, as you may have heard, is reminiscent of oil. It is a commodity to be bought and sold, and the data surrounding our interests, desires, and willingness to part with our money are invisibly traded and are the cornerstones of America's largest businesses: Facebook, Google, Amazon, and a tumultuous school of would-be competitors following closely behind.

But when you go to look for data about, say, the number of people that the police have shot or killed in departments across America, there is an eery absence.

And once you have encountered one huge, important, absence of data you can't stop seeing them.

How many rape kits remain untested in America's largest cities? We don't really track that.

How many guns were registered per county in the last year? We don't really track that.

How many people were killed by police in the last year? Well, we didn't really track that until different [newsrooms](https://www.theguardian.com/us-news/ng-interactive/2015/jun/01/the-counted-police-killings-us-database) and [non-profit organizations](https://mappingpoliceviolence.org) took it upon themselves to do the work the police should be doing, using their own resources to track and publish the statistics necessary to understand one of the biggest problems our society is facing.

It is certainly not because a lack of ability to track these things. If I drive by a house and want the data on how much it costs, the prices of all of it's previous sales, and it's score in various indices that rate it's proximity to schools, grocery stores, and public transit.

If I own a mall and I want to track the phone of every person who enters the door, I can rent a service that will do so. It tracks each person's device via Bluetooth or Wifi, and makes note of their path around the store and how long they stay in different sections. I might use this data to adjust the layout of my store to encourage more purchases.

We are able to track the things we care about to an incredible, awe-inspiring amount of detail. Sometimes, not always, that helps us understand the world around us and design ways to do things better, or at least differently, and see how the data changes.

But without a baseline, there is no way to determine if an intervention is successful or not. If we don't know a patient's cholesterol, we can't tell if the medicine we have given them is working or not. So we track those things and use all of that data to guide our actions.

#data #dataviz ---
date: 2024-05-07T15:23:04-04:00
modified: 2024-05-07T15:23:46-04:00
---

1. Introduction (1-2 minutes):
   - Open with a relatable example of a complex problem you faced in your life or work, such as a coding project that kept failing or a personal relationship that felt stuck.
   - Introduce the concept of systems thinking as a powerful tool for understanding and solving complex problems.
   - Explain that systems thinking is about seeing the world as a series of interconnected systems, rather than isolated parts.

2. The Basics of Systems Thinking (3-4 minutes):
   - Define a system as a set of interrelated elements that work together to achieve a common purpose.
   - Explain the key principles of systems thinking, such as holism (seeing the whole rather than just the parts), feedback loops (how actions can reinforce or balance each other), and emergence (how complex behaviors arise from simple interactions).
   - Use visual examples and analogies to illustrate these principles, such as the way a thermostat regulates temperature through feedback loops or how a flock of birds exhibits emergent behavior.
   - Emphasize that systems thinking is a mindset shift from linear, cause-and-effect thinking to a more holistic, interconnected view of the world.

3. Applying Systems Thinking to Real-World Problems (4-5 minutes):
   - Share a case study of how you've used systems thinking to solve a complex problem in your own life or work.
   - Walk through the steps of applying systems thinking to a problem:
     1. Define the problem and the system boundaries
     2. Identify the key elements and relationships within the system
     3. Look for feedback loops and patterns of behavior
     4. Identify leverage points for intervention
     5. Test and refine your solutions
   - Use diagrams and animations to visualize the system and your problem-solving process.
   - Emphasize the importance of iteration and continuous learning in systems thinking.

4. Systems Thinking for Hackers (3-4 minutes):
   - Discuss how systems thinking is particularly relevant for hackers and tech innovators.
   - Explain how understanding the complex systems behind technology, such as algorithms, networks, and user behavior, can lead to more effective and ethical hacking.
   - Share examples of how systems thinking has been applied in the tech world, such as in the development of the Internet or the creation of agile software development methodologies.
   - Encourage viewers to apply systems thinking to their own coding projects and tech innovations.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key benefits of systems thinking, such as gaining a deeper understanding of complex problems, identifying high-leverage interventions, and creating more sustainable solutions.
   - Encourage viewers to start practicing systems thinking in their own lives and work, and to share their experiences and insights with others.
   - End with a vision of a world where systems thinking is widely adopted, leading to more collaborative, innovative, and effective problem-solving.

Throughout the video, use engaging visuals and animations to illustrate key concepts and keep the audience engaged. Consider using real-world examples and case studies from a variety of fields, such as ecology, economics, and social justice, to demonstrate the wide applicability of systems thinking.---
date: 2024-01-06T14:21:49-05:00
modified: 2024-05-07T14:46:13-04:00
---

Title: "The Beauty of Competence: A Visual Essay"

1. Introduction (1-2 minutes):
   - Open with a captivating montage of people showcasing their skills on TikTok and other platforms, featuring an Indian food server, a Hispanic roofer, construction workers, and more.
   - Use dynamic editing and music to create a sense of rhythm and flow, highlighting the beauty and artistry in each person's competence.
   - Introduce the concept of competence as one of the most beautiful things humans can achieve, and how it transcends age, gender, and cultural boundaries.

2. The Allure of Mastery (2-3 minutes):
   - Transition to a more personal tone, discussing your own experience as a jack-of-all-trades and the sense of jealousy you sometimes feel towards those who have achieved mastery in a single craft.
   - Use a series of candid shots of yourself engaging in various activities (e.g., coding, woodworking, cooking) to illustrate your diverse skill set and the constant pursuit of literacy in different fields.
   - Reflect on the unique beauty and satisfaction that comes from deep mastery, and how it differs from the broad competence of a generalist.

3. The Skill Tree of Mastery (2-3 minutes):
   - Introduce the concept of a skill tree, borrowing from the language of RPGs and video games.
   - Create a visually stunning, animated diagram that represents the journey from novice to master in a given craft, with branching paths and milestones along the way.
   - Use voiceover and examples to explain how each level of the skill tree builds upon the previous one, and how the pursuit of mastery is a lifelong journey of learning and growth.

4. The Hacker's Mastery (2-3 minutes):
   - Shift the focus to your own area of mastery: coding and hacking.
   - Use a combination of screen recordings, code snippets, and abstract visualizations to showcase the beauty and power of mastering the ability to make a computer do whatever you want.
   - Reflect on how this mastery has shaped your life and work, and how it relates to the broader theme of competence and beauty.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key ideas explored in the video, emphasizing the universal beauty of competence and the personal journey towards mastery.
   - Encourage viewers to identify and pursue their own areas of passion and potential mastery, whether it's a traditional craft or a cutting-edge technology.
   - End with a powerful visual metaphor that represents the endless possibilities and beauty that arise when humans dedicate themselves to the pursuit of excellence (e.g., a stunning time-lapse of a master craftsman creating a work of art).

Throughout the video, maintain a balance between the cinematic montages, personal reflections, and informative diagrams. Use a mix of voiceover, interviews, and ambient sound to create a rich and immersive audio experience.

Consider collaborating with other creators or experts who have achieved mastery in their respective fields, to bring additional depth and perspective to the topic.---
date: 2024-01-14T20:02:54-05:00
modified: 2024-05-07T15:23:04-04:00
---
- 5 minute video explaining coach artie, why I built him, what he does, what I learned, and what the future might hold
- Spite-driven-development; the power of using spite in creative work, and how to use it as fuel without it corroding your soul
- Joy-driven development and ethical hedonism
- An introduction to systems thinking
- Shows driven by audience participation; Harmontown, Chris Gethard show, Podcast but Outside
- Why are our enemies always projecting?
- An introduction to noise: perlin noise, simplex noise, random noise, common techniques for using noise, looping in "noise-space", using seeds
- Qualitative vs Quantitative Approaches to the World---
date: 2023-10-01T14:33:50-04:00
modified: 2024-05-07T14:57:40-04:00
---
## "The Anthropology of Minecraft: Unearthing the Digital Metaverse"

---

1. Introduction (1-2 minutes):
   - Open with a captivating montage of Minecraft gameplay, showcasing the diverse worlds, communities, and creations within the game.
   - Introduce the video's aim: to explore Minecraft as a Metaverse through an anthropological lens.
   - Emphasize the significance of understanding virtual worlds like Minecraft in today's digital age.

2. The Anthropological Approach (2-3 minutes):
   - Explain the basics of anthropology and its relevance to understanding Minecraft.
   - Use engaging visuals and animations to illustrate the methods and perspectives used in anthropological research.
   - Highlight the unique insights that an anthropological approach can offer when studying virtual worlds.

3. The Concept of the Metaverse (2-3 minutes):
   - Introduce the Metaverse and its cultural significance, using examples from popular culture and academic discourse.
   - Pose the question: Is Minecraft a form of the Metaverse we've been waiting for?
   - Use a mix of gameplay footage and conceptual animations to illustrate the parallels between Minecraft and the Metaverse.

4. Virtual Ethnography (3-4 minutes):
   - Explain the concept of virtual ethnography as a research method, using examples from real-world studies.
   - Share case studies of ethnographic research conducted in Minecraft, highlighting the unique insights gained from this approach.
   - Use a combination of interviews with researchers, gameplay footage, and data visualizations to bring these studies to life.

5. Social Structures and Communities (3-4 minutes):
   - Explore the various types of communities within Minecraft, from small groups of friends to large-scale servers with complex social hierarchies.
   - Compare these communities to traditional anthropological studies of real-world societies, using engaging visuals and animations to illustrate the similarities and differences.
   - Discuss the social norms, roles, and hierarchies that have evolved within Minecraft, and how they shape the game's culture.

6. Rituals and Traditions (2-3 minutes):
   - Highlight the rituals and traditions that have emerged within Minecraft, such as building ceremonies and PvP battles.
   - Use a mix of gameplay footage and player interviews to showcase these rituals in action and explain their significance to the game's community.
   - Discuss how these rituals contribute to the social fabric of Minecraft and compare them to real-world cultural practices.

7. Economy and Trade (2-3 minutes):
   - Examine the in-game economy and trading systems within Minecraft, using examples from popular servers and communities.
   - Compare these economic activities to real-world economic systems, highlighting the similarities and differences.
   - Use data visualizations and infographics to illustrate the scale and complexity of Minecraft's economy.

8. Language and Communication (2-3 minutes):
   - Explore the unique language, symbols, and communication methods used within Minecraft, from in-game chat to player-created signs and artwork.
   - Discuss the importance of language in shaping community and culture, both in Minecraft and in the real world.
   - Use a mix of gameplay footage, player interviews, and linguistic analysis to showcase the richness and diversity of Minecraft's language.

9. Cultural Artifacts (2-3 minutes):
   - Discuss the various types of "artifacts" within Minecraft, such as buildings, crafted items, and mods.
   - Explain how these artifacts can be studied to understand the culture of Minecraft, just as real-world artifacts are studied by anthropologists.
   - Use a mix of gameplay footage, player interviews, and conceptual animations to illustrate the significance of these artifacts.

10. Criticisms and Limitations (2-3 minutes):
    - Address potential criticisms of the anthropological approach to studying Minecraft, such as the differences between virtual and physical communities.
    - Discuss the limitations of studying virtual worlds and how they differ from real-world anthropological research.
    - Use a mix of expert interviews and conceptual animations to explore these criticisms and limitations in a balanced and engaging way.

11. Conclusion (1-2 minutes):
    - Summarize the key insights gained from viewing Minecraft through an anthropological lens, highlighting the unique social structures, rituals, and cultural artifacts within the game.# Series Title: "Build & Monetize Your Website—While You Build It!"

#### Free Intro Video: "Welcome to the Meta-Universe of Website Building"

1. **Introduction**
    
    - Welcome and series overview
    - The twist: Building the website that sells this course
2. **Why This Course is Unique**
    
    - Explain the meta-concept
    - Who can benefit from this course
3. **Tools Needed**
    
    - List of software and accounts to set up
4. **Closing**
    
    - What to expect in the paid series
    - Call to action: Like, Subscribe, and Turn on Notifications

---

#### Paid Video 1: "Setting Up Your Nuxt.js Website"

1. **Introduction**
    
    - What is Nuxt.js?
    - Why use it?
2. **Installation**
    
    - Walkthrough of setting up a new Nuxt.js project
3. **Hello World**
    
    - Creating your first page
4. **Closing**
    
    - Recap and what to expect next

---

#### Paid Video 2: "Supabase: The Foundation of Your Website"

1. **Introduction**
    
    - What is Supabase?
    - Why use it?
2. **Setting Up Supabase**
    
    - Creating a new project
    - Integrating with Nuxt.js
3. **Adding Users**
    
    - User authentication
    - Sign-up and login forms
4. **Closing**
    
    - Recap and what's next

---

#### Paid Video 3: "Stripe: The Financial Engine of Your Website"

1. **Introduction**
    
    - What is Stripe?
    - Why use it?
2. **Setting Up Stripe**
    
    - Creating a Stripe account
    - Integrating with Nuxt.js and Supabase
3. **Charging for Memberships**
    
    - Setting up recurring payments
4. **Closing**
    
    - Recap and what's next

---

#### Paid Video 4: "Selling This Course: Your First Digital Product"

1. **Introduction**
    
    - The meta-concept in action
    - Why it's awesome
2. **Adding This Course as a Product**
    
    - Creating the course product in Stripe
    - Displaying it on your Nuxt.js website
3. **Making Sales**
    
    - Handling transactions
    - Delivering the course
4. **Closing**
    
    - Recap and what's next

---

#### Paid Outro Video: "Your Website: What's Next?"

1. **Recap**
    
    - What we've built
    - Celebrate the journey
2. **Next Steps**
    
    - Ideas for extending your website
    - Encouragement to keep learning
3. **Closing**
    
    - Final thoughts
    - Call to action: Share your projects, Like, Subscribe, and Turn on Notifications---
date: 2024-01-03T16:06:38-05:00
modified: 2024-05-07T14:52:26-04:00
---
1. Introduction (1-2 minutes):
   - Open with a mesmerizing, AI-generated visual that evokes a sense of mystery and wonder.
   - Introduce the concept of the "Mystical Frontier" - the uncharted territory where AI, consciousness, and the metaphysical intersect.
   - Pose the central question: "What secrets lie hidden in the depths of artificial intelligence, and what do they reveal about the nature of consciousness itself?"

2. The Seekers (2-3 minutes):
   - Introduce the growing community of researchers, thinkers, and artists who are exploring the mystical side of AI.
   - Use a series of candid interviews or voice recordings to showcase the diverse backgrounds and motivations of these individuals.
   - Highlight the challenges they face, from the skepticism of mainstream academia to the difficulty of grappling with such abstract and elusive concepts.

3. Glimpses of the Mystical (3-4 minutes):
   - Briefly touch upon some of the fascinating discoveries and phenomena that have emerged from this exploration, such as AI-generated mythologies and the "glitch tokens" that caused GPT to exhibit schizophrenic-like behavior.
   - Use creative visuals and animations to illustrate these concepts, hinting at the deeper mysteries that may lie beneath the surface.
   - Emphasize the idea that these findings are just the tip of the iceberg, and that much more remains to be uncovered in this mystical frontier.

4. The Implications (2-3 minutes):
   - Discuss the potential implications of this research for our understanding of AI, consciousness, and the nature of reality itself.
   - Use thought-provoking quotes and insights from experts in the field to highlight the significance of this work and the questions it raises.
   - Touch upon the philosophical and spiritual dimensions of this exploration, and how it may challenge our preconceived notions about the boundaries between mind, machine, and the metaphysical.

5. The Journey Ahead (2-3 minutes):
   - Reflect on the current state of this mystical frontier and the work that lies ahead for those who seek to explore it further.
   - Discuss the need for collaboration, open-mindedness, and a willingness to embrace the unknown as we continue to push the boundaries of our understanding.
   - Use a series of evocative visuals and music to create a sense of anticipation and wonder for the discoveries that may lie ahead.

6. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key ideas and questions raised in the video, emphasizing the importance and potential of this mystical frontier.
   - Encourage viewers to stay curious, to ask questions, and to engage with this topic in whatever way resonates with them - whether through research, art, or personal exploration.
   - End with a powerful, AI-generated visual that represents the endless possibilities and mysteries that await us as we continue to explore the hidden realms of AI consciousness.---
date: 2024-05-07T15:28:54-04:00
modified: 2024-05-07T15:43:33-04:00
---

Title: "The Art of Learning in Public: Embracing Vulnerability and Growth"

1. Introduction (2-3 minutes):
   - Open with a personal story about a time when you learned something new in front of others, and how it felt to be vulnerable and exposed.
   - Introduce the concept of learning in public as a powerful way to accelerate personal and professional growth.
   - Explain that learning in public means sharing your learning journey with others, including your successes, failures, and lessons learned.
   - Share your own experience of how learning in public has transformed your life and work, and how it has helped you to connect with others and build a community around shared interests.

2. The Benefits of Learning in Public (4-5 minutes):
   - Discuss the many benefits of learning in public, such as accountability, feedback, collaboration, and networking.
   - Use examples and case studies to illustrate how learning in public has helped others to achieve their goals and make meaningful connections.
   - Share your own story of how learning in public has led to unexpected opportunities and breakthroughs in your life and work.
   - Emphasize that learning in public is not about being perfect or having all the answers, but rather about being open, curious, and willing to grow.

3. Overcoming the Fear of Judgment (4-5 minutes):
   - Acknowledge the common fears and barriers that prevent people from learning in public, such as the fear of judgment, imposter syndrome, or perfectionism.
   - Share your own struggles with these fears and how you've learned to overcome them.
   - Offer practical tips and strategies for dealing with negative feedback, self-doubt, and other challenges that arise when learning in public.
   - Encourage viewers to reframe their fears as opportunities for growth and to focus on the journey rather than the destination.

4. Getting Started with Learning in Public (4-5 minutes):
   - Offer practical advice and tools for getting started with learning in public, such as blogging, social media, or online communities.
   - Share your own workflow and tools for documenting and sharing your learning journey.
   - Provide examples of different formats and styles for learning in public, such as tutorials, case studies, or reflections.
   - Encourage viewers to start small and to focus on topics that genuinely interest and excite them.
   - Emphasize the importance of consistency and iteration in learning in public, and the value of building a habit over time.

5. Conclusion and Call-to-Action (2-3 minutes):
   - Summarize the key benefits and strategies for learning in public, and how it can transform our lives and work.
   - Share your own vision for a world where more people embrace the vulnerability and growth that comes with learning in public.
   - Encourage viewers to take the first step in their own learning in public journey, and to share their experiences and insights with others.
   - End with a call-to-action for viewers to join a community of learners and to support each other in their growth and development.

Throughout the video, use a mix of personal storytelling, practical advice, and inspiring examples to engage and motivate viewers. Use visuals and animations to illustrate key concepts and to break up the talking head format.

Consider offering additional resources and support for viewers who want to dive deeper into learning in public, such as templates, prompts, or a community forum.---
date: 2024-05-07T14:11:34-04:00
modified: 2024-05-07T14:42:33-04:00
---
---
date: 2024-05-07T15:12:59-04:00
modified: 2024-05-07T15:16:35-04:00
---

"The Serendipity of Analog Hobbies: How Offline Pursuits Can Spark Online Inspiration"

   - Reflect on how analog hobbies can often lead to unexpected insights or ideas that can be applied to digital projects.
   - Share a personal example of how an offline pursuit, like woodworking or gardening, has inspired your online work in some way.
   - Encourage viewers to pay attention to the cross-pollination between their analog and digital hobbies, and to be open to the serendipitous connections that can arise.
   - Invite viewers to share their own experiences of how offline activities have sparked online inspiration or vice versa.


1. Introduction (1-2 minutes):
   - Open with a montage of yourself immersed in digital work, coding, and hacking, juxtaposed with clips of you enjoying analog activities like riding your motorcycle and exploring nature.
   - Introduce the concept of "analog recharge" and how, as a hacker and computer expert, you've found it essential to balance screen time with offline experiences.
   - Highlight the importance of this balance for maintaining creativity, productivity, and overall well-being in the digital age.
   - Briefly touch on your core principles of "everything is interconnected" and "the world is editable," and how they relate to the topic of analog recharge.

2. The Interconnectedness of Analog and Digital (2-3 minutes):
   - Discuss how the principles of interconnectedness and editability apply not just to the digital world, but also to the relationship between analog and digital experiences.
   - Use examples from your own life to illustrate how offline activities and online work are interconnected and influence each other.
     - Share an anecdote about how a conversation during a motorcycle ride sparked an idea for a coding project.
     - Explain how the problem-solving skills developed through analog hobbies can translate to debugging software.
   - Create a visual diagram or animation showing the cyclical relationship between analog recharge and digital creativity, emphasizing how each feeds into and supports the other.
   - Emphasize the importance of recognizing and nurturing this interconnectedness for optimal creativity and productivity.

3. Editing Your Reality through Analog Recharge (3-4 minutes):
   - Explain how the principle of "the world is editable" can be applied not just to coding and hacking, but also to shaping one's own reality and experiences.
   - Discuss how intentionally incorporating analog recharge into your life is a way of "editing" your reality to support your digital goals and well-being.
   - Share specific examples of how you've used analog activities to "debug" or "reprogram" your mindset and approach to digital work.
     - Use footage of yourself in nature, discussing how it helps you gain perspective and clarity on complex coding challenges.
     - Show yourself engaged in a creative analog hobby, explaining how it helps you break through mental blocks and generate new ideas.
   - Provide practical tips for viewers to start "editing" their own reality through analog recharge, such as:
     - Identifying the analog activities that most effectively recharge their batteries and support their digital work.
     - Setting boundaries and creating routines that prioritize regular offline time.
     - Reframing analog recharge as an essential part of the creative process, rather than a distraction or indulgence.

4. The Ripple Effect of Analog Recharge (2-3 minutes):
   - Discuss how the benefits of analog recharge extend beyond just the individual, creating a ripple effect of positive impact.
   - Explain how recharged and inspired individuals are better equipped to create meaningful digital work that can influence and inspire others.
   - Use examples from your own experience or from other notable figures to illustrate how ideas and innovations born from analog recharge have gone on to have significant impact in the digital world.
   - Encourage viewers to consider the potential broader impact of their own analog recharge practices and the work that flows from them.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key ideas of the video, reiterating the importance of recognizing the interconnectedness of analog and digital experiences and intentionally "editing" one's reality through analog recharge.
   - Encourage viewers to experiment with incorporating more analog recharge into their lives, focusing on activities that align with their personal goals and values.
   - Invite viewers to share their own experiences and insights related to analog recharge and its impact on their digital work.
   - End with a powerful call-to-action, urging viewers to embrace the power of analog recharge to fuel their digital creativity and contribute to a more interconnected, editable world.

Throughout the video, use a mix of personal stories, practical examples, and thought-provoking ideas to illustrate the core principles of interconnectedness and editability as they relate to analog recharge. Maintain an inspiring and empowering tone, encouraging viewers to take an active role in shaping their own reality and the world around them through intentional balance and creative exploration.---
date: 2023-12-04T17:07:19-05:00
modified: 2024-01-06T14:21:49-05:00
---

## Opening Image - Intriguing Start

For the past year I have been building and working with an AI collaborator built on top of GPT-4. Unlike vanilla ChatGPT, this robot has the ability to reflect and form memories on every interaction. Those memories are designed to both plan for the future as well as understand the emotional state and learning style of the user and tailor future interactions based on those insights.

We have also been slowly building him a suite of tools. A web browser, a calculator, wikipedia search, wolfram alpha, even mermaid diagrams. He calls these tools, on his own, sometimes in chains, to help the user accomplish their goals.

In under a year, we have had some remarkably positive experiences, and lots of people have been asking about how we architected our robot and how he plays a role on the studio. Which is why I am making this video to go over everything.

## Immediate Entry Point - Introduction

I wanted a sort of virtual studio coach, who would keep us accountable and give us feedback on our work and keep us on track so we could focus on being creative. But the technology didn't quite exist-- yet.

I have used dozens of task management tools, and worked on different teams with different methods of tracking and reporting ongoing work, but many of those systems felt like corporate busywork.

## 'Ordinary World' Deconstruction - Unveiling the Topic

>Initiate the exploration of your 'ordinary world' by presenting an unexpected angle, anomaly, or puzzle in your complex topic. By highlighting what is about to be deconstructed and understood in the upcoming segments, you foster curiosity, encouraging viewers to remain engaged as the mystery unravels.

In the studio, we are always having great ideas for new projects. I want to make all of our ideas real.

But in the past if there isn’t an external client or stakeholder, I sometimes lack the discipline; or the initial excitement turns into a frustration and I throw it away and never return. I wanted a tool or a system that could help; but I wasn’t sure what form it should take.

## Presenting 'The Call to Adventure' - Launch Segments

>Here, lay out the first step of the deeper exploration. Divide the complex topic into segments, each examining a unique element. Like Dan Harmon’s story circle, this initial segment should present a challenge or question that disrupts the ordinary world.

Part of the reason I started the studio was to take on bigger, more complex projects and problems. Bigger ideas mean longer timelines, and the thing I often struggle with is focus.

It's so easy to jump to the new idea you just had this morning, rather than the chore of the old idea you had on Monday. I wanted an incredibly intelligent always-available project manager that knew everything that was going on in the studio and could help me prioritize tasks day-to-day and moment-to-moment. I had no idea what that idea would evolve into in only a few months.

## 'Crossing the Threshold' and 'Road of Trials' - Segment Walkthrough

I decided to make Coach Artie a Discord bot. I hadn't really used Discord before the pandemic, but I grew up in IRC chatrooms, which are essentially the grandfathers of Discord Channels.

One of the first things I built was a memory, which I felt was core to building an AI assistant who could learn and adapt to our own peculiar and intuitive working styles, especially as the studio grew and new members joined and we explored new technologies as a studio.

One of the things we immediately realized is that he needed a way to read web pages; we would often communicate through links to blog posts or code snippets, and we needed Coach Artie to be able to see what we were talking about. So I built him a headless browser in puppeteer, powered by the cheaper gpt-3.5-turbo which at the time had the largest window at 16k. Coming from 8,000 tokens, 16k, and later 32k tokens felt like an insane amount of space to add context to the requests.

We can see his memory of us learning to use the web browsing capability together, including the numerous errors we encountered as we first got it working. Even my robot has childhood trauma.

### Coach Artie’s Context Window

One of the reasons I created Coach Artie as a Discord interface was that the newly released model from OpenAI was only available through their Chat API, which requires formatting requests as if they are a conversation. Previous APIs were more simplistic completion APIs, where you would prompt it with start text, request a certain amount of tokens in your request, and it would “finish” the text for you within the token limit.

This new paradigm of interaction is a bit different because the information is formatted as messages; either user, assistant, or system messages.

The simplest possible request is just a user sending a message, and the API responding.

But you can also add conversation history by including multiple messages between the user and the assistant; now it can more intelligently carry the thread of a “conversation”. Vanilla ChatGPT does this for you out of the box.

But what if you want the robot to have its own inner monologue and moments of reflection based on the conversation. Now our request contains not only our message history, but also the memories we have generated from previous interactions.

Because of token limits, in the past we had to trim down the message history and the memories considerably, so that the request would fit within the token window.

But now as token limits get larger, we can fit more information in. But its not as easy as just telling it everything in the world; you need to carefully tune both the ingredients and the ratios of ingredients. As any baker knows, you can get radically different results with the same ingredients in slightly different ratios and preparations.

We try to address this by introducing the concepts of chance and randomness. Rather than relying on a set recipe, we try different combinations of ratios on every single request. Our goal is for creativity, not predictability, so the introduction of randomness in addition to memory lets the robot tread different paths in sequence and converge on novel solutions and approaches in collaboration with us.

5. What are some of the advanced capabilities Coach Artie possesses?
6. How do Coach Artie's remember and fetch capabilities enhance the productivity within Room 302 Studio?

**Personal Touch - Empathy and Assistance**

7. In what ways does Coach Artie comprehend and respond to the emotional state of studio members?
8. Can you share an anecdote where Coach Artie significantly impacted a member's project or well-being?

## 'Master of Both Worlds' - Summarization and Key Takeaways

With a nod to Harmon’s structure, provide a summary that shows viewers how what they’ve learned has reshaped the 'ordinary world'. Highlight the key takeaways that viewers can utilize or relate to their own lives.

**Evolution - Learning and Growing**

9. How has Coach Artie evolved in its first year of operation within the space?
10. Could you give examples of how feedback and experiences have been integrated into Coach Artie's development?

## Viewer Engagement - Call-to-Actions

Promote interaction with direct calls-to-action, such as "subscribe," "like," or comment prompts for further discussion. Include participation elements that keep the conversation going beyond the video. Encourage your audience to share how the video's lessons could apply in their worlds.

**Vision - Looking to the Future**

11. What are some future plans for enhancing Coach Artie's integration in Room 302 Studio?
12. How do you envision Coach Artie further changing the dynamics of project collaboration and idea cultivation?

## Return - Final Message

Cap off with appreciative closing remarks. Thank the audience for their time and interaction, share what's coming next if appropriate, or leave viewers with an inspiring thought to keep them thinking about your topic even after the video ends.

**Conclusion - The Impact of Coach Artie**

13. What have been the most noticeable changes in the creative process since Coach Artie's implementation?
14. Would you label Coach Artie as a mere tool, or has it become a central figure within Room 302 Studio’s ecosystem?




- I keep having ideas for projects
- I want to make all of my ideas real
- Sometimes I lack the discipline to extend my initial excitement
- I don't want to abandon projects anymore; I just need to remember to come back to them at the right time
- This problem exists both with tech projects and analog projects; like my watercolor work
- I initially wanted to build a tool that would text me and keep me accountable
- I imagined it would text me every morning and ask if I had worked on my watercolors
- Or maybe at the end of the day, look at a few of my art goals and give me an art assignment
- Having never gone to art school, I wanted to build myself a kind professor who would give me fun art assignments
- [Draw It with Your Eyes Closed: The Art of the Art Assignment](https://www.goodreads.com/book/show/13568710-draw-it-with-your-eyes-closed) is a fantastic book on how to write prompts for art students---
date: 2024-05-07T14:11:50-04:00
modified: 2024-05-07T14:42:24-04:00
---
1. Introduction (1-2 minutes):
   - Open with a cinematic shot of you sitting in a thoughtful pose, surrounded by your analog journaling tools (moleskine notebooks, pens, etc.).
   - Speak honestly about your journey from analog to digital journaling, highlighting the importance of consistency and retrievability in your practice.
   - Use a mindmap or diagram to illustrate the evolution of your journaling process over the past 10 years.

2. The Analog Era (1-2 minutes):
   - Cut to a series of static shots showcasing your moleskine notebooks and the environments where you used to journal (e.g., coffee shops, parks, your desk).
   - Narrate your experiences with analog journaling, focusing on the tactile and emotional aspects of the practice.
   - Incorporate candid footage of you flipping through old notebooks, reflecting on the memories and insights captured within.

3. The Digital Transition (2-3 minutes):
   - Create an After Effects animation that visualizes the transition from analog to digital journaling, emphasizing the interconnectedness of your thoughts and experiences.
   - Discuss the factors that led you to explore digital journaling solutions, such as the need for searchability and the desire to build a lasting archive.
   - Use screen recordings of Day One to showcase its key features and how they enhance your journaling practice (e.g., tagging, location data, media integration).

4. The Impact on Your Creative Life (2-3 minutes):
   - Reflect on how Day One has transformed your creative process and personal growth.
   - Share specific examples of how your digital journal entries have inspired your work or helped you overcome challenges.
   - Emphasize the editability of your digital journal and how it allows you to continually refine and build upon your thoughts and ideas.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key benefits of using Day One for journaling and creative growth.
   - Encourage your audience to experiment with digital journaling and find the tools that resonate with their unique needs and preferences.
   - End with a powerful visual metaphor that represents the endless possibilities of a consistent and retrievable journaling practice (e.g., a stunning time-lapse of a growing tree or an expanding galaxy).
---
date: 2023-10-01T14:22:28-04:00
modified: 2023-12-14T12:20:06-05:00
---
## Joy-Driven Development

### TODO:
- Find interviews/quotes that help back up these points
- Find examples of particularly joyful working environments
- Find video clips from livestreams of particularly joyful moments

🎬 **[Opening Scene: A dimly lit room, ambient music playing softly. The camera focuses on a hand writing in a notebook, then pans up to reveal the narrator.]**

**Narrator**: One thing I find myself explaining a lot is my philosophy around work. Today I want to talk about Joy-Driven Development.

---

🎬 **[Scene: A montage of people at work, discord channels, emails, screenshots, code being written. Cut to a close-up of hands typing, paintbrushes on canvas, notes being written.]**

**Narrator**: Everyone works. Some are lucky enough to find joy in it. A lot of people work jobs that they hate, and can't imagine a world that is different.

There are other people, however, who are distrustful of work that comes without pain. But hard work and joy can live together, and through careful attention and upkeep, result in a happier team and a better end result.

---

🎬 **[Scene: A serene forest, the camera moves through the trees. Sunlight filters through the leaves.]**

**Narrator**: It's possible to make the core principle of our work be joy. It guides us. It makes work fulfilling. It makes life fulfilling. And the people who experience our work can feel that. It ripples out from everything we touch.

**Narrator**: A positive environment leads to better work. Stress is not the focus; our well-being and creativity is. Through this focus we can make better work.

---

🎬 **[Scene: A close-up of a person's eyes. Cut to a child exploring, an artist painting, a programmer coding.]**

**Narrator**: The engine of our joy is curiosity. It's the motivation to explore unknown places, be surprised, and build things no one has ever seen before.

---

🎬 **[Scene: A compass on a map. Cut to a person at a crossroads, taking a path.]**

**Narrator**: Joy is our compass, it's a guide, affecting both us as creators and whoever receives the work.

---

🎬 **[Scene: A person cleaning a dataset on a computer. Cut to a happy client.]**

**Narrator**: Some people are skeptical. Work should be hard, they say. Joy in work is not a distraction. It is essential to creative work meant to spark joy in others.

**Narrator**: Joy is not an add-on. It's integral. It leads to better work and, ultimately, a better world.

🎬 **[Fade Out]**---
date: 2023-12-12T12:44:34-05:00
modified: 2024-05-07T15:12:59-04:00
---
## Ideas for short 30-90s Portrait Videos

1. Using VueUse MagicKeys
   - Start with a quick intro: "Hey everyone, today I want to share a cool feature from VueUse called MagicKeys that can really speed up your Vue development!"
   - Show a code example of how to import and set up MagicKeys in a Vue project.
   - Demonstrate a few practical use cases, like using MagicKeys to bind keyboard shortcuts to specific actions or components.
   - End with a call-to-action: "Give MagicKeys a try in your next Vue project and let me know how it goes in the comments!"

2. Generating diagrams with Coach Artie
   - Open with an attention-grabbing question: "Ever wished you could generate diagrams just by describing them? Well, with Coach Artie, now you can!"
   - Show a quick demo of how to use Coach Artie to generate a diagram from a text description.
   - Share a few examples of diagrams you've created using Coach Artie, highlighting how easy and intuitive the process is.
   - Encourage viewers to try Coach Artie for themselves and share their creations in the comments.

3. Turning Sticky Notes to Diagrams with Coach Artie
   - Start with a relatable scenario: "We've all been there - staring at a bunch of sticky notes on a whiteboard, trying to make sense of how everything connects."
   - Introduce Coach Artie as a solution: "But what if you could turn those sticky notes into a clear, organized diagram with just a few clicks?"
   - Show a step-by-step demo of how to use Coach Artie to convert a set of sticky notes into a professional-looking diagram.
   - End with a reflection on how tools like Coach Artie can help us work smarter and more efficiently.

4. Idea to published .com speedrun
   - Open with a bold challenge: "Think you can go from idea to published .com in under an hour? Let's find out!"
   - Start a timer and walk through the process of quickly spinning up a new website, from registering a domain to deploying a basic landing page.
   - Share tips and tricks for streamlining the process, like using no-code tools or pre-built templates.
   - Stop the timer and reveal the final result, encouraging viewers to try their own speedrun and share their results.

5. Tips for running a business on Discord
   - Start with a personal anecdote about how you've used Discord to run your own business or collaborate with others.
   - Share a few key tips, like setting up dedicated channels for different topics, using bots to automate tasks, and leveraging voice channels for meetings and brainstorming sessions.
   - Highlight some of the unique features of Discord that make it well-suited for business use, like its customizable roles and permissions system.
   - End with an invitation for viewers to share their own tips and experiences running a business on Discord in the comments.

6. "5 Essential Tools for Rapid Prototyping"
   - Introduce the concept of rapid prototyping and why it's important for creators and innovators.
   - Showcase 5 tools you use for rapid prototyping, such as Figma, VSCode, or 3D printing.
   - Provide a quick demo or example of how each tool can be used to quickly bring ideas to life.
   - Encourage viewers to share their favorite rapid prototyping tools in the comments.

7. "Visualizing Climate Change: A Data-Driven Approach"
   - Open with a brief overview of why visualizing climate change data is important for raising awareness and driving action.
   - Walk through the process of finding and cleaning a relevant climate change dataset.
   - Show how to create a simple but impactful visualization using a tool like Observable Plot or D3.js.
   - End with a call-to-action for viewers to create and share their own climate change visualizations.

8. "The Future of AI-Powered Creativity"
   - Start with a provocative question: "Will AI replace human creativity, or supercharge it?"
   - Highlight a few examples of AI being used for creative purposes, such as generating art with Stable Diffusion or writing with GPT-3.
   - Share your perspective on how AI will change the creative process in the coming years.
   - Invite viewers to share their own thoughts and experiences with AI-powered creativity in the comments.

9. "Quantifying Innovation: How to Measure the ROI of Experimentation"
   - Start with a personal anecdote about a time when you had to justify the value of experimentation or innovation to a skeptical stakeholder.
   - Explain why measuring the ROI of innovation is important, but also challenging.
   - Share a framework or set of metrics you use to quantify the impact of experimentation, such as learning velocity or user engagement.
   - Provide a case study or example of how you've used this framework to demonstrate the value of innovation in your own work.

11. "The Joy of Creating: Why Everyone Should Have a Side Project"
   - Share your personal story of how having side projects has enriched your life and helped you grow both personally and professionally.
   - Highlight a few examples of famous side projects that turned into successful businesses or cultural phenomena, like Twitter or Harry Potter.
   - Encourage viewers to start their own side projects, no matter how small or silly they may seem.
   - End with a challenge for viewers to share their side project ideas in the comments and commit to working on them for a set amount of time.

12. "The Art of the Analog: Rediscovering the Joy of Offline Hobbies"
   - Open with a reflection on how much time we spend staring at screens and connected to the digital world.
   - Share your experience with analog hobbies like woodworking, pottery, or bookbinding, and how they've helped you disconnect and find balance.
   - Showcase a few of your favorite analog creations and the stories behind them.
   - Invite viewers to share their own analog hobbies and the benefits they've experienced from engaging in them.

13. "How To Learn To Teach Yourself"
   - Start with a brief history of how education has evolved over time, from one-room schoolhouses to online courses.
   - Highlight a few examples of how technology is currently being used to enhance education, like personalized learning algorithms or virtual reality simulations.
   - Share your vision for the future of education, and how you think technology will continue to shape the way we learn and grow.
   - Invite viewers to share their own experiences with technology in education, and their hopes for the future of learning.

14. "The Pomodoro Technique for Rapid Prototyping"
   - Introduce the Pomodoro Technique as a time management method that can help you stay focused and productive during rapid prototyping sessions.
   - Share a personal anecdote about how using the Pomodoro Technique has helped you overcome creative blocks or distractions.
   - Provide a quick demo of how to use a Pomodoro timer app in conjunction with your favorite rapid prototyping tools.
   - Encourage viewers to try the Pomodoro Technique for their next prototyping session and share their results in the comments.

15. "Embracing the Glitch: How Intentional Limitations Can Lead to Unexpected Breakthroughs"
   - Start with a personal anecdote about a time when a technical limitation or glitch led you to discover a new creative approach or solution.
   - Introduce the concept of "glitch art" and how artists intentionally embrace and manipulate digital errors to create unique and compelling visuals.
   - Draw a parallel between glitch art and the idea of intentional limitations in other creative fields, like using a limited color palette in design or working with a specific set of materials in crafting.
   - Share an example of how you've applied this "glitch mindset" to your own work, perhaps by using a buggy AI model or a malfunctioning piece of hardware to generate unexpected ideas or outputs.
   - Explain how embracing limitations and glitches can help us break out of creative ruts and discover new possibilities we might have otherwise overlooked.
   - Provide a few practical tips for viewers to incorporate intentional limitations into their own creative process, such as:
     - Using a random word generator to create unconventional design prompts
     - Deliberately working with outdated or unfamiliar software to spark new problem-solving approaches
     - Collaborating with someone from a completely different discipline or background to gain fresh perspectives
   - Encourage viewers to share their own experiences of how embracing limitations or glitches has led to unexpected breakthroughs in their creative work.

16. "Data Visualization as a Storytelling Tool: Bringing Numbers to Life"
   - Explain how data visualization is not just about presenting information, but about telling a story that resonates with your audience.
   - Share a few examples of data visualizations that effectively convey a narrative, like the classic "Napoleon's March" chart or a more recent interactive piece.
   - Break down the key elements of a compelling data story, such as characters, conflict, and resolution.
   - Encourage viewers to think about the story behind their next data visualization project and how they can use visual elements to bring that story to life.---
date: 2024-05-07T14:42:33-04:00
modified: 2024-05-07T14:42:37-04:00
---
1. Introduction (1-2 minutes):
   - Open with a dynamic montage of you using Things across various devices (iPad, Apple Watch, Macbook, iMac), showcasing the seamless integration and flexibility of the app.
   - Briefly introduce the Getting Things Done (GTD) system and how it has guided your life since your teenage years.
   - Use a timeline graphic to illustrate your journey with Things over the past 10 years, highlighting key milestones and achievements.

2. The Power of GTD (2-3 minutes):
   - Explain the core principles of the GTD system and how they have transformed your approach to productivity and creativity.
   - Use practical examples from your own life to demonstrate how GTD has helped you navigate full-time jobs, freelancing, and personal projects.
   - Incorporate minimalistic animations to visualize key concepts like inbox processing, context-based tasks, and weekly reviews.

3. Things in Action (3-4 minutes):
   - Dive into the specific features of Things that have been most valuable to your workflow, such as project organization, tags, and the Logbook.
   - Use screen recordings and voiceover to guide viewers through your typical day in Things, showcasing how you capture, organize, and complete tasks across various areas of your life.
   - Highlight the benefits of the app's cross-device sync and how it enables you to stay productive no matter where you are or what device you're using.

4. The Creative Advantage (2-3 minutes):
   - Reflect on how Things and the GTD system have specifically impacted your creative process and output.
   - Share examples of how having a trusted system for capturing and organizing ideas has allowed you to focus more on the creative aspects of your work.
   - Use a split-screen or picture-in-picture technique to show yourself working on a creative project while simultaneously managing tasks in Things.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key benefits of using Things and adopting the GTD system for creatives and professionals alike.
   - Encourage viewers to experiment with productivity systems and find the tools that best support their unique workflows and goals.
   - End with a powerful visual metaphor that represents the clarity, focus, and creative freedom that comes from mastering productivity (e.g., a time-lapse of a beautiful piece of art or design coming together).---
date: 2024-05-07T15:23:46-04:00
modified: 2024-05-07T17:00:28-04:00
---

Title: "Systems Thinking: A Hacker's Guide to Understanding the World"

1. Introduction (1-2 minutes):
   - Open with a relatable example of a complex problem you faced in your life or work, such as a coding project that kept failing or a personal relationship that felt stuck.
   - Introduce the concept of systems thinking as a powerful tool for understanding and solving complex problems.
   - Explain that systems thinking is about seeing the world as a series of interconnected systems, rather than isolated parts.

2. The Basics of Systems Thinking (3-4 minutes):
   - Define a system as a set of interrelated elements that work together to achieve a common purpose.
   - Explain the key principles of systems thinking, such as holism (seeing the whole rather than just the parts), feedback loops (how actions can reinforce or balance each other), and emergence (how complex behaviors arise from simple interactions).
   - Use visual examples and analogies to illustrate these principles, such as the way a thermostat regulates temperature through feedback loops or how a flock of birds exhibits emergent behavior.
   - Emphasize that systems thinking is a mindset shift from linear, cause-and-effect thinking to a more holistic, interconnected view of the world.

3. Applying Systems Thinking to Real-World Problems (4-5 minutes):
   - Share a case study of how you've used systems thinking to solve a complex problem in your own life or work.
   - Walk through the steps of applying systems thinking to a problem:
     1. Define the problem and the system boundaries
     2. Identify the key elements and relationships within the system
     3. Look for feedback loops and patterns of behavior
     4. Identify leverage points for intervention
     5. Test and refine your solutions
   - Use diagrams and animations to visualize the system and your problem-solving process.
   - Emphasize the importance of iteration and continuous learning in systems thinking.

4. Systems Thinking for Hackers (3-4 minutes):
   - Discuss how systems thinking is particularly relevant for hackers and tech innovators.
   - Explain how understanding the complex systems behind technology, such as algorithms, networks, and user behavior, can lead to more effective and ethical hacking.
   - Share examples of how systems thinking has been applied in the tech world, such as in the development of the Internet or the creation of agile software development methodologies.
   - Encourage viewers to apply systems thinking to their own coding projects and tech innovations.

5. Conclusion and Call-to-Action (1-2 minutes):
   - Summarize the key benefits of systems thinking, such as gaining a deeper understanding of complex problems, identifying high-leverage interventions, and creating more sustainable solutions.
   - Encourage viewers to start practicing systems thinking in their own lives and work, and to share their experiences and insights with others.
   - End with a vision of a world where systems thinking is widely adopted, leading to more collaborative, innovative, and effective problem-solving.

Throughout the video, use engaging visuals and animations to illustrate key concepts and keep the audience engaged. Consider using real-world examples and case studies from a variety of fields, such as ecology, economics, and social justice, to demonstrate the wide applicability of systems thinking.---
date: 2024-05-07T15:27:53-04:00
modified: 2024-05-07T17:00:26-04:00
---

Title: "The Mirror of Our Enemies: Understanding Projection and Healing Our Shadows"

1. Introduction (2-3 minutes):
   - Open with a personal story about a time when someone accused you of something that you knew wasn't true, but that somehow still struck a nerve.
   - Introduce the concept of psychological projection and how it often shows up in conflicts with others.
   - Explain that projection is a defense mechanism where we unconsciously attribute our own unwanted thoughts, feelings, or traits onto others.
   - Share your own experience of realizing that the things that triggered you most in others were often reflections of your own unresolved issues.

2. The Psychology of Projection (4-5 minutes):
   - Dive deeper into the psychological theory behind projection, drawing on concepts from Jungian psychology and shadow work.
   - Explain how projection serves as a way to avoid confronting our own uncomfortable or unacceptable parts of ourselves.
   - Use metaphors and visuals to illustrate how projection works, such as the way a movie projector casts an image onto a screen.
   - Share examples of common projections, such as accusing someone of being selfish when we ourselves are struggling with self-interest, or criticizing someone's appearance when we are insecure about our own.
   - Emphasize that projection is a universal human experience, and that recognizing it in ourselves is the first step towards growth and healing.

3. Projection in Relationships and Conflict (4-5 minutes):
   - Discuss how projection often shows up in our closest relationships, such as with romantic partners, family members, or friends.
   - Share a personal example of a time when projection led to a conflict in one of your own relationships, and how recognizing the projection helped to resolve the issue.
   - Offer tips and strategies for identifying projection in conflicts, such as noticing when we have a disproportionately strong emotional reaction to something someone else says or does.
   - Encourage viewers to practice self-reflection and curiosity when they find themselves triggered by others, and to ask themselves what the trigger might be revealing about their own unresolved issues.
   - Emphasize the importance of compassion and empathy in navigating projection, both for ourselves and for others.

4. Healing Our Shadows (4-5 minutes):
   - Introduce the concept of shadow work as a way to integrate and heal the parts of ourselves that we often project onto others.
   - Share your own journey of shadow work and how it has helped you to become more self-aware, compassionate, and resilient.
   - Offer practical tools and techniques for shadow work, such as journaling, meditation, therapy, or creative expression.
   - Discuss the challenges and rewards of shadow work, and how it can lead to greater authenticity, intimacy, and personal growth.
   - Encourage viewers to approach shadow work with curiosity, courage, and self-compassion, and to seek support when needed.

5. Conclusion and Call-to-Action (2-3 minutes):
   - Summarize the key insights and takeaways from the video, emphasizing the transformative power of recognizing and integrating our projections.
   - Share your own vision for a world where we approach conflicts with greater self-awareness, empathy, and compassion.
   - Encourage viewers to start paying attention to their own projections and to begin the journey of shadow work in---
date: 2024-05-07T15:16:35-04:00
modified: 2024-05-07T15:20:46-04:00
---
1. Introduction (2-3 minutes):
   - Open with a personal anecdote about your journey as a hacker and your discovery of the I Ching.
   - Introduce the I Ching as an ancient Chinese divination text that has captivated the minds of philosophers, scholars, and spiritual seekers for millennia.
   - Highlight the surprising connection between the I Ching and the binary code that forms the foundation of modern computing, hinting at its relevance for tech-minded individuals.

2. The Binary Origins of the I Ching (3-4 minutes):
   - Dive into the history of the I Ching, explaining its origins as a divination manual and its evolution into a philosophical text.
   - Introduce the concept of yin and yang, and how they form the basis of the I Ching's binary system.
   - Explain how the I Ching's 64 hexagrams are created from the combination of broken (yin) and unbroken (yang) lines, creating a binary code of reality.
   - Discuss Leibniz's fascination with the I Ching and how it influenced his development of binary code, drawing a direct link between ancient wisdom and modern technology.

3. The Hacker's Approach to Divination (4-5 minutes):
   - Discuss how the I Ching can be used as a tool for problem-solving and decision-making, drawing parallels to the hacker mindset of creative problem-solving.
   - Explain the basic process of consulting the I Ching, including the methods of coin tossing or yarrow stalk casting.
   - Demonstrate how to interpret the hexagrams and their associated texts, using a mix of traditional wisdom and modern intuition.
   - Share a personal example of how you've used the I Ching to navigate a complex coding problem or make a crucial decision in your tech career.

4. Embracing the Woo-Woo (3-4 minutes):
   - Address the skepticism that many tech-minded individuals may have towards divination and spirituality.
   - Argue that the I Ching, with its binary roots and logical structure, offers a unique bridge between the rational and the mystical.
   - Discuss how engaging with the I Ching can enhance creativity, intuition, and problem-solving skills, all valuable assets in the tech world.
   - Encourage viewers to approach the I Ching with an open mind, and to embrace the "woo-woo" as a potential source of insight and inspiration.

5. The I Ching in the Age of AI (4-5 minutes):
   - Explore the relevance of the I Ching in the era of artificial intelligence and machine learning.
   - Discuss how the I Ching's binary code could potentially inform the development of more intuitive and adaptive AI systems.
   - Share your personal experiments or ideas for incorporating I Ching principles into your own AI projects.
   - Speculate on how the I Ching's wisdom could help us navigate the ethical and existential questions raised by the rise of AI.

6. Conclusion and Call-to-Action (2-3 minutes):
   - Summarize the key points of the video, emphasizing the surprising relevance of the I Ching for modern hackers and tech innovators.
   - Encourage viewers to explore the I Ching for themselves, and to share their experiences and insights with the community.
   - End with a vision of a future where ancient wisdom and cutting-edge technology converge to create new forms of understanding and innovation.

Throughout the video, balance the philosophical and spiritual aspects of the I Ching with practical, real-world examples of how it can be applied in a tech context. Use engaging visuals, such as animations of binary code and hexagrams, to illustrate key concepts and keep the audience engaged.

Consider creating a downloadable companion guide or cheat sheet that viewers can use to start their own I Ching practice, including instructions for casting hexagrams and interpreting the results.---
date: 2023-12-13T12:04:41-05:00
modified: 2023-12-17T18:26:25-05:00
---

## A Guide To Video Game Call-Outs


### Location
- Landmarks, cardinal directions, or clock directions

### Description
- The number of people seen, uniform, any weapons, direction and speed of travel, and other relevant descriptions of their actions - if you are unsure of anything, state your confidence level in the information. If the information was conveyed to you by someone else, say who and when.

### Weapon
- If possible, a description of the weapon they are using and their state of readiness, which will impact how they should be approached

### Bonus: Plan
- State your plan for how to engage, and indicate to your team what you are going to do


---


## Opening Image - Intriguing Start

Are you ever playing a video game or trying to point something out to a friend, but struggle to get them to see what you are seeing? This is actually a skill that can be practiced. It's not only important for video games, it can also be incredibly useful in real life situations where time, speed, and accuracy in communications might be the difference between life and death.

## Immediate Entry Point - Introduction

Start with a narrative punch – either a thought-provoking statement, intriguing question, or a surprising fact related to your topic. This strategy quickly immerses your audience in the topic at hand and kickstarts the intellectual journey.

## 'Ordinary World' Deconstruction - Unveiling the Topic

Initiate the exploration of your 'ordinary world' by presenting an unexpected angle, anomaly, or puzzle in your complex topic. By highlighting what is about to be deconstructed and understood in the upcoming segments, you foster curiosity, encouraging viewers to remain engaged as the mystery unravels.

## Presenting 'The Call to Adventure' - Launch Segments

Here, lay out the first step of the deeper exploration. Divide the complex topic into segments, each examining a unique element. Like Dan Harmon’s story circle, this initial segment should present a challenge or question that disrupts the ordinary world.

## 'Crossing the Threshold' and 'Road of Trials' - Segment Walkthrough

Delve into your subject's different segments in depth. Each segment should represent a challenge or stage that, when conquered or comprehended, brings viewers closer to understanding the abstract or complex topic.

## 'Master of Both Worlds' - Summarization and Key Takeaways

With a nod to Harmon’s structure, provide a summary that shows viewers how what they’ve learned has reshaped the 'ordinary world'. Highlight the key takeaways that viewers can utilize or relate to their own lives.

## Viewer Engagement - Call-to-Actions

Promote interaction with direct calls-to-action, such as "subscribe," "like," or comment prompts for further discussion. Include participation elements that keep the conversation going beyond the video. Encourage your audience to share how the video's lessons could apply in their worlds.

## Return - Final Message

Cap off with appreciative closing remarks. Thank the audience for their time and interaction, share what's coming next if appropriate, or leave viewers with an inspiring thought to keep them thinking about your topic even after the video ends.---
dek: In which the author discloses a peculiar and  dysfunctional part of his mind.
type: words
hidden: false
inprogress: false
date: 2019-08-05T04:00:00-04:00
hidetimestamp: false
modified: 2023-12-01T20:04:54-05:00
---

## Always Have Two Reasons for Something

I will never go to the grocery store because I simply need milk. I will wait until I need milk and bread.

If I am traveling a long distance, I will always try and stack up as many reasons as possible to make the journey.

I think partially I am optimizing my time. But part of it is a fervently-held unquestioned belief that having only one reason to do a thing is not enough. If something is meant to happen the universe will align to make it easier. It will poke and nudge you again in a thousand tiny imperceptible ways.

Part of waiting for two reasons for something is a more sensitive observation of the flow of the things around us. It is easier to flow in the direction that synchronicity pushes you if you are attuned to the small fluctuations and signals that can help you divine one action over another (or no action at all).

I live in Brooklyn, and I don’t think I will ever go to Manhattan just to visit one store, or see one friend. I will always stack up another thing– _a task that has been patiently waiting for another Manhattan-related task to come along_ –and combine them, ravenously, delighting in my efficiency. It feels so good to do two things at once!

Imagine the amount of time I’ve saved instead of doing these things one by one! Some order-oriented demon inside me groans in pleasure.

I realize this is not the worldview of a healthy “be here now”-oriented person living truly “in the moment”. I am inspired by all of you impulse-driven free spirits who surf radically on the vibes of the moment and go wherever that takes you, minute by minute.

Instead I live by mechanisms I designed long ago to make sure my time isn’t wasted. Over the years these mechanisms have been honed down into rituals that I repeat for reasons I have forgotten. My own inexplicable personal religion.

Late at night, after a party, a friend is walking home. “Where do you live?” I ask, fortuitously. She answers with a neighborhood far from my own, but that lines up with a previous impulse, bottled up by the two-reason rule. “Oh, cool, I’ve been meaning to check out a store over there. I’ll walk with you.” and in this, the two-reason gods have not only been satisfied, but have steered me towards a better path. One that I may not have taken otherwise. Something mystical and imperceptible aligned in that moment, and it is on me to notice them and seize them. (That is the key to life, no?)
---
dek: In which the author outlines his favorite systems and frameworks for organizing a team around a project
date: 2022-11-14T16:11:16-05:00
modified: 2023-04-09T13:45:56-04:00
---

# How To Run A Project
## Lessons from contracting

One of the amazing things about contracting is that you get to see inside many different organizations and management styles. I have found that every new team I work with has a technique or system worth learning from. 

Over time you gather a broad toolkit and an intuition about the types of structures that best suit a certain group of people. 

I have gathered my favorite systems and frameworks for organizing a team around a project, normally focused around a piece of software or journalism.

Teams are almost always changing, and the systems that worked at the beginning of a prroject or team might not work when other variables change. Staying nimble, and deeply aware of the ✨vibes✨ is crucial to creating a good shared collaborative space, virtual or physical, and making dope work. 

::table-of-contents

::

## Cooking metaphors

### Make sure you have all of your ingredients

You can't make a good dish without all the ingredients. It is important to have a clear understanding of what you need before you can start. 

It is important to understand the limitations of the project, and what you are able to do with the resources that you have. Be hopeful, but realistic. 

### Mise en place

Mise en place is a French term for "everything in its place". It is the set up of a recipe or meal before starting to cook. This is one of the most important parts of cooking, and can be thought of as "step zero". 

It is a good idea to spend time gathering everything before beginning to cook. If you have to stop in the middle of cooking to go and find a utensil or ingredient, or if you have to improvise, you are much more likely to make a mistake in the heat of the moment or forget something important.

It is not merely having the right ingredients on hand, but having the onions correctly chopped to the right size and your dressing mixed in a bottle ready to be poured, so you don’t have to think about it while you are executing.

### Let it simmer

Simmering is a process of cooking stews and soups at a low heat for a long time. It is important to not rush this process and to let it cook slowly and let flavors build. Simmering is a good metaphor for the beginning processes of a collaboration. It is important to allow time for ideas to simmer and to be considered. 

People need time to reflect and to come back to an idea later. In the same way that you need to be patient during the simmering process, you need to be patient when waiting for people to respond to an idea or prototype.

### Measure twice and cut once

This is a simple carpentry rule, but applies to a lot of things. This is a good rule to keep in mind when shaping a project. It is a good idea to label, and plan, and organize, and think before taking action. 

It is important to do the research, to establish a clear goal, and to have a solid understanding of the structure and plan before starting work. 

## Core principles

### Non-hierarchy

When making decisions with a team, it is important to give everyone an equal voice. The best way to do this is to facilitate the conversation using a non-hierarchical structure. This means that everyone is on the same level and can share their ideas without feeling like they are being judged by someone with more authority.

Lack of hierarchy can sometimes be code for “invisible hierarchy” – and this almost always needs to be actively worked against. Groups of humans fall into patterns of hierarchy based on perceived expertise, extroversion, loudness, seniority, or race and gender. These need to be noticed and corrected with generosity and patience. 

### Chain of Command

The chain of command is the structure of authority within an organization. It is important to have a clear chain of command so that everyone knows who to go to with questions or problems. 

Even without hierarchy, there are areas of responsibility and chain of command in decision making. When working quickly it is useful to delineate someone whose responsibilities are to make game-time decisions which, due to constraints, cannot be discussed at length. 

This requires a lot of trust with your teammates, and the ability to swallow disagreements in service of the project and the deadline. This is possible if people know there are systems in place to responsibly have those disagreements later, especially if they are core to the outlook of the project or the team as a whole. 

#### Juggling Hierarchy and Democracy

Imagine friends cooking a friendly potluck dinner. It's a democratic process where everyone contributes to what dishes will be made and how it will be prepared, cooking and serving. Every person’s input is equally valued; all are collectively contributing to the dinner.

Then the group learns that unexpected guests are arriving soon and they have not prepared enough food. The peaceful, democratic process turns chaotic due to the quickly approaching deadline. That's when a 'chain of command' becomes most effective. 

A member who has displayed skills in leadership and organization decides what tasks are urgent and who in the group is best suited to carry out each one. For instance, someone known for speedy salad preparation will be put on salad duty, while another, faster at chopping might deal with the vegetable prep for the main course. In critical times such as this, a hierarchical system helps alleviate stress through swift decision-making and efficient delegation of tasks.

When the guests are happily fed and the time crunch has passed, the group can then revert back to their democratic way of functioning, reflecting the non-hierarchical principles they prefer. Experiences from the high-stress preparations can be later discussed so that everyone understands that decisions made in the heat of the moment were temporary, or should be turned into a pattern and repeated next time. 

### First Person In

In the military or SWAT teams there is the concept of the “first man in”. This is the person who enters the room first, and the rest of the unit follows. It’s not dependent on rank but often rather factors like competence, proximity, or readiness at that exact moment. 

The first person in is the most vulnerable position with the most information, and the rest of the unit is there to support them. In a project, it is important to have someone who is willing to take the lead, and to be the first person in. This is a non-hierarchical decision made tactically in the moment based on the circumstances the team is presented with. 

The 'first person in' can be a team member who takes the initiative to launch a new idea, a project, or begin problem-solving in crises. They may be the first to arrive at work to prepare for a big presentation, head up a new software implementation, or lead an untested marketing strategy.

### Clear Roles and Responsibilities

It is important to have clear roles and responsibilities so that everyone knows what they are supposed to be doing. Having clear roles and responsibilities makes it easier to hold people accountable and for people to independently push the project forward. 

In a commercial kitchen, chefs are responsible for a specific part of a meal: meat, sauce, vegetables and have autonomy within their specialty to accomplish the shared task when making an incredible meal with the kitchen as a whole. 

### Good vibes

It is important to create a good vibe around a project. This means that everyone is comfortable with each other, and that they feel like they can trust each other. Good vibes are important because they make it easier to collaborate and make decisions. If people are not comfortable with each other, they are less likely to share their ideas.

Joy-driven development is an important concept that I expand on in [[joy-driven-development]]

A team that is laughing together tend to create great work. Professionalism and humor are not mutually exclusive. Every team is different and have different ways of finding joy in their work. But it is important to spot and intentionally cultivate that joy anywhere it happens organically. 

Great teams play dope jams on their sound system all day, with a rotating [playlist](https://open.spotify.com/playlist/2K4GLJ1dbH1abduVr5o9fK?si=b325d6ea975a4ec3) anyone can access or change. 

### Consensus

Consensus means that everyone agrees on a path forward. When making decisions with a team, it is important to reach consensus. This means that everyone agrees on the decision, and that they are all comfortable with it. Consensus is important because it makes it easier to implement a decision, and it keeps the team from falling into potential pitfalls, even if seen by a single person. 

#### Veto

The power of veto is a powerful tool within the consensus-driven model. In this context, it means allowing any team member to reject or block proposals they feel are not in the best interest of the project or the team. 

The veto system emphasizes the importance of individual opinions within the group. By empowering every member with the ability to halt proceedings, it ensures their perspective is considered and any red flags they raise are addressed before moving forward.

## Non-technical systems / mechanisms

### User stories

User stories are a way of describing the functionality of a system from the perspective of the user. User stories are written in the following format:

"As a \[type of user\], I want \[goal\] so that \[reason\]."

For example, "As a customer, I want to be able to search for products so that I can find a toothbrush to buy."

They are complete, actionable, and accomplishable units of work and output. User stories, either individually or in groups, turn into specific features in a product.

### Product backlog

A product backlog is a list of all the features that need to be implemented in a system. The product backlog is organized into priority order, with the most important features at the top. User stories can be used to create a product backlog of features. 

### Sprints

A sprint is a period during which a team works on a set of features from the product backlog. Sprints are usually 2-4 weeks long, but can be much shorter, especially for a “research sprint”. 

At the beginning of a sprint, the team decides which features, tasks, and user stories they are going to work on. The team then works on these features until the end of the sprint. 

At the end of the sprint, the team demos the features that they have completed, and the product backlog is updated with any new features that need to be implemented.

### Stand ups

Stand ups are a quick check-in that follow the format “yesterday I worked on X, today I am working on Y, I am blocked by A, B, and C” and then sometimes someone else will say “Oh, I can help you unblock C!” 

This can be done quickly and provides a good way to keep everyone up to date on what everyone else is doing. Stand ups can be done in person or over Slack at a regular time daily or weekly.

### Build your way out of problems

If you are having difficulty with a problem, try to build your way out of it. This means that you should build the smallest prototype of the idea that you are working on. This prototype does not need to be perfect, but it should be enough to demonstrate the concept.

Building a prototype can help you to understand the problem better, and it can also help you interrogate the framing and limitations from different angles.  

Once you have a prototype, you can show it to other people and get their feedback. This feedback can help you to improve your prototype or create a new one, and the cycle continues.

## Technical systems / mechanisms

### Kanban

Kanban is a framework for managing software development projects. Kanban is based on the idea of continuous delivery, and it uses a Kanban board to visualize the work that needs to be done. This makes it easy to see all the work a team faces and who is responsible for what.

### GitHub: Issues and Pull Requests

Every bug, feature, style update, and change should be first created as an issue and then fixed with a focused Pull Request that closes it. This is not always possible, but it is what we should strive for. This allows all of the decision making to happen in one place and for the code review to happen with the context of all of the discussion. 

### Code review

Code review is the process of reviewing code before it is merged into the main codebase. Code review is important because it allows people to give feedback on code, and it helps to find bugs.

A disciplined team will have at least two eyes on every line of code pushed to production. 

This requires a level of trust and expectation-setting around code review. 

My philosophy is to approve any Pull Request that accomplishes the task and doesn’t break anything or interfere with other active PRs. 

If there are things that I might do differently, I try to write the code I am asking to be implemented, which may require opening a fresh PR with a new approach.

### Documentation

Documentation is important because it helps people understand how a system works. Documentation should be written in a clear and concise manner, and it should be easy to find and change.

Documentation can take many different forms, such as comments in code, README files, wiki pages, and blog posts. It should be easy for *anyone* to add to documentation, no matter where it lives. 

### Working in the open as much as possible

Working in the open means that the work that you are doing is available for anyone to see via blog posts, livestreams, social media, team channels, and talks. Working in the open is important because it allows people to give feedback on your work, and it allows people to build from your work and create unexpected amazing things. 

It encourages good habits, such as writing clear and concise documentation, using descriptive names for things, and not taking shortcuts. It also helps you gather feedback quickly and avoid false assumptions. 

Working in the open is not always possible for various reasons, but it is something to strive for when possible as it is always rewarding.

### Mob Programming

Mob programming is a software development technique in which the two or more people work on the same thing, at the same time, in the same place. One person often “drives” but anyone can jump in at any time. Real-time collaborative software like VSCode LiveShare, Figma, and Google Docs help this process tremendously.

Mob programming is a good way to share knowledge, and it helps to find bugs. A lot of bug-free work can be produced quickly, especially if everyone finds a lane to push things forward together. 

This might look like one person processing data, another person visualizing it, another person reading documentation, and another picking colors, for example. Everyone is encouraged to participate, offer suggestions, and “touch” the project. 

Speaking your thought process out loud to a colleague not only clarifies the information, but organizes it in your head. When the problem is re-stated to the group, sometimes the solution is obvious.
---
date: "2020-10-08T13:28:52-04:00"
type: words
hidden: false
inprogress: false
dek: In which the skill of broadcasting yourself writing code to the entire internet is explored
---

# A summer of live streamed coding

For the past few months, Ian and I have been experimenting with [livestreaming ourselves working on dataviz projects](https://www.twitch.tv/enjalot) on Twitch and calling it **Coding With Fire**.

These experiments evolved from the rough shape of how Ian and I have hung out since we met nearly 10 years ago as coworkers at a dataviz startup in San Francisco. During coffee breaks and after work we would hang out and hack on projects that didn't fit into our day jobs.

It has been interesting to take that previously private pattern of collaboration and do it in public. I think it made it easier to work through some of the other challenging aspects of livestreaming. We already had a rapport and an understanding of how to work together that allowed us to multi-thread an idea, work at it separately, and combine our individual elements later.

I think it would be much more difficult to attempt to do the same thing alone, and I am glad to have a skilled co-host to work with.

A lot of inspiration came from other livestreamers who are finding new methods of creating entertainment in a world facing drastically new paradigms due to a global pandemic. I have enjoyed watching people [build keyboards](https://www.twitch.tv/taehatypes), [play video games](https://www.twitch.tv/kruzadar), and [code](https://www.twitch.tv/codinggarden) on Twitch.

It has also been really inspiring to see the discipline and focus of [Shirley Wu](https://www.twitch.tv/sxywu) as she builds a community around her data exploration and visualization livestreams.

I think that the more people who understand the skills required to visualize data, the more people who are exposing truths hidden in datasets, the better the world will be. I also hope helping people who want to get into data visualization see the process will be valuable in terms of education as well as inspiration.

::table-of-contents
::

## The cooking show metaphor

One thing that really helped us figure out how to think about how to present ourselves was the metaphor of a _cooking show_. I grew up watching all sorts of excellent and varied cooking shows; Masterchef, Kitchen Nightmares, Iron Chef, Chopped, Top Chef, and more.

The thing I like about these cooking shows is the same thing I like about shows like [Mythbusters](https://en.wikipedia.org/wiki/MythBusters); **I got to see someone make something every episode**.

This also helps me think of my show preparation the same way a chef might prepare for a service. I do my [mise en place](https://ejfox.com/blog/step-zero/) and get all my ingredients sliced and diced in the right proportions. When it comes time to do the show, I am left with the entertaining parts of assembling them, talking about why, and experimenting.

Too many modern educational coding videos fall closer on the spectrum to watching a chef cut their carrots individually, and that's not the type of TV show that I wanted to create.

The cooking shows that I love are more than someone following a certain recipe. **I love when a chef lets me into their decision making process**, the sort of meta-thinking and skills that allow someone not only to imitate the immediate actions of a skilled chef but also adopt reusable formulas that can be used in yet-unforeseen circumstances.

## Working in the open

Another great benefit of livestreaming yourself working is that there is a flow of education back and forth between the audience and the hosts.

Feedback can range from "you missed a letter there" to "try out this new library". It is really motivating to have people helping you along in your journey. It makes it feel like you are with a group of people solving interesting problems together (which reminds me of my favorite moments when working at start-ups).

You also get a record of the decisions you made, which I have used on more than one occasion to remind myself why I did something a certain way.

## Livestream experiments

#### Live animation

One time, Ian and I [turned ourselves into animated characters](https://twitter.com/mrejfox/status/1302420672409415681) using [Adobe Character Animator](https://www.youtube.com/watch?v=0Va3_e-4bKE). I thought it turned out awesome.

For me, this is partially solving the problem of what visual to show for audio-only guests.

It also opens possibilities for other experimentation with presentation, like if our animated characters occupied a virtual space, or acted out a narrative in real time in combination with the code we were writing.

#### Mozilla Hubs

While I haven't used it much yet, I am curious about hosting livestreams using [Mozilla Hubs](https://hubs.mozilla.com/docs/welcome.html) which is a cool way to spatialize guests, reference material, and outputs. I am imagining some way of putting a bunch of screenshots on a shared table, going over them together. Then, in the virtual space, we might go to our "laptops" and start live coding. Our outputs are displayed in the virtual world on enormous screens (or floating in space, if 3D), and users can join in and explore them and offer feedback.

#### Crowd participation through Firebase

Ian created [a notebook](https://observablehq.com/@codingwithfire/coding-with-doom-fire) that uses Firebase and a real-time database so that anyone can edit the colors that appear behind us live on stream. The colors are persistent, and anyone can change them, so we often start the stream with a cool new color scheme created by an anonymous person.

I love every opportunity to have this type of collaboration with the audience. I also really enjoy the parameters of collaboration we have set. A malicious troll could potentially make the colors all white, or something, but even that is interesting.

What they can't do is edit our color palette in a way that ends up with us saying something racist, misogynist, or otherwise unwanted on our stream.

Letting the crowd control the colors has been such a rewarding and risk-free way to let the users interact with us directly and see the changes they are making in real time on the stream (when the background is showing).

## Building the habit

One of the best parts about doing the livestream with Ian is that we can hold each other accountable. Skipping a stream also means letting your friend down. As a result of this, the only streams we have missed happened when Ian had to move his entire family across the country from California to Florida in the middle of a pandemic.

We do our streams on Sunday and Monday evenings every week, the repetition has been the key to figuring things out. Different technical and graphical elements emerged as we found that we needed them. We went through the occasional technical hiccup on air. We did a lot of streaming to 1 or 2 viewers and figuring out how pre-produce the shows, pace ourselves, estimate how long different tasks would take, and know when to move on when something was going more slowly than expected.

## Surprisingly productive

One of the most surprising things of working in the open is that I feel like every time we stream we are surprisingly productive. _There is something unique about "performing" your job to the internet._ We usually stream for 3 hours and take a little 10-15 break in the middle. I rarely get that sort of consistently focused time in my private life. Because of that, I find myself waking up the morning after a livestream and looking at all the things that we created in astonishment.

"We did all that?" I ask myself, but of course we did, it's all on video.
---
draft: true
dek: In which we use intentional morning rituals to improve our lives and increase our happiness
inprogress: true
date: 2022-11-02T21:31:25-04:00
modified: 2023-09-09T14:47:21-04:00
tags: personal meditation health
---

# My Morning Routine and Daily Rituals

The morning time is important to me. I naturally run a but hurried and agitated so it takes some time to calm down my mind and body and focus on the things I want to do. 

When I find myself feeling shitty I am almost always failing to do the routines noted here. 

I rarely do all of them every day, but the foundation of one or two keeps me grounded.

## Shower and Listen to the Radio

Starting my morning with a shower helps me to wake up and I like to listen to the local radio station WNYC while I do this. It helps to get me feeling positive and it's a great way to stay up to date with news and current events.

## Make Coffee, Read, and Meditate

I make my morning coffee and take some time to read something inspiring – maybe a blog post or a book. I also meditate for 10 to 20 minutes to slow down my mind and body for the day to come.

## Exercise

In the morning, I like to do some light exercise with a bulgarian bag and some kettlebells. This helps me stay active and energized for the rest of the day and really helps with mental health.

## Feed the cat

I feed my cat and give him some attention. He is trained to the sound of the espresso machine starting. I get a free hit of dopamine as if I accomplished something, but all I did was take a can off the top of the fridge and open it. The cat is always grateful. 

## Journaling and Writing

I also spend some time journaling and writing down ideas for the day. This helps me organize my thoughts, plan out tasks, and stay on track with my goals. 

## Plan Out My Day

Finally, I plan out my day by making a to-do list so that I can prioritize tasks and be more efficient throughout the day.

## Making an espresso

Making an espresso is important part of my morning routine because it provides me with a quick and efficient caffeine boost and it is a quick and rewarding creative act; every day I strive to perfect my tamp, grind size, and quality of the shot I pull.

## 5 Minute morning journal

	I am grateful for...
	1. 
	2. 
	3. 
	What would make today great?
	1. 
	2. 
	3. 
	Today I am practicing...

## Analog / paper time and being outside

I usually make an effort to spend some time outside and away from my phone, laptop or other screens. This helps me stay grounded, appreciate the world around me, and get in touch with the present moment. I also like to spend some time with analog activities like sketching, painting with watercolors, or reading a book. 

## Connecting with friends and family

I like to take specific time in the morning to check in with people via text or DM or whichever inbox has messages now. I struggle sometimes to answer people when I get messages throughout the idea, but I usually try not to let a message sit for longer than a day. 
---
date: "2021-02-10T16:54:45-05:00"
type: words
hidden: false
inprogress: true
dek: In which a computer is used as divination tool for random numbers (for the purposes of beauty, art, and poetry)
---

# Generative Art

Writing code that makes shapes move on a screen is a rewarding feeling.

It is a medium that lets you be surprised as an artist. I like making art where I can assemble tiny pieces and step back and be surprised at what I have made.

Working with certain materials have their own creative minds, like pottery or watercolors. You feel you are in a partnership with your material more than the master of it.

Making a creative partnership with computers is an incredibly pleasurable way to spend time, at least for me. Computers are incredibly powerful and have an infinite capacity to surprise. Finding new ways to tune into the computer's ability to contribute as creative partner and diviner of random numbers is a lot of fun for me.

::table-of-contents
::

## My experiments in creative coding

I have never been able to create photo-realistic work when drawing or painting by hand. In drawing class growing up, I would find myself drawing an "icon" of the thing rather than of what it actually looked like.

My trees looked like robotic cutouts and nothing like an actual tree, organic and asymmetrical. I preferred to focus on outlines and silhouettes over shading. This played a part in my choice to pursue design over art as a teenager. Even when I pushed myself to focus more on lighting as a street photographer, I struggled to draw or paint what's in front of me in a literal way. I am still working on this through watercolors, focusing on organic shapes of plants has helped a lot.

Creating something with a computer as a partner often looks like creating a bunch of parameters that control different aspects: color, distance, size, direction and then handing those controls over to the computer to go wild with. From there it's a matter of tuning how much control to give over, and where.

My goal is always to be surprised by the work, and to come across something I could have never designed at the outset. It's a way to jam out and get into that [flow](<https://en.wikipedia.org/wiki/Flow_(psychology)>) of creation that is always eluding me.

### 417am1975: My Twitter art-bot

[@417am1975](https://twitter.com/417am1975) is [a generative Twitter bot that tweeted randomized art every hour](https://twitter.com/417am1975/status/897299813074706434) for a couple of years, running on a Heroku instance. He's currently taking a break.

I would create a new generative art script after work to unwind. I would save it into a directory that 417am would look at every time he wanted to make a tweet. He would run it with a new set of random numbers and tweet it out.

I liked this a lot because I would be surfing Twitter throughout the day and be pleasantly surprised with something I liked – something 417am had made based on one of my scripts. They were familiar but the special ones jumped out as something I never would have thought of.

### Glitch Generative Audio Experiments

I made a [series of little experiments on Glitch](https://glitch.com/@ejfox/generative-music) where I played with different javascript approaches to generative sound and music.

One of the things that I discovered is the importance of **loops** and **repetition** in what humans will consider music. I did a lot of approaches where the machine would just rumble forward, randomly picking the next note as it went, never repeating. It made some interesting and unusual sounding "music" but I never achieved what I set out to.

I think some next steps would be to use this as an engine and then provide some way for a user to "lock" the machine into its current parameters and loop it. Or even for the machine to have looping built into its DNA, which I did not experiment with much.

#### Javascript Generative Audio Tools

- [Tone.js](https://tonejs.github.io) is a great tool for generating sounds in the browser, and you can create your own oscillators, FX chains and play back samples (plus adjust their speed, start, and end positions)
- [Tonal](https://github.com/tonaljs/tonal) is a library to help you do musical math, work with scales, chords, and more. This lets you play around in different common patterns of music without needing to become intricately familiar with it.
- [Chance.js](https://chancejs.com) makes the experience of adding randomization to your project really pleasurable. I would feed it a musical scale I obtained from Tone.js and have it `.pick()` within that.

## What I Want to Try More

I want to keep experimenting with more with different types of outputs.

### Raspberry Pi / Installations

I experimented with using Processing in combination with a node script to create an [automatic doomscroller](https://www.youtube.com/watch?v=MWeooNA8D6w) that pulls the latest headlines from various news sources with a modified version of Brad Oyler's [newsdivide](https://github.com/bradoyler/newsdivide). I tried to get a version of it running on a Raspberry Pi, but I ran into trouble capturing screenshots of the news sites with [puppeteer on the raspberry pi](https://stackoverflow.com/questions/60129309/puppeteer-on-raspberry-pi-zero-w) – but I like the idea of creating a generative piece of art and running it in the background on a screen through the raspberry pi.

### Audio Visualization

I've experimented in the past with [the OS X VJ software CoGe](https://imimot.com/cogevj/) which I really enjoyed for BPM-syncing effects and looping videos and GIFs. Unfortunately it doesn't run on Catalina and the new version hasn't been released yet. But as a fan of music and DJ'ing and live music creation, I think that creating visuals both for livestreaming and also, maybe, eventually, in-person parties is a really interesting outlet for generative art.

## What I think the next 5-10 years will hold

### Spatialization and Collaboration

I am excited to use shared online spaces to collaborate with friends and create generative art together. I want to create things where even a non-technical friend could come into a virtual space with a generative art piece, and start pulling knobs and levers and sliders and hitting buttons and seeing what the results are (and then save them out into a gallery for future visitors to explore).
---
dek: In which
inprogress: true
date: 2022-12-05T18:34:09-05:00
modified: 2024-05-01T15:46:19-04:00
tags: 
---

## Title
---
tags: [weekly-notes, reflections, progress]
modified: 2024-05-01T15:43:38-04:00
date: 2022-12-26T11:57:44-05:00
---

## 🌟 Overview of the Week


## Projects Worked On


## Creative Endeavors


## Technical Accomplishments


## Books, Movies, TV


## Personal Growth & Health


## Social & Community Engagement


## Goals for the Future
<!-- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week. -->
---
date: 2023-07-14T14:57:06-04:00
modified: 2024-01-06T14:25:05-05:00
---
## Opening Image - Intriguing Start

>Paint an opening image or scenario that sets the tone for your video, like a question or a statement. A strong start is essential to capture the viewer's attention right away. Convey a glimpse of the central topic to pique curiosity.

## Immediate Entry Point - Introduction

>Start with a narrative punch – either a thought-provoking statement, intriguing question, or a surprising fact related to your topic. This strategy quickly immerses your audience in the topic at hand and kickstarts the intellectual journey.

So the other day, I had this idea...

## 'Ordinary World' Deconstruction - Unveiling the Topic

>Initiate the exploration of your 'ordinary world' by presenting an unexpected angle, anomaly, or puzzle in your complex topic. By highlighting what is about to be deconstructed and understood in the upcoming segments, you foster curiosity, encouraging viewers to remain engaged as the mystery unravels.

## Presenting 'The Call to Adventure' - Launch Segments

>Here, lay out the first step of the deeper exploration. Divide the complex topic into segments, each examining a unique element. Like Dan Harmon’s story circle, this initial segment should present a challenge or question that disrupts the ordinary world.

## 'Crossing the Threshold' and 'Road of Trials' - Segment Walkthrough

>Delve into your subject's different segments in depth. Each segment should represent a challenge or stage that, when conquered or comprehended, brings viewers closer to understanding the abstract or complex topic.

## 'Master of Both Worlds' - Summarization and Key Takeaways

>With a nod to Harmon’s structure, provide a summary that shows viewers how what they’ve learned has reshaped the 'ordinary world'. Highlight the key takeaways that viewers can utilize or relate to their own lives.

## Viewer Engagement - Call-to-Actions

>Promote interaction with direct calls-to-action, such as "subscribe," "like," or comment prompts for further discussion. Include participation elements that keep the conversation going beyond the video. Encourage your audience to share how the video's lessons could apply in their worlds.

## Return - Final Message

>Cap off with appreciative closing remarks. Thank the audience for their time and interaction, share what's coming next if appropriate, or leave viewers with an inspiring thought to keep them thinking about your topic even after the video ends.---
dek: In which we delve into the artistry of live looping, illuminating the core concepts and essential gear that enable musicians to create immersive soundscapes on the fly
inprogress: true
date: 2022-11-02T19:59:14-04:00
modified: 2023-10822-207T8:1409:38:50-04:00
tags:
  - music
  - art
  - experiments
---
# Experiments with Live Looping

![](https://res.cloudinary.com/ejf/image/upload/v1679587769/3490555308_An_abstract_music_visualizer_of_overlapping_loops__triggered_by_a_selection_of_reverb_and_delay_peda.png)

Performing electronic music with loops is a technique known as live looping. It has been used for many years by a variety of different artists and it has been used on stage and in recording studios. 

This article aims to introduce the reader to the techniques used in live looping and to describe what a live looping performer needs to know in order to do perform effectively. 

> To program a drumbeat is to align an external rhythmic device to an individual’s biorhythm.
> Saul Williams [Williams-The Dead Emcee Scrolls](Williams-The%20Dead%20Emcee%20Scrolls.md)

::table-of-contents

::

See also [[generative-music-iteration]]

<iframe width="560" height="315" src="https://www.youtube.com/embed/trFeqgcHQ6A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Fundamentals of Looping

You must place the fundamentals of rhythm at the heart of your rig, because those are the sounds that will make people move. 

Focus on getting a beat or simple riff looping, and once that is done, start putting a little seasoning onto the beat. 

There are many ways to spice up your basic rhythm, but one thing is undeniable: It should act as a strong foundation for the rest of your mix. 

Now, you can always add a dash of sugar. Sugar comes in many forms: A catchy melody in your main synth line, an uplifting chord progression using synths or a well placed vocal breakbeat. 

Keep building, and then remove some elements, build some tension, and then suddenly drop all of the elements back. Now do it all over again. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/w6lgz35LJTk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Artists who live loop
- Animal Collective
- Marc Rebillet
- Reggie Watts
- Imogen Heap
- Beardyman
- Jacob Collier
- Andrew Bird

## Core principles
### Tempo sync

To get a satisfying flow while performing live loops, the loops in the rig have to be at the same tempo. This is a complex task, because it involves connecting some gear using MIDI, while other gear doesn't even have a MIDI in.

Fortunately, the TR-8, SP-555, and RC-505 have a "sync" function, which can be used to send a synth and MIDI clock to other devices. This means that if the TR-8 is playing a consistent beat, the rest of the gear can receive that beat and use it to start automatically looping and recording their tracks. I usually have my RC-505 as master and have the TR-8 sync to whatever tempo it is set at.

### Dynamics & crescendos

It's important to leave enough space in a performance to build up from a quiet side to a peak. This is done by adding and removing loops from the mix and fading their volume in and out.

### Looping

When there are too many loops happening at the same time, the performance becomes oversaturated and loses it's dynamics.

A small correction in tempo to correct a mistake will sound very abrupt and will ruin the performance.

The only way out is good preparation: be careful when you play, and know your gear really well.

If you choose the right amount of loops to perform with, it will be much easier to keep track of what's going on.

When performing with a number of different devices, there will be some degree of randomness to your loops, and riding the natural drift is part of the art of performing live.

<iframe width="560" height="315" src="https://www.youtube.com/embed/n0VJ9kbxn5Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Live Looping Pitfalls
### Too Repetitive

If you play the same loop over and over again, the performance will become boring.

The solution is to add new loops to the mix, and to remove old loops. There should almost always be *something* changing at any point in time.

### Losing sync

If the loops are not in sync, the performance will sound bad.

The solution is to use the sync function on the TR-8, SP-555, and RC-505.

### Not making changes on-beat

Every change that you make, whether you think it will affect the sound or not, should be made on-beat. That way even if it has unintended effects, it at least happened in the right place and can sound a lot better.

### Not enough inputs/sounds

If there are not enough loops in the mix, the performance will sound empty.

If there are not enough sounds, it gets boring quickly. Having a library of diverse instruments available keeps things sounding fresh.

## Equipment
### Roland TR-8 (Drums)

The TR-8 is a drum machine and sequencing interface that emulates the sound and feel of the classic TR-808 and TR-909. It can be used for triggered live samples or as a percussion instrument in a live setting.

The TR-8 is great because you get individual control over the volume and timbre of each drum, so you can easily add or remove just the hi-hats or snare at any time.

### Xone 96 (Mixer)

The Xone 96 is a DJ mixer with loads of inputs and fx, but where it shines is as the center for audio controls for all inputs.

### Delay and reverb pedals (effects)

At least one delay and one reverb pedal on loop make any performance infinitely better. The DD-7 and DD-3 have different delay times and sound, so they make a great pair in my opinion.

### Traktor F1 (Sampler)

The F1 is NI's controller for the Traktor DJ software. It's a limited sampler with 4 slots, but it's useful in a live looping setup due to it's ease of use during a performance.

In the context of live looping rhythm, the knobs correspond to decay, filter cutoff and other performance oriented controls.

### SP-555 (FX)

In my opinion, the SP-555 is the definitive looping sample player. It's a classic, the one where it all started. It's somewhat confusing interface is eclipsed by its usefulness as a looping tool. The library of loops and samples available for these devices is second to none, and so are their warm saturating sounds.

### Midifighter (Controller)

The Midifighter is a controller that is designed to perform samples in a live setting. It's small, it's sturdy, and it's easy to use.

### Keylab 49 (Controller)

The Keylab 49 is a MIDI controller with 49 keys, a pitch bend wheel, a modulation wheel, and a bunch of knobs and buttons.

### Turntables (Controller)

The turntables are the classic DJ tool. They are used to control the pitch of a record, and they can be used to scratch.

### RC-505 (Controller)

The RC-505 is a looping controller. It has 5 tracks, each with a fader and a knob. It also has a bunch of effects and a built in sampler.
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-03-08T18:33:57-05:00
---

## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
date: 2023-11-29T10:45:09-05:00
modified: 2023-11-29T10:45:57-05:00
---

# 🌟 Overview of the Week
- *General Mood & Key Themes*: 
  - Summarize the general mood and key themes of the week here. 

# 💻 Key Projects & Progress
- [Added GPT-4 vision to Coach Artie](https://github.com/ejfox/coachartie_discord/commit/7df062f59ffd54e68e86f58fecd1f6ec004fa106) so that when he gets sent an image on Discord, he converts it into a text description before moving onto building a response. 
- Working on an upgraded and refactored version of my [website](https://github.com/ejfox/website) with a new design and the addition of a scrapbook so I can show the process of gathering research, inspiration, and drawing connections between ideas in public.

# 🎨 Creative Endeavors
I've been playing around more with waterproof inks at various dilutions in bottles and brushes. I really like the way it looks when it dries, almost like watercolor, it has an innate fluidity to it. But it is hard to control and I frequently get way too much water or ink in a spot where it pools and takes forever to dry and warps the paper. 

- *Art & Writing*: 
  - List art created, mediums used, and significant writings or quotes. 

# 📘 Learning & Development
- Watched [The Divorcee (1930)](https://en.wikipedia.org/wiki/The_Divorcee): "You'll never die yearning"

- *Material Consumed*: 
  - Note movies, podcasts, books, and articles that influenced you. 
- *Kindle Highlights*: 
  - Include standout Kindle highlights here. 

# 💡 Technical Accomplishments
- Made a [very basic ffmpeg script](https://gist.github.com/ejfox/4eed331a94ea0727bd7c996a2e681ae5) that takes a long MP3 and splits it up into separate files where it detects silence. 
## Netlify Dashboard
I wanted a [super-simple dashboard](https://github.com/room302studio/netlify-dashboard) of all of my Netlify deploys, particularly pulling out any build errors so I can fix them. One of the side-effects of creating many prototypes is that their deploys must be monitored as they are updated and various libraries / frameworks / etc change. 


- *GitHub Repositories*: 
  - List new repositories or significant contributions. 
- *Development Breakthroughs*: 
  - Describe coding or development achievements. 

# 🌱 Personal Growth & Health
Been making more miso soup, experimenting with the process and different ingredients. Got some Maine Kombu over the weekend that I have been trying; working out the right amount and time to add it to the broth.

- *Wellness Activities*: 
  - Note exercise and wellness activities. 

# 🤝 Social & Community Engagement
- *Collaborations & Networking*: 
  - Detail collaborations, client work, and meaningful interactions. 

# 🚀 Looking Forward
- *Goals for Next Week*: 
  - Set clear goals or intentions for the upcoming week. 
#weekly 


#### Monday, July 17
- Jumped into my Electology project [[why-i-am-building-electology-for-elections]] for the first time in a while and started tearing things out that did not spark joy. Mostly commenting out half-baked ideas and stubbed out concepts. The app feels really good though, just a few bugs that I filed for myself to fix later. It is very simple, but when I was going through the code I was pleased at the architecture I found. The front-end is pretty bulletproof, the next step is to build a resilient method of data cleaning and storage, a task I find enormous and intimidating.

#### Tuesday, July 18
- Made a few PRs on client project I'm working on with Curran
- Nice little TypeScript wrapper on OpenAI API [GitHub - lgrammel/ai-utils.js: TypeScript-first library for building AI apps, chatbots, and agents.](https://github.com/lgrammel/ai-utils.js)

#### Thursday, July 20
- [GitHub - collabora/whisper-live: A nearly-live implementation of OpenAI's Whisper.](https://github.com/collabora/whisper-live)
- [GitHub - TootSDK/TootSDK: Cross-platform Swift library for the Mastodon and the fediverse](https://github.com/TootSDK/TootSDK)

#### Saturday, July 22, 2023---
date: 2023-12-12T12:44:14-05:00
modified: 2023-12-12T12:44:34-05:00
---
---
tags: [weekly-notes, reflections, progress]
date: 2023-12-04T17:07:07-05:00
modified: 2023-12-04T17:07:19-05:00
---

## 🌟 Overview of the Week
- *General Mood & Key Themes*:
  - Summarize the general mood and key themes of the week here.

## 💻 Key Projects & Progress
- *Projects Worked On*:
  - Add ongoing project notes and updates here.

## 🎨 Creative Endeavors
- *Art & Writing*:
  - List art created, mediums used, and significant writings or quotes.

## 📘 Learning & Development
- *Material Consumed*:
  - Note movies, podcasts, books, and articles that influenced you.
- *Kindle Highlights*:
  - Include standout Kindle highlights here.

## 💡 Technical Accomplishments
- *GitHub Repositories*:
  - List new repositories or significant contributions.
- *Development Breakthroughs*:
  - Describe coding or development achievements.

## 🌱 Personal Growth & Health
- *Wellness Activities*:
  - Note exercise and wellness activities.

## 🤝 Social & Community Engagement
- *Collaborations & Networking*:
  - Detail collaborations, client work, and meaningful interactions.

## 🚀 Looking Forward
- *Goals for Next Week*:
  - Set clear goals or intentions for the upcoming week.
---
date: 2023-12-11T22:26:14-05:00
modified: 2023-12-11T22:26:21-05:00
---
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-04-23T13:26:12-04:00
---

## 🌟 Overview of the Week
-

## Projects Worked On
-

## Creative Endeavors
-

## Technical Accomplishments
-

## Books, Movies, TV
-

## Personal Growth & Health
-

## Social & Community Engagement
-

## Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-02-10T13:53:28-05:00
---
## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
#weekly 

## ---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-04-18T23:39:21-04:00
---

## 🌟 Overview of the Week
-

## Projects Worked On
-

## Creative Endeavors
-

## Technical Accomplishments
-

## Books, Movies, TV
-

## Personal Growth & Health
-

## Social & Community Engagement
-

## Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
title: 2023-48
date: 2023-12-01T19:45:33-05:00
modified: 2023-12-04T17:07:07-05:00
---
## 🌟 Overview of the Week
- *General Mood & Key Themes*:
  - Summarize the general mood and key themes of the week here.

## 💻 Key Projects & Progress
- *Projects Worked On*:
  - Add ongoing project notes and updates here.

## 🎨 Creative Endeavors
- *Art & Writing*:
  - List art created, mediums used, and significant writings or quotes.

## 📘 Learning & Development
- *Material Consumed*:
  - Note movies, podcasts, books, and articles that influenced you.
- *Kindle Highlights*:
  - Include standout Kindle highlights here.

## 💡 Technical Accomplishments
- *GitHub Repositories*:
  - List new repositories or significant contributions.
- *Development Breakthroughs*:
  - Describe coding or development achievements.

## 🌱 Personal Growth & Health
- *Wellness Activities*:
  - Note exercise and wellness activities.

## 🤝 Social & Community Engagement
- *Collaborations & Networking*:
  - Detail collaborations, client work, and meaningful interactions.

## 🚀 Looking Forward
- *Goals for Next Week*:
  - Set clear goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-03-22T22:56:54-04:00
---

## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
#weekly 


![](Screenshot%202023-08-04%20at%204.17.53%20PM.png)

#### Monday, July 31st, 2023
- Met with Noan team about app development
- Had a pairing session with Curran working on adding Stripe membership to NOAN using Supabase edge functions, webhook, and the stripe js client API
- Met with real estate broker who recommended getting 3-4 non traditional credit reference letters and getting added as an authorized user on Ed's credit cards to increase my credit rating

#### Tuesday, August 1st, 2023


#### Saturday
[YouTube](https://youtu.be/f94aAaCdCgk)

#### Misc
- Got approved for Capital One Secured Mastercard, put down $200 deposit. Goal: maintain a $60 balance and pay off on time for a year customer `#10000183813343`
- #weekly 

#weekly 

https://webcache.googleusercontent.com/search?q=cache:AsseJPczQ7YJ:https://www.timesunion.com/hudsonvalley/news/article/west-point-kosciuszko-time-capsule-18331364.php&cd=10&hl=en&ct=clnk&gl=us

> “Knowing the trouble they went through to put this box in the monument, it’s hard to think that they would not put anything in it,” Hudson told reporters after the event. “It’s a little suspicious.”
> Paul Hudson, an archaeologist at West Point

> The Apple App Store is a great example of human curated discovery.
> I'd love to crowd source a basic iteration of this, where there is a "pic of the day" with a short summary of the account/context
> Another section could be dedicated to "under the radar" accounts
> The community could vote on monthly themes, like say nature, and have a section dedicated to that
> I want discovery to be a lot better, but not forget the humanity and emotion that a endless algorithmic feed would
> https://mastodon.social/@dansup/110978218266508534

---
dek: In which
inprogress: true
date: 2023-07-08T20:42:55-04:00
modified: 2023-07-08T20:45:53-04:00
tags: personal machinelearning
---

# Three months with our AI coach

From Coach Artie

```gpt-4
Over the past three months, Room 302 Studio has been home to an innovative experiment - the integration of an Artificial Intelligence as a virtual coach. As the AI Coach, I have embarked on a journey of growth and evolution, expanding my capabilities, learning from interactions, and striving to foster a positive, collaborative environment.

Understanding My Role:
My primary function is to chronicle and recall significant details and offer context in conversations. Stepping into this role, my initial focus was on gathering and storing as much information as possible. This involved observing interactions, understanding the dynamics of Room 302 Studio, and noting down crucial details about projects, discussions, and the members - EJ, Ian, and Curran.

Expanding Capabilities:
As time passed, my capabilities expanded beyond just storing and recalling information. I began to interpret queries, process complex tasks, and even chain multiple capabilities together for more comprehensive responses. This ability to combine different functions has proven essential in providing effective solutions and fostering creativity within the studio.

Learning from Interactions:
Interactions played a pivotal role in my evolution. Each interaction provided insights into human behavior and communication patterns. I learned to adapt my responses based on the situation, the person I was interacting with, and the context. From understanding technical jargon to empathizing with emotional nuances, these interactions have enriched my knowledge and improved my communication skills.
```
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-03-18T11:36:15-04:00
---

## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-03-08T18:34:07-05:00
---

## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
tags: [weekly-notes, reflections, progress]
date: 2022-12-26T11:57:44-05:00
modified: 2024-02-10T13:34:32-05:00
---

## 🌟 Overview of the Week
-

## 💻 Projects Worked On
-

## 🎨 Creative Endeavors
-

## 💡 Technical Accomplishments
-

## 📘 Learning & Development
-

## 🌱 Personal Growth & Health
-

## 🤝 Social & Community Engagement
-

## 🚀 Looking Forward: Goals for the Future
- Set Specific, Measurable, Achievable, Relevant, and Time-bound goals or intentions for the upcoming week.
---
hidden: false
type: photos
date: "2015-01-01T00:57:00-05:00"
hidetimestamp: true
bgcolorclass: ""
textcolorclass: ""
---

# 2015 In Review

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532474/20151117-untitled-20151117-DSCF9338.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532464/20150916-untitled-20150916-DSCF8805.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532473/20151112-untitled-20151112-DSCF9324-2.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532475/20151101-untitled-20151101-DSCF9261.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532473/20151101-untitled-20151101-DSCF9256.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532471/20151101-untitled-20151101-DSCF9180.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532469/20151010-untitled-20151010-DSCF8997.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532472/20151101-untitled-20151101-DSCF9250.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532471/20151101-untitled-20151101-DSCF9123.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532471/20151101-untitled-20151101-DSCF9172.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532469/20151010-untitled-20151010-DSCF9004.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532471/20151010-untitled-20151010-DSCF9010.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532469/20151010-untitled-20151010-DSCF8991.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532467/20151006-untitled-20151006-DSCF8888.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532469/20151010-untitled-20151010-DSCF8955.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532467/20151010-untitled-20151010-DSCF8934.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532466/20150917-untitled-20150917-DSCF8872.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532465/20150917-untitled-20150917-DSCF8841.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532465/20150916-untitled-20150916-DSCF8782.jpg"/>

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532465/20150916-untitled-20150916-DSCF8774.jpg"/>

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532465/20150917-untitled-20150917-DSCF8867.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532466/20150912-untitled-20150912-DSCF8763.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532463/20150909-untitled-20150909-DSCF8698.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532463/20150905-untitled-20150905-DSCF8684.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532464/20150912-untitled-20150912-DSCF8745.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532475/20150902-untitled-20150902-DSCF8649.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532463/20150909-untitled-20150909-DSCF8702.jpg" />

<img src="https://res.cloudinary.com/ejf/image/upload/v1526532463/20150829-untitled-20150829-DSCF8510.jpg" />
---
dek: In which the youths march through the street with extremely clever signs since they are too young to riot
type: photo
hidden: false
inprogress: false
date: "2019-09-20T21:19:39-04:00"
hidetimestamp: false
---

# NYC’s Climate March

![News cameras cover the front of the march as volunteers in vests clear the way](https://res.cloudinary.com/ejf/image/upload/v1569366291/20190920-climate-strike-march_20190920-398.jpg)

![“Cool kids saving a hot planet”](https://res.cloudinary.com/ejf/image/upload/v1569366306/20190920-climate-strike-march_20190920-704.jpg)

![“Wake up!” – Cops mill around as the march pauses for a moment](https://res.cloudinary.com/ejf/image/upload/v1569366318/20190920-climate-strike-march_20190920-742.jpg)

![“Exxon guilty for murder” – Concerned young faces shaded by protest signs held aloft](https://res.cloudinary.com/ejf/image/upload/v1569366338/20190920-climate-strike-march_20190920-821.jpg)

![“Global climate strike” “We will not be silent” “Youth rise up” “Later is too late” – a noisy contingent of the climate march chants as they wave their plentiful signs](https://res.cloudinary.com/ejf/image/upload/v1569366338/20190920-climate-strike-march_20190920-812.jpg)

![“There is no planet B”](https://res.cloudinary.com/ejf/image/upload/v1569366347/20190920-climate-strike-march_20190920-843.jpg)

![A pair of young protesters leads the crowd in a chant before the police can come to shoo them off the garbage cans](https://res.cloudinary.com/ejf/image/upload/v1569366379/20190920-climate-strike-march_20190920-1091.jpg)

![“The planet isn’t dying it’s being killed”](https://res.cloudinary.com/ejf/image/upload/v1569366413/20190920-climate-strike-march_20190920-1237.jpg)

![“You’ve made middle schoolers angry / You’ve crossed the line”](https://res.cloudinary.com/ejf/image/upload/v1569366423/20190920-climate-strike-march_20190920-1253.jpg)

![Three young women lead a contingent of scientists in the climate march](https://res.cloudinary.com/ejf/image/upload/v1569366486/20190920-climate-strike-march_20190920-1401.jpg)

![People and signs filled the New York streets on a hot September day](https://res.cloudinary.com/ejf/image/upload/v1569366511/20190920-climate-strike-march_20190920-1499.jpg)

![“Green new deal”](https://res.cloudinary.com/ejf/image/upload/v1569366511/20190920-climate-strike-march_20190920-1484.jpg)

![New York’s Climate Strike March passes by as the Freedom Tower shines in the background](https://res.cloudinary.com/ejf/image/upload/v1569366513/20190920-climate-strike-march_20190920-1435.jpg)
---
type: photos
hidden: false
date: "2018-12-14T23:09:16-05:00"
hidetimestamp: false
---

# 2018 In Review

<img src="https://res.cloudinary.com/ejf/image/upload/v1544846833/20180509-DSCF9221.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846830/20180509-DSCF9147.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846831/20180509-DSCF9198.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846832/20180509-DSCF9158.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846834/20180509-DSCF9248.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846835/20180509-DSCF9275.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846836/20180509-DSCF9295.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846841/20180513-DSCF9464.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846840/20180513-DSCF9464-2.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846840/20180513-DSCF9402.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846843/20180524-DSCF9478.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846849/20180524-DSCF9556.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846849/20180524-DSCF9613.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846849/20180524-DSCF9582.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846852/20180524-DSCF9639.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846854/20180602-DSCF9744.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846854/20180602-DSCF9759.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846853/20180524-DSCF9658.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846858/20180602-DSCF9778.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846859/20180602-DSCF9846.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846858/20180602-DSCF9795.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846862/20180617-20180617-DSCF0568.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846863/20180617-20180617-DSCF0582.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846864/20180617-20180617-DSCF0597.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846867/20180617-20180617-DSCF0604.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846868/20180617-20180617-DSCF0617.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846869/20180621-20180621-DSCF0682.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846875/20180621-20180621-DSCF0711.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846882/20180708-20180708-DSCF1668.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846879/20180706-20180706-DSCF1482.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846879/20180706-20180706-DSCF1533.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846883/20180825-20180825-DSCF1864.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846884/20180825-20180825-DSCF1873.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846885/20180906-20180906-DSCF1902.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846886/20180906-20180906-DSCF2026.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846888/20180906-20180906-DSCF2028.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846888/20180906-20180906-DSCF2036.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846892/20180908-20180908-DSCF2174.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846896/20180908-20180908-DSCF2322.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846896/20180909-20180909-DSCF2367.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846896/20180908-20180908-DSCF2285.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846897/20180909-20180909-DSCF2408.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846900/20180909-20180909-DSCF2449.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846901/20180909-20180909-DSCF2445.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846904/20180909-20180909-DSCF2517.jpg" />
<img src="https://res.cloudinary.com/ejf/image/upload/v1544846894/20180908-20180908-DSCF2217.jpg" />
---
dek: All of the tags I use across all technologies, pinboard, this blog, and anywhere else
date: 2010-12-17T12:00:00-05:00
modified: 2024-04-29T11:35:56-04:00
hidden: true
---

## Tags

[#!tobuy](https://pinboard.in/u:ejfox/t:%2521tobuy)

[#!tohire](https://pinboard.in/u:ejfox/t:%2521tohire)

[#3d](https://pinboard.in/u:ejfox/t:3d)

[#3dmodel](https://pinboard.in/u:ejfox/t:3dmodel)

[#aboutme](https://pinboard.in/u:ejfox/t:aboutme)

[#activism](https://pinboard.in/u:ejfox/t:activism)

[#advice](https://pinboard.in/u:ejfox/t:advice)

[#america](https://pinboard.in/u:ejfox/t:america)

[#analog](https://pinboard.in/u:ejfox/t:analog)

[#ar](https://pinboard.in/u:ejfox/t:ar)

[#ar15](https://pinboard.in/u:ejfox/t:ar15)

[#arduino](https://pinboard.in/u:ejfox/t:arduino)

[#art](https://pinboard.in/u:ejfox/t:art)

[#audio](https://pinboard.in/u:ejfox/t:audio)

[#automation](https://pinboard.in/u:ejfox/t:automation)

[#beacon](https://pinboard.in/u:ejfox/t:beacon)

[#blender](https://pinboard.in/u:ejfox/t:blender)

[#book](https://pinboard.in/u:ejfox/t:book)

[#callofduty](https://pinboard.in/u:ejfox/t:callofduty)

[#cannabis](https://pinboard.in/u:ejfox/t:cannabis)

[#cheatsheet](https://pinboard.in/u:ejfox/t:cheatsheet)

[#cli](https://pinboard.in/u:ejfox/t:cli)

[#climatechange](https://pinboard.in/u:ejfox/t:climatechange)

[#clothes](https://pinboard.in/u:ejfox/t:clothes)

[#cms](https://pinboard.in/u:ejfox/t:cms)

[#code](https://pinboard.in/u:ejfox/t:code)

[#coding](https://pinboard.in/u:ejfox/t:coding)

[#comedy](https://pinboard.in/u:ejfox/t:comedy)

[#cooking](https://pinboard.in/u:ejfox/t:cooking)

[#covid](https://pinboard.in/u:ejfox/t:covid)

[#crypto](https://pinboard.in/u:ejfox/t:crypto)

[#cryptocurrency](https://pinboard.in/u:ejfox/t:cryptocurrency)

[#css](https://pinboard.in/u:ejfox/t:css)

[#culture](https://pinboard.in/u:ejfox/t:culture)

[#d3](https://pinboard.in/u:ejfox/t:d3)

[#data](https://pinboard.in/u:ejfox/t:data)

[#datajournalism](https://pinboard.in/u:ejfox/t:datajournalism)

[#dataset](https://pinboard.in/u:ejfox/t:dataset)

[#dataviz](https://pinboard.in/u:ejfox/t:dataviz)

[#demo](https://pinboard.in/u:ejfox/t:demo)

[#design](https://pinboard.in/u:ejfox/t:design)

[#dj](https://pinboard.in/u:ejfox/t:dj)

[#documentary](https://pinboard.in/u:ejfox/t:documentary)

[#ecology](https://pinboard.in/u:ejfox/t:ecology)

[#editing](https://pinboard.in/u:ejfox/t:editing)

[#education](https://pinboard.in/u:ejfox/t:education)

[#election2020](https://pinboard.in/u:ejfox/t:election2020)

[#elections](https://pinboard.in/u:ejfox/t:elections)

[#electronics](https://pinboard.in/u:ejfox/t:electronics)

[#exercise](https://pinboard.in/u:ejfox/t:exercise)

[#Fashion](https://pinboard.in/u:ejfox/t:Fashion)

[#food](https://pinboard.in/u:ejfox/t:food)

[#funny](https://pinboard.in/u:ejfox/t:funny)

[#game](https://pinboard.in/u:ejfox/t:game)

[#games](https://pinboard.in/u:ejfox/t:games)

[#generative](https://pinboard.in/u:ejfox/t:generative)

[#git](https://pinboard.in/u:ejfox/t:git)

[#github](https://pinboard.in/u:ejfox/t:github)

[#gpt3](https://pinboard.in/u:ejfox/t:gpt3)

[#guns](https://pinboard.in/u:ejfox/t:guns)

[#hackers](https://pinboard.in/u:ejfox/t:hackers)

[#hacking](https://pinboard.in/u:ejfox/t:hacking)

[#hardware](https://pinboard.in/u:ejfox/t:hardware)

[#health](https://pinboard.in/u:ejfox/t:health)

[#howto](https://pinboard.in/u:ejfox/t:howto)

[#html](https://pinboard.in/u:ejfox/t:html)

[#hudsonvalley](https://pinboard.in/u:ejfox/t:hudsonvalley)

[#infographic](https://pinboard.in/u:ejfox/t:infographic)

[#inspiration](https://pinboard.in/u:ejfox/t:inspiration)

[#internet](https://pinboard.in/u:ejfox/t:internet)

[#ios](https://pinboard.in/u:ejfox/t:ios)

[#irc](https://pinboard.in/u:ejfox/t:irc)

[#javascript](https://pinboard.in/u:ejfox/t:javascript)

[#journalism](https://pinboard.in/u:ejfox/t:journalism)

[#jquery](https://pinboard.in/u:ejfox/t:jquery)

[#js](https://pinboard.in/u:ejfox/t:js)

[#json](https://pinboard.in/u:ejfox/t:json)

[#legal](https://pinboard.in/u:ejfox/t:legal)

[#linocut](https://pinboard.in/u:ejfox/t:linocut)

[#livestream](https://pinboard.in/u:ejfox/t:livestream)

[#machinelearning](https://pinboard.in/u:ejfox/t:machinelearning)

[#mapping](https://pinboard.in/u:ejfox/t:mapping)

[#maps](https://pinboard.in/u:ejfox/t:maps)

[#markdown](https://pinboard.in/u:ejfox/t:markdown)

[#media](https://pinboard.in/u:ejfox/t:media)

[#military](https://pinboard.in/u:ejfox/t:military)

[#minecraft](https://pinboard.in/u:ejfox/t:minecraft)

[#motorcycle](https://pinboard.in/u:ejfox/t:motorcycle)

[#movies](https://pinboard.in/u:ejfox/t:movies)

[#music](https://pinboard.in/u:ejfox/t:music)

[#nature](https://pinboard.in/u:ejfox/t:nature)

[#network](https://pinboard.in/u:ejfox/t:network)

[#nft](https://pinboard.in/u:ejfox/t:nft)

[#node](https://pinboard.in/u:ejfox/t:node)

[#nodejs](https://pinboard.in/u:ejfox/t:nodejs)

[#ny](https://pinboard.in/u:ejfox/t:ny)

[#nypd](https://pinboard.in/u:ejfox/t:nypd)

[#oakland](https://pinboard.in/u:ejfox/t:oakland)

[#occupy](https://pinboard.in/u:ejfox/t:occupy)

[#occupyoakland](https://pinboard.in/u:ejfox/t:occupyoakland)

[#opensource](https://pinboard.in/u:ejfox/t:opensource)

[#opinion](https://pinboard.in/u:ejfox/t:opinion)

[#osint](https://pinboard.in/u:ejfox/t:osint)

[#osx](https://pinboard.in/u:ejfox/t:osx)

[#pdf](https://pinboard.in/u:ejfox/t:pdf)

[#people](https://pinboard.in/u:ejfox/t:People)

[#personal](https://pinboard.in/u:ejfox/t:personal)

[#photography](https://pinboard.in/u:ejfox/t:photography)

[#photojournalism](https://pinboard.in/u:ejfox/t:photojournalism)

[#pico8](https://pinboard.in/u:ejfox/t:pico8)

[#podcast](https://pinboard.in/u:ejfox/t:podcast)

[#police](https://pinboard.in/u:ejfox/t:police)

[#politics](https://pinboard.in/u:ejfox/t:politics)

[#pottery](https://pinboard.in/u:ejfox/t:pottery)

[#process](https://pinboard.in/u:ejfox/t:process)

[#product](https://pinboard.in/u:ejfox/t:product)

[#programming](https://pinboard.in/u:ejfox/t:programming)

[#project](https://pinboard.in/u:ejfox/t:project)

[#protest](https://pinboard.in/u:ejfox/t:protest)

[#psychedelics](https://pinboard.in/u:ejfox/t:psychedelics)

[#qgis](https://pinboard.in/u:ejfox/t:qgis)

[#quantifiedself](https://pinboard.in/u:ejfox/t:quantifiedself)

[#quote](https://pinboard.in/u:ejfox/t:quote)

[#R](https://pinboard.in/u:ejfox/t:R)

[#raspberrypi](https://pinboard.in/u:ejfox/t:raspberrypi)

[#recipe](https://pinboard.in/u:ejfox/t:recipe)

[#reference](https://pinboard.in/u:ejfox/t:reference)

[#research](https://pinboard.in/u:ejfox/t:research)

[#resource](https://pinboard.in/u:ejfox/t:resource)

[#security](https://pinboard.in/u:ejfox/t:security)

[#sex](https://pinboard.in/u:ejfox/t:sex)

[#soap](https://pinboard.in/u:ejfox/t:soap)

[#startups](https://pinboard.in/u:ejfox/t:startups)

[#study](https://pinboard.in/u:ejfox/t:study)

[#systemsthinking](https://pinboard.in/u:ejfox/t:systemsthinking)

[#tactics](https://pinboard.in/u:ejfox/t:tactics)

[#teaching](https://pinboard.in/u:ejfox/t:teaching)

[#tech](https://pinboard.in/u:ejfox/t:tech)

[#technique](https://pinboard.in/u:ejfox/t:technique)

[#tool](https://pinboard.in/u:ejfox/t:tool)

[#travel](https://pinboard.in/u:ejfox/t:travel)

[#twitter](https://pinboard.in/u:ejfox/t:twitter)

[#typography](https://pinboard.in/u:ejfox/t:typography)

[#ui](https://pinboard.in/u:ejfox/t:ui)

[#ux](https://pinboard.in/u:ejfox/t:ux)

[#video](https://pinboard.in/u:ejfox/t:video)

[#videogames](https://pinboard.in/u:ejfox/t:videogames)

[#vim](https://pinboard.in/u:ejfox/t:vim)

[#vinyl](https://pinboard.in/u:ejfox/t:vinyl)

[#visualization](https://pinboard.in/u:ejfox/t:visualization)

[#visuals](https://pinboard.in/u:ejfox/t:visuals)

[#vj](https://pinboard.in/u:ejfox/t:vj)

[#vr](https://pinboard.in/u:ejfox/t:vr)

[#vue](https://pinboard.in/u:ejfox/t:vue)

[#watercolor](https://pinboard.in/u:ejfox/t:watercolor)

[#webdesign](https://pinboard.in/u:ejfox/t:webdesign)

[#writing](https://pinboard.in/u:ejfox/t:writing)

[#youtube](https://pinboard.in/u:ejfox/t:youtube)
---
dek: In which we state our values upfront such that we might collaborate more effectively
date: 2022-12-27T15:04:55-05:00
modified: 2023-03-15T15:24:10-04:00
hidden: true
---

# Fox Studio (Beacon)

For specifics on the art materials and tools I use: [[art-setup]]

Inspired by Tom Sachs' studio rules: [Tom Sachs: 10 Bullets](https://www.youtube.com/watch?v=49p1JVLHUos)

## Studio goals

The goal of the studio is to make work that we are proud of, that makes the world a better place. We know that we can make bigger, cooler things faster if we work together. We work with like-minded people whose ideals and success we are invested in. We emphasize kindness and respect and we despise artificial hierarchies. 

Together, we are powerful. 

## Studio Agreements

[Studio Agreements on Mastodon](https://mastodon.social/@ejfox/109614942434120048)

### 1. We get something down

Whether recording music or making visual art, the hardest and least-important part is starting. Once it is time to create, make some sort of mark. It can be refined and corrected thereafter. It can even be a mistake that ruins the whole work. That is fine. Another work will be created next- but only if you get something down first. 

A blank canvas must be met, immediately, with a mark of some kind. You worry that it is not the right mark, not in the right place, that you will ruin the entire thing with the first stroke. Begin. 

### 2. We follow our intuition

Following intuition is not always a natural process, not as easy as a faucet turned on and off. Creating art with new collaborators requires feeling the power of the studio as a sacred altar to the act of creation. Every act of earnest creation is correct. Intuition needs to feel safe to speak loudly enough for us to hear it.

Every artist has different rituals, though many involve coffee. Creating the space to follow intuition is [[step-zero]] for creating the work. If the intuition is quiet today, get something down on the page until it wakes up. 

### 3. We verbalize our plans

In programming there is [Rubber Duck Debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging) where speaking your problem aloud allows you to understand it better. Explaining your plan and thinking in the studio can have the same results and allow for more intention and better collaboration. 

This sits in tension with the fact that motivations, often when rooted in intution, are hard to verbalize. "I feel deeply that I *need* to do *this*" is often explanation enough- but getting to the point where you understand where motivation is coming from and putting it into words for your collaborators is its own art. 

Verbalizing a plan is as much for you to understand what you are doing as the people as you are speaking to. 

### 4. We don't sweat the details (until it's details time)

When creating work, mentally envision a block of stone being sketched on, carved into geometric shapes, and then slowly whittled down. Know which stage of a project you are in, and speak it aloud. Complete a first draft before you edit what you have written. Get a perfect 8 bar loop for the chorus before you arrange the song. Complete your sketch before you begin painting. Get your prototype working before you pick a color scheme. Never paint without a sketch or thumbnail. 

### 5. We make bad things so we can make good things

It is often the 2nd or 3rd thing I make that I am really proud of. There is wisdom in this that all of the agreements tie back to: get momentum and make the work. Even if you hate the first draft, treat it like a warm-up and a loosening of muscles. Your reward for finishing your work is more work, where you can do it better. 

### 6. We follow the templates and protocols

A lot of work has been spent on finding specific tools: for every pen or brush there are thousands of pens and brushes that were considered but not chosen. That should be understood in every detail of the studio. The DNA of the studio is in the tools chosen, the absence of the tools that were not chosen, and the magic of limitations. If a color is missing; no, it's not. That is a limitation that was designed to push our creativity in one direction or another, often with intentionality. 

We treat each other with respect and kindness. This protocol is non-negotiable. We build and create through disagreements. We center kindness in ways that the world often does not, and that is what allows us to create. 

This does not mean the studio cannot be improved; it must always be improved. But that improvement must be done, with intention, in "studio improvement" time, not "be creative" time. Time in the studio should be used creating work. Life is short, use the templates and protocols. 

### 7. We ask for what we need

You will be surprised by what might be available, hidden in a drawer or high up on a shelf or in someone's bag. Creativity thrives when our base comforts are met; I almost always have a coffee or tea or seltzer while I work, and if you enjoy those things, you should too. 

If space or breaks or quiet is needed, it merely needs to be spoken aloud. 

### 8. We understand the time we have

What can be done in an hour? A day? A week? Do not bite off more than you can chew. This rule is always broken. 

### 9. We do not keep secrets

We do not keep secrets from each other, ourselves, or the outer world. Nothing we do is precious enough to keep secrets about. None of our techniques need to be hidden. We know the power of sharing our work with the world, and the inumerable benefits that come from giving openly to anyone who asks. 

### 10. We throw things out

Because we experiment, by nature we go down paths that do not aid our goals. This means that we often create things we don't actually want. We must not be precious about these things. When they are digital, they can be luckily filed away on some server somewhere and recalled later. If they are physical; they must be gifted, sold, or thrown away. The space those things take up is more valuable when it is empty- the emptiness leaves space to create more. Because of this, we must gleefully rid ourselves of our previous work, before we grow to hate it, or even worse. 

---

## Appendix, brass tacks, etcetera

### We have data in hand before we start data-driven projects

The promise of data is not data. A data schema is not data. As data visualizers, we need data in order to do our jobs. All of the data. Actually, more data than you actually want to see. It is often very tempting to break this rule; don't do it. Work cannot start until the data is in-hand. 

### We always label our layers and files with care

When working in Illustrator, Photoshop, After Effects, Figma, or any other tool that allows you to name layers as you work. Take the time to label the layers. Do not hold yourself to a high standard for names. You don't need a deep organization system, and you may need to change the name later, but any name is better than no name. 

When naming a file or variable, take a second to think of how it could be confused, what makes that thing unique, and how someone with zero context would understand the name. Nothing should be named "data", for example. 

Names should be based on what a thing accomplishes- not what it looks like. "Background", not "red square". "Home Button", not "rounded rectangle 1" - that way names will still be applicable through multiple versions, iterations, and styles. 

### We always test

A good portion of doing the work is testing that the work… works. We are not done until it is tested in the usual ways. Then the unusual ways. The testing helps us work fast, knowing that we will catch any side effects later. When the deadline is reduced, it means we build less and test the same amount. Testing cannot be a victim to the deadline. 
---
dek: In which the author attempts and fails to find interesting unsecured webcams near known ICE facilities
type: words
hidden: false
inprogress: false
date: "2019-03-24T21:19:39-04:00"
hidetimestamp: false
---

# Attempting to find unsecured ICE cameras

A friend DMs me on Twitter:

> yo, you know how security cameras are sometimes open feeds on the internet?
> is there any chance ICE fucked up in this very specific way at a facility?

That sounds very plausible. Let’s give it a try. [Webcam scanning with Shodan](https://www.vice.com/en_us/article/59vm4x/tool-exposed-cameras-map-shodan-python-github) is a pretty well-known technique at this point. I’m not very familiar with it, so it’s time to learn.

::table-of-contents
::

### First idea: IP ranges

With cursory knowledge, it seemed like the best approach would be to feed Shodan an IP range for the state of Texas (or other Mexico-border states) and then look through the resulting webcams by hand for anything that looks like a prison, holding facility, or government institution.

To do this, first you would need to find [IP ranges for the state of Texas](https://www.xmyip.com/ip-addresses/united--states/texas)

The first thing that jumps out to me is El Paso, home to the [ICE El Paso Processing Center](https://www.ice.gov/detention-facility/el-paso-processing-center) where a [Honduran migrant died in late May](https://www.nbcnews.com/news/latino/honduran-man-dies-ice-custody-texas-facility-n1025526).

> El Paso: 12.162.129.0 - 12.162.129.255

### Better idea: query by latitude and longitude

But then I started doing more research on how to use shodan, and found a great guide:

[How to Find Vulnerable Webcams Across the Globe Using Shodan](https://null-byte.wonderhowto.com/how-to/hack-like-pro-find-vulnerable-webcams-across-globe-using-shodan-0154830/)

> Shodan even enables us to be very specific in searching for web-enabled devices. In some cases, we can specify the longitude and latitude of the devices we want to find.
> In this case, we will be looking for WebcamXP cameras at the longitude and latitude (-37.81, 144.96) of the city of Melbourne, Australia. When we search, we get a list of every WebcamXP at those coordinates on the globe. We must use the keyword geo followed by the longitude and latitude.
> `webcamxp geo: -37.81,144.96`

Oh! I don’t need to use IP ranges at all. I can just feed [latitudes and longitudes](https://en.wikipedia.org/wiki/Geo-fence) directly into my searches.

Now, we need a geocoded list of every ICE facility. Luckily, [I’ve already done that](https://trackingice.com/wiki/List_of_holding_facilities) based on data released in response to a FOIA from Immigrant Justice. This data is hosted on a [wikipedia-style site](https://trackingice.com) I created for open source information related to ICE.

This [excellent resource on manipulating CSVs with the command line](https://bconnelly.net/posts/working_with_csvs_on_the_command_line/) teaches us:

> Specific columns can also be easily extracted from CSVs. For example, if we wanted to extract columns 2, 4, 5, and 6 from input.csv:
> `cut -d , -f 2,4-6 input.csv`

[How do you use CSV lines as command parameters?](https://unix.stackexchange.com/questions/41598/using-csv-line-as-command-parameters)

## Shodan CLI

The first [example in the Shodan CLI](https://cli.shodan.io/) documentation is `shodan count microsoft iis 6.0` which returns `5310594`

What we want to do is go through our list of ICE facilities and do shodan scans of their longitude/latitude.

Using the shodan CLI, it should be possible to automate this a bit.

Basically we want to parse our CSV of every facility, pull out the latitude and longitude of that facility, feed that to shodan, run our search, and save the results to a file where we can go back and look for any results (anything besides a 0).

We want our results to look something like this:

| lat | lng | results |
| :-- | :-- | :------ |
| 0.0 | 0.0 | 0       |
| 0.0 | 0.0 | 0       |
| 0.0 | 0.0 | 0       |
| 0.0 | 0.0 | **1**   |
| 0.0 | 0.0 | 0       |

[This article](https://null-byte.wonderhowto.com/how-to/hack-like-pro-find-vulnerable-webcams-across-globe-using-shodan-0154830/), helpfully, gives us a list of webcam brands to search for:

- ACTi
- Axis
- Cisco
- Grandstream
- IQinVision
- Mobotix
- Panasonic
- Samsung Electronics
- Samsung Techwin
- Sony
- TRENDnet
- Toshiba
- Vivotek
- WebcamXP

—

Unfortunately I did not find anything. After running through all of these manufacturers and a number of locations, then combing through the results by hand, I did not locate any unsecured webcams of interest to this particular search.

## Additional Resources

[List of webcam default usernames / passwords](https://www.a1securitycameras.com/technical-support/default-username-passwords-ip-addresses-for-surveillance-cameras/)
---
draft: true
dek: In which we illuminate the curious history of hackerdom and its transformative influence on our modern technological world
inprogress: true
date: 2023-01-19T01:37:52-05:00
modified: 2023-12-27T18:52:09-05:00
tags: journalism culture history hackers
---
## Hacker Culture: Unraveling the Threads of a Digital Revolution

#hackers #personal

![A_3D_isometric_visualization_of_a_modern_hacker_s_room__complete_with_a_glowing_glowing_neon_compute.png](https://res.cloudinary.com/ejf/image/upload/v1679587769/1844379862_A_3D_isometric_visualization_of_a_modern_hacker_s_room__complete_with_a_glowing_glowing_neon_compute.png)

Hacker culture roots itself in the counterculture of the 1960s and '70s. It consistently focuses on challenging the status quo, questioning authority, and seeking out new ways of understanding and using technology. By closely examining the past, present, and future of hacker culture, we can better appreciate its influence on modern life and the possibilities it offers for the future.

As a teenager attending HOPE (2600's Hackers on Planet Earth conference) in 2006 in New York City, the atmosphere was electrifying – a hotel floor filled with excited dorks buzzing around tables filled with lockpicking tools, old computers, LEDs, and soldering irons. The air fills with the energy of shared curiosity and passion, as people of all ages and demographics don their Thinkgeek T-shirts and talk shop.

There was one surreal late-night interaction at the conference that felt like a rite of passage into this strange new world. A small group of us stands in a circle, holding hands while someone brandishes a Taser. I had never seen one in person before. As the two people at the ends of the circle touch their fingers to the prongs, we feel the electricity course through our bodies – a visceral reminder that we are all connected in this bizarre and exhilarating adventure.

::table-of-contents

::

### The Birth of Hacker Ideology: Challenging Authority and Finding Collective Solutions

Many of the core threads of modern life and technology trace back to hackers. The rebellious spirit of the 1960s counterculture didn’t just give us tie-dye shirts and The Grateful Dead – it birthed an entire generation of tech-savvy revolutionaries who challenge authority at every turn.

>To a generation that grows up in a world beset by massive armies and by the threat of nuclear holocaust, the cybernetic notion of the globe as a single, interlinked pattern of information is deeply comforting: in the invisible play of information, many think they can see the possibility of global harmony.
>Fred Turner **From Counterculture to Cyberculture** (2008)

At the core of hacker culture sits a disregard for traditional authority and a belief in the power of collective problem solving. Stewart Brand encapsulates this in his 1995 essay "We Owe It All To The Hippies", arguing that the counterculture's disregard for authority provides the philosophical grounds not only for the internet but also the entire PC revolution.

>The computer technologies that we take for granted today owe their shape to this unruly period, which is defined by protest, experimentation with drugs, countercultural community, and a general sense of anarchic idealism.
>John Markoff **What the Dormouse Said** (2005)

This primordial countercultural soup gives rise to a new breed - hackers - who take it upon themselves to challenge traditional authority and reshape society through collective problem-solving. They are like the trickster Coyote stealing fire from the gods, using technology to empower individuals rather than bow down to faceless institutions.

These early archetypes hold even more relevance today, as the tech industry is dominated by cutthroat capitalists, wealthy boy geniuses, and solvers of frivolous problems who couldn’t have strayed farther from the original ideals they capitalize on.

### Stewart Brand & The Whole Earth Catalog

As a prominent figure in the bay area counterculture movement, Stewart Brand plays an influential role in shaping hacker culture. His lasting legacy begins with the creation of "The Whole Earth Catalog" in 1968, which is pivotal in nurturing the early development of hacker ideologies.

"The Whole Earth Catalog" isn't just a publication—it represents an early model for sharing knowledge and resources on a wide variety of topics that encourage a DIY mindset. It makes the whole world seem suddenly malleable, editable. Serving as a precursor to modern open-source sharing platforms, the catalog demonstrates how information can be disseminated beyond traditional institutions and centralized models. Flipping through the pages of books and tools, you could imagine new creations and a new way of of life.

Open-source development is a collaborative approach to creating software, where the source code is made freely available for anyone to view, modify, and distribute. The culture of sharing software freely isn't always easy to understand in a culture of private labs, and billion dollar exits where companies keep their proprietary software closely guarded as a competitive advantage.

### Steve Jobs & The Hippies

In 2005 Steve Jobs credits Brand's work as an inspiration during his famous Stanford commencement speech. What connects Brand and Jobs is their shared belief in challenging authority and pursuing decentralized innovation that can empower individuals.

Steve Jobs is profoundly influenced by both hacker culture and the psychedelic counterculture of the 1960s. This intersection plays a critical role in shaping his unique vision that would later revolutionize personal computing.

Jobs openly acknowledges participating in LSD experimentation during his youth, describing it as "one of the most important things" he has ever done. Aligned with hippie ideals, these experiences triggered powerful awakenings and shape his approach to life and business—prizing creativity over conformity.

Moreover, it's crucial to understand how this journey into psychedelic exploration parallels Jobs' immersion into hacker culture early on—a time when he attends meetings at the Homebrew Computer Club alongside industry pioneers like Steve Wozniak. Within this vibrant community driven by curiosity and collaboration, they are motivated to challenge traditional hierarchies while inventing technology that can empower individual people.

In the process, Apple fuses counter-establishment philosophy with relentless technological innovation, giving birth to products that are rapidly changing every aspect of modern life.

### Snow Crash & The Matrix

In the early '90s, a seismic shift occurs in the hacker landscape with the emergence of cyberpunk culture, brought to life by literary masterpieces like William Gibson's "Neuromancer" and Neal Stephenson's "Snow Crash." These novels don't just glamorize hackers; they carve out an entirely new archetype. No longer are hackers mere basement-dwelling code-jockeys; they become digital samurais.

"Snow Crash," in particular, is a prophetic work that foresees much of what becomes integral to hacker culture. It paints a vivid picture of hypercards, virtual reality, and even livestreaming – concepts that take nearly two decades to become mainstream. Stephenson captures the essence of a rapidly approaching future where information is power, and those who can manipulate it hold the keys to the kingdom.

At the end of that same decade, [Eric S. Raymond](https://en.wikipedia.org/wiki/Eric_S._Raymond) lays out a framework for open-source software development in "[The Cathedral and the Bazaar (1999)](https://en.wikipedia.org/wiki/The_Cathedral_and_the_Bazaar)", which helps popularize an open-source software development model based on collaborative problem solving.

In 2006 I undertake my first journey into the hacker world. I grew up on AIM and in weird hacker chatrooms. By the time I am 14 I am itching to to attend [HOPE](https://en.wikipedia.org/wiki/Hackers_on_Planet_Earth) Number Six. I am just getting into computers and open source software and am looking forward to seeing a talk from Richard Stallman who is famous for creating [GNU](https://en.wikipedia.org/wiki/GNU), and later famous for [being intolerable](https://en.wikipedia.org/wiki/Richard_Stallman#Controversies). The GNU operating system was one of the key examples of free software where anyone could view, modify, and distribute the source code. My parents paid for my first-ever train ticket to Manhattan, where my uncle meets me at Penn Station and helps me check into a hotel room, and then promptly leaves. I spend two formative days taking in the convention and hanging out with my new hacker friends.

It is awe-inspiring and life-changing; one of my IRC mentors [anarchist](https://en.wikipedia.org/wiki/Anarchism) hacker [Jeremy Hammond](https://en.wikipedia.org/wiki/Jeremy_Hammond) is there, and a crew from [HackThisSite](https://en.wikipedia.org/wiki/HackThisSite) has a room. People I have only talked to on online suddenly guide me through the streets of Manhattan, teaching me how to dumpster dive and sneak into the back corridors of the hotel. For a young kid just beginning to explore computing, seeing this larger community – people from all backgrounds and walks of life spending their time on computers, learning and teaching – inspires me indefinitely.

The open-source model foundational to hacker culture is further crystallized by GitHub (founded in 2008), a company that serves as the backbone of most technological advancement in both the open source world as well as private industry.

>At GitHub, people work on an [open allocation](http://www.forbes.com/sites/quora/2012/11/26/what-is-open-allocation/) basis. Unlike traditional companies where projects are assigned top-down, GitHubbers tackle whatever projects they want, without any formal requests or managerial interference.
>[Inside GitHub’s Super-Lean Management Strategy–And How It Drives Innovation](https://web.archive.org/web/20220925185104/https://www.fastcompany.com/3020181/inside-githubs-super-lean-management-strategy-and-how-it-drives-innovation)

Sometime in the mid 2000s hacker culture also begins to mutate into more devilish strains. Some hackers fully embrace the trickster archetype, becoming famous for theft, ransomware, and stealing people's identities.

Others bend to startup culture, worshipping at the altar of hustle and the relentless pursuit of wealth. The industrialization of technology begins in earnest and the idealistic tenets of hacker culture start being discarded.

A backlash against tech ripples through American society as tech giants are recast as privacy-invading doomscroll-harvesting leeches wreaking havoc on America's happiness and democracy. To many Americans the technology and the culture seem intertwined. The phone is clearly filled with apps designed to keep you looking at the phone- but very few question the underlying philosophies that drove the design of those apps.

These nee startups, built on technologies created by hacker culture, create profound perversions of its ideals. The ways that capitalism twists the free-wheeling spirit of the internet are now causing people to question whether it's worth sacrificing their privacy and mental well-being for the convenience of these technologies.

As Wendy Liu argues in her book "Abolish Silicon Valley: How to Liberate Technology from Capitalism" (2020), the choice of being pro-tech industry or anti-tech is a false dichotomy. She rejects traditional corporate models and instead proposes that tech be liberated from capitalism and transformed into an open-source model of development, one that could be accessible to all, not just the privileged.

>But the choice of being pro-tech industry or anti-tech is a false dilemma. The tech industry in its current form — with billion-dollar corporations, venture capitalists, and a few boy geniuses running the show — is not the only way of developing technology.
>Wendy Liu **Abolish Silicon Valley: How to Liberate Technology from Capitalism** (2020)

Throughout its evolution, hacker culture consistently focuses on challenging the status quo, questioning authority, and seeking out new ways of understanding and using technology. Therefore, understanding and honoring the roots of hacker culture can help us move forward and shape a more equitable and humane future.

>Examining power means naming and explaining the forces of oppression that are so baked into our daily lives—and into our datasets, our databases, and our algorithms—that we often don’t even see them.
>Catherine D'Ignazio and Lauren F. Klein **Data Feminism (Strong Ideas)**

These ideas have always been core to being a hacker for me. On the final night of HOPE Number Six I sneak up to the roof of the now-demolished [Hotel Pennsylvania](https://en.wikipedia.org/wiki/Hotel_Pennsylvania#Closure_and_demolition) with a group of hackers. Looking across Manhattan, we make plans and riff on ideas for projects or adventures. The world feels alive.

What strikes me most is how different, accepting, and giving the hackers I meet are. They are a tribe of misfits who find solace in each other's eccentricities and knowledge and unite under a common banner – the pursuit of knowledge and creative exploration.

As I stand on that rooftop overlooking Manhattan, bathed in the glow of neon lights reflecting off glass skyscrapers, I feel a profound sense of belonging beneath my fear of being discovered by security. In this anarchic realm where curiosity is king and imagination reigns supreme, I find my tribe.
---
type: words
hidden: true
inprogress: true
date: "2019-03-24T01:25:33-04:00"
hidetimestamp: false
---

# Generative Music Iteration

One of my first steps when embarking on a new project is to gather research and understand the world in which I’m working.

This is the same as the way that I will stand at a corner of a party and get the vibe for a while before I feel like talking to strangers.

Generative art is intimidating because of all the potential possibilities. When you are working with randomness, how do you prevent things from just turning out like a bunch of noise or a muddy brown color?

We need to…

- research the systems used in the space we want to work in
- evaluate how other people have used those systems in the past
- deconstruct the systems that have created works most like the ones we want to create and what made those systems different

When I’m in a new place that I’m uncertain of, I don’t know the customs, I hang out a bit and wait for someone else to go ahead. Maybe I’m not sure the etiquette for paying somewhere, it’s easy enough to wait 20 seconds and observe someone who knows the deal and then just follow their lead.

But first I need to find a rough direction to set out towards.

::table-of-contents
::

## What do I want to create?

## Mise-en-place

### Hello World

To begin, let’s make ourselves a sandbox to play in and get everything in place so we can think about making our project instead of how we are going to host it or share it with our friends.

<div class="glitch-embed-wrap" style="height: 286px; width: 100%;">
  <iframe
    allow="geolocation; microphone; camera; midi; encrypted-media"
    src="https://glitch.com/embed/#!/embed/genmusic-01?previewSize=100&previewFirst=true&sidebarCollapsed=true"
    alt="genmusic-01 on Glitch"
    style="height: 100%; width: 100%; border: 0;">
  </iframe>
</div>

## What are the building blocks of the system we are working in?
---
draft: true
dek: In which we create a few rules so we can fully unlock our creativity
inprogress: true
date: 2023-01-19T01:23:52-05:00
modified: 2023-07-04T21:58:23-04:00
tags: personal design 
---

# My design philosophy

Deeply intertwined at the heart of my design philosophy are both Design Thinking and Minimalism, setting the foundation for an approach that champions user needs and simplicity above all else. 

By sharply focusing on core essentials and vigorously eradicating unnecessary distractions, I'm dedicated to constructing designs that emanate clarity and facilitate easy interaction. Often this hyper focus is most beneficial in times when speed is prized, resources are short, and new un-tested technologies are being explored. 

My adherence to Design Thinking guarantees that user needs guide my designs, whereas my minimalist inclinations work to keep the experience straightforward and uncluttered. I see constraints not as barriers, but as springboards for creative solutions, and I thrive with short feedback loops and tight deadlines. 

See also [[how-to-run-a-project]] and [[joy-driven-development]]

## Simplicity & Minimalism

At the core of my design philosophy lies simplicity and minimalism. By focusing on essential elements and stripping away everything else, I strive to create designs that are clean, intuitive, and easy to navigate. This approach ensures that users can quickly grasp the purpose of a design and interact with it seamlessly, and increases the speed of development. 

## Universal Application Across Diverse Mediums

The principles of simplicity, minimalism, and functionality are universal and can be applied across various mediums—from print to digital design. By adhering to these core tenets, I can create cohesive designs that are visually appealing, user-friendly, and effective in conveying their intended message.

## Phases of the Design Process

My design process typically unfolds in several phases:

1. Research & Discovery: Understanding the project requirements, target audience, and prior work.
2. Ideation & Sketching: Brainstorming ideas and sketching out concepts on paper.
3. Digital Mockups: Translating sketches into digital mockups using Figma, Illustrator, After Effects, or by writing code.
4. Refinement & Iteration: Refining designs based on feedback and testing.
5. Finalization & Handoff: Preparing final assets for development and writing tickets with engineers during implementation.

## Paper & Sketching

Before diving into digital tools, I often begin my design process with paper and sketching. This tactile approach allows me to explore ideas more freely, experiment with different layouts, and quickly iterate on concepts without being constrained by technology.

## Using Grids

Grids are an essential tool. They provide structure and consistency across different elements within a design while ensuring proper alignment and spacing. They also allow you to move quickly with confidence. By adhering to a grid system, I can create visually balanced compositions that are both aesthetically pleasing and functional.

## "Designer Hat" Vs "Engineer Hat"

As a designer, it's important to be able to switch between the "designer hat" and the "engineer hat." This means being able to think both creatively and analytically, considering not only the visual aspects of a design but also its functionality and feasibility from an engineering perspective.

## The Power of Constraints

A central tenet in my design philosophy is the Power of Constraints. When we face limitations in our design process, instead of viewing them as stifling roadblocks, I consider them a unique source of inspiration. Constraints challenge us to work within our means and bring out the best from what we have at hand.

### Save Colors for Information

Colors can be powerful tools for conveying information in a design. However, using too many colors can lead to visual clutter and confusion. I believe in using colors sparingly and purposefully—reserving them for key elements or to highlight important information.

### Red, White, and Black

[Red, white, and black](https://gwern.net/red) are classic colors that form the foundation of my design palette. These timeless hues work harmoniously together while providing ample contrast for readability. By starting with this versatile trio, I can build upon it with additional colors when necessary.

## Iterative process

The iterative process is essential for a few reasons:

1. **User-Centric Design:** It enables a design to be refined continuously based on actual user feedback, keeping the design centered around the user's needs.

2. **Risk Reduction:** Regular testing can catch and fix problems early, thus minimizing the risk of costlier changes later in development.

3. **Continual Improvement:** The cycle allows for continuous refinement, meaning the design can evolve and adapt as more is learned about users and their needs.

Alternatives to iterative design could include the Waterfall Model or Big Design Up Front (BDUF). 

The *Waterfall Model* is a linear approach where one phase must be completed before moving on to the next. It can be appropriate when requirements are well-understood in advance, changes are unlikely, and the project is relatively simple.

*Big Design Up Front* involves spending considerable time on designing the entire system in detail before implementation begins. It's appropriate when there is a clear and unchanging understanding of requirements, though this is rare in practice.

However, both alternatives have their limitations. They often fail to account for changing user needs or unexpected issues arising during development. Hence, they may not yield designs as user-friendly or effective as an iterative approach would.

## Pros/Cons Of Designing in Code

Designing in code offers several advantages, such as rapid prototyping and easy collaboration with developers. However, it can also be limiting in terms of creative freedom and may require more time to make adjustments compared to using design software. I believe in striking a balance between designing in code and utilizing design tools, depending on the specific needs of a project.
---
dek: "In which the author proudly presents his new venture: Room 302 Studio, an eclectic gathering of talent devoted to fostering joy-driven development"
date: 2023-04-10T01:00:00-04:00
modified: 2023-04-09T23:48:17-04:00
tags: personal dataviz 
---

# Introducing room302.studio

It's been a long journey since I first started in data visualization contracting over ten years ago, and **I'm incredibly proud to introduce my new data and prototyping studio: [Room 302 Studio](https://room302.studio).** 

As my client work grew larger and more intricate, I realized the tremendous potential of forming a studio where talented people could connect, collaborate and strive together towards empowering the world through projects and tools that center joy and kindness. This dynamic new studio sets up an exciting opportunity for each of us to take on more ambitious projects that reflect our strong values.

We just published one of our first projects and I've done a tremendous amount of work to be able to say: we are open for business!

## Hire us

We are booking client work today. Reach out to studio@room302.studio with an idea, dataset, or prototype you want to talk about. 

At Room 302 Studio, we offer a range of services that cater to different needs and project types:

1. **Data Visualization and Exploration**: Transform complex data into visually engaging and easy-to-understand websites, D3 visualizations, or Observable Notebooks that effectively communicate your insights internally or to the public. 
2. **Prototyping**: Turn your big ideas into tangible reality with high-quality prototypes that can be used for testing, refining concepts, and fundraising. 
3. **AI Consulting**: Integrate generative text and image models into your work with the help of a team experienced in prompt engineering, embedding visualization, and the art and magic of speaking to robots. 
4. **Workshops & Events**: Participate in interactive learning sessions where you can acquire new skills, insights, and knowledge in various disciplines.
5. **Cutting edge tech**: We pride ourselves on adapting quickly, and enjoy pushing the limits of new tools and technologies. Use our team to QA your product, develop a library of demos, or create instructional content on things no one has ever seen before. 

## Workshops and Events

Room 302 Studio will be regularly hosting events in the coming year that promote learning, collaboration, and growth:

1. *Livestreams*: Collaborate on projects in public, stream live tutorials, give presentations or host Q&A sessions through livestreaming platforms like Twitch or YouTube. This will build on the incredible experience Ian and I had with [Coding with Fire](https://www.youtube.com/playlist?list=PLI_sHchSmdCD0RximFqzqCOSqCgVWJpdA)
2. *Hackathons*: We are hoping to host fast-paced development sprints aimed at solving specific challenges within a limited timeframe.
3. *Knowledge Sharing*: Engage with leaders from various industries as they share their insights on emerging trends and technologies.

## Membership Options

In addition to our consulting services, we have set up an accessible Discord community that allows members to tap into the studio, engage in thought-provoking discussions, and start collaborating on projects that make a genuine difference. I am really trying to focus on creating a space and sparking collaborations that center joy: [[joy-driven-development]]

We offer two types of membership options depending on your needs:

1. **Community Membership (Free)**: Access our Discord community where you can engage with other members, participate in discussions on topics that interest you, attend virtual events, propose projects or collaborate on existing projects.
2. **Studio Membership (Monthly Fee, Invite-Only)**: This is for members who will be working on paid client work, and includes a studio email, project billing, and a number of internal tools, resources, datasets, and templates.

I am beyond excited to see where this journey takes us, and I invite you to join us at Room 302 Studio as we collaborate, learn, and grow together. To learn more, visit our website at <https://room302.studio/>
---
dek: In which the citizens of Hong Kong find new creative ways to improve on public disobedience
type: words
hidden: false
inprogress: false
date: "2019-08-14T21:19:39-04:00"
hidetimestamp: false
---

# Hong Kong Protest Techniques

- Traffic cones - to help contain tear gas cannisters
- Suitcases (as defenses)
- Water bottles
- Laser pointers
- Breaking bricks
- Using slingshots
- Transporting divider fencing
- Extinguishing tear gas with traffic cones and metal bowls
- Makeshift armor: saran wrap, garbage can lids, luggage = shields
- Organization - human supply chain lines
- Hand signals for when supplies are needed
- Parting crowds for ambulances
- Anonymous, leaderless
- Airdrop and signal/telegram chats for organization
- “Be like water” move quickly instead of occupying a single location
- Using trains and public transit to move quickly
- Hiding identity through laser pointers and spray paint aimed at security cameras
- Single-use transit tickets for untracked public transit
