---
draft: true
dek: "In which we learn to tell computers what is in our imagination"
inprogress: true
date: "2022-11-02T23:57:07.000Z"
modified: "2023-09-09T18:59:38.000Z"
tags: "machinelearning howto"
hidden: true
---
# How I Use Generative Image AI

![[374074605_A_complex_and_intricate_network_of_data_representing_the_power_of_Stable_Diffusion__illustrated_in_a.png]]

See also [[how-i-use-gpt3]]

Generating computer-generated imagery is one of the most innovative ways to produce beautiful visuals that can convey complex concepts. When it comes to creating AI-generated imagery, I turn to Stable Diffusion because of its incredible range of applications and capabilities.

## Goals with AI-generated imagery

The goals when creating AI imagery vary depending on the particular project. Generally speaking, the goal is to create visuals that are both aesthetically pleasing and accurately represent the concept or idea being conveyed. To do this, it is important to understand how AI works so that these goals can be properly communicated to the robot.

## How to explain things to a robot

When it comes to teaching a computer something to generate a desired visual, it is important to understand the AI's capabilities. This means breaking down the concept into components that a computer can understand, as well as giving it a set of rules to follow.

For example, if I'm trying to create a visual of a food dish, I need to explain the components of a dish to the computer. This means breaking it down into its individual elements such as ingredients, presentation elements, and cooking techniques. Additionally, I may provide a few rules to the computer so that the visuals created have an overall cohesive aesthetic.

## Phases

When I am using Stable Diffusion to create AI-generated imagery, I break down the process into three phases.

### Prompt-sketching

First, I start by sketching out a few ideas with the library of prompts. This helps me to focus on what the final visual should look like and to get a feel for the vector of the visuals I am creating.

### Parameter tuning

In this phase, I start to customize the visuals by tuning parameters such as color, size, and opacity. This allows me to create visuals that are unique and capture the essence of what I am trying to convey.

### Zeroing in

In this final phase, I start to make the fine-tuning adjustments that will help the visuals to come together in a cohesive way. This may include adding shading or adding subtle textures or shapes.

## How I think about prompts
### Lexica.art Prompt library

One great resource to use when starting with prompts is the Lexica.art Prompt Library. This library provides a huge selection of prompts in various categories that can be used to create visuals.

### Change one thing at a time

When customizing the prompts, I like to change one thing at a time. This makes it easier to track the changes and leads to better results. For example, if I'm adjusting a color, I might start with the hue and then adjust the saturation and brightness separately. This allows me to have finer control over the visuals.

Sometimes it is tempting to change a bunch of words, or add and remove a lot at once, but sometimes you can achieve the same result with more subtle inputs.
